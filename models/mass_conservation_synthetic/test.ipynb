{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344aa74c-6e90-4e39-bd28-ca1d77e61b54",
   "metadata": {},
   "source": [
    "# Testing new repo structure\n",
    "Last modified March 18\n",
    "\n",
    "The goal of this notebook is to serve as a preliminary example doing a PINNs inversion with the current setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0ed3cb-9176-4cfb-a1b1-fa47f71be4ef",
   "metadata": {},
   "source": [
    "First, we import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a04231d6-a80c-429f-8268-6fe0e5bb7a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax.tree_util import tree_map\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "\n",
    "# Go up 3 levels to the repo's root directory\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "# Add the repo root to sys.path\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "from data_processing.helpers import normalize, sample, init_single_net, neural_net\n",
    "from data_processing.load_data_functions import load_elmer_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813120f-7a4d-413f-8491-4ec5677295e9",
   "metadata": {},
   "source": [
    "Next, we load in our data. This is a custom function, stored in the data_processing folder. The results are standardized though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc33ed18-99c5-40d2-bf55-e5379c3645e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = '../../elmer_results/results/pvm.csv'\n",
    "df_filtered, df_surface, df_divide, df_bed, df_flanks = load_elmer_results(csv,0,4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1da9bb4-c9d3-479e-b92b-3e3aae4650f9",
   "metadata": {},
   "source": [
    "Everything is loaded! Next, we initialize the PINN for our problem. \n",
    "\n",
    "Testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe5d551-0226-4ef2-92ed-e4feacb7f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pinns(parent_key, n_hl, n_unit): \n",
    "    # This should be general! Try to get solution/loss functions to adapt to this\n",
    "    '''\n",
    "    :param n_hl: number of hidden layers [int]\n",
    "    :param n_unit: number of units in each layer [int]\n",
    "    '''\n",
    "\n",
    "    # set the neural network shape for u, w\n",
    "    layers1 = [2] + n_hl * [n_unit] + [2] \n",
    "\n",
    "    # set the neural network shape for p, mu\n",
    "    layers2 = [2] + n_hl * [n_unit] + [2] \n",
    "\n",
    "    # generate the random key for each network\n",
    "    keys = random.split(parent_key, 3)\n",
    "    \n",
    "    # generate weights and biases for density\n",
    "    params_uw = init_single_net(keys[0], layers1)\n",
    "    params_pmu = init_single_net(keys[1], layers2)\n",
    "\n",
    "    params_rho = random.truncated_normal(keys[2], -2, 2, shape=(2,)) # 2 params rho_s and L\n",
    "\n",
    "    return [params_uw, params_rho, params_pmu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff024e3-0032-46a7-8c2d-3c7623099f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate PINN\n",
    "# select a random seed\n",
    "seed = 1234 #2134\n",
    "key = random.PRNGKey(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create the subkeys\n",
    "keys = random.split(key, 4) # NEED TO UPDATE 4 to relevant number\n",
    "n_hl = 6\n",
    "n_unit = 30\n",
    "# initialize the weights and biases of the network\n",
    "trained_params = init_pinns(keys[0], n_hl, n_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f903a0-8a0e-44fe-acf7-afbd03c8750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "df_norm,df_bcs,info = normalize(df_filtered, df_surface, df_divide, df_bed, df_flanks)\n",
    "# df_bcs contains the data for surface, divide,bed and flanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2900d5-55eb-4ede-988f-b1a22ffbfbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_solution(df_surf,scl=1, act_s=0):\n",
    "    # this should also be a general function!\n",
    "    # df_surf is nondimensional\n",
    "    x_s = df_surf['x'].values\n",
    "    z_s = df_surf['z'].values\n",
    "    \n",
    "    def f(params,x):\n",
    "        x0, z0 = jnp.split(x, 2, axis=1)\n",
    "        uw = neural_net(params[0], x, scl, act_s)\n",
    "        pm_rho = params[1]\n",
    "        H = jnp.interp(x0,x_s,z_s)  \n",
    "        rho = 1 + (jnp.exp(pm_rho[0]) - 1) * jnp.exp((-H+z0)/jnp.exp(pm_rho[1]))\n",
    "        pmu = neural_net(params[2], x, scl, act_s)\n",
    "        sol = jnp.hstack([uw,rho,pmu])\n",
    "        return sol\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e826879-5b00-4943-b579-9484a68b3c94",
   "metadata": {},
   "source": [
    "The loss function is where i will whittle down data into relevant bits. This way I can use multiple equations. Equations also have to fit the generalized data structure. Initializing the solution function has to be a general thing as well then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63bc5ec0-66ae-4dac-8b1b-1fed2a0b661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_u = create_solution(df_bcs[0]) # need to modify as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db276afc-0297-4d23-a262-b7eb12c9d727",
   "metadata": {},
   "source": [
    "Now we make our samples for Adam and L-BFGS. For this simple mass conservation, we need the boundaries at the bed, divide, and surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28a4398-58ef-48ab-a957-ce5d8339dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for adam\n",
    "n_samples = jnp.array([400,200]) # small number for now\n",
    "dataf = sample(df_norm,n_samples,df_bcs) # nsamples is for data loss + colocation points\n",
    "keys_adam = random.split(keys[1], 5)\n",
    "data = dataf(keys_adam[0])\n",
    "\n",
    "# for L-BFGS\n",
    "n_pt2 = n_samples * 2\n",
    "dataf_l = sample(df_norm, n_pt2,df_bcs)\n",
    "key_lbfgs = random.split(keys[2], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a81b6-d003-499a-9421-60884a3389f4",
   "metadata": {},
   "source": [
    "Assuming that we have defined our equations properly, now we need to define our loss function (i.e. the function to create the loss function). This is the custom function that lies within the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d11b69a0-3dec-463d-bda9-d34f5554c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from equations.simple_mass_conservation import gov_eqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0b7f755-6d4c-4b88-a5bc-a5f8807f3711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_error(diff):\n",
    "    return jnp.mean(jnp.square(diff), axis=0)\n",
    "\n",
    "def create_loss_masscon(predf,gov_eqn,scales,lw):\n",
    "    # for now do 3 lw weights: data, eqn, bc\n",
    "    def loss_fun(params, data):\n",
    "        # create the function for gradient calculation involves input Z only\n",
    "        net = lambda z: predf(params, z)\n",
    "        \n",
    "        # load the ground truth for dataloss\n",
    "        x_smp = data['smp'][0]\n",
    "        w_smp = data['smp'][1][:,1:2] # ground truth w\n",
    "        x_div = data['div'][0]\n",
    "        u_div = data['div'][1][:,0:1] # horizontal velocity at divide (should be 0)\n",
    "        x_bed = data['bed'][0]\n",
    "        w_bed = data['bed'][1][:,1:2] # ground truth w at bed (should be 0)\n",
    "        rho_bed = data['bed'][1][:,2:3] # ground truth rho at bed (should be rho_i)\n",
    "        x_surf = data['surf'][0]\n",
    "        u_surf = data['surf'][1][:,0:1] # ground truth surface horizontal velocity \n",
    "\n",
    "        # load the position and weight of collocation points\n",
    "        x_col = data['col'][0]\n",
    "\n",
    "        # calculate the predicted variables\n",
    "        w_pred = net(x_smp)[:, 1:2] # not 0:2 because we only have data in w\n",
    "\n",
    "        # boundary constraints\n",
    "        u_div_pred = net(x_div)[:,0:1]\n",
    "        bed_pred = net(x_bed)\n",
    "        w_bed_pred = bed_pred[:,1:2]\n",
    "        rho_bed_pred = bed_pred[:,2:3]\n",
    "        u_surf_pred = net(x_surf)[:,0:1]\n",
    "        \n",
    "        # calculate the residue of equation\n",
    "        f_pred = gov_eqn(net, x_col, scales)\n",
    "\n",
    "        # calculate the mean squared root error of data\n",
    "        data_err = ms_error(w_pred - w_smp)\n",
    "\n",
    "        # calculate the mean squared root error of equation\n",
    "        eqn_err = ms_error(f_pred)\n",
    "\n",
    "        # calculate errors of boundary conditions\n",
    "        div_err = ms_error(u_div_pred-u_div)\n",
    "        rho_bed_err = ms_error(rho_bed-rho_bed_pred)\n",
    "        w_bed_err = ms_error(w_bed-w_bed_pred)\n",
    "        surf_err = ms_error(u_surf-u_surf_pred)\n",
    "\n",
    "        # all errors should be 1d arrays\n",
    "        # calculate the overall data loss and equation loss\n",
    "        loss_data = jnp.sum(data_err)\n",
    "        loss_eqn = jnp.sum(eqn_err)\n",
    "        loss_bd = jnp.sum(div_err) + jnp.sum(rho_bed_err) + jnp.sum(w_bed_err) + jnp.sum(surf_err)\n",
    "\n",
    "        loss_ref = loss_fun.lref\n",
    "        # calculate total loss\n",
    "\n",
    "        # lw should have 3 weights\n",
    "        loss = (lw[0]*loss_data + lw[1]*loss_eqn + lw[2]*loss_bd ) / loss_ref\n",
    "        \n",
    "        # group the loss of all conditions and equations\n",
    "        loss_info = jnp.hstack([jnp.array([loss, loss_data, loss_eqn, loss_bd]),\n",
    "                                data_err, eqn_err, div_err, rho_bed_err, w_bed_err,surf_err])\n",
    "        return loss, loss_info\n",
    "\n",
    "    loss_fun.lref = 1.0\n",
    "    return loss_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05029592-22ce-4057-870c-395d83723652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the loss function\n",
    "NN_loss = create_loss_masscon(pred_u, gov_eqn, info, [1,1,1])\n",
    "# calculate the initial loss and set it as the reference value for loss\n",
    "NN_loss.lref = NN_loss(trained_params, data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93161f6f-1552-4ef2-a28c-34e68840f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.optimization import adam_optimizer, lbfgs_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8578f02c-5165-4230-89d9-f1bb3bffdbd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step: 100 | Loss: 8.4415e-02 | Loss_d: 2.0794e-01 | Loss_e: 7.0678e-02 | Loss_b: 4.7791e+00\n",
      "Step: 200 | Loss: 2.4810e-02 | Loss_d: 1.5597e-01 | Loss_e: 6.4962e-02 | Loss_b: 1.2655e+00\n",
      "Step: 300 | Loss: 1.1304e-02 | Loss_d: 1.3005e-01 | Loss_e: 6.9292e-02 | Loss_b: 4.7791e-01\n",
      "Step: 400 | Loss: 5.4955e-03 | Loss_d: 7.2261e-02 | Loss_e: 4.0905e-02 | Loss_b: 2.1609e-01\n",
      "Step: 500 | Loss: 2.8428e-03 | Loss_d: 3.6588e-02 | Loss_e: 1.9604e-02 | Loss_b: 1.1413e-01\n",
      "Step: 600 | Loss: 1.8271e-03 | Loss_d: 2.2314e-02 | Loss_e: 1.9262e-02 | Loss_b: 6.7893e-02\n",
      "Step: 700 | Loss: 1.1398e-03 | Loss_d: 1.3088e-02 | Loss_e: 1.0663e-02 | Loss_b: 4.4541e-02\n",
      "Step: 800 | Loss: 7.3233e-04 | Loss_d: 7.5802e-03 | Loss_e: 1.0102e-02 | Loss_b: 2.6195e-02\n",
      "Step: 900 | Loss: 5.0337e-04 | Loss_d: 6.4076e-03 | Loss_e: 6.1370e-03 | Loss_b: 1.7614e-02\n",
      "Step: 1000 | Loss: 3.7416e-04 | Loss_d: 5.6787e-03 | Loss_e: 3.8494e-03 | Loss_b: 1.2889e-02\n",
      "Step: 1100 | Loss: 2.9319e-04 | Loss_d: 4.7396e-03 | Loss_e: 3.2989e-03 | Loss_b: 9.5276e-03\n",
      "Step: 1200 | Loss: 2.1322e-04 | Loss_d: 3.4909e-03 | Loss_e: 2.2670e-03 | Loss_b: 7.0173e-03\n",
      "Step: 1300 | Loss: 1.9559e-04 | Loss_d: 3.3207e-03 | Loss_e: 2.8290e-03 | Loss_b: 5.5687e-03\n",
      "Step: 1400 | Loss: 1.6094e-04 | Loss_d: 3.1149e-03 | Loss_e: 1.8609e-03 | Loss_b: 4.6672e-03\n",
      "Step: 1500 | Loss: 1.3685e-04 | Loss_d: 2.7137e-03 | Loss_e: 1.5580e-03 | Loss_b: 3.9275e-03\n",
      "Step: 1600 | Loss: 1.6098e-04 | Loss_d: 2.5410e-03 | Loss_e: 2.2264e-03 | Loss_b: 4.8773e-03\n",
      "Step: 1700 | Loss: 1.1240e-04 | Loss_d: 2.7401e-03 | Loss_e: 9.7017e-04 | Loss_b: 3.0241e-03\n",
      "Step: 1800 | Loss: 1.0978e-04 | Loss_d: 2.5157e-03 | Loss_e: 1.1627e-03 | Loss_b: 2.8987e-03\n",
      "Step: 1900 | Loss: 9.8503e-05 | Loss_d: 2.1769e-03 | Loss_e: 1.1625e-03 | Loss_b: 2.5624e-03\n",
      "Step: 2000 | Loss: 9.6291e-05 | Loss_d: 2.2048e-03 | Loss_e: 1.1064e-03 | Loss_b: 2.4580e-03\n",
      "Step: 2100 | Loss: 9.9132e-05 | Loss_d: 2.4958e-03 | Loss_e: 1.0709e-03 | Loss_b: 2.3728e-03\n",
      "Step: 2200 | Loss: 9.1778e-05 | Loss_d: 2.2814e-03 | Loss_e: 1.0252e-03 | Loss_b: 2.1922e-03\n",
      "Step: 2300 | Loss: 8.0838e-05 | Loss_d: 2.0499e-03 | Loss_e: 6.6691e-04 | Loss_b: 2.1265e-03\n",
      "Step: 2400 | Loss: 7.8842e-05 | Loss_d: 1.9577e-03 | Loss_e: 7.1859e-04 | Loss_b: 2.0475e-03\n",
      "Step: 2500 | Loss: 9.2863e-05 | Loss_d: 2.0794e-03 | Loss_e: 1.1671e-03 | Loss_b: 2.3173e-03\n",
      "Step: 2600 | Loss: 7.6786e-05 | Loss_d: 1.9721e-03 | Loss_e: 7.4872e-04 | Loss_b: 1.8797e-03\n",
      "Step: 2700 | Loss: 8.0419e-05 | Loss_d: 2.0278e-03 | Loss_e: 8.4993e-04 | Loss_b: 1.9405e-03\n",
      "Step: 2800 | Loss: 9.6392e-05 | Loss_d: 1.9955e-03 | Loss_e: 8.2379e-04 | Loss_b: 2.9559e-03\n",
      "Step: 2900 | Loss: 7.5504e-05 | Loss_d: 1.7364e-03 | Loss_e: 1.0221e-03 | Loss_b: 1.7653e-03\n",
      "Step: 3000 | Loss: 6.6594e-05 | Loss_d: 1.5567e-03 | Loss_e: 7.6500e-04 | Loss_b: 1.6682e-03\n",
      "Step: 3100 | Loss: 6.3616e-05 | Loss_d: 1.5234e-03 | Loss_e: 6.4515e-04 | Loss_b: 1.6429e-03\n",
      "Step: 3200 | Loss: 9.2811e-05 | Loss_d: 1.7434e-03 | Loss_e: 5.0946e-04 | Loss_b: 3.3079e-03\n",
      "Step: 3300 | Loss: 9.9272e-05 | Loss_d: 1.6614e-03 | Loss_e: 6.8272e-04 | Loss_b: 3.6037e-03\n",
      "Step: 3400 | Loss: 6.6230e-05 | Loss_d: 1.8038e-03 | Loss_e: 6.4286e-04 | Loss_b: 1.5214e-03\n",
      "Step: 3500 | Loss: 5.9698e-05 | Loss_d: 1.4068e-03 | Loss_e: 6.5334e-04 | Loss_b: 1.5167e-03\n",
      "Step: 3600 | Loss: 6.1794e-05 | Loss_d: 1.3964e-03 | Loss_e: 7.2269e-04 | Loss_b: 1.5832e-03\n",
      "Step: 3700 | Loss: 6.3880e-05 | Loss_d: 1.7388e-03 | Loss_e: 5.4164e-04 | Loss_b: 1.5469e-03\n",
      "Step: 3800 | Loss: 5.3843e-05 | Loss_d: 1.4245e-03 | Loss_e: 5.3377e-04 | Loss_b: 1.2677e-03\n",
      "Step: 3900 | Loss: 5.6039e-05 | Loss_d: 1.5529e-03 | Loss_e: 5.5106e-04 | Loss_b: 1.2535e-03\n",
      "Step: 4000 | Loss: 1.5213e-04 | Loss_d: 1.2518e-03 | Loss_e: 5.7433e-04 | Loss_b: 7.2888e-03\n",
      "Step: 4100 | Loss: 5.6407e-05 | Loss_d: 1.4867e-03 | Loss_e: 6.7015e-04 | Loss_b: 1.2227e-03\n",
      "Step: 4200 | Loss: 5.0892e-05 | Loss_d: 1.2845e-03 | Loss_e: 6.1617e-04 | Loss_b: 1.1485e-03\n",
      "Step: 4300 | Loss: 5.9745e-05 | Loss_d: 1.2655e-03 | Loss_e: 6.4021e-04 | Loss_b: 1.6739e-03\n",
      "Step: 4400 | Loss: 4.7348e-05 | Loss_d: 1.2066e-03 | Loss_e: 5.3526e-04 | Loss_b: 1.0950e-03\n",
      "Step: 4500 | Loss: 4.7159e-05 | Loss_d: 1.0314e-03 | Loss_e: 5.7533e-04 | Loss_b: 1.2188e-03\n",
      "Step: 4600 | Loss: 4.6035e-05 | Loss_d: 1.0377e-03 | Loss_e: 6.2895e-04 | Loss_b: 1.0915e-03\n",
      "Step: 4700 | Loss: 4.2050e-05 | Loss_d: 1.2564e-03 | Loss_e: 3.3262e-04 | Loss_b: 9.3035e-04\n",
      "Step: 4800 | Loss: 4.2008e-05 | Loss_d: 1.0197e-03 | Loss_e: 4.8541e-04 | Loss_b: 1.0117e-03\n",
      "Step: 4900 | Loss: 5.5095e-05 | Loss_d: 1.0401e-03 | Loss_e: 3.1604e-04 | Loss_b: 1.9449e-03\n",
      "Step: 5000 | Loss: 3.9703e-05 | Loss_d: 1.1213e-03 | Loss_e: 3.9575e-04 | Loss_b: 8.6168e-04\n",
      "Step: 5100 | Loss: 3.7781e-05 | Loss_d: 1.0056e-03 | Loss_e: 4.2191e-04 | Loss_b: 8.3606e-04\n",
      "Step: 5200 | Loss: 3.8587e-05 | Loss_d: 1.0081e-03 | Loss_e: 4.1854e-04 | Loss_b: 8.8526e-04\n",
      "Step: 5300 | Loss: 4.6763e-05 | Loss_d: 9.3480e-04 | Loss_e: 6.2669e-04 | Loss_b: 1.2403e-03\n",
      "Step: 5400 | Loss: 6.8732e-05 | Loss_d: 9.5472e-04 | Loss_e: 4.9619e-04 | Loss_b: 2.6671e-03\n",
      "Step: 5500 | Loss: 3.5270e-05 | Loss_d: 9.7205e-04 | Loss_e: 3.8956e-04 | Loss_b: 7.5159e-04\n",
      "Step: 5600 | Loss: 3.7593e-05 | Loss_d: 8.6507e-04 | Loss_e: 3.6582e-04 | Loss_b: 1.0215e-03\n",
      "Step: 5700 | Loss: 3.4083e-05 | Loss_d: 8.6465e-04 | Loss_e: 3.5613e-04 | Loss_b: 8.2130e-04\n",
      "Step: 5800 | Loss: 3.3741e-05 | Loss_d: 9.4377e-04 | Loss_e: 3.2147e-04 | Loss_b: 7.5635e-04\n",
      "Step: 5900 | Loss: 3.1262e-05 | Loss_d: 8.0768e-04 | Loss_e: 4.1180e-04 | Loss_b: 6.5356e-04\n",
      "Step: 6000 | Loss: 3.3484e-05 | Loss_d: 9.5746e-04 | Loss_e: 3.6958e-04 | Loss_b: 6.7915e-04\n",
      "Step: 6100 | Loss: 4.8954e-05 | Loss_d: 9.5200e-04 | Loss_e: 3.2403e-04 | Loss_b: 1.6570e-03\n",
      "Step: 6200 | Loss: 3.0856e-05 | Loss_d: 8.4372e-04 | Loss_e: 3.4376e-04 | Loss_b: 6.6125e-04\n",
      "Step: 6300 | Loss: 2.8832e-05 | Loss_d: 9.2016e-04 | Loss_e: 2.7753e-04 | Loss_b: 5.2978e-04\n",
      "Step: 6400 | Loss: 3.1159e-05 | Loss_d: 1.0148e-03 | Loss_e: 2.3649e-04 | Loss_b: 6.1555e-04\n",
      "Step: 6500 | Loss: 3.6170e-05 | Loss_d: 6.6882e-04 | Loss_e: 2.5370e-04 | Loss_b: 1.2446e-03\n",
      "Step: 6600 | Loss: 6.1799e-05 | Loss_d: 8.9701e-04 | Loss_e: 3.1003e-04 | Loss_b: 2.4956e-03\n",
      "Step: 6700 | Loss: 3.1287e-05 | Loss_d: 7.2434e-04 | Loss_e: 2.7460e-04 | Loss_b: 8.7564e-04\n",
      "Step: 6800 | Loss: 2.3767e-05 | Loss_d: 6.9147e-04 | Loss_e: 2.7032e-04 | Loss_b: 4.6218e-04\n",
      "Step: 6900 | Loss: 2.2742e-05 | Loss_d: 5.9246e-04 | Loss_e: 2.9158e-04 | Loss_b: 4.7851e-04\n",
      "Step: 7000 | Loss: 2.3556e-05 | Loss_d: 7.0960e-04 | Loss_e: 2.7230e-04 | Loss_b: 4.2944e-04\n",
      "Step: 7100 | Loss: 2.0022e-05 | Loss_d: 5.5852e-04 | Loss_e: 2.1092e-04 | Loss_b: 4.3014e-04\n",
      "Step: 7200 | Loss: 2.4717e-05 | Loss_d: 6.0868e-04 | Loss_e: 1.8422e-04 | Loss_b: 6.8800e-04\n",
      "Step: 7300 | Loss: 2.0544e-05 | Loss_d: 6.2342e-04 | Loss_e: 1.9534e-04 | Loss_b: 4.1214e-04\n",
      "Step: 7400 | Loss: 6.8027e-05 | Loss_d: 6.9184e-04 | Loss_e: 1.8067e-04 | Loss_b: 3.2033e-03\n",
      "Step: 7500 | Loss: 1.8569e-05 | Loss_d: 5.9345e-04 | Loss_e: 1.7721e-04 | Loss_b: 3.4188e-04\n",
      "Step: 7600 | Loss: 2.4579e-05 | Loss_d: 7.5583e-04 | Loss_e: 1.6841e-04 | Loss_b: 5.4841e-04\n",
      "Step: 7700 | Loss: 3.4151e-05 | Loss_d: 6.1800e-04 | Loss_e: 1.4649e-04 | Loss_b: 1.2817e-03\n",
      "Step: 7800 | Loss: 2.6131e-05 | Loss_d: 5.9221e-04 | Loss_e: 1.9831e-04 | Loss_b: 7.7509e-04\n",
      "Step: 7900 | Loss: 2.2853e-05 | Loss_d: 5.6092e-04 | Loss_e: 2.2148e-04 | Loss_b: 5.8683e-04\n",
      "Step: 8000 | Loss: 1.8505e-05 | Loss_d: 6.4289e-04 | Loss_e: 1.6951e-04 | Loss_b: 2.9631e-04\n",
      "Step: 8100 | Loss: 1.6544e-05 | Loss_d: 5.4298e-04 | Loss_e: 1.7919e-04 | Loss_b: 2.6905e-04\n",
      "Step: 8200 | Loss: 1.6219e-05 | Loss_d: 5.7565e-04 | Loss_e: 1.5756e-04 | Loss_b: 2.3856e-04\n",
      "Step: 8300 | Loss: 1.4873e-05 | Loss_d: 4.7559e-04 | Loss_e: 1.5808e-04 | Loss_b: 2.5746e-04\n",
      "Step: 8400 | Loss: 8.2847e-05 | Loss_d: 5.1419e-04 | Loss_e: 1.2949e-04 | Loss_b: 4.3201e-03\n",
      "Step: 8500 | Loss: 1.4808e-05 | Loss_d: 5.2788e-04 | Loss_e: 1.1726e-04 | Loss_b: 2.4206e-04\n",
      "Step: 8600 | Loss: 1.2677e-05 | Loss_d: 4.0520e-04 | Loss_e: 1.2978e-04 | Loss_b: 2.2454e-04\n",
      "Step: 8700 | Loss: 1.4620e-05 | Loss_d: 4.9359e-04 | Loss_e: 1.2892e-04 | Loss_b: 2.5346e-04\n",
      "Step: 8800 | Loss: 4.2103e-04 | Loss_d: 5.2697e-04 | Loss_e: 1.7171e-04 | Loss_b: 2.4527e-02\n",
      "Step: 8900 | Loss: 1.3498e-05 | Loss_d: 4.8780e-04 | Loss_e: 1.2503e-04 | Loss_b: 1.9592e-04\n",
      "Step: 9000 | Loss: 8.0796e-05 | Loss_d: 4.5488e-04 | Loss_e: 1.5510e-04 | Loss_b: 4.2309e-03\n",
      "Step: 9100 | Loss: 2.6698e-05 | Loss_d: 5.2343e-04 | Loss_e: 1.3375e-04 | Loss_b: 9.4243e-04\n",
      "Step: 9200 | Loss: 9.1385e-05 | Loss_d: 3.7094e-04 | Loss_e: 1.3093e-04 | Loss_b: 4.9734e-03\n",
      "Step: 9300 | Loss: 1.4768e-05 | Loss_d: 4.6330e-04 | Loss_e: 1.3164e-04 | Loss_b: 2.8984e-04\n",
      "Step: 9400 | Loss: 1.2266e-05 | Loss_d: 4.4389e-04 | Loss_e: 1.1929e-04 | Loss_b: 1.7172e-04\n",
      "Step: 9500 | Loss: 1.1228e-04 | Loss_d: 4.6147e-04 | Loss_e: 1.0133e-04 | Loss_b: 6.1643e-03\n",
      "Step: 9600 | Loss: 1.1371e-05 | Loss_d: 3.7078e-04 | Loss_e: 1.2192e-04 | Loss_b: 1.8857e-04\n",
      "Step: 9700 | Loss: 1.7471e-05 | Loss_d: 4.4932e-04 | Loss_e: 1.2483e-04 | Loss_b: 4.7259e-04\n",
      "Step: 9800 | Loss: 1.0671e-05 | Loss_d: 3.7025e-04 | Loss_e: 1.4108e-04 | Loss_b: 1.2800e-04\n",
      "Step: 9900 | Loss: 1.1900e-05 | Loss_d: 3.9499e-04 | Loss_e: 1.0016e-04 | Loss_b: 2.1781e-04\n",
      "Step: 10000 | Loss: 7.8331e-05 | Loss_d: 3.6030e-04 | Loss_e: 1.1450e-04 | Loss_b: 4.2183e-03\n"
     ]
    }
   ],
   "source": [
    "# set the learning rate for Adam\n",
    "lr = 1e-3\n",
    "# set the training iteration\n",
    "epoch1 = 10000\n",
    "\n",
    "# training with Adam\n",
    "trained_params, loss1 = adam_optimizer(keys_adam[1], NN_loss, trained_params, dataf, epoch1, lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87b707ce-c1fe-45f0-b934-42e45b069b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(loss):\n",
    "  np_loss = np.array(loss)\n",
    "  plt.semilogy(np_loss[:,0],label='Total')\n",
    "  plt.semilogy(np_loss[:,1],label='W Data')\n",
    "  plt.semilogy(np_loss[:,2],label='Eqn')\n",
    "  plt.semilogy(np_loss[:,3],label='BC (U Data)')\n",
    "  plt.legend()\n",
    "  plt.xlabel('Iteration')\n",
    "  plt.ylabel('Loss')\n",
    "plot_loss(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e766a89-3069-4af1-bf15-d991a1ddfacb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: NaN | Loss: 1.0945e-05 | Loss_d: 4.3849e-04 Loss_e: 1.0742e-04 | Loss_b: 1.0987e-04\n",
      "Step: NaN | Loss: 4.7770e-05 | Loss_d: 4.0211e-04 Loss_e: 1.1179e-04 | Loss_b: 2.3482e-03\n",
      "Step: NaN | Loss: 1.0616e-05 | Loss_d: 4.3470e-04 Loss_e: 1.0753e-04 | Loss_b: 9.3827e-05\n",
      "Step: NaN | Loss: 1.0511e-05 | Loss_d: 4.3236e-04 Loss_e: 1.0778e-04 | Loss_b: 8.9593e-05\n",
      "Step: NaN | Loss: 1.1609e-05 | Loss_d: 4.2386e-04 Loss_e: 1.0938e-04 | Loss_b: 1.6230e-04\n",
      "Step: NaN | Loss: 1.0508e-05 | Loss_d: 4.3192e-04 Loss_e: 1.0784e-04 | Loss_b: 8.9808e-05\n",
      "Step: NaN | Loss: 1.0484e-05 | Loss_d: 4.2924e-04 Loss_e: 1.0785e-04 | Loss_b: 9.1059e-05\n",
      "Step: NaN | Loss: 1.0424e-05 | Loss_d: 4.1929e-04 Loss_e: 1.0796e-04 | Loss_b: 9.7297e-05\n",
      "Step: NaN | Loss: 1.0939e-05 | Loss_d: 3.8778e-04 Loss_e: 1.0937e-04 | Loss_b: 1.5828e-04\n",
      "Step: NaN | Loss: 1.0414e-05 | Loss_d: 4.1386e-04 Loss_e: 1.0805e-04 | Loss_b: 1.0204e-04\n",
      "Step: NaN | Loss: 1.0388e-05 | Loss_d: 4.1095e-04 Loss_e: 1.0716e-04 | Loss_b: 1.0430e-04\n",
      "Step: NaN | Loss: 1.0388e-05 | Loss_d: 4.1117e-04 Loss_e: 1.0723e-04 | Loss_b: 1.0399e-04\n",
      "Step: NaN | Loss: 1.0379e-05 | Loss_d: 4.1189e-04 Loss_e: 1.0662e-04 | Loss_b: 1.0333e-04\n",
      "Step: NaN | Loss: 1.0354e-05 | Loss_d: 4.1495e-04 Loss_e: 1.0459e-04 | Loss_b: 1.0083e-04\n",
      "Step: NaN | Loss: 1.0544e-05 | Loss_d: 4.3550e-04 Loss_e: 1.0460e-04 | Loss_b: 9.1610e-05\n",
      "Step: NaN | Loss: 1.0349e-05 | Loss_d: 4.1723e-04 Loss_e: 1.0360e-04 | Loss_b: 9.9252e-05\n",
      "Step: NaN | Loss: 1.0331e-05 | Loss_d: 4.1719e-04 Loss_e: 1.0293e-04 | Loss_b: 9.8846e-05\n",
      "Step: NaN | Loss: 1.0311e-05 | Loss_d: 4.1719e-04 Loss_e: 1.0147e-04 | Loss_b: 9.9140e-05\n",
      "Step: NaN | Loss: 1.0308e-05 | Loss_d: 4.1717e-04 Loss_e: 1.0168e-04 | Loss_b: 9.8753e-05\n",
      "Step: NaN | Loss: 1.0275e-05 | Loss_d: 4.1649e-04 Loss_e: 1.0090e-04 | Loss_b: 9.8232e-05\n",
      "Step: NaN | Loss: 1.0659e-05 | Loss_d: 4.1529e-04 Loss_e: 1.1340e-04 | Loss_b: 1.0994e-04\n",
      "Step: NaN | Loss: 1.0274e-05 | Loss_d: 4.1640e-04 Loss_e: 1.0092e-04 | Loss_b: 9.8269e-05\n",
      "Step: NaN | Loss: 1.0260e-05 | Loss_d: 4.1590e-04 Loss_e: 1.0024e-04 | Loss_b: 9.8614e-05\n",
      "Step: NaN | Loss: 1.0218e-05 | Loss_d: 4.1393e-04 Loss_e: 9.8043e-05 | Loss_b: 1.0024e-04\n",
      "Step: NaN | Loss: 1.0329e-05 | Loss_d: 4.0540e-04 Loss_e: 9.9276e-05 | Loss_b: 1.1416e-04\n",
      "Step: NaN | Loss: 1.0195e-05 | Loss_d: 4.1119e-04 Loss_e: 9.6292e-05 | Loss_b: 1.0334e-04\n",
      "Step: NaN | Loss: 1.0154e-05 | Loss_d: 4.0856e-04 Loss_e: 9.5223e-05 | Loss_b: 1.0457e-04\n",
      "Step: NaN | Loss: 1.0162e-05 | Loss_d: 3.9998e-04 Loss_e: 9.3059e-05 | Loss_b: 1.1580e-04\n",
      "Step: NaN | Loss: 1.0123e-05 | Loss_d: 4.0414e-04 Loss_e: 9.3786e-05 | Loss_b: 1.0858e-04\n",
      "Step: NaN | Loss: 1.0101e-05 | Loss_d: 4.0301e-04 Loss_e: 9.3377e-05 | Loss_b: 1.0883e-04\n",
      "Step: NaN | Loss: 1.0071e-05 | Loss_d: 3.9917e-04 Loss_e: 9.2779e-05 | Loss_b: 1.1147e-04\n",
      "Step: NaN | Loss: 1.0070e-05 | Loss_d: 3.9973e-04 Loss_e: 9.2763e-05 | Loss_b: 1.1085e-04\n",
      "Step: NaN | Loss: 1.0063e-05 | Loss_d: 3.9975e-04 Loss_e: 9.2753e-05 | Loss_b: 1.1040e-04\n",
      "Step: NaN | Loss: 1.0062e-05 | Loss_d: 3.9987e-04 Loss_e: 9.2772e-05 | Loss_b: 1.1024e-04\n",
      "Step: NaN | Loss: 1.0057e-05 | Loss_d: 3.9980e-04 Loss_e: 9.2750e-05 | Loss_b: 1.0999e-04\n",
      "Step: NaN | Loss: 1.0047e-05 | Loss_d: 3.9942e-04 Loss_e: 9.2706e-05 | Loss_b: 1.0985e-04\n",
      "Step: NaN | Loss: 1.0027e-05 | Loss_d: 3.9795e-04 Loss_e: 9.2602e-05 | Loss_b: 1.1018e-04\n",
      "Step: NaN | Loss: 1.0344e-05 | Loss_d: 3.9156e-04 Loss_e: 9.3918e-05 | Loss_b: 1.3426e-04\n",
      "Step: NaN | Loss: 1.0026e-05 | Loss_d: 3.9762e-04 Loss_e: 9.2595e-05 | Loss_b: 1.1048e-04\n",
      "Step: NaN | Loss: 9.9653e-06 | Loss_d: 3.9572e-04 Loss_e: 9.2690e-05 | Loss_b: 1.0865e-04\n",
      "Step: NaN | Loss: 1.0053e-05 | Loss_d: 3.9027e-04 Loss_e: 9.7142e-05 | Loss_b: 1.1493e-04\n",
      "Step: NaN | Loss: 9.9363e-06 | Loss_d: 3.9352e-04 Loss_e: 9.3450e-05 | Loss_b: 1.0835e-04\n",
      "Step: NaN | Loss: 9.9332e-06 | Loss_d: 3.9335e-04 Loss_e: 9.3356e-05 | Loss_b: 1.0844e-04\n",
      "Step: NaN | Loss: 9.9538e-06 | Loss_d: 3.9275e-04 Loss_e: 9.3359e-05 | Loss_b: 1.1026e-04\n",
      "Step: NaN | Loss: 9.9329e-06 | Loss_d: 3.9327e-04 Loss_e: 9.3328e-05 | Loss_b: 1.0852e-04\n",
      "Step: NaN | Loss: 9.9294e-06 | Loss_d: 3.9326e-04 Loss_e: 9.3312e-05 | Loss_b: 1.0834e-04\n",
      "Step: NaN | Loss: 9.9170e-06 | Loss_d: 3.9325e-04 Loss_e: 9.3267e-05 | Loss_b: 1.0765e-04\n",
      "Step: NaN | Loss: 9.8900e-06 | Loss_d: 3.9408e-04 Loss_e: 9.3426e-05 | Loss_b: 1.0504e-04\n",
      "Step: NaN | Loss: 9.8899e-06 | Loss_d: 3.9403e-04 Loss_e: 9.3409e-05 | Loss_b: 1.0511e-04\n",
      "Step: NaN | Loss: 9.8573e-06 | Loss_d: 3.8791e-04 Loss_e: 9.4514e-05 | Loss_b: 1.0817e-04\n",
      "Step: NaN | Loss: 9.8573e-06 | Loss_d: 3.8794e-04 Loss_e: 9.4507e-05 | Loss_b: 1.0815e-04\n",
      "Step: NaN | Loss: 9.8497e-06 | Loss_d: 3.8554e-04 Loss_e: 9.4602e-05 | Loss_b: 1.1000e-04\n",
      "Step: NaN | Loss: 9.8626e-06 | Loss_d: 3.7663e-04 Loss_e: 9.5427e-05 | Loss_b: 1.1886e-04\n",
      "Step: NaN | Loss: 9.8463e-06 | Loss_d: 3.8263e-04 Loss_e: 9.4784e-05 | Loss_b: 1.1252e-04\n",
      "Step: NaN | Loss: 9.8383e-06 | Loss_d: 3.8305e-04 Loss_e: 9.4549e-05 | Loss_b: 1.1185e-04\n",
      "Step: NaN | Loss: 9.8168e-06 | Loss_d: 3.8488e-04 Loss_e: 9.3821e-05 | Loss_b: 1.0946e-04\n",
      "Step: NaN | Loss: 9.9704e-06 | Loss_d: 3.9795e-04 Loss_e: 9.5238e-05 | Loss_b: 1.0419e-04\n",
      "Step: NaN | Loss: 9.8121e-06 | Loss_d: 3.8639e-04 Loss_e: 9.3502e-05 | Loss_b: 1.0799e-04\n",
      "Step: NaN | Loss: 9.7849e-06 | Loss_d: 3.8597e-04 Loss_e: 9.3386e-05 | Loss_b: 1.0689e-04\n",
      "Step: NaN | Loss: 9.7856e-06 | Loss_d: 3.8523e-04 Loss_e: 9.5755e-05 | Loss_b: 1.0531e-04\n",
      "Step: NaN | Loss: 9.7631e-06 | Loss_d: 3.8542e-04 Loss_e: 9.3992e-05 | Loss_b: 1.0554e-04\n",
      "Step: NaN | Loss: 9.7518e-06 | Loss_d: 3.8452e-04 Loss_e: 9.3818e-05 | Loss_b: 1.0594e-04\n",
      "Step: NaN | Loss: 9.7299e-06 | Loss_d: 3.8105e-04 Loss_e: 9.3588e-05 | Loss_b: 1.0832e-04\n",
      "Step: NaN | Loss: 1.0182e-05 | Loss_d: 3.6777e-04 Loss_e: 1.0368e-04 | Loss_b: 1.3860e-04\n",
      "Step: NaN | Loss: 9.7297e-06 | Loss_d: 3.8078e-04 Loss_e: 9.3602e-05 | Loss_b: 1.0857e-04\n",
      "Step: NaN | Loss: 9.7173e-06 | Loss_d: 3.8022e-04 Loss_e: 9.4077e-05 | Loss_b: 1.0791e-04\n",
      "Step: NaN | Loss: 9.7186e-06 | Loss_d: 3.7848e-04 Loss_e: 9.6901e-05 | Loss_b: 1.0690e-04\n",
      "Step: NaN | Loss: 9.7077e-06 | Loss_d: 3.7929e-04 Loss_e: 9.5255e-05 | Loss_b: 1.0709e-04\n",
      "Step: NaN | Loss: 9.7023e-06 | Loss_d: 3.7953e-04 Loss_e: 9.5118e-05 | Loss_b: 1.0666e-04\n",
      "Step: NaN | Loss: 9.7079e-06 | Loss_d: 3.8053e-04 Loss_e: 9.4725e-05 | Loss_b: 1.0638e-04\n",
      "Step: NaN | Loss: 9.6993e-06 | Loss_d: 3.7990e-04 Loss_e: 9.4942e-05 | Loss_b: 1.0629e-04\n",
      "Step: NaN | Loss: 9.6868e-06 | Loss_d: 3.8012e-04 Loss_e: 9.4709e-05 | Loss_b: 1.0555e-04\n",
      "Step: NaN | Loss: 9.6796e-06 | Loss_d: 3.8109e-04 Loss_e: 9.4343e-05 | Loss_b: 1.0451e-04\n",
      "Step: NaN | Loss: 9.6743e-06 | Loss_d: 3.8070e-04 Loss_e: 9.4379e-05 | Loss_b: 1.0455e-04\n",
      "Step: NaN | Loss: 9.6657e-06 | Loss_d: 3.7992e-04 Loss_e: 9.4198e-05 | Loss_b: 1.0499e-04\n",
      "Step: NaN | Loss: 9.6645e-06 | Loss_d: 3.7723e-04 Loss_e: 9.4067e-05 | Loss_b: 1.0775e-04\n",
      "Step: NaN | Loss: 9.6585e-06 | Loss_d: 3.7843e-04 Loss_e: 9.4011e-05 | Loss_b: 1.0624e-04\n",
      "Step: NaN | Loss: 9.6390e-06 | Loss_d: 3.7700e-04 Loss_e: 9.4503e-05 | Loss_b: 1.0601e-04\n",
      "Step: NaN | Loss: 9.6100e-06 | Loss_d: 3.7179e-04 Loss_e: 9.7574e-05 | Loss_b: 1.0641e-04\n",
      "Step: NaN | Loss: 9.6093e-06 | Loss_d: 3.7240e-04 Loss_e: 9.7090e-05 | Loss_b: 1.0624e-04\n",
      "Step: NaN | Loss: 9.5735e-06 | Loss_d: 3.7691e-04 Loss_e: 9.4662e-05 | Loss_b: 1.0202e-04\n",
      "Step: NaN | Loss: 1.0054e-05 | Loss_d: 4.0120e-04 Loss_e: 9.2808e-05 | Loss_b: 1.0839e-04\n",
      "Step: NaN | Loss: 9.5733e-06 | Loss_d: 3.7726e-04 Loss_e: 9.4517e-05 | Loss_b: 1.0180e-04\n",
      "Step: NaN | Loss: 9.5900e-06 | Loss_d: 3.7882e-04 Loss_e: 9.5856e-05 | Loss_b: 9.9902e-05\n",
      "Step: NaN | Loss: 9.5685e-06 | Loss_d: 3.7772e-04 Loss_e: 9.4921e-05 | Loss_b: 1.0065e-04\n",
      "Step: NaN | Loss: 9.5620e-06 | Loss_d: 3.7722e-04 Loss_e: 9.5087e-05 | Loss_b: 1.0059e-04\n",
      "Step: NaN | Loss: 9.5476e-06 | Loss_d: 3.7534e-04 Loss_e: 9.6146e-05 | Loss_b: 1.0055e-04\n",
      "Step: NaN | Loss: 9.7642e-06 | Loss_d: 3.6878e-04 Loss_e: 1.1083e-04 | Loss_b: 1.0540e-04\n",
      "Step: NaN | Loss: 9.5470e-06 | Loss_d: 3.7490e-04 Loss_e: 9.6511e-05 | Loss_b: 1.0059e-04\n",
      "Step: NaN | Loss: 9.5297e-06 | Loss_d: 3.7322e-04 Loss_e: 9.6245e-05 | Loss_b: 1.0150e-04\n",
      "Step: NaN | Loss: 9.5278e-06 | Loss_d: 3.6715e-04 Loss_e: 9.5927e-05 | Loss_b: 1.0777e-04\n",
      "Step: NaN | Loss: 9.5154e-06 | Loss_d: 3.6994e-04 Loss_e: 9.5931e-05 | Loss_b: 1.0423e-04\n",
      "Step: NaN | Loss: 9.5035e-06 | Loss_d: 3.7178e-04 Loss_e: 9.6039e-05 | Loss_b: 1.0157e-04\n",
      "Step: NaN | Loss: 9.5502e-06 | Loss_d: 3.8116e-04 Loss_e: 9.7083e-05 | Loss_b: 9.3954e-05\n",
      "Step: NaN | Loss: 9.5008e-06 | Loss_d: 3.7332e-04 Loss_e: 9.6163e-05 | Loss_b: 9.9752e-05\n",
      "Step: NaN | Loss: 9.4924e-06 | Loss_d: 3.7327e-04 Loss_e: 9.5604e-05 | Loss_b: 9.9860e-05\n",
      "Step: NaN | Loss: 9.5458e-06 | Loss_d: 3.7331e-04 Loss_e: 9.5107e-05 | Loss_b: 1.0351e-04\n",
      "Step: NaN | Loss: 9.4914e-06 | Loss_d: 3.7325e-04 Loss_e: 9.5404e-05 | Loss_b: 1.0002e-04\n",
      "Step: NaN | Loss: 9.4927e-06 | Loss_d: 3.7405e-04 Loss_e: 9.5256e-05 | Loss_b: 9.9444e-05\n",
      "Step: NaN | Loss: 9.4868e-06 | Loss_d: 3.7362e-04 Loss_e: 9.5242e-05 | Loss_b: 9.9533e-05\n",
      "Step: NaN | Loss: 9.4845e-06 | Loss_d: 3.7354e-04 Loss_e: 9.5232e-05 | Loss_b: 9.9484e-05\n",
      "Step: NaN | Loss: 9.4760e-06 | Loss_d: 3.7323e-04 Loss_e: 9.5212e-05 | Loss_b: 9.9304e-05\n",
      "Step: NaN | Loss: 9.4565e-06 | Loss_d: 3.7188e-04 Loss_e: 9.5666e-05 | Loss_b: 9.9034e-05\n",
      "Step: NaN | Loss: 9.9259e-06 | Loss_d: 3.6934e-04 Loss_e: 1.1180e-04 | Loss_b: 1.1357e-04\n",
      "Step: NaN | Loss: 9.4565e-06 | Loss_d: 3.7185e-04 Loss_e: 9.5683e-05 | Loss_b: 9.9043e-05\n",
      "Step: NaN | Loss: 9.5784e-06 | Loss_d: 3.6707e-04 Loss_e: 9.8965e-05 | Loss_b: 1.0785e-04\n",
      "Step: NaN | Loss: 9.4523e-06 | Loss_d: 3.7107e-04 Loss_e: 9.6059e-05 | Loss_b: 9.9203e-05\n",
      "Step: NaN | Loss: 9.4401e-06 | Loss_d: 3.6844e-04 Loss_e: 9.6709e-05 | Loss_b: 1.0044e-04\n",
      "Step: NaN | Loss: 9.4994e-06 | Loss_d: 3.5965e-04 Loss_e: 1.0233e-04 | Loss_b: 1.0717e-04\n",
      "Step: NaN | Loss: 9.4378e-06 | Loss_d: 3.6687e-04 Loss_e: 9.7275e-05 | Loss_b: 1.0132e-04\n",
      "Step: NaN | Loss: 9.4235e-06 | Loss_d: 3.6522e-04 Loss_e: 9.8043e-05 | Loss_b: 1.0134e-04\n",
      "Step: NaN | Loss: 9.4610e-06 | Loss_d: 3.5969e-04 Loss_e: 1.0269e-04 | Loss_b: 1.0447e-04\n",
      "Step: NaN | Loss: 9.4188e-06 | Loss_d: 3.6365e-04 Loss_e: 9.8981e-05 | Loss_b: 1.0169e-04\n",
      "Step: NaN | Loss: 9.3867e-06 | Loss_d: 3.6197e-04 Loss_e: 9.8555e-05 | Loss_b: 1.0187e-04\n",
      "Step: NaN | Loss: 9.3480e-06 | Loss_d: 3.5717e-04 Loss_e: 9.8460e-05 | Loss_b: 1.0445e-04\n",
      "Step: NaN | Loss: 9.3442e-06 | Loss_d: 3.5801e-04 Loss_e: 9.8253e-05 | Loss_b: 1.0358e-04\n",
      "Step: NaN | Loss: 9.3279e-06 | Loss_d: 3.5890e-04 Loss_e: 9.7669e-05 | Loss_b: 1.0230e-04\n",
      "Step: NaN | Loss: 9.3493e-06 | Loss_d: 3.6294e-04 Loss_e: 9.7130e-05 | Loss_b: 1.0009e-04\n",
      "Step: NaN | Loss: 9.3197e-06 | Loss_d: 3.6021e-04 Loss_e: 9.7158e-05 | Loss_b: 1.0101e-04\n",
      "Step: NaN | Loss: 9.2986e-06 | Loss_d: 3.5939e-04 Loss_e: 9.6903e-05 | Loss_b: 1.0083e-04\n",
      "Step: NaN | Loss: 9.4384e-06 | Loss_d: 3.5955e-04 Loss_e: 1.0006e-04 | Loss_b: 1.0589e-04\n",
      "Step: NaN | Loss: 9.2964e-06 | Loss_d: 3.5914e-04 Loss_e: 9.6923e-05 | Loss_b: 1.0093e-04\n",
      "Step: NaN | Loss: 9.2909e-06 | Loss_d: 3.5849e-04 Loss_e: 9.7084e-05 | Loss_b: 1.0109e-04\n",
      "Step: NaN | Loss: 9.3001e-06 | Loss_d: 3.5638e-04 Loss_e: 9.8277e-05 | Loss_b: 1.0256e-04\n",
      "Step: NaN | Loss: 9.2885e-06 | Loss_d: 3.5774e-04 Loss_e: 9.7364e-05 | Loss_b: 1.0141e-04\n",
      "Step: NaN | Loss: 9.2808e-06 | Loss_d: 3.5739e-04 Loss_e: 9.7851e-05 | Loss_b: 1.0081e-04\n",
      "Step: NaN | Loss: 9.2696e-06 | Loss_d: 3.5613e-04 Loss_e: 1.0034e-04 | Loss_b: 9.8911e-05\n",
      "Step: NaN | Loss: 9.2693e-06 | Loss_d: 3.5631e-04 Loss_e: 9.9898e-05 | Loss_b: 9.9155e-05\n",
      "Step: NaN | Loss: 9.2496e-06 | Loss_d: 3.5433e-04 Loss_e: 9.9737e-05 | Loss_b: 1.0011e-04\n",
      "Step: NaN | Loss: 9.4739e-06 | Loss_d: 3.4731e-04 Loss_e: 1.0865e-04 | Loss_b: 1.1166e-04\n",
      "Step: NaN | Loss: 9.2493e-06 | Loss_d: 3.5404e-04 Loss_e: 9.9794e-05 | Loss_b: 1.0032e-04\n",
      "Step: NaN | Loss: 9.2377e-06 | Loss_d: 3.5387e-04 Loss_e: 9.9572e-05 | Loss_b: 1.0003e-04\n",
      "Step: NaN | Loss: 9.2174e-06 | Loss_d: 3.5371e-04 Loss_e: 9.9099e-05 | Loss_b: 9.9443e-05\n",
      "Step: NaN | Loss: 9.2174e-06 | Loss_d: 3.5371e-04 Loss_e: 9.9100e-05 | Loss_b: 9.9444e-05\n",
      "Step: NaN | Loss: 9.1949e-06 | Loss_d: 3.5495e-04 Loss_e: 9.8665e-05 | Loss_b: 9.7290e-05\n",
      "Step: NaN | Loss: 9.2254e-06 | Loss_d: 3.6051e-04 Loss_e: 9.8436e-05 | Loss_b: 9.3792e-05\n",
      "Step: NaN | Loss: 9.1836e-06 | Loss_d: 3.5674e-04 Loss_e: 9.8315e-05 | Loss_b: 9.5172e-05\n",
      "Step: NaN | Loss: 9.1745e-06 | Loss_d: 3.5461e-04 Loss_e: 9.8813e-05 | Loss_b: 9.6261e-05\n",
      "Step: NaN | Loss: 9.1970e-06 | Loss_d: 3.4664e-04 Loss_e: 1.0140e-04 | Loss_b: 1.0299e-04\n",
      "Step: NaN | Loss: 9.1714e-06 | Loss_d: 3.5245e-04 Loss_e: 9.9397e-05 | Loss_b: 9.7651e-05\n",
      "Step: NaN | Loss: 9.1619e-06 | Loss_d: 3.5025e-04 Loss_e: 9.9241e-05 | Loss_b: 9.9440e-05\n",
      "Step: NaN | Loss: 9.2537e-06 | Loss_d: 3.4293e-04 Loss_e: 9.9110e-05 | Loss_b: 1.1239e-04\n",
      "Step: NaN | Loss: 9.1616e-06 | Loss_d: 3.4977e-04 Loss_e: 9.9213e-05 | Loss_b: 9.9928e-05\n",
      "Step: NaN | Loss: 9.1569e-06 | Loss_d: 3.5024e-04 Loss_e: 9.8526e-05 | Loss_b: 9.9865e-05\n",
      "Step: NaN | Loss: 9.1450e-06 | Loss_d: 3.5222e-04 Loss_e: 9.5987e-05 | Loss_b: 9.9710e-05\n",
      "Step: NaN | Loss: 9.2491e-06 | Loss_d: 3.6464e-04 Loss_e: 8.8256e-05 | Loss_b: 1.0125e-04\n",
      "Step: NaN | Loss: 9.1431e-06 | Loss_d: 3.5347e-04 Loss_e: 9.4643e-05 | Loss_b: 9.9692e-05\n",
      "Step: NaN | Loss: 9.1431e-06 | Loss_d: 3.5060e-04 Loss_e: 9.7342e-05 | Loss_b: 9.9857e-05\n",
      "Step: NaN | Loss: 9.1210e-06 | Loss_d: 3.5185e-04 Loss_e: 9.5580e-05 | Loss_b: 9.9055e-05\n",
      "Step: NaN | Loss: 9.0966e-06 | Loss_d: 3.5061e-04 Loss_e: 9.5335e-05 | Loss_b: 9.9068e-05\n",
      "Step: NaN | Loss: 9.2182e-06 | Loss_d: 3.4679e-04 Loss_e: 9.9944e-05 | Loss_b: 1.0557e-04\n",
      "Step: NaN | Loss: 9.0925e-06 | Loss_d: 3.4991e-04 Loss_e: 9.5461e-05 | Loss_b: 9.9404e-05\n",
      "Step: NaN | Loss: 9.0845e-06 | Loss_d: 3.5065e-04 Loss_e: 9.5358e-05 | Loss_b: 9.8283e-05\n",
      "Step: NaN | Loss: 9.1434e-06 | Loss_d: 3.5437e-04 Loss_e: 9.5439e-05 | Loss_b: 9.8007e-05\n",
      "Step: NaN | Loss: 9.0839e-06 | Loss_d: 3.5095e-04 Loss_e: 9.5332e-05 | Loss_b: 9.7971e-05\n",
      "Step: NaN | Loss: 9.0779e-06 | Loss_d: 3.5045e-04 Loss_e: 9.5158e-05 | Loss_b: 9.8288e-05\n",
      "Step: NaN | Loss: 9.0756e-06 | Loss_d: 3.4915e-04 Loss_e: 9.4909e-05 | Loss_b: 9.9701e-05\n",
      "Step: NaN | Loss: 9.0724e-06 | Loss_d: 3.4957e-04 Loss_e: 9.4929e-05 | Loss_b: 9.9065e-05\n",
      "Step: NaN | Loss: 9.0760e-06 | Loss_d: 3.4481e-04 Loss_e: 9.5222e-05 | Loss_b: 1.0375e-04\n",
      "Step: NaN | Loss: 9.0608e-06 | Loss_d: 3.4723e-04 Loss_e: 9.4827e-05 | Loss_b: 1.0082e-04\n",
      "Step: NaN | Loss: 9.0470e-06 | Loss_d: 3.4718e-04 Loss_e: 9.4782e-05 | Loss_b: 1.0008e-04\n",
      "Step: NaN | Loss: 9.1288e-06 | Loss_d: 3.4795e-04 Loss_e: 9.8515e-05 | Loss_b: 1.0048e-04\n",
      "Step: NaN | Loss: 9.0452e-06 | Loss_d: 3.4719e-04 Loss_e: 9.4909e-05 | Loss_b: 9.9840e-05\n",
      "Step: NaN | Loss: 9.0396e-06 | Loss_d: 3.4702e-04 Loss_e: 9.4615e-05 | Loss_b: 9.9967e-05\n",
      "Step: NaN | Loss: 9.0348e-06 | Loss_d: 3.4664e-04 Loss_e: 9.3936e-05 | Loss_b: 1.0073e-04\n",
      "Step: NaN | Loss: 9.0332e-06 | Loss_d: 3.4671e-04 Loss_e: 9.4073e-05 | Loss_b: 1.0044e-04\n",
      "Step: NaN | Loss: 9.0253e-06 | Loss_d: 3.4366e-04 Loss_e: 9.4595e-05 | Loss_b: 1.0249e-04\n",
      "Step: NaN | Loss: 9.0247e-06 | Loss_d: 3.4430e-04 Loss_e: 9.4471e-05 | Loss_b: 1.0194e-04\n",
      "Step: NaN | Loss: 9.0214e-06 | Loss_d: 3.4340e-04 Loss_e: 9.5018e-05 | Loss_b: 1.0210e-04\n",
      "Step: NaN | Loss: 9.0169e-06 | Loss_d: 3.3988e-04 Loss_e: 9.7418e-05 | Loss_b: 1.0294e-04\n",
      "Step: NaN | Loss: 9.0167e-06 | Loss_d: 3.4050e-04 Loss_e: 9.6963e-05 | Loss_b: 1.0277e-04\n",
      "Step: NaN | Loss: 9.0030e-06 | Loss_d: 3.3894e-04 Loss_e: 9.7783e-05 | Loss_b: 1.0268e-04\n",
      "Step: NaN | Loss: 9.0218e-06 | Loss_d: 3.3339e-04 Loss_e: 1.0173e-04 | Loss_b: 1.0542e-04\n",
      "Step: NaN | Loss: 8.9962e-06 | Loss_d: 3.3693e-04 Loss_e: 9.9008e-05 | Loss_b: 1.0307e-04\n",
      "Step: NaN | Loss: 8.9763e-06 | Loss_d: 3.3655e-04 Loss_e: 9.8455e-05 | Loss_b: 1.0281e-04\n",
      "Step: NaN | Loss: 9.0013e-06 | Loss_d: 3.3691e-04 Loss_e: 9.7824e-05 | Loss_b: 1.0457e-04\n",
      "Step: NaN | Loss: 8.9660e-06 | Loss_d: 3.3633e-04 Loss_e: 9.7947e-05 | Loss_b: 1.0291e-04\n",
      "Step: NaN | Loss: 8.9478e-06 | Loss_d: 3.3916e-04 Loss_e: 9.6313e-05 | Loss_b: 1.0063e-04\n",
      "Step: NaN | Loss: 8.9463e-06 | Loss_d: 3.3851e-04 Loss_e: 9.6587e-05 | Loss_b: 1.0092e-04\n",
      "Step: NaN | Loss: 8.9338e-06 | Loss_d: 3.3683e-04 Loss_e: 9.6787e-05 | Loss_b: 1.0164e-04\n",
      "Step: NaN | Loss: 9.0086e-06 | Loss_d: 3.3110e-04 Loss_e: 1.0014e-04 | Loss_b: 1.0850e-04\n",
      "Step: NaN | Loss: 8.9322e-06 | Loss_d: 3.3603e-04 Loss_e: 9.6985e-05 | Loss_b: 1.0215e-04\n",
      "Step: NaN | Loss: 8.9273e-06 | Loss_d: 3.3557e-04 Loss_e: 9.6939e-05 | Loss_b: 1.0236e-04\n",
      "Step: NaN | Loss: 8.9505e-06 | Loss_d: 3.3386e-04 Loss_e: 9.7073e-05 | Loss_b: 1.0533e-04\n",
      "Step: NaN | Loss: 8.9264e-06 | Loss_d: 3.3528e-04 Loss_e: 9.6926e-05 | Loss_b: 1.0261e-04\n",
      "Step: NaN | Loss: 8.9229e-06 | Loss_d: 3.3495e-04 Loss_e: 9.6795e-05 | Loss_b: 1.0286e-04\n",
      "Step: NaN | Loss: 8.9125e-06 | Loss_d: 3.3370e-04 Loss_e: 9.6335e-05 | Loss_b: 1.0395e-04\n",
      "Step: NaN | Loss: 8.9475e-06 | Loss_d: 3.2922e-04 Loss_e: 9.5562e-05 | Loss_b: 1.1130e-04\n",
      "Step: NaN | Loss: 8.9077e-06 | Loss_d: 3.3227e-04 Loss_e: 9.5892e-05 | Loss_b: 1.0554e-04\n",
      "Step: NaN | Loss: 8.8970e-06 | Loss_d: 3.3158e-04 Loss_e: 9.6679e-05 | Loss_b: 1.0479e-04\n",
      "Step: NaN | Loss: 8.9097e-06 | Loss_d: 3.2913e-04 Loss_e: 1.0129e-04 | Loss_b: 1.0339e-04\n",
      "Step: NaN | Loss: 8.8912e-06 | Loss_d: 3.3066e-04 Loss_e: 9.8044e-05 | Loss_b: 1.0400e-04\n",
      "Step: NaN | Loss: 8.8856e-06 | Loss_d: 3.3112e-04 Loss_e: 9.7937e-05 | Loss_b: 1.0332e-04\n",
      "Step: NaN | Loss: 8.8764e-06 | Loss_d: 3.3302e-04 Loss_e: 9.7617e-05 | Loss_b: 1.0118e-04\n",
      "Step: NaN | Loss: 8.8764e-06 | Loss_d: 3.3291e-04 Loss_e: 9.7631e-05 | Loss_b: 1.0128e-04\n",
      "Step: NaN | Loss: 8.8641e-06 | Loss_d: 3.3475e-04 Loss_e: 9.7381e-05 | Loss_b: 9.8951e-05\n",
      "Step: NaN | Loss: 8.9021e-06 | Loss_d: 3.4263e-04 Loss_e: 9.7177e-05 | Loss_b: 9.3561e-05\n",
      "Step: NaN | Loss: 8.8604e-06 | Loss_d: 3.3648e-04 Loss_e: 9.7223e-05 | Loss_b: 9.7167e-05\n",
      "Step: NaN | Loss: 8.8395e-06 | Loss_d: 3.3340e-04 Loss_e: 9.8974e-05 | Loss_b: 9.7239e-05\n",
      "Step: NaN | Loss: 8.8487e-06 | Loss_d: 3.2228e-04 Loss_e: 1.0922e-04 | Loss_b: 9.8667e-05\n",
      "Step: NaN | Loss: 8.8255e-06 | Loss_d: 3.2825e-04 Loss_e: 1.0287e-04 | Loss_b: 9.7661e-05\n",
      "Step: NaN | Loss: 8.7786e-06 | Loss_d: 3.2771e-04 Loss_e: 1.0134e-04 | Loss_b: 9.6911e-05\n",
      "Step: NaN | Loss: 8.9880e-06 | Loss_d: 3.3417e-04 Loss_e: 1.0334e-04 | Loss_b: 1.0100e-04\n",
      "Step: NaN | Loss: 8.7693e-06 | Loss_d: 3.2784e-04 Loss_e: 1.0077e-04 | Loss_b: 9.6801e-05\n",
      "Step: NaN | Loss: 8.7575e-06 | Loss_d: 3.2641e-04 Loss_e: 1.0103e-04 | Loss_b: 9.7262e-05\n",
      "Step: NaN | Loss: 8.7461e-06 | Loss_d: 3.2096e-04 Loss_e: 1.0260e-04 | Loss_b: 1.0046e-04\n",
      "Step: NaN | Loss: 8.7435e-06 | Loss_d: 3.2256e-04 Loss_e: 1.0203e-04 | Loss_b: 9.9264e-05\n",
      "Step: NaN | Loss: 8.7170e-06 | Loss_d: 3.1947e-04 Loss_e: 1.0349e-04 | Loss_b: 9.9310e-05\n",
      "Step: NaN | Loss: 8.8681e-06 | Loss_d: 3.0965e-04 Loss_e: 1.1550e-04 | Loss_b: 1.0617e-04\n",
      "Step: NaN | Loss: 8.7136e-06 | Loss_d: 3.1794e-04 Loss_e: 1.0450e-04 | Loss_b: 9.9623e-05\n",
      "Step: NaN | Loss: 8.7048e-06 | Loss_d: 3.1773e-04 Loss_e: 1.0418e-04 | Loss_b: 9.9633e-05\n",
      "Step: NaN | Loss: 8.6869e-06 | Loss_d: 3.1713e-04 Loss_e: 1.0328e-04 | Loss_b: 1.0006e-04\n",
      "Step: NaN | Loss: 9.0101e-06 | Loss_d: 3.1997e-04 Loss_e: 1.0813e-04 | Loss_b: 1.1173e-04\n",
      "Step: NaN | Loss: 8.6866e-06 | Loss_d: 3.1707e-04 Loss_e: 1.0320e-04 | Loss_b: 1.0018e-04\n",
      "Step: NaN | Loss: 8.6721e-06 | Loss_d: 3.1920e-04 Loss_e: 1.0369e-04 | Loss_b: 9.6696e-05\n",
      "Step: NaN | Loss: 8.6710e-06 | Loss_d: 3.1871e-04 Loss_e: 1.0351e-04 | Loss_b: 9.7296e-05\n",
      "Step: NaN | Loss: 8.6577e-06 | Loss_d: 3.1841e-04 Loss_e: 1.0436e-04 | Loss_b: 9.5953e-05\n",
      "Step: NaN | Loss: 8.6576e-06 | Loss_d: 3.1843e-04 Loss_e: 1.0426e-04 | Loss_b: 9.6024e-05\n",
      "Step: NaN | Loss: 8.6532e-06 | Loss_d: 3.1902e-04 Loss_e: 1.0366e-04 | Loss_b: 9.5772e-05\n",
      "Step: NaN | Loss: 8.6535e-06 | Loss_d: 3.2157e-04 Loss_e: 1.0167e-04 | Loss_b: 9.5220e-05\n",
      "Step: NaN | Loss: 8.6499e-06 | Loss_d: 3.2024e-04 Loss_e: 1.0260e-04 | Loss_b: 9.5412e-05\n",
      "Step: NaN | Loss: 8.6427e-06 | Loss_d: 3.1887e-04 Loss_e: 1.0336e-04 | Loss_b: 9.5585e-05\n",
      "Step: NaN | Loss: 8.6259e-06 | Loss_d: 3.1361e-04 Loss_e: 1.0670e-04 | Loss_b: 9.6503e-05\n",
      "Step: NaN | Loss: 8.8486e-06 | Loss_d: 2.9218e-04 Loss_e: 1.3039e-04 | Loss_b: 1.0759e-04\n",
      "Step: NaN | Loss: 8.6245e-06 | Loss_d: 3.1192e-04 Loss_e: 1.0792e-04 | Loss_b: 9.6890e-05\n",
      "Step: NaN | Loss: 8.6019e-06 | Loss_d: 3.0978e-04 Loss_e: 1.0733e-04 | Loss_b: 9.8269e-05\n",
      "Step: NaN | Loss: 8.8691e-06 | Loss_d: 3.0454e-04 Loss_e: 1.0925e-04 | Loss_b: 1.1760e-04\n",
      "Step: NaN | Loss: 8.6016e-06 | Loss_d: 3.0952e-04 Loss_e: 1.0728e-04 | Loss_b: 9.8554e-05\n",
      "Step: NaN | Loss: 8.5719e-06 | Loss_d: 3.0823e-04 Loss_e: 1.0679e-04 | Loss_b: 9.8567e-05\n",
      "Step: NaN | Loss: 8.5174e-06 | Loss_d: 3.0373e-04 Loss_e: 1.0673e-04 | Loss_b: 9.9860e-05\n",
      "Step: NaN | Loss: 9.9141e-06 | Loss_d: 2.9690e-04 Loss_e: 1.5355e-04 | Loss_b: 1.4355e-04\n",
      "Step: NaN | Loss: 8.5174e-06 | Loss_d: 3.0364e-04 Loss_e: 1.0676e-04 | Loss_b: 9.9911e-05\n",
      "Step: NaN | Loss: 8.4429e-06 | Loss_d: 3.0573e-04 Loss_e: 1.0664e-04 | Loss_b: 9.3480e-05\n",
      "Step: NaN | Loss: 8.7046e-06 | Loss_d: 3.2530e-04 Loss_e: 1.1446e-04 | Loss_b: 8.1762e-05\n",
      "Step: NaN | Loss: 8.4232e-06 | Loss_d: 3.0831e-04 Loss_e: 1.0717e-04 | Loss_b: 8.9191e-05\n",
      "Step: NaN | Loss: 8.3886e-06 | Loss_d: 3.0741e-04 Loss_e: 1.0703e-04 | Loss_b: 8.8167e-05\n",
      "Step: NaN | Loss: 8.3882e-06 | Loss_d: 3.0746e-04 Loss_e: 1.0701e-04 | Loss_b: 8.8104e-05\n",
      "Step: NaN | Loss: 8.3651e-06 | Loss_d: 3.0508e-04 Loss_e: 1.0768e-04 | Loss_b: 8.8426e-05\n",
      "Step: NaN | Loss: 8.3979e-06 | Loss_d: 2.9722e-04 Loss_e: 1.1256e-04 | Loss_b: 9.3378e-05\n",
      "Step: NaN | Loss: 8.3538e-06 | Loss_d: 3.0213e-04 Loss_e: 1.0894e-04 | Loss_b: 8.9449e-05\n",
      "Step: NaN | Loss: 8.3498e-06 | Loss_d: 2.9938e-04 Loss_e: 1.0822e-04 | Loss_b: 9.2668e-05\n",
      "Step: NaN | Loss: 8.3436e-06 | Loss_d: 3.0056e-04 Loss_e: 1.0846e-04 | Loss_b: 9.0879e-05\n",
      "Step: NaN | Loss: 8.3402e-06 | Loss_d: 3.0110e-04 Loss_e: 1.0795e-04 | Loss_b: 9.0639e-05\n",
      "Step: NaN | Loss: 8.3352e-06 | Loss_d: 3.0340e-04 Loss_e: 1.0611e-04 | Loss_b: 8.9883e-05\n",
      "Step: NaN | Loss: 8.3351e-06 | Loss_d: 3.0310e-04 Loss_e: 1.0633e-04 | Loss_b: 8.9963e-05\n",
      "Step: NaN | Loss: 8.3149e-06 | Loss_d: 3.0249e-04 Loss_e: 1.0675e-04 | Loss_b: 8.8939e-05\n",
      "Step: NaN | Loss: 8.2660e-06 | Loss_d: 3.0032e-04 Loss_e: 1.0929e-04 | Loss_b: 8.5642e-05\n",
      "Step: NaN | Loss: 8.9245e-06 | Loss_d: 2.9550e-04 Loss_e: 1.4343e-04 | Loss_b: 9.5778e-05\n",
      "Step: NaN | Loss: 8.2615e-06 | Loss_d: 2.9967e-04 Loss_e: 1.1047e-04 | Loss_b: 8.4841e-05\n",
      "Step: NaN | Loss: 8.6100e-06 | Loss_d: 3.0289e-04 Loss_e: 1.1149e-04 | Loss_b: 1.0148e-04\n",
      "Step: NaN | Loss: 8.2562e-06 | Loss_d: 2.9997e-04 Loss_e: 1.1041e-04 | Loss_b: 8.4279e-05\n",
      "Step: NaN | Loss: 8.2479e-06 | Loss_d: 2.9982e-04 Loss_e: 1.0993e-04 | Loss_b: 8.4419e-05\n",
      "Step: NaN | Loss: 8.3550e-06 | Loss_d: 2.9993e-04 Loss_e: 1.0957e-04 | Loss_b: 9.1087e-05\n",
      "Step: NaN | Loss: 8.2478e-06 | Loss_d: 2.9981e-04 Loss_e: 1.0989e-04 | Loss_b: 8.4463e-05\n",
      "Step: NaN | Loss: 8.2347e-06 | Loss_d: 2.9964e-04 Loss_e: 1.0920e-04 | Loss_b: 8.4535e-05\n",
      "Step: NaN | Loss: 8.2162e-06 | Loss_d: 2.9966e-04 Loss_e: 1.0699e-04 | Loss_b: 8.5620e-05\n",
      "Step: NaN | Loss: 8.2155e-06 | Loss_d: 2.9958e-04 Loss_e: 1.0729e-04 | Loss_b: 8.5359e-05\n",
      "Step: NaN | Loss: 8.1907e-06 | Loss_d: 3.0063e-04 Loss_e: 1.0604e-04 | Loss_b: 8.4077e-05\n",
      "Step: NaN | Loss: 8.3129e-06 | Loss_d: 3.0666e-04 Loss_e: 1.0812e-04 | Loss_b: 8.3275e-05\n",
      "Step: NaN | Loss: 8.1864e-06 | Loss_d: 3.0137e-04 Loss_e: 1.0562e-04 | Loss_b: 8.3501e-05\n",
      "Step: NaN | Loss: 8.1576e-06 | Loss_d: 3.0051e-04 Loss_e: 1.0540e-04 | Loss_b: 8.2851e-05\n",
      "Step: NaN | Loss: 8.1556e-06 | Loss_d: 2.9774e-04 Loss_e: 1.0566e-04 | Loss_b: 8.5238e-05\n",
      "Step: NaN | Loss: 8.1338e-06 | Loss_d: 2.9896e-04 Loss_e: 1.0530e-04 | Loss_b: 8.3071e-05\n",
      "Step: NaN | Loss: 8.1344e-06 | Loss_d: 3.0291e-04 Loss_e: 1.0531e-04 | Loss_b: 7.9152e-05\n",
      "Step: NaN | Loss: 8.1245e-06 | Loss_d: 3.0076e-04 Loss_e: 1.0520e-04 | Loss_b: 8.0818e-05\n",
      "Step: NaN | Loss: 8.1177e-06 | Loss_d: 2.9895e-04 Loss_e: 1.0682e-04 | Loss_b: 8.0598e-05\n",
      "Step: NaN | Loss: 8.1327e-06 | Loss_d: 2.9248e-04 Loss_e: 1.1449e-04 | Loss_b: 8.0293e-05\n",
      "Step: NaN | Loss: 8.1151e-06 | Loss_d: 2.9704e-04 Loss_e: 1.0875e-04 | Loss_b: 8.0423e-05\n",
      "Step: NaN | Loss: 8.1045e-06 | Loss_d: 2.9727e-04 Loss_e: 1.0881e-04 | Loss_b: 7.9496e-05\n",
      "Step: NaN | Loss: 8.1197e-06 | Loss_d: 2.9870e-04 Loss_e: 1.1059e-04 | Loss_b: 7.7194e-05\n",
      "Step: NaN | Loss: 8.0993e-06 | Loss_d: 2.9765e-04 Loss_e: 1.0914e-04 | Loss_b: 7.8472e-05\n",
      "Step: NaN | Loss: 8.0921e-06 | Loss_d: 2.9708e-04 Loss_e: 1.0836e-04 | Loss_b: 7.9381e-05\n",
      "Step: NaN | Loss: 8.0914e-06 | Loss_d: 2.9720e-04 Loss_e: 1.0850e-04 | Loss_b: 7.9083e-05\n",
      "Step: NaN | Loss: 8.0823e-06 | Loss_d: 2.9589e-04 Loss_e: 1.0883e-04 | Loss_b: 7.9522e-05\n",
      "Step: NaN | Loss: 8.0746e-06 | Loss_d: 2.9104e-04 Loss_e: 1.1059e-04 | Loss_b: 8.2159e-05\n",
      "Step: NaN | Loss: 8.0719e-06 | Loss_d: 2.9260e-04 Loss_e: 1.0991e-04 | Loss_b: 8.1107e-05\n",
      "Step: NaN | Loss: 8.0643e-06 | Loss_d: 2.9333e-04 Loss_e: 1.0864e-04 | Loss_b: 8.1200e-05\n",
      "Step: NaN | Loss: 8.0639e-06 | Loss_d: 2.9649e-04 Loss_e: 1.0402e-04 | Loss_b: 8.2634e-05\n",
      "Step: NaN | Loss: 8.0581e-06 | Loss_d: 2.9489e-04 Loss_e: 1.0619e-04 | Loss_b: 8.1719e-05\n",
      "Step: NaN | Loss: 8.0451e-06 | Loss_d: 2.9539e-04 Loss_e: 1.0495e-04 | Loss_b: 8.1674e-05\n",
      "Step: NaN | Loss: 8.0451e-06 | Loss_d: 2.9535e-04 Loss_e: 1.0504e-04 | Loss_b: 8.1627e-05\n",
      "Step: NaN | Loss: 8.0202e-06 | Loss_d: 2.9495e-04 Loss_e: 1.0510e-04 | Loss_b: 8.0468e-05\n",
      "Step: NaN | Loss: 7.9870e-06 | Loss_d: 2.9427e-04 Loss_e: 1.0681e-04 | Loss_b: 7.7458e-05\n",
      "Step: NaN | Loss: 7.9850e-06 | Loss_d: 2.9428e-04 Loss_e: 1.0629e-04 | Loss_b: 7.7838e-05\n",
      "Step: NaN | Loss: 7.9360e-06 | Loss_d: 2.9414e-04 Loss_e: 1.0352e-04 | Loss_b: 7.7815e-05\n",
      "Step: NaN | Loss: 8.4930e-06 | Loss_d: 2.9820e-04 Loss_e: 1.1093e-04 | Loss_b: 9.9726e-05\n",
      "Step: NaN | Loss: 7.9352e-06 | Loss_d: 2.9416e-04 Loss_e: 1.0327e-04 | Loss_b: 7.7996e-05\n",
      "Step: NaN | Loss: 7.9180e-06 | Loss_d: 2.9304e-04 Loss_e: 1.0316e-04 | Loss_b: 7.8204e-05\n",
      "Step: NaN | Loss: 7.8703e-06 | Loss_d: 2.8893e-04 Loss_e: 1.0318e-04 | Loss_b: 7.9440e-05\n",
      "Step: NaN | Loss: 8.1268e-06 | Loss_d: 2.7719e-04 Loss_e: 1.1485e-04 | Loss_b: 9.4870e-05\n",
      "Step: NaN | Loss: 7.8559e-06 | Loss_d: 2.8558e-04 Loss_e: 1.0390e-04 | Loss_b: 8.1199e-05\n",
      "Step: NaN | Loss: 7.8079e-06 | Loss_d: 2.8511e-04 Loss_e: 1.0237e-04 | Loss_b: 8.0319e-05\n",
      "Step: NaN | Loss: 7.7985e-06 | Loss_d: 2.8487e-04 Loss_e: 1.0233e-04 | Loss_b: 8.0042e-05\n",
      "Step: NaN | Loss: 7.7760e-06 | Loss_d: 2.8435e-04 Loss_e: 1.0216e-04 | Loss_b: 7.9387e-05\n",
      "Step: NaN | Loss: 8.0235e-06 | Loss_d: 2.8507e-04 Loss_e: 1.0576e-04 | Loss_b: 8.9895e-05\n",
      "Step: NaN | Loss: 7.7756e-06 | Loss_d: 2.8429e-04 Loss_e: 1.0217e-04 | Loss_b: 7.9406e-05\n",
      "Step: NaN | Loss: 7.7606e-06 | Loss_d: 2.8440e-04 Loss_e: 1.0209e-04 | Loss_b: 7.8481e-05\n",
      "Step: NaN | Loss: 7.7617e-06 | Loss_d: 2.8615e-04 Loss_e: 1.0312e-04 | Loss_b: 7.5763e-05\n",
      "Step: NaN | Loss: 7.7490e-06 | Loss_d: 2.8499e-04 Loss_e: 1.0232e-04 | Loss_b: 7.6957e-05\n",
      "Step: NaN | Loss: 7.7220e-06 | Loss_d: 2.8203e-04 Loss_e: 1.0279e-04 | Loss_b: 7.7840e-05\n",
      "Step: NaN | Loss: 7.6978e-06 | Loss_d: 2.7120e-04 Loss_e: 1.0645e-04 | Loss_b: 8.3552e-05\n",
      "Step: NaN | Loss: 7.6909e-06 | Loss_d: 2.7450e-04 Loss_e: 1.0497e-04 | Loss_b: 8.1332e-05\n",
      "Step: NaN | Loss: 7.6485e-06 | Loss_d: 2.7435e-04 Loss_e: 1.0524e-04 | Loss_b: 7.8668e-05\n",
      "Step: NaN | Loss: 8.2941e-06 | Loss_d: 2.7753e-04 Loss_e: 1.2106e-04 | Loss_b: 9.8344e-05\n",
      "Step: NaN | Loss: 7.6485e-06 | Loss_d: 2.7435e-04 Loss_e: 1.0527e-04 | Loss_b: 7.8641e-05\n",
      "Step: NaN | Loss: 7.7466e-06 | Loss_d: 2.7310e-04 Loss_e: 1.0657e-04 | Loss_b: 8.4455e-05\n",
      "Step: NaN | Loss: 7.6388e-06 | Loss_d: 2.7402e-04 Loss_e: 1.0539e-04 | Loss_b: 7.8272e-05\n",
      "Step: NaN | Loss: 7.6365e-06 | Loss_d: 2.7378e-04 Loss_e: 1.0570e-04 | Loss_b: 7.8056e-05\n",
      "Step: NaN | Loss: 7.6339e-06 | Loss_d: 2.7292e-04 Loss_e: 1.0711e-04 | Loss_b: 7.7351e-05\n",
      "Step: NaN | Loss: 7.6335e-06 | Loss_d: 2.7312e-04 Loss_e: 1.0674e-04 | Loss_b: 7.7501e-05\n",
      "Step: NaN | Loss: 7.6227e-06 | Loss_d: 2.7236e-04 Loss_e: 1.0640e-04 | Loss_b: 7.7949e-05\n",
      "Step: NaN | Loss: 7.6292e-06 | Loss_d: 2.6974e-04 Loss_e: 1.0681e-04 | Loss_b: 8.0543e-05\n",
      "Step: NaN | Loss: 7.6158e-06 | Loss_d: 2.7118e-04 Loss_e: 1.0624e-04 | Loss_b: 7.8882e-05\n",
      "Step: NaN | Loss: 7.6251e-06 | Loss_d: 2.6971e-04 Loss_e: 1.0595e-04 | Loss_b: 8.1195e-05\n",
      "Step: NaN | Loss: 7.6113e-06 | Loss_d: 2.7061e-04 Loss_e: 1.0609e-04 | Loss_b: 7.9336e-05\n",
      "Step: NaN | Loss: 7.6039e-06 | Loss_d: 2.7035e-04 Loss_e: 1.0614e-04 | Loss_b: 7.9090e-05\n",
      "Step: NaN | Loss: 7.5891e-06 | Loss_d: 2.6963e-04 Loss_e: 1.0652e-04 | Loss_b: 7.8553e-05\n",
      "Step: NaN | Loss: 7.8770e-06 | Loss_d: 2.7283e-04 Loss_e: 1.1234e-04 | Loss_b: 8.6768e-05\n",
      "Step: NaN | Loss: 7.5890e-06 | Loss_d: 2.6958e-04 Loss_e: 1.0658e-04 | Loss_b: 7.8541e-05\n",
      "Step: NaN | Loss: 7.5734e-06 | Loss_d: 2.6868e-04 Loss_e: 1.0738e-04 | Loss_b: 7.7691e-05\n",
      "Step: NaN | Loss: 7.6127e-06 | Loss_d: 2.6587e-04 Loss_e: 1.1170e-04 | Loss_b: 7.8535e-05\n",
      "Step: NaN | Loss: 7.5681e-06 | Loss_d: 2.6783e-04 Loss_e: 1.0834e-04 | Loss_b: 7.7268e-05\n",
      "Step: NaN | Loss: 7.5590e-06 | Loss_d: 2.6778e-04 Loss_e: 1.0833e-04 | Loss_b: 7.6779e-05\n",
      "Step: NaN | Loss: 7.5412e-06 | Loss_d: 2.6768e-04 Loss_e: 1.0843e-04 | Loss_b: 7.5713e-05\n",
      "Step: NaN | Loss: 7.8985e-06 | Loss_d: 2.6894e-04 Loss_e: 1.1241e-04 | Loss_b: 9.1875e-05\n",
      "Step: NaN | Loss: 7.5411e-06 | Loss_d: 2.6768e-04 Loss_e: 1.0845e-04 | Loss_b: 7.5686e-05\n",
      "Step: NaN | Loss: 7.5265e-06 | Loss_d: 2.6745e-04 Loss_e: 1.0836e-04 | Loss_b: 7.5136e-05\n",
      "Step: NaN | Loss: 7.4918e-06 | Loss_d: 2.6669e-04 Loss_e: 1.0866e-04 | Loss_b: 7.3509e-05\n",
      "Step: NaN | Loss: 7.8798e-06 | Loss_d: 2.6731e-04 Loss_e: 1.2560e-04 | Loss_b: 7.9211e-05\n",
      "Step: NaN | Loss: 7.4883e-06 | Loss_d: 2.6646e-04 Loss_e: 1.0910e-04 | Loss_b: 7.3092e-05\n",
      "Step: NaN | Loss: 7.4614e-06 | Loss_d: 2.6426e-04 Loss_e: 1.0893e-04 | Loss_b: 7.3847e-05\n",
      "Step: NaN | Loss: 7.5009e-06 | Loss_d: 2.5609e-04 Loss_e: 1.1161e-04 | Loss_b: 8.1707e-05\n",
      "Step: NaN | Loss: 7.4484e-06 | Loss_d: 2.6144e-04 Loss_e: 1.0923e-04 | Loss_b: 7.5600e-05\n",
      "Step: NaN | Loss: 7.4413e-06 | Loss_d: 2.6021e-04 Loss_e: 1.0953e-04 | Loss_b: 7.6102e-05\n",
      "Step: NaN | Loss: 7.4387e-06 | Loss_d: 2.5566e-04 Loss_e: 1.1106e-04 | Loss_b: 7.8969e-05\n",
      "Step: NaN | Loss: 7.4347e-06 | Loss_d: 2.5759e-04 Loss_e: 1.1032e-04 | Loss_b: 7.7536e-05\n",
      "Step: NaN | Loss: 7.4268e-06 | Loss_d: 2.5733e-04 Loss_e: 1.0998e-04 | Loss_b: 7.7664e-05\n",
      "Step: NaN | Loss: 7.4154e-06 | Loss_d: 2.5643e-04 Loss_e: 1.0890e-04 | Loss_b: 7.8960e-05\n",
      "Step: NaN | Loss: 7.4151e-06 | Loss_d: 2.5654e-04 Loss_e: 1.0903e-04 | Loss_b: 7.8694e-05\n",
      "Step: NaN | Loss: 7.3979e-06 | Loss_d: 2.5644e-04 Loss_e: 1.0949e-04 | Loss_b: 7.7313e-05\n",
      "Step: NaN | Loss: 7.3902e-06 | Loss_d: 2.5633e-04 Loss_e: 1.1272e-04 | Loss_b: 7.3737e-05\n",
      "Step: NaN | Loss: 7.3812e-06 | Loss_d: 2.5631e-04 Loss_e: 1.1105e-04 | Loss_b: 7.4878e-05\n",
      "Step: NaN | Loss: 7.3436e-06 | Loss_d: 2.5687e-04 Loss_e: 1.0921e-04 | Loss_b: 7.3905e-05\n",
      "Step: NaN | Loss: 7.3790e-06 | Loss_d: 2.6078e-04 Loss_e: 1.0661e-04 | Loss_b: 7.4718e-05\n",
      "Step: NaN | Loss: 7.3220e-06 | Loss_d: 2.5805e-04 Loss_e: 1.0732e-04 | Loss_b: 7.3323e-05\n",
      "Step: NaN | Loss: 7.3219e-06 | Loss_d: 2.5520e-04 Loss_e: 1.1010e-04 | Loss_b: 7.3387e-05\n",
      "Step: NaN | Loss: 7.3054e-06 | Loss_d: 2.5639e-04 Loss_e: 1.0840e-04 | Loss_b: 7.2906e-05\n",
      "Step: NaN | Loss: 7.3056e-06 | Loss_d: 2.5592e-04 Loss_e: 1.0893e-04 | Loss_b: 7.2868e-05\n",
      "Step: NaN | Loss: 7.3019e-06 | Loss_d: 2.5615e-04 Loss_e: 1.0862e-04 | Loss_b: 7.2716e-05\n",
      "Step: NaN | Loss: 7.2957e-06 | Loss_d: 2.5589e-04 Loss_e: 1.0826e-04 | Loss_b: 7.2969e-05\n",
      "Step: NaN | Loss: 7.2944e-06 | Loss_d: 2.5504e-04 Loss_e: 1.0734e-04 | Loss_b: 7.4667e-05\n",
      "Step: NaN | Loss: 7.2903e-06 | Loss_d: 2.5539e-04 Loss_e: 1.0767e-04 | Loss_b: 7.3737e-05\n",
      "Step: NaN | Loss: 7.2846e-06 | Loss_d: 2.5553e-04 Loss_e: 1.0736e-04 | Loss_b: 7.3564e-05\n",
      "Step: NaN | Loss: 7.2729e-06 | Loss_d: 2.5620e-04 Loss_e: 1.0651e-04 | Loss_b: 7.3040e-05\n",
      "Step: NaN | Loss: 7.4829e-06 | Loss_d: 2.6287e-04 Loss_e: 1.1100e-04 | Loss_b: 7.4471e-05\n",
      "Step: NaN | Loss: 7.2727e-06 | Loss_d: 2.5633e-04 Loss_e: 1.0643e-04 | Loss_b: 7.2982e-05\n",
      "Step: NaN | Loss: 7.2536e-06 | Loss_d: 2.5532e-04 Loss_e: 1.0640e-04 | Loss_b: 7.2872e-05\n",
      "Step: NaN | Loss: 7.2443e-06 | Loss_d: 2.5205e-04 Loss_e: 1.0792e-04 | Loss_b: 7.4071e-05\n",
      "Step: NaN | Loss: 7.2352e-06 | Loss_d: 2.5325e-04 Loss_e: 1.0698e-04 | Loss_b: 7.3257e-05\n",
      "Step: NaN | Loss: 7.2257e-06 | Loss_d: 2.5330e-04 Loss_e: 1.0620e-04 | Loss_b: 7.3423e-05\n",
      "Step: NaN | Loss: 7.3441e-06 | Loss_d: 2.5627e-04 Loss_e: 1.0637e-04 | Loss_b: 7.7372e-05\n",
      "Step: NaN | Loss: 7.2256e-06 | Loss_d: 2.5332e-04 Loss_e: 1.0614e-04 | Loss_b: 7.3457e-05\n",
      "Step: NaN | Loss: 7.2231e-06 | Loss_d: 2.5502e-04 Loss_e: 1.0617e-04 | Loss_b: 7.1578e-05\n",
      "Step: NaN | Loss: 7.2224e-06 | Loss_d: 2.5448e-04 Loss_e: 1.0614e-04 | Loss_b: 7.2111e-05\n",
      "Step: NaN | Loss: 7.2195e-06 | Loss_d: 2.5495e-04 Loss_e: 1.0583e-04 | Loss_b: 7.1772e-05\n",
      "Step: NaN | Loss: 7.2446e-06 | Loss_d: 2.5730e-04 Loss_e: 1.0522e-04 | Loss_b: 7.1534e-05\n",
      "Step: NaN | Loss: 7.2193e-06 | Loss_d: 2.5510e-04 Loss_e: 1.0575e-04 | Loss_b: 7.1690e-05\n",
      "Step: NaN | Loss: 7.2158e-06 | Loss_d: 2.5478e-04 Loss_e: 1.0597e-04 | Loss_b: 7.1582e-05\n",
      "Step: NaN | Loss: 7.2094e-06 | Loss_d: 2.5357e-04 Loss_e: 1.0690e-04 | Loss_b: 7.1477e-05\n",
      "Step: NaN | Loss: 7.3906e-06 | Loss_d: 2.4887e-04 Loss_e: 1.1339e-04 | Loss_b: 8.0540e-05\n",
      "Step: NaN | Loss: 7.2094e-06 | Loss_d: 2.5356e-04 Loss_e: 1.0691e-04 | Loss_b: 7.1478e-05\n",
      "Step: NaN | Loss: 7.1938e-06 | Loss_d: 2.5194e-04 Loss_e: 1.0715e-04 | Loss_b: 7.1924e-05\n",
      "Step: NaN | Loss: 7.1987e-06 | Loss_d: 2.4676e-04 Loss_e: 1.0897e-04 | Loss_b: 7.5574e-05\n",
      "Step: NaN | Loss: 7.1827e-06 | Loss_d: 2.4931e-04 Loss_e: 1.0781e-04 | Loss_b: 7.3226e-05\n",
      "Step: NaN | Loss: 7.1732e-06 | Loss_d: 2.4931e-04 Loss_e: 1.0768e-04 | Loss_b: 7.2787e-05\n",
      "Step: NaN | Loss: 7.1894e-06 | Loss_d: 2.4961e-04 Loss_e: 1.0867e-04 | Loss_b: 7.2471e-05\n",
      "Step: NaN | Loss: 7.1689e-06 | Loss_d: 2.4935e-04 Loss_e: 1.0773e-04 | Loss_b: 7.2438e-05\n",
      "Step: NaN | Loss: 7.1656e-06 | Loss_d: 2.4771e-04 Loss_e: 1.0864e-04 | Loss_b: 7.2972e-05\n",
      "Step: NaN | Loss: 7.1649e-06 | Loss_d: 2.4818e-04 Loss_e: 1.0835e-04 | Loss_b: 7.2747e-05\n",
      "Step: NaN | Loss: 7.1597e-06 | Loss_d: 2.4799e-04 Loss_e: 1.0813e-04 | Loss_b: 7.2849e-05\n",
      "Step: NaN | Loss: 7.1699e-06 | Loss_d: 2.4735e-04 Loss_e: 1.0767e-04 | Loss_b: 7.4556e-05\n",
      "Step: NaN | Loss: 7.1575e-06 | Loss_d: 2.4778e-04 Loss_e: 1.0792e-04 | Loss_b: 7.3135e-05\n",
      "Step: NaN | Loss: 7.1475e-06 | Loss_d: 2.4726e-04 Loss_e: 1.0718e-04 | Loss_b: 7.3790e-05\n",
      "Step: NaN | Loss: 7.1770e-06 | Loss_d: 2.4574e-04 Loss_e: 1.0544e-04 | Loss_b: 7.8824e-05\n",
      "Step: NaN | Loss: 7.1444e-06 | Loss_d: 2.4683e-04 Loss_e: 1.0660e-04 | Loss_b: 7.4619e-05\n",
      "Step: NaN | Loss: 7.1408e-06 | Loss_d: 2.4648e-04 Loss_e: 1.0675e-04 | Loss_b: 7.4617e-05\n",
      "Step: NaN | Loss: 7.1324e-06 | Loss_d: 2.4512e-04 Loss_e: 1.0749e-04 | Loss_b: 7.4722e-05\n",
      "Step: NaN | Loss: 7.2408e-06 | Loss_d: 2.4002e-04 Loss_e: 1.1512e-04 | Loss_b: 7.8680e-05\n",
      "Step: NaN | Loss: 7.1316e-06 | Loss_d: 2.4467e-04 Loss_e: 1.0781e-04 | Loss_b: 7.4803e-05\n",
      "Step: NaN | Loss: 7.1088e-06 | Loss_d: 2.4503e-04 Loss_e: 1.0790e-04 | Loss_b: 7.2990e-05\n",
      "Step: NaN | Loss: 7.2204e-06 | Loss_d: 2.4757e-04 Loss_e: 1.1307e-04 | Loss_b: 7.1966e-05\n",
      "Step: NaN | Loss: 7.1048e-06 | Loss_d: 2.4531e-04 Loss_e: 1.0820e-04 | Loss_b: 7.2173e-05\n",
      "Step: NaN | Loss: 7.0914e-06 | Loss_d: 2.4429e-04 Loss_e: 1.0867e-04 | Loss_b: 7.1921e-05\n",
      "Step: NaN | Loss: 7.1123e-06 | Loss_d: 2.4073e-04 Loss_e: 1.1327e-04 | Loss_b: 7.2128e-05\n",
      "Step: NaN | Loss: 7.0852e-06 | Loss_d: 2.4304e-04 Loss_e: 1.0968e-04 | Loss_b: 7.1780e-05\n",
      "Step: NaN | Loss: 7.0794e-06 | Loss_d: 2.4063e-04 Loss_e: 1.0982e-04 | Loss_b: 7.3717e-05\n",
      "Step: NaN | Loss: 7.0791e-06 | Loss_d: 2.4107e-04 Loss_e: 1.0978e-04 | Loss_b: 7.3290e-05\n",
      "Step: NaN | Loss: 7.0744e-06 | Loss_d: 2.4101e-04 Loss_e: 1.0960e-04 | Loss_b: 7.3248e-05\n",
      "Step: NaN | Loss: 7.1216e-06 | Loss_d: 2.4141e-04 Loss_e: 1.1018e-04 | Loss_b: 7.5097e-05\n",
      "Step: NaN | Loss: 7.0743e-06 | Loss_d: 2.4101e-04 Loss_e: 1.0958e-04 | Loss_b: 7.3266e-05\n",
      "Step: NaN | Loss: 7.0698e-06 | Loss_d: 2.4101e-04 Loss_e: 1.0929e-04 | Loss_b: 7.3287e-05\n",
      "Step: NaN | Loss: 7.0549e-06 | Loss_d: 2.4105e-04 Loss_e: 1.0819e-04 | Loss_b: 7.3452e-05\n",
      "Step: NaN | Loss: 7.0550e-06 | Loss_d: 2.4218e-04 Loss_e: 1.0441e-04 | Loss_b: 7.6100e-05\n",
      "Step: NaN | Loss: 7.0397e-06 | Loss_d: 2.4142e-04 Loss_e: 1.0593e-04 | Loss_b: 7.4422e-05\n",
      "Step: NaN | Loss: 7.0659e-06 | Loss_d: 2.4469e-04 Loss_e: 1.0592e-04 | Loss_b: 7.2734e-05\n",
      "Step: NaN | Loss: 7.0285e-06 | Loss_d: 2.4249e-04 Loss_e: 1.0586e-04 | Loss_b: 7.2761e-05\n",
      "Step: NaN | Loss: 7.0178e-06 | Loss_d: 2.4190e-04 Loss_e: 1.0608e-04 | Loss_b: 7.2482e-05\n",
      "Step: NaN | Loss: 7.0169e-06 | Loss_d: 2.3992e-04 Loss_e: 1.0818e-04 | Loss_b: 7.2315e-05\n",
      "Step: NaN | Loss: 7.0090e-06 | Loss_d: 2.4080e-04 Loss_e: 1.0693e-04 | Loss_b: 7.2211e-05\n",
      "Step: NaN | Loss: 6.9904e-06 | Loss_d: 2.3736e-04 Loss_e: 1.0757e-04 | Loss_b: 7.3898e-05\n",
      "Step: NaN | Loss: 7.2197e-06 | Loss_d: 2.2755e-04 Loss_e: 1.1535e-04 | Loss_b: 8.9669e-05\n",
      "Step: NaN | Loss: 6.9902e-06 | Loss_d: 2.3697e-04 Loss_e: 1.0769e-04 | Loss_b: 7.4162e-05\n",
      "Step: NaN | Loss: 6.9839e-06 | Loss_d: 2.3635e-04 Loss_e: 1.0602e-04 | Loss_b: 7.6065e-05\n",
      "Step: NaN | Loss: 6.9813e-06 | Loss_d: 2.3653e-04 Loss_e: 1.0655e-04 | Loss_b: 7.5193e-05\n",
      "Step: NaN | Loss: 6.9787e-06 | Loss_d: 2.3565e-04 Loss_e: 1.0571e-04 | Loss_b: 7.6773e-05\n",
      "Step: NaN | Loss: 6.9748e-06 | Loss_d: 2.3603e-04 Loss_e: 1.0602e-04 | Loss_b: 7.5846e-05\n",
      "Step: NaN | Loss: 6.9729e-06 | Loss_d: 2.3598e-04 Loss_e: 1.0603e-04 | Loss_b: 7.5764e-05\n",
      "Step: NaN | Loss: 6.9664e-06 | Loss_d: 2.3582e-04 Loss_e: 1.0610e-04 | Loss_b: 7.5474e-05\n",
      "Step: NaN | Loss: 6.9679e-06 | Loss_d: 2.3528e-04 Loss_e: 1.0692e-04 | Loss_b: 7.5274e-05\n",
      "Step: NaN | Loss: 6.9600e-06 | Loss_d: 2.3550e-04 Loss_e: 1.0638e-04 | Loss_b: 7.5119e-05\n",
      "Step: NaN | Loss: 6.9468e-06 | Loss_d: 2.3540e-04 Loss_e: 1.0608e-04 | Loss_b: 7.4734e-05\n",
      "Step: NaN | Loss: 7.0089e-06 | Loss_d: 2.3563e-04 Loss_e: 1.0555e-04 | Loss_b: 7.8750e-05\n",
      "Step: NaN | Loss: 6.9444e-06 | Loss_d: 2.3537e-04 Loss_e: 1.0592e-04 | Loss_b: 7.4782e-05\n",
      "Step: NaN | Loss: 6.9416e-06 | Loss_d: 2.3471e-04 Loss_e: 1.0624e-04 | Loss_b: 7.4949e-05\n",
      "Step: NaN | Loss: 6.9482e-06 | Loss_d: 2.3219e-04 Loss_e: 1.0771e-04 | Loss_b: 7.6404e-05\n",
      "Step: NaN | Loss: 6.9405e-06 | Loss_d: 2.3400e-04 Loss_e: 1.0661e-04 | Loss_b: 7.5218e-05\n",
      "Step: NaN | Loss: 6.9361e-06 | Loss_d: 2.3366e-04 Loss_e: 1.0647e-04 | Loss_b: 7.5436e-05\n",
      "Step: NaN | Loss: 6.9253e-06 | Loss_d: 2.3244e-04 Loss_e: 1.0604e-04 | Loss_b: 7.6442e-05\n",
      "Step: NaN | Loss: 7.0370e-06 | Loss_d: 2.2991e-04 Loss_e: 1.0713e-04 | Loss_b: 8.4581e-05\n",
      "Step: NaN | Loss: 6.9241e-06 | Loss_d: 2.3195e-04 Loss_e: 1.0591e-04 | Loss_b: 7.6990e-05\n",
      "Step: NaN | Loss: 6.9084e-06 | Loss_d: 2.3323e-04 Loss_e: 1.0479e-04 | Loss_b: 7.5898e-05\n",
      "Step: NaN | Loss: 7.1346e-06 | Loss_d: 2.4103e-04 Loss_e: 1.0662e-04 | Loss_b: 7.9809e-05\n",
      "Step: NaN | Loss: 6.9084e-06 | Loss_d: 2.3329e-04 Loss_e: 1.0475e-04 | Loss_b: 7.5871e-05\n",
      "Step: NaN | Loss: 6.8967e-06 | Loss_d: 2.3360e-04 Loss_e: 1.0455e-04 | Loss_b: 7.5057e-05\n",
      "Step: NaN | Loss: 6.9092e-06 | Loss_d: 2.3562e-04 Loss_e: 1.0471e-04 | Loss_b: 7.3627e-05\n",
      "Step: NaN | Loss: 6.8902e-06 | Loss_d: 2.3420e-04 Loss_e: 1.0443e-04 | Loss_b: 7.4192e-05\n",
      "Step: NaN | Loss: 6.8858e-06 | Loss_d: 2.3401e-04 Loss_e: 1.0448e-04 | Loss_b: 7.4067e-05\n",
      "Step: NaN | Loss: 6.8735e-06 | Loss_d: 2.3331e-04 Loss_e: 1.0482e-04 | Loss_b: 7.3689e-05\n",
      "Step: NaN | Loss: 6.9431e-06 | Loss_d: 2.3084e-04 Loss_e: 1.1027e-04 | Loss_b: 7.4875e-05\n",
      "Step: NaN | Loss: 6.8698e-06 | Loss_d: 2.3273e-04 Loss_e: 1.0534e-04 | Loss_b: 7.3523e-05\n",
      "Step: NaN | Loss: 6.8618e-06 | Loss_d: 2.3339e-04 Loss_e: 1.0459e-04 | Loss_b: 7.3134e-05\n",
      "Step: NaN | Loss: 6.8865e-06 | Loss_d: 2.3648e-04 Loss_e: 1.0262e-04 | Loss_b: 7.3501e-05\n",
      "Step: NaN | Loss: 6.8595e-06 | Loss_d: 2.3403e-04 Loss_e: 1.0400e-04 | Loss_b: 7.2950e-05\n",
      "Step: NaN | Loss: 6.8575e-06 | Loss_d: 2.3400e-04 Loss_e: 1.0388e-04 | Loss_b: 7.2980e-05\n",
      "Step: NaN | Loss: 6.8522e-06 | Loss_d: 2.3390e-04 Loss_e: 1.0343e-04 | Loss_b: 7.3214e-05\n",
      "Step: NaN | Loss: 6.8883e-06 | Loss_d: 2.3363e-04 Loss_e: 1.0197e-04 | Loss_b: 7.7108e-05\n",
      "Step: NaN | Loss: 6.8509e-06 | Loss_d: 2.3383e-04 Loss_e: 1.0312e-04 | Loss_b: 7.3516e-05\n",
      "Step: NaN | Loss: 6.8457e-06 | Loss_d: 2.3392e-04 Loss_e: 1.0252e-04 | Loss_b: 7.3716e-05\n",
      "Step: NaN | Loss: 6.8379e-06 | Loss_d: 2.3435e-04 Loss_e: 1.0040e-04 | Loss_b: 7.4932e-05\n",
      "Step: NaN | Loss: 6.8377e-06 | Loss_d: 2.3429e-04 Loss_e: 1.0064e-04 | Loss_b: 7.4744e-05\n",
      "Step: NaN | Loss: 6.8220e-06 | Loss_d: 2.3335e-04 Loss_e: 1.0050e-04 | Loss_b: 7.4885e-05\n",
      "Step: NaN | Loss: 6.9560e-06 | Loss_d: 2.3261e-04 Loss_e: 1.0437e-04 | Loss_b: 7.9793e-05\n",
      "Step: NaN | Loss: 6.8211e-06 | Loss_d: 2.3313e-04 Loss_e: 1.0054e-04 | Loss_b: 7.5011e-05\n",
      "Step: NaN | Loss: 6.8132e-06 | Loss_d: 2.3407e-04 Loss_e: 9.9913e-05 | Loss_b: 7.4219e-05\n",
      "Step: NaN | Loss: 6.8530e-06 | Loss_d: 2.3869e-04 Loss_e: 9.8263e-05 | Loss_b: 7.3640e-05\n",
      "Step: NaN | Loss: 6.8119e-06 | Loss_d: 2.3469e-04 Loss_e: 9.9574e-05 | Loss_b: 7.3862e-05\n",
      "Step: NaN | Loss: 6.8050e-06 | Loss_d: 2.3528e-04 Loss_e: 9.9147e-05 | Loss_b: 7.3295e-05\n",
      "Step: NaN | Loss: 6.7983e-06 | Loss_d: 2.3795e-04 Loss_e: 9.7771e-05 | Loss_b: 7.1589e-05\n",
      "Step: NaN | Loss: 6.7968e-06 | Loss_d: 2.3710e-04 Loss_e: 9.8127e-05 | Loss_b: 7.2000e-05\n",
      "Step: NaN | Loss: 6.7940e-06 | Loss_d: 2.3769e-04 Loss_e: 9.7905e-05 | Loss_b: 7.1467e-05\n",
      "Step: NaN | Loss: 6.7917e-06 | Loss_d: 2.3745e-04 Loss_e: 9.7983e-05 | Loss_b: 7.1493e-05\n",
      "Step: NaN | Loss: 6.7865e-06 | Loss_d: 2.3753e-04 Loss_e: 9.7707e-05 | Loss_b: 7.1368e-05\n",
      "Step: NaN | Loss: 6.7713e-06 | Loss_d: 2.3791e-04 Loss_e: 9.6666e-05 | Loss_b: 7.1119e-05\n",
      "Step: NaN | Loss: 6.8336e-06 | Loss_d: 2.4069e-04 Loss_e: 9.2992e-05 | Loss_b: 7.5743e-05\n",
      "Step: NaN | Loss: 6.7653e-06 | Loss_d: 2.3842e-04 Loss_e: 9.5597e-05 | Loss_b: 7.1317e-05\n",
      "Step: NaN | Loss: 6.7538e-06 | Loss_d: 2.3849e-04 Loss_e: 9.5483e-05 | Loss_b: 7.0673e-05\n",
      "Step: NaN | Loss: 6.7800e-06 | Loss_d: 2.3922e-04 Loss_e: 9.6343e-05 | Loss_b: 7.0658e-05\n",
      "Step: NaN | Loss: 6.7495e-06 | Loss_d: 2.3862e-04 Loss_e: 9.5507e-05 | Loss_b: 7.0265e-05\n",
      "Step: NaN | Loss: 6.7452e-06 | Loss_d: 2.3841e-04 Loss_e: 9.5449e-05 | Loss_b: 7.0274e-05\n",
      "Step: NaN | Loss: 6.7338e-06 | Loss_d: 2.3763e-04 Loss_e: 9.5373e-05 | Loss_b: 7.0449e-05\n",
      "Step: NaN | Loss: 6.8203e-06 | Loss_d: 2.3504e-04 Loss_e: 9.8841e-05 | Loss_b: 7.4751e-05\n",
      "Step: NaN | Loss: 6.7316e-06 | Loss_d: 2.3714e-04 Loss_e: 9.5469e-05 | Loss_b: 7.0707e-05\n",
      "Step: NaN | Loss: 6.8319e-06 | Loss_d: 2.3088e-04 Loss_e: 9.4995e-05 | Loss_b: 8.3455e-05\n",
      "Step: NaN | Loss: 6.7200e-06 | Loss_d: 2.3532e-04 Loss_e: 9.4717e-05 | Loss_b: 7.2582e-05\n",
      "Step: NaN | Loss: 6.6899e-06 | Loss_d: 2.3479e-04 Loss_e: 9.4314e-05 | Loss_b: 7.1712e-05\n",
      "Step: NaN | Loss: 6.7920e-06 | Loss_d: 2.3844e-04 Loss_e: 9.6094e-05 | Loss_b: 7.2407e-05\n",
      "Step: NaN | Loss: 6.6818e-06 | Loss_d: 2.3479e-04 Loss_e: 9.4238e-05 | Loss_b: 7.1301e-05\n",
      "Step: NaN | Loss: 6.6792e-06 | Loss_d: 2.3091e-04 Loss_e: 9.5613e-05 | Loss_b: 7.3650e-05\n",
      "Step: NaN | Loss: 6.6680e-06 | Loss_d: 2.3272e-04 Loss_e: 9.4857e-05 | Loss_b: 7.1929e-05\n",
      "Step: NaN | Loss: 6.6613e-06 | Loss_d: 2.3213e-04 Loss_e: 9.5019e-05 | Loss_b: 7.1955e-05\n",
      "Step: NaN | Loss: 6.6397e-06 | Loss_d: 2.2983e-04 Loss_e: 9.5783e-05 | Loss_b: 7.2197e-05\n",
      "Step: NaN | Loss: 6.6525e-06 | Loss_d: 2.2015e-04 Loss_e: 1.0241e-04 | Loss_b: 7.6018e-05\n",
      "Step: NaN | Loss: 6.6209e-06 | Loss_d: 2.2521e-04 Loss_e: 9.8106e-05 | Loss_b: 7.3367e-05\n",
      "Step: NaN | Loss: 6.6596e-06 | Loss_d: 2.2560e-04 Loss_e: 9.4886e-05 | Loss_b: 7.8518e-05\n",
      "Step: NaN | Loss: 6.6100e-06 | Loss_d: 2.2520e-04 Loss_e: 9.6786e-05 | Loss_b: 7.4043e-05\n",
      "Step: NaN | Loss: 6.5929e-06 | Loss_d: 2.2554e-04 Loss_e: 9.6722e-05 | Loss_b: 7.2745e-05\n",
      "Step: NaN | Loss: 6.5946e-06 | Loss_d: 2.2763e-04 Loss_e: 9.7760e-05 | Loss_b: 6.9722e-05\n",
      "Step: NaN | Loss: 6.5796e-06 | Loss_d: 2.2640e-04 Loss_e: 9.6964e-05 | Loss_b: 7.0848e-05\n",
      "Step: NaN | Loss: 6.5639e-06 | Loss_d: 2.2536e-04 Loss_e: 9.6564e-05 | Loss_b: 7.1347e-05\n",
      "Step: NaN | Loss: 6.7103e-06 | Loss_d: 2.2314e-04 Loss_e: 9.9801e-05 | Loss_b: 7.9102e-05\n",
      "Step: NaN | Loss: 6.5632e-06 | Loss_d: 2.2513e-04 Loss_e: 9.6540e-05 | Loss_b: 7.1562e-05\n",
      "Step: NaN | Loss: 6.5642e-06 | Loss_d: 2.2419e-04 Loss_e: 9.6696e-05 | Loss_b: 7.2399e-05\n",
      "Step: NaN | Loss: 6.5601e-06 | Loss_d: 2.2469e-04 Loss_e: 9.6604e-05 | Loss_b: 7.1754e-05\n",
      "Step: NaN | Loss: 6.5570e-06 | Loss_d: 2.2416e-04 Loss_e: 9.6801e-05 | Loss_b: 7.1895e-05\n",
      "Step: NaN | Loss: 6.5575e-06 | Loss_d: 2.2215e-04 Loss_e: 9.7744e-05 | Loss_b: 7.2996e-05\n",
      "Step: NaN | Loss: 6.5547e-06 | Loss_d: 2.2319e-04 Loss_e: 9.7218e-05 | Loss_b: 7.2311e-05\n",
      "Step: NaN | Loss: 6.5484e-06 | Loss_d: 2.2316e-04 Loss_e: 9.7122e-05 | Loss_b: 7.2058e-05\n",
      "Step: NaN | Loss: 6.5370e-06 | Loss_d: 2.2313e-04 Loss_e: 9.6997e-05 | Loss_b: 7.1532e-05\n",
      "Step: NaN | Loss: 6.8098e-06 | Loss_d: 2.2475e-04 Loss_e: 1.0256e-04 | Loss_b: 8.0687e-05\n",
      "Step: NaN | Loss: 6.5370e-06 | Loss_d: 2.2313e-04 Loss_e: 9.6998e-05 | Loss_b: 7.1531e-05\n",
      "Step: NaN | Loss: 6.5282e-06 | Loss_d: 2.2250e-04 Loss_e: 9.7686e-05 | Loss_b: 7.0941e-05\n",
      "Step: NaN | Loss: 6.6358e-06 | Loss_d: 2.2176e-04 Loss_e: 1.0253e-04 | Loss_b: 7.3288e-05\n",
      "Step: NaN | Loss: 6.5281e-06 | Loss_d: 2.2244e-04 Loss_e: 9.7778e-05 | Loss_b: 7.0904e-05\n",
      "Step: NaN | Loss: 6.5193e-06 | Loss_d: 2.2191e-04 Loss_e: 9.8100e-05 | Loss_b: 7.0592e-05\n",
      "Step: NaN | Loss: 6.6038e-06 | Loss_d: 2.2120e-04 Loss_e: 1.0081e-04 | Loss_b: 7.3649e-05\n",
      "Step: NaN | Loss: 6.5190e-06 | Loss_d: 2.2180e-04 Loss_e: 9.8199e-05 | Loss_b: 7.0580e-05\n",
      "Step: NaN | Loss: 6.5169e-06 | Loss_d: 2.2216e-04 Loss_e: 9.7700e-05 | Loss_b: 7.0592e-05\n",
      "Step: NaN | Loss: 6.5194e-06 | Loss_d: 2.2371e-04 Loss_e: 9.5941e-05 | Loss_b: 7.0955e-05\n",
      "Step: NaN | Loss: 6.5158e-06 | Loss_d: 2.2269e-04 Loss_e: 9.7035e-05 | Loss_b: 7.0663e-05\n",
      "Step: NaN | Loss: 6.5111e-06 | Loss_d: 2.2241e-04 Loss_e: 9.6960e-05 | Loss_b: 7.0742e-05\n",
      "Step: NaN | Loss: 6.5105e-06 | Loss_d: 2.2138e-04 Loss_e: 9.6847e-05 | Loss_b: 7.1841e-05\n",
      "Step: NaN | Loss: 6.5071e-06 | Loss_d: 2.2185e-04 Loss_e: 9.6864e-05 | Loss_b: 7.1156e-05\n",
      "Step: NaN | Loss: 6.5006e-06 | Loss_d: 2.2182e-04 Loss_e: 9.6726e-05 | Loss_b: 7.0927e-05\n",
      "Step: NaN | Loss: 6.4855e-06 | Loss_d: 2.2205e-04 Loss_e: 9.6330e-05 | Loss_b: 7.0191e-05\n",
      "Step: NaN | Loss: 6.6746e-06 | Loss_d: 2.3088e-04 Loss_e: 9.8104e-05 | Loss_b: 7.0922e-05\n",
      "Step: NaN | Loss: 6.4844e-06 | Loss_d: 2.2226e-04 Loss_e: 9.6250e-05 | Loss_b: 6.9999e-05\n",
      "Step: NaN | Loss: 6.4837e-06 | Loss_d: 2.2008e-04 Loss_e: 9.8097e-05 | Loss_b: 7.0293e-05\n",
      "Step: NaN | Loss: 6.4725e-06 | Loss_d: 2.2104e-04 Loss_e: 9.6983e-05 | Loss_b: 6.9770e-05\n",
      "Step: NaN | Loss: 6.4612e-06 | Loss_d: 2.2153e-04 Loss_e: 9.6478e-05 | Loss_b: 6.9111e-05\n",
      "Step: NaN | Loss: 6.4394e-06 | Loss_d: 2.2357e-04 Loss_e: 9.4952e-05 | Loss_b: 6.7292e-05\n",
      "Step: NaN | Loss: 6.8886e-06 | Loss_d: 2.3601e-04 Loss_e: 9.9115e-05 | Loss_b: 7.7600e-05\n",
      "Step: NaN | Loss: 6.4393e-06 | Loss_d: 2.2374e-04 Loss_e: 9.4862e-05 | Loss_b: 6.7201e-05\n",
      "Step: NaN | Loss: 6.4171e-06 | Loss_d: 2.2328e-04 Loss_e: 9.4674e-05 | Loss_b: 6.6522e-05\n",
      "Step: NaN | Loss: 6.4365e-06 | Loss_d: 2.2240e-04 Loss_e: 9.6510e-05 | Loss_b: 6.6726e-05\n",
      "Step: NaN | Loss: 6.4040e-06 | Loss_d: 2.2275e-04 Loss_e: 9.4890e-05 | Loss_b: 6.6046e-05\n",
      "Step: NaN | Loss: 6.3955e-06 | Loss_d: 2.2235e-04 Loss_e: 9.4577e-05 | Loss_b: 6.6253e-05\n",
      "Step: NaN | Loss: 6.3924e-06 | Loss_d: 2.2104e-04 Loss_e: 9.3762e-05 | Loss_b: 6.8201e-05\n",
      "Step: NaN | Loss: 6.3878e-06 | Loss_d: 2.2156e-04 Loss_e: 9.4032e-05 | Loss_b: 6.7132e-05\n",
      "Step: NaN | Loss: 6.3844e-06 | Loss_d: 2.2001e-04 Loss_e: 9.4092e-05 | Loss_b: 6.8417e-05\n",
      "Step: NaN | Loss: 6.3823e-06 | Loss_d: 2.2058e-04 Loss_e: 9.4056e-05 | Loss_b: 6.7758e-05\n",
      "Step: NaN | Loss: 6.3790e-06 | Loss_d: 2.1990e-04 Loss_e: 9.4396e-05 | Loss_b: 6.7897e-05\n",
      "Step: NaN | Loss: 6.3968e-06 | Loss_d: 2.1748e-04 Loss_e: 9.5978e-05 | Loss_b: 6.9797e-05\n",
      "Step: NaN | Loss: 6.3784e-06 | Loss_d: 2.1952e-04 Loss_e: 9.4603e-05 | Loss_b: 6.8034e-05\n",
      "Step: NaN | Loss: 6.3755e-06 | Loss_d: 2.1958e-04 Loss_e: 9.4405e-05 | Loss_b: 6.7998e-05\n",
      "Step: NaN | Loss: 6.3673e-06 | Loss_d: 2.1984e-04 Loss_e: 9.3690e-05 | Loss_b: 6.7960e-05\n",
      "Step: NaN | Loss: 6.4086e-06 | Loss_d: 2.2162e-04 Loss_e: 9.1917e-05 | Loss_b: 7.0433e-05\n",
      "Step: NaN | Loss: 6.3646e-06 | Loss_d: 2.2013e-04 Loss_e: 9.3098e-05 | Loss_b: 6.8099e-05\n",
      "Step: NaN | Loss: 6.3495e-06 | Loss_d: 2.1924e-04 Loss_e: 9.4322e-05 | Loss_b: 6.6865e-05\n",
      "Step: NaN | Loss: 6.3486e-06 | Loss_d: 2.1938e-04 Loss_e: 9.4036e-05 | Loss_b: 6.6959e-05\n",
      "Step: NaN | Loss: 6.3383e-06 | Loss_d: 2.1899e-04 Loss_e: 9.4858e-05 | Loss_b: 6.5902e-05\n",
      "Step: NaN | Loss: 6.3294e-06 | Loss_d: 2.1895e-04 Loss_e: 9.4204e-05 | Loss_b: 6.6062e-05\n",
      "Step: NaN | Loss: 6.3213e-06 | Loss_d: 2.1901e-04 Loss_e: 9.4038e-05 | Loss_b: 6.5686e-05\n",
      "Step: NaN | Loss: 6.3079e-06 | Loss_d: 2.1928e-04 Loss_e: 9.3675e-05 | Loss_b: 6.4976e-05\n",
      "Step: NaN | Loss: 6.3078e-06 | Loss_d: 2.1926e-04 Loss_e: 9.3684e-05 | Loss_b: 6.4983e-05\n",
      "Step: NaN | Loss: 6.2950e-06 | Loss_d: 2.1827e-04 Loss_e: 9.3800e-05 | Loss_b: 6.5093e-05\n",
      "Step: NaN | Loss: 6.3075e-06 | Loss_d: 2.1514e-04 Loss_e: 9.5362e-05 | Loss_b: 6.7412e-05\n",
      "Step: NaN | Loss: 6.2875e-06 | Loss_d: 2.1694e-04 Loss_e: 9.4177e-05 | Loss_b: 6.5595e-05\n",
      "Step: NaN | Loss: 6.2717e-06 | Loss_d: 2.1694e-04 Loss_e: 9.3584e-05 | Loss_b: 6.5241e-05\n",
      "Step: NaN | Loss: 6.3191e-06 | Loss_d: 2.1820e-04 Loss_e: 9.3998e-05 | Loss_b: 6.6407e-05\n",
      "Step: NaN | Loss: 6.2669e-06 | Loss_d: 2.1705e-04 Loss_e: 9.3285e-05 | Loss_b: 6.5144e-05\n",
      "Step: NaN | Loss: 6.2537e-06 | Loss_d: 2.1562e-04 Loss_e: 9.3088e-05 | Loss_b: 6.5982e-05\n",
      "Step: NaN | Loss: 6.2963e-06 | Loss_d: 2.1035e-04 Loss_e: 9.3940e-05 | Loss_b: 7.2943e-05\n",
      "Step: NaN | Loss: 6.2500e-06 | Loss_d: 2.1439e-04 Loss_e: 9.3050e-05 | Loss_b: 6.7022e-05\n",
      "Step: NaN | Loss: 6.2371e-06 | Loss_d: 2.1443e-04 Loss_e: 9.2412e-05 | Loss_b: 6.6843e-05\n",
      "Step: NaN | Loss: 6.2366e-06 | Loss_d: 2.1480e-04 Loss_e: 9.0465e-05 | Loss_b: 6.8392e-05\n",
      "Step: NaN | Loss: 6.2265e-06 | Loss_d: 2.1458e-04 Loss_e: 9.1307e-05 | Loss_b: 6.7171e-05\n",
      "Step: NaN | Loss: 6.2044e-06 | Loss_d: 2.1447e-04 Loss_e: 9.0785e-05 | Loss_b: 6.6472e-05\n",
      "Step: NaN | Loss: 6.1760e-06 | Loss_d: 2.1460e-04 Loss_e: 8.9767e-05 | Loss_b: 6.5657e-05\n",
      "Step: NaN | Loss: 6.1739e-06 | Loss_d: 2.1450e-04 Loss_e: 8.9838e-05 | Loss_b: 6.5565e-05\n",
      "Step: NaN | Loss: 6.1637e-06 | Loss_d: 2.1800e-04 Loss_e: 8.7380e-05 | Loss_b: 6.3912e-05\n",
      "Step: NaN | Loss: 6.1491e-06 | Loss_d: 2.1638e-04 Loss_e: 8.8291e-05 | Loss_b: 6.3746e-05\n",
      "Step: NaN | Loss: 6.1350e-06 | Loss_d: 2.1587e-04 Loss_e: 8.7771e-05 | Loss_b: 6.3933e-05\n",
      "Step: NaN | Loss: 6.1330e-06 | Loss_d: 2.1411e-04 Loss_e: 8.6745e-05 | Loss_b: 6.6599e-05\n",
      "Step: NaN | Loss: 6.1232e-06 | Loss_d: 2.1489e-04 Loss_e: 8.7024e-05 | Loss_b: 6.4954e-05\n",
      "Step: NaN | Loss: 6.1015e-06 | Loss_d: 2.1297e-04 Loss_e: 8.7341e-05 | Loss_b: 6.5255e-05\n",
      "Step: NaN | Loss: 6.1708e-06 | Loss_d: 2.0646e-04 Loss_e: 9.2602e-05 | Loss_b: 7.0652e-05\n",
      "Step: NaN | Loss: 6.0953e-06 | Loss_d: 2.1136e-04 Loss_e: 8.7947e-05 | Loss_b: 6.5887e-05\n",
      "Step: NaN | Loss: 6.0761e-06 | Loss_d: 2.1108e-04 Loss_e: 8.8070e-05 | Loss_b: 6.4898e-05\n",
      "Step: NaN | Loss: 6.0703e-06 | Loss_d: 2.1045e-04 Loss_e: 8.9408e-05 | Loss_b: 6.3838e-05\n",
      "Step: NaN | Loss: 6.0588e-06 | Loss_d: 2.1063e-04 Loss_e: 8.8636e-05 | Loss_b: 6.3740e-05\n",
      "Step: NaN | Loss: 6.0314e-06 | Loss_d: 2.1015e-04 Loss_e: 8.7378e-05 | Loss_b: 6.3840e-05\n",
      "Step: NaN | Loss: 6.0408e-06 | Loss_d: 2.1015e-04 Loss_e: 8.5629e-05 | Loss_b: 6.6156e-05\n",
      "Step: NaN | Loss: 6.0119e-06 | Loss_d: 2.0976e-04 Loss_e: 8.5949e-05 | Loss_b: 6.4484e-05\n",
      "Step: NaN | Loss: 6.0118e-06 | Loss_d: 2.1153e-04 Loss_e: 8.4706e-05 | Loss_b: 6.3959e-05\n",
      "Step: NaN | Loss: 6.0011e-06 | Loss_d: 2.1058e-04 Loss_e: 8.5163e-05 | Loss_b: 6.3808e-05\n",
      "Step: NaN | Loss: 5.9937e-06 | Loss_d: 2.1022e-04 Loss_e: 8.5014e-05 | Loss_b: 6.3872e-05\n",
      "Step: NaN | Loss: 5.9889e-06 | Loss_d: 2.0911e-04 Loss_e: 8.4910e-05 | Loss_b: 6.4801e-05\n",
      "Step: NaN | Loss: 5.9860e-06 | Loss_d: 2.0948e-04 Loss_e: 8.4856e-05 | Loss_b: 6.4316e-05\n",
      "Step: NaN | Loss: 5.9693e-06 | Loss_d: 2.0950e-04 Loss_e: 8.4374e-05 | Loss_b: 6.3767e-05\n",
      "Step: NaN | Loss: 5.9840e-06 | Loss_d: 2.1111e-04 Loss_e: 8.4293e-05 | Loss_b: 6.3123e-05\n",
      "Step: NaN | Loss: 5.9594e-06 | Loss_d: 2.0984e-04 Loss_e: 8.3993e-05 | Loss_b: 6.3219e-05\n",
      "Step: NaN | Loss: 5.9556e-06 | Loss_d: 2.0907e-04 Loss_e: 8.3976e-05 | Loss_b: 6.3780e-05\n",
      "Step: NaN | Loss: 5.9595e-06 | Loss_d: 2.0612e-04 Loss_e: 8.4117e-05 | Loss_b: 6.6819e-05\n",
      "Step: NaN | Loss: 5.9534e-06 | Loss_d: 2.0794e-04 Loss_e: 8.3989e-05 | Loss_b: 6.4762e-05\n",
      "Step: NaN | Loss: 5.9416e-06 | Loss_d: 2.0742e-04 Loss_e: 8.3690e-05 | Loss_b: 6.4875e-05\n",
      "Step: NaN | Loss: 5.9306e-06 | Loss_d: 2.0567e-04 Loss_e: 8.3059e-05 | Loss_b: 6.6598e-05\n",
      "Step: NaN | Loss: 5.9279e-06 | Loss_d: 2.0616e-04 Loss_e: 8.3158e-05 | Loss_b: 6.5848e-05\n",
      "Step: NaN | Loss: 5.9166e-06 | Loss_d: 2.0615e-04 Loss_e: 8.3406e-05 | Loss_b: 6.4934e-05\n",
      "Step: NaN | Loss: 5.9934e-06 | Loss_d: 2.0748e-04 Loss_e: 8.6287e-05 | Loss_b: 6.5325e-05\n",
      "Step: NaN | Loss: 5.9154e-06 | Loss_d: 2.0619e-04 Loss_e: 8.3569e-05 | Loss_b: 6.4662e-05\n",
      "Step: NaN | Loss: 5.9134e-06 | Loss_d: 2.0627e-04 Loss_e: 8.3460e-05 | Loss_b: 6.4568e-05\n",
      "Step: NaN | Loss: 5.9123e-06 | Loss_d: 2.0664e-04 Loss_e: 8.3120e-05 | Loss_b: 6.4478e-05\n",
      "Step: NaN | Loss: 5.9114e-06 | Loss_d: 2.0648e-04 Loss_e: 8.3240e-05 | Loss_b: 6.4460e-05\n",
      "Step: NaN | Loss: 5.9054e-06 | Loss_d: 2.0653e-04 Loss_e: 8.3030e-05 | Loss_b: 6.4255e-05\n",
      "Step: NaN | Loss: 5.9031e-06 | Loss_d: 2.0708e-04 Loss_e: 8.2527e-05 | Loss_b: 6.4072e-05\n",
      "Step: NaN | Loss: 5.8999e-06 | Loss_d: 2.0678e-04 Loss_e: 8.2678e-05 | Loss_b: 6.4032e-05\n",
      "Step: NaN | Loss: 5.8948e-06 | Loss_d: 2.0580e-04 Loss_e: 8.2885e-05 | Loss_b: 6.4496e-05\n",
      "Step: NaN | Loss: 5.9110e-06 | Loss_d: 2.0249e-04 Loss_e: 8.4260e-05 | Loss_b: 6.7405e-05\n",
      "Step: NaN | Loss: 5.8933e-06 | Loss_d: 2.0498e-04 Loss_e: 8.3115e-05 | Loss_b: 6.4997e-05\n",
      "Step: NaN | Loss: 5.8895e-06 | Loss_d: 2.0477e-04 Loss_e: 8.3102e-05 | Loss_b: 6.4988e-05\n",
      "Step: NaN | Loss: 5.8853e-06 | Loss_d: 2.0398e-04 Loss_e: 8.3217e-05 | Loss_b: 6.5419e-05\n",
      "Step: NaN | Loss: 5.8846e-06 | Loss_d: 2.0418e-04 Loss_e: 8.3160e-05 | Loss_b: 6.5230e-05\n",
      "Step: NaN | Loss: 5.8806e-06 | Loss_d: 2.0386e-04 Loss_e: 8.3139e-05 | Loss_b: 6.5331e-05\n",
      "Step: NaN | Loss: 5.8816e-06 | Loss_d: 2.0287e-04 Loss_e: 8.3278e-05 | Loss_b: 6.6245e-05\n",
      "Step: NaN | Loss: 5.8777e-06 | Loss_d: 2.0335e-04 Loss_e: 8.3160e-05 | Loss_b: 6.5653e-05\n",
      "Step: NaN | Loss: 5.8753e-06 | Loss_d: 2.0287e-04 Loss_e: 8.3241e-05 | Loss_b: 6.5901e-05\n",
      "Step: NaN | Loss: 5.8806e-06 | Loss_d: 2.0110e-04 Loss_e: 8.3739e-05 | Loss_b: 6.7498e-05\n",
      "Step: NaN | Loss: 5.8744e-06 | Loss_d: 2.0236e-04 Loss_e: 8.3352e-05 | Loss_b: 6.6249e-05\n",
      "Step: NaN | Loss: 5.8694e-06 | Loss_d: 2.0276e-04 Loss_e: 8.3524e-05 | Loss_b: 6.5377e-05\n",
      "Step: NaN | Loss: 5.8749e-06 | Loss_d: 2.0473e-04 Loss_e: 8.4647e-05 | Loss_b: 6.2618e-05\n",
      "Step: NaN | Loss: 5.8668e-06 | Loss_d: 2.0341e-04 Loss_e: 8.3854e-05 | Loss_b: 6.4237e-05\n",
      "Step: NaN | Loss: 5.8557e-06 | Loss_d: 2.0274e-04 Loss_e: 8.3607e-05 | Loss_b: 6.4490e-05\n",
      "Step: NaN | Loss: 5.9978e-06 | Loss_d: 2.0171e-04 Loss_e: 8.8087e-05 | Loss_b: 6.9551e-05\n",
      "Step: NaN | Loss: 5.8556e-06 | Loss_d: 2.0268e-04 Loss_e: 8.3612e-05 | Loss_b: 6.4537e-05\n",
      "Step: NaN | Loss: 5.8473e-06 | Loss_d: 2.0184e-04 Loss_e: 8.3676e-05 | Loss_b: 6.4815e-05\n",
      "Step: NaN | Loss: 5.9140e-06 | Loss_d: 1.9885e-04 Loss_e: 8.6370e-05 | Loss_b: 6.9113e-05\n",
      "Step: NaN | Loss: 5.8467e-06 | Loss_d: 2.0158e-04 Loss_e: 8.3751e-05 | Loss_b: 6.4976e-05\n",
      "Step: NaN | Loss: 5.8481e-06 | Loss_d: 2.0176e-04 Loss_e: 8.3903e-05 | Loss_b: 6.4725e-05\n",
      "Step: NaN | Loss: 5.8442e-06 | Loss_d: 2.0165e-04 Loss_e: 8.3776e-05 | Loss_b: 6.4728e-05\n",
      "Step: NaN | Loss: 5.8435e-06 | Loss_d: 2.0155e-04 Loss_e: 8.3826e-05 | Loss_b: 6.4731e-05\n",
      "Step: NaN | Loss: 5.8415e-06 | Loss_d: 2.0119e-04 Loss_e: 8.4039e-05 | Loss_b: 6.4760e-05\n",
      "Step: NaN | Loss: 5.8462e-06 | Loss_d: 1.9966e-04 Loss_e: 8.5471e-05 | Loss_b: 6.5132e-05\n",
      "Step: NaN | Loss: 5.8403e-06 | Loss_d: 2.0067e-04 Loss_e: 8.4414e-05 | Loss_b: 6.4831e-05\n",
      "Step: NaN | Loss: 5.9030e-06 | Loss_d: 2.0144e-04 Loss_e: 8.4743e-05 | Loss_b: 6.7484e-05\n",
      "Step: NaN | Loss: 5.8384e-06 | Loss_d: 2.0073e-04 Loss_e: 8.4311e-05 | Loss_b: 6.4757e-05\n",
      "Step: NaN | Loss: 5.8327e-06 | Loss_d: 2.0104e-04 Loss_e: 8.4112e-05 | Loss_b: 6.4307e-05\n",
      "Step: NaN | Loss: 5.8369e-06 | Loss_d: 2.0272e-04 Loss_e: 8.3625e-05 | Loss_b: 6.3375e-05\n",
      "Step: NaN | Loss: 5.8292e-06 | Loss_d: 2.0163e-04 Loss_e: 8.3857e-05 | Loss_b: 6.3767e-05\n",
      "Step: NaN | Loss: 5.8272e-06 | Loss_d: 2.0129e-04 Loss_e: 8.3842e-05 | Loss_b: 6.4003e-05\n",
      "Step: NaN | Loss: 5.8304e-06 | Loss_d: 2.0003e-04 Loss_e: 8.3843e-05 | Loss_b: 6.5454e-05\n",
      "Step: NaN | Loss: 5.8263e-06 | Loss_d: 2.0087e-04 Loss_e: 8.3832e-05 | Loss_b: 6.4377e-05\n",
      "Step: NaN | Loss: 5.8221e-06 | Loss_d: 2.0065e-04 Loss_e: 8.3646e-05 | Loss_b: 6.4527e-05\n",
      "Step: NaN | Loss: 5.8267e-06 | Loss_d: 1.9984e-04 Loss_e: 8.3270e-05 | Loss_b: 6.5988e-05\n",
      "Step: NaN | Loss: 5.8198e-06 | Loss_d: 2.0035e-04 Loss_e: 8.3440e-05 | Loss_b: 6.4902e-05\n",
      "Step: NaN | Loss: 5.8140e-06 | Loss_d: 1.9983e-04 Loss_e: 8.3141e-05 | Loss_b: 6.5374e-05\n",
      "Step: NaN | Loss: 5.8779e-06 | Loss_d: 1.9830e-04 Loss_e: 8.2653e-05 | Loss_b: 7.1223e-05\n",
      "Step: NaN | Loss: 5.8139e-06 | Loss_d: 1.9975e-04 Loss_e: 8.3099e-05 | Loss_b: 6.5492e-05\n",
      "Step: NaN | Loss: 5.8117e-06 | Loss_d: 1.9985e-04 Loss_e: 8.3048e-05 | Loss_b: 6.5304e-05\n",
      "Step: NaN | Loss: 5.8110e-06 | Loss_d: 2.0033e-04 Loss_e: 8.2907e-05 | Loss_b: 6.4925e-05\n",
      "Step: NaN | Loss: 5.8097e-06 | Loss_d: 2.0010e-04 Loss_e: 8.2958e-05 | Loss_b: 6.5023e-05\n",
      "Step: NaN | Loss: 5.8048e-06 | Loss_d: 2.0050e-04 Loss_e: 8.2889e-05 | Loss_b: 6.4404e-05\n",
      "Step: NaN | Loss: 5.7946e-06 | Loss_d: 2.0217e-04 Loss_e: 8.2735e-05 | Loss_b: 6.2275e-05\n",
      "Step: NaN | Loss: 5.9628e-06 | Loss_d: 2.1233e-04 Loss_e: 8.4984e-05 | Loss_b: 5.9941e-05\n",
      "Step: NaN | Loss: 5.7943e-06 | Loss_d: 2.0251e-04 Loss_e: 8.2730e-05 | Loss_b: 6.1920e-05\n",
      "Step: NaN | Loss: 5.7787e-06 | Loss_d: 2.0249e-04 Loss_e: 8.2215e-05 | Loss_b: 6.1527e-05\n",
      "Step: NaN | Loss: 5.7536e-06 | Loss_d: 2.0270e-04 Loss_e: 8.1303e-05 | Loss_b: 6.0720e-05\n",
      "Step: NaN | Loss: 5.7534e-06 | Loss_d: 2.0267e-04 Loss_e: 8.1308e-05 | Loss_b: 6.0740e-05\n",
      "Step: NaN | Loss: 5.7405e-06 | Loss_d: 2.0238e-04 Loss_e: 8.0623e-05 | Loss_b: 6.0933e-05\n",
      "Step: NaN | Loss: 5.7825e-06 | Loss_d: 2.0171e-04 Loss_e: 8.0243e-05 | Loss_b: 6.4504e-05\n",
      "Step: NaN | Loss: 5.7368e-06 | Loss_d: 2.0217e-04 Loss_e: 8.0214e-05 | Loss_b: 6.1333e-05\n",
      "Step: NaN | Loss: 5.7323e-06 | Loss_d: 2.0190e-04 Loss_e: 8.0148e-05 | Loss_b: 6.1402e-05\n",
      "Step: NaN | Loss: 5.7405e-06 | Loss_d: 2.0105e-04 Loss_e: 8.0297e-05 | Loss_b: 6.2597e-05\n",
      "Step: NaN | Loss: 5.7304e-06 | Loss_d: 2.0160e-04 Loss_e: 8.0124e-05 | Loss_b: 6.1611e-05\n",
      "Step: NaN | Loss: 5.7204e-06 | Loss_d: 2.0159e-04 Loss_e: 7.9829e-05 | Loss_b: 6.1308e-05\n",
      "Step: NaN | Loss: 5.6920e-06 | Loss_d: 2.0169e-04 Loss_e: 7.9025e-05 | Loss_b: 6.0316e-05\n",
      "Step: NaN | Loss: 5.8315e-06 | Loss_d: 2.0488e-04 Loss_e: 8.3990e-05 | Loss_b: 6.0521e-05\n",
      "Step: NaN | Loss: 5.6823e-06 | Loss_d: 2.0197e-04 Loss_e: 7.8818e-05 | Loss_b: 5.9664e-05\n",
      "Step: NaN | Loss: 5.6669e-06 | Loss_d: 2.0159e-04 Loss_e: 7.8577e-05 | Loss_b: 5.9361e-05\n",
      "Step: NaN | Loss: 5.7865e-06 | Loss_d: 2.0212e-04 Loss_e: 8.1307e-05 | Loss_b: 6.3264e-05\n",
      "Step: NaN | Loss: 5.6659e-06 | Loss_d: 2.0151e-04 Loss_e: 7.8580e-05 | Loss_b: 5.9378e-05\n",
      "Step: NaN | Loss: 5.6495e-06 | Loss_d: 2.0144e-04 Loss_e: 7.8616e-05 | Loss_b: 5.8428e-05\n",
      "Step: NaN | Loss: 5.7646e-06 | Loss_d: 2.0251e-04 Loss_e: 8.1770e-05 | Loss_b: 6.1107e-05\n",
      "Step: NaN | Loss: 5.6481e-06 | Loss_d: 2.0145e-04 Loss_e: 7.8717e-05 | Loss_b: 5.8229e-05\n",
      "Step: NaN | Loss: 5.6426e-06 | Loss_d: 2.0108e-04 Loss_e: 7.8766e-05 | Loss_b: 5.8225e-05\n",
      "Step: NaN | Loss: 5.6350e-06 | Loss_d: 2.0004e-04 Loss_e: 7.9063e-05 | Loss_b: 5.8513e-05\n",
      "Step: NaN | Loss: 5.6347e-06 | Loss_d: 2.0017e-04 Loss_e: 7.9001e-05 | Loss_b: 5.8429e-05\n",
      "Step: NaN | Loss: 5.6257e-06 | Loss_d: 1.9952e-04 Loss_e: 7.9276e-05 | Loss_b: 5.8266e-05\n",
      "Step: NaN | Loss: 5.7086e-06 | Loss_d: 1.9743e-04 Loss_e: 8.2053e-05 | Loss_b: 6.2544e-05\n",
      "Step: NaN | Loss: 5.6253e-06 | Loss_d: 1.9936e-04 Loss_e: 7.9375e-05 | Loss_b: 5.8302e-05\n",
      "Step: NaN | Loss: 5.6240e-06 | Loss_d: 1.9837e-04 Loss_e: 7.9397e-05 | Loss_b: 5.9191e-05\n",
      "Step: NaN | Loss: 5.6220e-06 | Loss_d: 1.9879e-04 Loss_e: 7.9368e-05 | Loss_b: 5.8683e-05\n",
      "Step: NaN | Loss: 5.6178e-06 | Loss_d: 1.9854e-04 Loss_e: 7.9466e-05 | Loss_b: 5.8585e-05\n",
      "Step: NaN | Loss: 5.6388e-06 | Loss_d: 1.9777e-04 Loss_e: 8.0344e-05 | Loss_b: 5.9734e-05\n",
      "Step: NaN | Loss: 5.6171e-06 | Loss_d: 1.9839e-04 Loss_e: 7.9550e-05 | Loss_b: 5.8600e-05\n",
      "Step: NaN | Loss: 5.6143e-06 | Loss_d: 1.9818e-04 Loss_e: 7.9556e-05 | Loss_b: 5.8639e-05\n",
      "Step: NaN | Loss: 5.6088e-06 | Loss_d: 1.9741e-04 Loss_e: 7.9701e-05 | Loss_b: 5.8934e-05\n",
      "Step: NaN | Loss: 5.7139e-06 | Loss_d: 1.9513e-04 Loss_e: 8.3316e-05 | Loss_b: 6.3904e-05\n",
      "Step: NaN | Loss: 5.6087e-06 | Loss_d: 1.9731e-04 Loss_e: 7.9736e-05 | Loss_b: 5.8993e-05\n",
      "Step: NaN | Loss: 5.6029e-06 | Loss_d: 1.9709e-04 Loss_e: 7.9918e-05 | Loss_b: 5.8682e-05\n",
      "Step: NaN | Loss: 5.6053e-06 | Loss_d: 1.9631e-04 Loss_e: 8.1115e-05 | Loss_b: 5.8414e-05\n",
      "Step: NaN | Loss: 5.5989e-06 | Loss_d: 1.9673e-04 Loss_e: 8.0354e-05 | Loss_b: 5.8372e-05\n",
      "Step: NaN | Loss: 5.5967e-06 | Loss_d: 1.9678e-04 Loss_e: 8.0379e-05 | Loss_b: 5.8157e-05\n",
      "Step: NaN | Loss: 5.5945e-06 | Loss_d: 1.9707e-04 Loss_e: 8.0675e-05 | Loss_b: 5.7448e-05\n",
      "Step: NaN | Loss: 5.5940e-06 | Loss_d: 1.9697e-04 Loss_e: 8.0555e-05 | Loss_b: 5.7635e-05\n",
      "Step: NaN | Loss: 5.5883e-06 | Loss_d: 1.9678e-04 Loss_e: 8.0433e-05 | Loss_b: 5.7608e-05\n",
      "Step: NaN | Loss: 5.5882e-06 | Loss_d: 1.9681e-04 Loss_e: 8.0423e-05 | Loss_b: 5.7581e-05\n",
      "Step: NaN | Loss: 5.5841e-06 | Loss_d: 1.9703e-04 Loss_e: 8.0282e-05 | Loss_b: 5.7260e-05\n",
      "Step: NaN | Loss: 5.5908e-06 | Loss_d: 1.9814e-04 Loss_e: 8.0038e-05 | Loss_b: 5.6794e-05\n",
      "Step: NaN | Loss: 5.5822e-06 | Loss_d: 1.9734e-04 Loss_e: 8.0150e-05 | Loss_b: 5.6968e-05\n",
      "Step: NaN | Loss: 5.5796e-06 | Loss_d: 1.9734e-04 Loss_e: 8.0040e-05 | Loss_b: 5.6922e-05\n",
      "Step: NaN | Loss: 5.5751e-06 | Loss_d: 1.9743e-04 Loss_e: 7.9671e-05 | Loss_b: 5.6929e-05\n",
      "Step: NaN | Loss: 5.5751e-06 | Loss_d: 1.9742e-04 Loss_e: 7.9678e-05 | Loss_b: 5.6927e-05\n",
      "Step: NaN | Loss: 5.5688e-06 | Loss_d: 1.9756e-04 Loss_e: 7.9070e-05 | Loss_b: 5.7026e-05\n",
      "Step: NaN | Loss: 5.5688e-06 | Loss_d: 1.9755e-04 Loss_e: 7.9104e-05 | Loss_b: 5.6999e-05\n",
      "Step: NaN | Loss: 5.5639e-06 | Loss_d: 1.9685e-04 Loss_e: 7.9122e-05 | Loss_b: 5.7390e-05\n",
      "Step: NaN | Loss: 5.5563e-06 | Loss_d: 1.9428e-04 Loss_e: 7.9290e-05 | Loss_b: 5.9328e-05\n",
      "Step: NaN | Loss: 5.5562e-06 | Loss_d: 1.9451e-04 Loss_e: 7.9268e-05 | Loss_b: 5.9119e-05\n",
      "Step: NaN | Loss: 5.5478e-06 | Loss_d: 1.9421e-04 Loss_e: 7.9133e-05 | Loss_b: 5.9056e-05\n",
      "Step: NaN | Loss: 5.5378e-06 | Loss_d: 1.9310e-04 Loss_e: 7.8778e-05 | Loss_b: 5.9920e-05\n",
      "Step: NaN | Loss: 5.5368e-06 | Loss_d: 1.9334e-04 Loss_e: 7.8834e-05 | Loss_b: 5.9557e-05\n",
      "Step: NaN | Loss: 5.5248e-06 | Loss_d: 1.9328e-04 Loss_e: 7.8581e-05 | Loss_b: 5.9160e-05\n",
      "Step: NaN | Loss: 5.4986e-06 | Loss_d: 1.9333e-04 Loss_e: 7.7992e-05 | Loss_b: 5.8122e-05\n",
      "Step: NaN | Loss: 5.8857e-06 | Loss_d: 2.0119e-04 Loss_e: 8.5290e-05 | Loss_b: 6.6158e-05\n",
      "Step: NaN | Loss: 5.4975e-06 | Loss_d: 1.9343e-04 Loss_e: 7.7950e-05 | Loss_b: 5.7999e-05\n",
      "Step: NaN | Loss: 5.4914e-06 | Loss_d: 1.9331e-04 Loss_e: 7.8715e-05 | Loss_b: 5.6985e-05\n",
      "Step: NaN | Loss: 5.4913e-06 | Loss_d: 1.9331e-04 Loss_e: 7.8657e-05 | Loss_b: 5.7037e-05\n",
      "Step: NaN | Loss: 5.4870e-06 | Loss_d: 1.9309e-04 Loss_e: 7.8857e-05 | Loss_b: 5.6805e-05\n",
      "Step: NaN | Loss: 5.5394e-06 | Loss_d: 1.9304e-04 Loss_e: 8.1220e-05 | Loss_b: 5.7633e-05\n",
      "Step: NaN | Loss: 5.4870e-06 | Loss_d: 1.9306e-04 Loss_e: 7.8893e-05 | Loss_b: 5.6789e-05\n",
      "Step: NaN | Loss: 5.4844e-06 | Loss_d: 1.9331e-04 Loss_e: 7.8926e-05 | Loss_b: 5.6365e-05\n",
      "Step: NaN | Loss: 5.4857e-06 | Loss_d: 1.9441e-04 Loss_e: 7.9256e-05 | Loss_b: 5.5002e-05\n",
      "Step: NaN | Loss: 5.4828e-06 | Loss_d: 1.9376e-04 Loss_e: 7.9030e-05 | Loss_b: 5.5711e-05\n",
      "Step: NaN | Loss: 5.4785e-06 | Loss_d: 1.9405e-04 Loss_e: 7.8917e-05 | Loss_b: 5.5272e-05\n",
      "Step: NaN | Loss: 5.4722e-06 | Loss_d: 1.9530e-04 Loss_e: 7.8659e-05 | Loss_b: 5.3905e-05\n",
      "Step: NaN | Loss: 5.4720e-06 | Loss_d: 1.9512e-04 Loss_e: 7.8676e-05 | Loss_b: 5.4058e-05\n",
      "Step: NaN | Loss: 5.4646e-06 | Loss_d: 1.9473e-04 Loss_e: 7.8390e-05 | Loss_b: 5.4286e-05\n",
      "Step: NaN | Loss: 5.4989e-06 | Loss_d: 1.9381e-04 Loss_e: 7.8131e-05 | Loss_b: 5.7517e-05\n",
      "Step: NaN | Loss: 5.4633e-06 | Loss_d: 1.9452e-04 Loss_e: 7.8251e-05 | Loss_b: 5.4562e-05\n",
      "Step: NaN | Loss: 5.4663e-06 | Loss_d: 1.9502e-04 Loss_e: 7.8102e-05 | Loss_b: 5.4388e-05\n",
      "Step: NaN | Loss: 5.4597e-06 | Loss_d: 1.9471e-04 Loss_e: 7.8127e-05 | Loss_b: 5.4275e-05\n",
      "Step: NaN | Loss: 5.4585e-06 | Loss_d: 1.9476e-04 Loss_e: 7.8103e-05 | Loss_b: 5.4184e-05\n",
      "Step: NaN | Loss: 5.4558e-06 | Loss_d: 1.9495e-04 Loss_e: 7.8033e-05 | Loss_b: 5.3896e-05\n",
      "Step: NaN | Loss: 5.4876e-06 | Loss_d: 1.9629e-04 Loss_e: 7.8285e-05 | Loss_b: 5.4212e-05\n",
      "Step: NaN | Loss: 5.4555e-06 | Loss_d: 1.9504e-04 Loss_e: 7.8016e-05 | Loss_b: 5.3812e-05\n",
      "Step: NaN | Loss: 5.4517e-06 | Loss_d: 1.9473e-04 Loss_e: 7.8028e-05 | Loss_b: 5.3875e-05\n",
      "Step: NaN | Loss: 5.4431e-06 | Loss_d: 1.9358e-04 Loss_e: 7.8283e-05 | Loss_b: 5.4255e-05\n",
      "Step: NaN | Loss: 5.5774e-06 | Loss_d: 1.8959e-04 Loss_e: 8.4695e-05 | Loss_b: 5.9882e-05\n",
      "Step: NaN | Loss: 5.4428e-06 | Loss_d: 1.9333e-04 Loss_e: 7.8393e-05 | Loss_b: 5.4379e-05\n",
      "Step: NaN | Loss: 5.4344e-06 | Loss_d: 1.9298e-04 Loss_e: 7.8540e-05 | Loss_b: 5.4078e-05\n",
      "Step: NaN | Loss: 5.4261e-06 | Loss_d: 1.9178e-04 Loss_e: 7.9506e-05 | Loss_b: 5.3809e-05\n",
      "Step: NaN | Loss: 5.4245e-06 | Loss_d: 1.9209e-04 Loss_e: 7.9176e-05 | Loss_b: 5.3743e-05\n",
      "Step: NaN | Loss: 5.4170e-06 | Loss_d: 1.9262e-04 Loss_e: 7.9312e-05 | Loss_b: 5.2628e-05\n",
      "Step: NaN | Loss: 5.4908e-06 | Loss_d: 1.9519e-04 Loss_e: 8.0306e-05 | Loss_b: 5.3487e-05\n",
      "Step: NaN | Loss: 5.4168e-06 | Loss_d: 1.9274e-04 Loss_e: 7.9349e-05 | Loss_b: 5.2451e-05\n",
      "Step: NaN | Loss: 5.4133e-06 | Loss_d: 1.9285e-04 Loss_e: 7.9472e-05 | Loss_b: 5.2010e-05\n",
      "Step: NaN | Loss: 5.4133e-06 | Loss_d: 1.9343e-04 Loss_e: 8.0313e-05 | Loss_b: 5.0586e-05\n",
      "Step: NaN | Loss: 5.4105e-06 | Loss_d: 1.9311e-04 Loss_e: 7.9825e-05 | Loss_b: 5.1227e-05\n",
      "Step: NaN | Loss: 5.4076e-06 | Loss_d: 1.9241e-04 Loss_e: 7.9954e-05 | Loss_b: 5.1624e-05\n",
      "Step: NaN | Loss: 5.4173e-06 | Loss_d: 1.8997e-04 Loss_e: 8.0647e-05 | Loss_b: 5.3951e-05\n",
      "Step: NaN | Loss: 5.4068e-06 | Loss_d: 1.9184e-04 Loss_e: 8.0081e-05 | Loss_b: 5.2026e-05\n",
      "Step: NaN | Loss: 5.4047e-06 | Loss_d: 1.9179e-04 Loss_e: 7.9947e-05 | Loss_b: 5.2078e-05\n",
      "Step: NaN | Loss: 5.3992e-06 | Loss_d: 1.9164e-04 Loss_e: 7.9462e-05 | Loss_b: 5.2391e-05\n",
      "Step: NaN | Loss: 5.4391e-06 | Loss_d: 1.9122e-04 Loss_e: 7.8181e-05 | Loss_b: 5.6477e-05\n",
      "Step: NaN | Loss: 5.3981e-06 | Loss_d: 1.9154e-04 Loss_e: 7.9161e-05 | Loss_b: 5.2721e-05\n",
      "Step: NaN | Loss: 5.3887e-06 | Loss_d: 1.9147e-04 Loss_e: 7.8981e-05 | Loss_b: 5.2407e-05\n",
      "Step: NaN | Loss: 5.3899e-06 | Loss_d: 1.9217e-04 Loss_e: 7.9146e-05 | Loss_b: 5.1619e-05\n",
      "Step: NaN | Loss: 5.3816e-06 | Loss_d: 1.9161e-04 Loss_e: 7.8884e-05 | Loss_b: 5.1936e-05\n",
      "Step: NaN | Loss: 5.3736e-06 | Loss_d: 1.9312e-04 Loss_e: 7.8370e-05 | Loss_b: 5.0466e-05\n",
      "Step: NaN | Loss: 5.3729e-06 | Loss_d: 1.9277e-04 Loss_e: 7.8417e-05 | Loss_b: 5.0725e-05\n",
      "Step: NaN | Loss: 5.3754e-06 | Loss_d: 1.9295e-04 Loss_e: 7.8012e-05 | Loss_b: 5.1108e-05\n",
      "Step: NaN | Loss: 5.3709e-06 | Loss_d: 1.9282e-04 Loss_e: 7.8213e-05 | Loss_b: 5.0766e-05\n",
      "Step: NaN | Loss: 5.3695e-06 | Loss_d: 1.9314e-04 Loss_e: 7.8082e-05 | Loss_b: 5.0490e-05\n",
      "Step: NaN | Loss: 5.3880e-06 | Loss_d: 1.9453e-04 Loss_e: 7.7742e-05 | Loss_b: 5.0543e-05\n",
      "Step: NaN | Loss: 5.3695e-06 | Loss_d: 1.9317e-04 Loss_e: 7.8072e-05 | Loss_b: 5.0473e-05\n",
      "Step: NaN | Loss: 5.3680e-06 | Loss_d: 1.9313e-04 Loss_e: 7.8035e-05 | Loss_b: 5.0448e-05\n",
      "Step: NaN | Loss: 5.3635e-06 | Loss_d: 1.9302e-04 Loss_e: 7.7927e-05 | Loss_b: 5.0403e-05\n",
      "Step: NaN | Loss: 5.3829e-06 | Loss_d: 1.9273e-04 Loss_e: 7.8359e-05 | Loss_b: 5.1428e-05\n",
      "Step: NaN | Loss: 5.3618e-06 | Loss_d: 1.9291e-04 Loss_e: 7.7884e-05 | Loss_b: 5.0450e-05\n",
      "Step: NaN | Loss: 5.3548e-06 | Loss_d: 1.9295e-04 Loss_e: 7.7891e-05 | Loss_b: 4.9987e-05\n",
      "Step: NaN | Loss: 5.3659e-06 | Loss_d: 1.9351e-04 Loss_e: 7.8727e-05 | Loss_b: 4.9260e-05\n",
      "Step: NaN | Loss: 5.3516e-06 | Loss_d: 1.9306e-04 Loss_e: 7.8017e-05 | Loss_b: 4.9556e-05\n",
      "Step: NaN | Loss: 5.3448e-06 | Loss_d: 1.9317e-04 Loss_e: 7.7960e-05 | Loss_b: 4.9096e-05\n",
      "Step: NaN | Loss: 5.3367e-06 | Loss_d: 1.9367e-04 Loss_e: 7.7956e-05 | Loss_b: 4.8117e-05\n",
      "Step: NaN | Loss: 5.3359e-06 | Loss_d: 1.9355e-04 Loss_e: 7.7925e-05 | Loss_b: 4.8224e-05\n",
      "Step: NaN | Loss: 5.3234e-06 | Loss_d: 1.9349e-04 Loss_e: 7.7374e-05 | Loss_b: 4.8081e-05\n",
      "Step: NaN | Loss: 5.3630e-06 | Loss_d: 1.9353e-04 Loss_e: 7.6054e-05 | Loss_b: 5.1733e-05\n",
      "Step: NaN | Loss: 5.3198e-06 | Loss_d: 1.9347e-04 Loss_e: 7.6956e-05 | Loss_b: 4.8313e-05\n",
      "Step: NaN | Loss: 5.3127e-06 | Loss_d: 1.9311e-04 Loss_e: 7.7029e-05 | Loss_b: 4.8172e-05\n",
      "Step: NaN | Loss: 5.3180e-06 | Loss_d: 1.9195e-04 Loss_e: 7.7778e-05 | Loss_b: 4.8892e-05\n",
      "Step: NaN | Loss: 5.3083e-06 | Loss_d: 1.9259e-04 Loss_e: 7.7241e-05 | Loss_b: 4.8212e-05\n",
      "Step: NaN | Loss: 5.2980e-06 | Loss_d: 1.9361e-04 Loss_e: 7.5876e-05 | Loss_b: 4.7944e-05\n",
      "Step: NaN | Loss: 5.2980e-06 | Loss_d: 1.9356e-04 Loss_e: 7.5925e-05 | Loss_b: 4.7938e-05\n",
      "Step: NaN | Loss: 5.2827e-06 | Loss_d: 1.9250e-04 Loss_e: 7.5575e-05 | Loss_b: 4.8431e-05\n",
      "Step: NaN | Loss: 5.3055e-06 | Loss_d: 1.8901e-04 Loss_e: 7.5832e-05 | Loss_b: 5.3035e-05\n",
      "Step: NaN | Loss: 5.2755e-06 | Loss_d: 1.9122e-04 Loss_e: 7.5367e-05 | Loss_b: 4.9489e-05\n",
      "Step: NaN | Loss: 5.2610e-06 | Loss_d: 1.9081e-04 Loss_e: 7.5175e-05 | Loss_b: 4.9219e-05\n",
      "Step: NaN | Loss: 5.2440e-06 | Loss_d: 1.8948e-04 Loss_e: 7.5434e-05 | Loss_b: 4.9275e-05\n",
      "Step: NaN | Loss: 5.2421e-06 | Loss_d: 1.8977e-04 Loss_e: 7.5218e-05 | Loss_b: 4.9090e-05\n",
      "Step: NaN | Loss: 5.2319e-06 | Loss_d: 1.8907e-04 Loss_e: 7.4747e-05 | Loss_b: 4.9649e-05\n",
      "Step: NaN | Loss: 5.2390e-06 | Loss_d: 1.8697e-04 Loss_e: 7.3901e-05 | Loss_b: 5.3022e-05\n",
      "Step: NaN | Loss: 5.2255e-06 | Loss_d: 1.8808e-04 Loss_e: 7.4200e-05 | Loss_b: 5.0807e-05\n",
      "Step: NaN | Loss: 5.2169e-06 | Loss_d: 1.8795e-04 Loss_e: 7.4015e-05 | Loss_b: 5.0600e-05\n",
      "Step: NaN | Loss: 5.2884e-06 | Loss_d: 1.8904e-04 Loss_e: 7.5583e-05 | Loss_b: 5.2230e-05\n",
      "Step: NaN | Loss: 5.2164e-06 | Loss_d: 1.8795e-04 Loss_e: 7.4004e-05 | Loss_b: 5.0585e-05\n",
      "Step: NaN | Loss: 5.2137e-06 | Loss_d: 1.8756e-04 Loss_e: 7.4236e-05 | Loss_b: 5.0575e-05\n",
      "Step: NaN | Loss: 5.2135e-06 | Loss_d: 1.8762e-04 Loss_e: 7.4188e-05 | Loss_b: 5.0554e-05\n",
      "Step: NaN | Loss: 5.2109e-06 | Loss_d: 1.8762e-04 Loss_e: 7.4122e-05 | Loss_b: 5.0459e-05\n",
      "Step: NaN | Loss: 5.2083e-06 | Loss_d: 1.8769e-04 Loss_e: 7.3916e-05 | Loss_b: 5.0446e-05\n",
      "Step: NaN | Loss: 5.2077e-06 | Loss_d: 1.8766e-04 Loss_e: 7.3969e-05 | Loss_b: 5.0388e-05\n",
      "Step: NaN | Loss: 5.2032e-06 | Loss_d: 1.8741e-04 Loss_e: 7.3823e-05 | Loss_b: 5.0509e-05\n",
      "Step: NaN | Loss: 5.1936e-06 | Loss_d: 1.8664e-04 Loss_e: 7.3343e-05 | Loss_b: 5.1190e-05\n",
      "Step: NaN | Loss: 5.3494e-06 | Loss_d: 1.8757e-04 Loss_e: 7.3472e-05 | Loss_b: 5.9461e-05\n",
      "Step: NaN | Loss: 5.1933e-06 | Loss_d: 1.8652e-04 Loss_e: 7.3264e-05 | Loss_b: 5.1370e-05\n",
      "Step: NaN | Loss: 5.1937e-06 | Loss_d: 1.8611e-04 Loss_e: 7.4154e-05 | Loss_b: 5.0911e-05\n",
      "Step: NaN | Loss: 5.1889e-06 | Loss_d: 1.8630e-04 Loss_e: 7.3630e-05 | Loss_b: 5.0963e-05\n",
      "Step: NaN | Loss: 5.1854e-06 | Loss_d: 1.8619e-04 Loss_e: 7.3645e-05 | Loss_b: 5.0843e-05\n",
      "Step: NaN | Loss: 5.1804e-06 | Loss_d: 1.8579e-04 Loss_e: 7.3910e-05 | Loss_b: 5.0675e-05\n",
      "Step: NaN | Loss: 5.1802e-06 | Loss_d: 1.8585e-04 Loss_e: 7.3850e-05 | Loss_b: 5.0669e-05\n",
      "Step: NaN | Loss: 5.1686e-06 | Loss_d: 1.8570e-04 Loss_e: 7.3891e-05 | Loss_b: 5.0077e-05\n",
      "Step: NaN | Loss: 5.1945e-06 | Loss_d: 1.8613e-04 Loss_e: 7.4781e-05 | Loss_b: 5.0313e-05\n",
      "Step: NaN | Loss: 5.1642e-06 | Loss_d: 1.8566e-04 Loss_e: 7.4022e-05 | Loss_b: 4.9730e-05\n",
      "Step: NaN | Loss: 5.1604e-06 | Loss_d: 1.8478e-04 Loss_e: 7.4100e-05 | Loss_b: 5.0304e-05\n",
      "Step: NaN | Loss: 5.1602e-06 | Loss_d: 1.8491e-04 Loss_e: 7.4068e-05 | Loss_b: 5.0196e-05\n",
      "Step: NaN | Loss: 5.1564e-06 | Loss_d: 1.8513e-04 Loss_e: 7.3943e-05 | Loss_b: 4.9875e-05\n",
      "Step: NaN | Loss: 5.1613e-06 | Loss_d: 1.8610e-04 Loss_e: 7.3785e-05 | Loss_b: 4.9349e-05\n",
      "Step: NaN | Loss: 5.1545e-06 | Loss_d: 1.8545e-04 Loss_e: 7.3825e-05 | Loss_b: 4.9555e-05\n",
      "Step: NaN | Loss: 5.1490e-06 | Loss_d: 1.8490e-04 Loss_e: 7.3713e-05 | Loss_b: 4.9885e-05\n",
      "Step: NaN | Loss: 5.1571e-06 | Loss_d: 1.8303e-04 Loss_e: 7.3767e-05 | Loss_b: 5.2183e-05\n",
      "Step: NaN | Loss: 5.1464e-06 | Loss_d: 1.8423e-04 Loss_e: 7.3641e-05 | Loss_b: 5.0475e-05\n",
      "Step: NaN | Loss: 5.1403e-06 | Loss_d: 1.8467e-04 Loss_e: 7.3743e-05 | Loss_b: 4.9564e-05\n",
      "Step: NaN | Loss: 5.2139e-06 | Loss_d: 1.8676e-04 Loss_e: 7.5331e-05 | Loss_b: 5.0292e-05\n",
      "Step: NaN | Loss: 5.1402e-06 | Loss_d: 1.8473e-04 Loss_e: 7.3765e-05 | Loss_b: 4.9478e-05\n",
      "Step: NaN | Loss: 5.1379e-06 | Loss_d: 1.8467e-04 Loss_e: 7.3606e-05 | Loss_b: 4.9554e-05\n",
      "Step: NaN | Loss: 5.1550e-06 | Loss_d: 1.8457e-04 Loss_e: 7.3505e-05 | Loss_b: 5.0788e-05\n",
      "Step: NaN | Loss: 5.1377e-06 | Loss_d: 1.8465e-04 Loss_e: 7.3560e-05 | Loss_b: 4.9607e-05\n",
      "Step: NaN | Loss: 5.1371e-06 | Loss_d: 1.8490e-04 Loss_e: 7.3360e-05 | Loss_b: 4.9527e-05\n",
      "Step: NaN | Loss: 5.1366e-06 | Loss_d: 1.8480e-04 Loss_e: 7.3436e-05 | Loss_b: 4.9522e-05\n",
      "Step: NaN | Loss: 5.1354e-06 | Loss_d: 1.8475e-04 Loss_e: 7.3432e-05 | Loss_b: 4.9505e-05\n",
      "Step: NaN | Loss: 5.1333e-06 | Loss_d: 1.8456e-04 Loss_e: 7.3434e-05 | Loss_b: 4.9562e-05\n",
      "Step: NaN | Loss: 5.1850e-06 | Loss_d: 1.8405e-04 Loss_e: 7.3849e-05 | Loss_b: 5.2761e-05\n",
      "Step: NaN | Loss: 5.1333e-06 | Loss_d: 1.8456e-04 Loss_e: 7.3434e-05 | Loss_b: 4.9564e-05\n",
      "Step: NaN | Loss: 5.1302e-06 | Loss_d: 1.8455e-04 Loss_e: 7.3462e-05 | Loss_b: 4.9356e-05\n",
      "Step: NaN | Loss: 5.1208e-06 | Loss_d: 1.8458e-04 Loss_e: 7.3628e-05 | Loss_b: 4.8604e-05\n",
      "Step: NaN | Loss: 5.1516e-06 | Loss_d: 1.8603e-04 Loss_e: 7.5819e-05 | Loss_b: 4.6804e-05\n",
      "Step: NaN | Loss: 5.1164e-06 | Loss_d: 1.8474e-04 Loss_e: 7.3979e-05 | Loss_b: 4.7820e-05\n",
      "Step: NaN | Loss: 5.1109e-06 | Loss_d: 1.8424e-04 Loss_e: 7.3341e-05 | Loss_b: 4.8632e-05\n",
      "Step: NaN | Loss: 5.1107e-06 | Loss_d: 1.8431e-04 Loss_e: 7.3420e-05 | Loss_b: 4.8477e-05\n",
      "Step: NaN | Loss: 5.1062e-06 | Loss_d: 1.8386e-04 Loss_e: 7.3477e-05 | Loss_b: 4.8596e-05\n",
      "Step: NaN | Loss: 5.1060e-06 | Loss_d: 1.8249e-04 Loss_e: 7.3866e-05 | Loss_b: 4.9565e-05\n",
      "Step: NaN | Loss: 5.1025e-06 | Loss_d: 1.8308e-04 Loss_e: 7.3642e-05 | Loss_b: 4.8990e-05\n",
      "Step: NaN | Loss: 5.0975e-06 | Loss_d: 1.8297e-04 Loss_e: 7.3601e-05 | Loss_b: 4.8840e-05\n",
      "Step: NaN | Loss: 5.0922e-06 | Loss_d: 1.8260e-04 Loss_e: 7.3787e-05 | Loss_b: 4.8706e-05\n",
      "Step: NaN | Loss: 5.0913e-06 | Loss_d: 1.8270e-04 Loss_e: 7.3678e-05 | Loss_b: 4.8667e-05\n",
      "Step: NaN | Loss: 5.0830e-06 | Loss_d: 1.8196e-04 Loss_e: 7.3756e-05 | Loss_b: 4.8828e-05\n",
      "Step: NaN | Loss: 5.0745e-06 | Loss_d: 1.7949e-04 Loss_e: 7.4496e-05 | Loss_b: 5.0053e-05\n",
      "Step: NaN | Loss: 5.0729e-06 | Loss_d: 1.8013e-04 Loss_e: 7.4210e-05 | Loss_b: 4.9600e-05\n",
      "Step: NaN | Loss: 5.0698e-06 | Loss_d: 1.8052e-04 Loss_e: 7.3710e-05 | Loss_b: 4.9521e-05\n",
      "Step: NaN | Loss: 5.0668e-06 | Loss_d: 1.8032e-04 Loss_e: 7.3839e-05 | Loss_b: 4.9416e-05\n",
      "Step: NaN | Loss: 5.0649e-06 | Loss_d: 1.8020e-04 Loss_e: 7.3916e-05 | Loss_b: 4.9343e-05\n",
      "Step: NaN | Loss: 5.0749e-06 | Loss_d: 1.7984e-04 Loss_e: 7.4629e-05 | Loss_b: 4.9594e-05\n",
      "Step: NaN | Loss: 5.0646e-06 | Loss_d: 1.8014e-04 Loss_e: 7.3980e-05 | Loss_b: 4.9324e-05\n",
      "Step: NaN | Loss: 5.0620e-06 | Loss_d: 1.7987e-04 Loss_e: 7.3838e-05 | Loss_b: 4.9583e-05\n",
      "Step: NaN | Loss: 5.0604e-06 | Loss_d: 1.7886e-04 Loss_e: 7.3377e-05 | Loss_b: 5.0956e-05\n",
      "Step: NaN | Loss: 5.0594e-06 | Loss_d: 1.7923e-04 Loss_e: 7.3533e-05 | Loss_b: 5.0363e-05\n",
      "Step: NaN | Loss: 5.0551e-06 | Loss_d: 1.7896e-04 Loss_e: 7.3469e-05 | Loss_b: 5.0444e-05\n",
      "Step: NaN | Loss: 5.0433e-06 | Loss_d: 1.7791e-04 Loss_e: 7.3302e-05 | Loss_b: 5.0956e-05\n",
      "Step: NaN | Loss: 5.1172e-06 | Loss_d: 1.7369e-04 Loss_e: 7.4592e-05 | Loss_b: 5.8312e-05\n",
      "Step: NaN | Loss: 5.0400e-06 | Loss_d: 1.7709e-04 Loss_e: 7.3270e-05 | Loss_b: 5.1607e-05\n",
      "Step: NaN | Loss: 5.0786e-06 | Loss_d: 1.7491e-04 Loss_e: 7.2974e-05 | Loss_b: 5.6400e-05\n",
      "Step: NaN | Loss: 5.0357e-06 | Loss_d: 1.7653e-04 Loss_e: 7.3109e-05 | Loss_b: 5.2069e-05\n",
      "Step: NaN | Loss: 5.0304e-06 | Loss_d: 1.7706e-04 Loss_e: 7.2601e-05 | Loss_b: 5.1726e-05\n",
      "Step: NaN | Loss: 5.0561e-06 | Loss_d: 1.8023e-04 Loss_e: 7.1686e-05 | Loss_b: 5.1022e-05\n",
      "Step: NaN | Loss: 5.0294e-06 | Loss_d: 1.7745e-04 Loss_e: 7.2337e-05 | Loss_b: 5.1545e-05\n",
      "Step: NaN | Loss: 5.0167e-06 | Loss_d: 1.7723e-04 Loss_e: 7.1825e-05 | Loss_b: 5.1509e-05\n",
      "Step: NaN | Loss: 5.0585e-06 | Loss_d: 1.7733e-04 Loss_e: 7.1342e-05 | Loss_b: 5.4408e-05\n",
      "Step: NaN | Loss: 5.0131e-06 | Loss_d: 1.7712e-04 Loss_e: 7.1506e-05 | Loss_b: 5.1726e-05\n",
      "Step: NaN | Loss: 5.0101e-06 | Loss_d: 1.7748e-04 Loss_e: 7.1721e-05 | Loss_b: 5.0973e-05\n",
      "Step: NaN | Loss: 5.0084e-06 | Loss_d: 1.7733e-04 Loss_e: 7.1607e-05 | Loss_b: 5.1133e-05\n",
      "Step: NaN | Loss: 5.0049e-06 | Loss_d: 1.7721e-04 Loss_e: 7.1724e-05 | Loss_b: 5.0929e-05\n",
      "Step: NaN | Loss: 4.9996e-06 | Loss_d: 1.7684e-04 Loss_e: 7.2370e-05 | Loss_b: 5.0335e-05\n",
      "Step: NaN | Loss: 4.9995e-06 | Loss_d: 1.7687e-04 Loss_e: 7.2290e-05 | Loss_b: 5.0380e-05\n",
      "Step: NaN | Loss: 4.9911e-06 | Loss_d: 1.7697e-04 Loss_e: 7.2000e-05 | Loss_b: 5.0067e-05\n",
      "Step: NaN | Loss: 5.0053e-06 | Loss_d: 1.7765e-04 Loss_e: 7.2131e-05 | Loss_b: 5.0105e-05\n",
      "Step: NaN | Loss: 4.9874e-06 | Loss_d: 1.7714e-04 Loss_e: 7.1819e-05 | Loss_b: 4.9858e-05\n",
      "Step: NaN | Loss: 4.9807e-06 | Loss_d: 1.7645e-04 Loss_e: 7.1516e-05 | Loss_b: 5.0447e-05\n",
      "Step: NaN | Loss: 5.0576e-06 | Loss_d: 1.7451e-04 Loss_e: 7.2002e-05 | Loss_b: 5.6513e-05\n",
      "Step: NaN | Loss: 4.9806e-06 | Loss_d: 1.7636e-04 Loss_e: 7.1486e-05 | Loss_b: 5.0563e-05\n",
      "Step: NaN | Loss: 4.9766e-06 | Loss_d: 1.7654e-04 Loss_e: 7.1358e-05 | Loss_b: 5.0273e-05\n",
      "Step: NaN | Loss: 4.9805e-06 | Loss_d: 1.7749e-04 Loss_e: 7.1102e-05 | Loss_b: 4.9814e-05\n",
      "Step: NaN | Loss: 4.9743e-06 | Loss_d: 1.7685e-04 Loss_e: 7.1213e-05 | Loss_b: 4.9969e-05\n",
      "Step: NaN | Loss: 4.9688e-06 | Loss_d: 1.7676e-04 Loss_e: 7.1288e-05 | Loss_b: 4.9653e-05\n",
      "Step: NaN | Loss: 4.9736e-06 | Loss_d: 1.7669e-04 Loss_e: 7.2085e-05 | Loss_b: 4.9215e-05\n",
      "Step: NaN | Loss: 4.9657e-06 | Loss_d: 1.7668e-04 Loss_e: 7.1503e-05 | Loss_b: 4.9329e-05\n",
      "Step: NaN | Loss: 4.9583e-06 | Loss_d: 1.7645e-04 Loss_e: 7.1252e-05 | Loss_b: 4.9374e-05\n",
      "Step: NaN | Loss: 4.9430e-06 | Loss_d: 1.7560e-04 Loss_e: 7.0637e-05 | Loss_b: 4.9916e-05\n",
      "Step: NaN | Loss: 5.2005e-06 | Loss_d: 1.7379e-04 Loss_e: 7.7324e-05 | Loss_b: 6.0469e-05\n",
      "Step: NaN | Loss: 4.9426e-06 | Loss_d: 1.7547e-04 Loss_e: 7.0593e-05 | Loss_b: 5.0074e-05\n",
      "Step: NaN | Loss: 4.9627e-06 | Loss_d: 1.7873e-04 Loss_e: 7.1586e-05 | Loss_b: 4.7017e-05\n",
      "Step: NaN | Loss: 4.9356e-06 | Loss_d: 1.7633e-04 Loss_e: 7.0742e-05 | Loss_b: 4.8643e-05\n",
      "Step: NaN | Loss: 4.9343e-06 | Loss_d: 1.7630e-04 Loss_e: 7.0785e-05 | Loss_b: 4.8548e-05\n",
      "Step: NaN | Loss: 4.9484e-06 | Loss_d: 1.7624e-04 Loss_e: 7.1013e-05 | Loss_b: 4.9223e-05\n",
      "Step: NaN | Loss: 4.9343e-06 | Loss_d: 1.7630e-04 Loss_e: 7.0792e-05 | Loss_b: 4.8543e-05\n",
      "Step: NaN | Loss: 4.9330e-06 | Loss_d: 1.7646e-04 Loss_e: 7.0814e-05 | Loss_b: 4.8290e-05\n",
      "Step: NaN | Loss: 4.9305e-06 | Loss_d: 1.7713e-04 Loss_e: 7.0911e-05 | Loss_b: 4.7367e-05\n",
      "Step: NaN | Loss: 4.9732e-06 | Loss_d: 1.8162e-04 Loss_e: 7.1634e-05 | Loss_b: 4.4709e-05\n",
      "Step: NaN | Loss: 4.9304e-06 | Loss_d: 1.7726e-04 Loss_e: 7.0931e-05 | Loss_b: 4.7213e-05\n",
      "Step: NaN | Loss: 4.9257e-06 | Loss_d: 1.7718e-04 Loss_e: 7.0697e-05 | Loss_b: 4.7243e-05\n",
      "Step: NaN | Loss: 4.9176e-06 | Loss_d: 1.7698e-04 Loss_e: 7.0023e-05 | Loss_b: 4.7634e-05\n",
      "Step: NaN | Loss: 4.9176e-06 | Loss_d: 1.7698e-04 Loss_e: 7.0034e-05 | Loss_b: 4.7619e-05\n",
      "Step: NaN | Loss: 4.9072e-06 | Loss_d: 1.7670e-04 Loss_e: 6.9830e-05 | Loss_b: 4.7480e-05\n",
      "Step: NaN | Loss: 5.0351e-06 | Loss_d: 1.7693e-04 Loss_e: 7.1130e-05 | Loss_b: 5.3611e-05\n",
      "Step: NaN | Loss: 4.9071e-06 | Loss_d: 1.7668e-04 Loss_e: 6.9820e-05 | Loss_b: 4.7506e-05\n",
      "Step: NaN | Loss: 4.9015e-06 | Loss_d: 1.7697e-04 Loss_e: 6.9594e-05 | Loss_b: 4.7103e-05\n",
      "Step: NaN | Loss: 4.9219e-06 | Loss_d: 1.7878e-04 Loss_e: 6.9249e-05 | Loss_b: 4.6865e-05\n",
      "Step: NaN | Loss: 4.9001e-06 | Loss_d: 1.7726e-04 Loss_e: 6.9452e-05 | Loss_b: 4.6879e-05\n",
      "Step: NaN | Loss: 4.8964e-06 | Loss_d: 1.7689e-04 Loss_e: 6.9510e-05 | Loss_b: 4.6962e-05\n",
      "Step: NaN | Loss: 4.8959e-06 | Loss_d: 1.7559e-04 Loss_e: 6.9985e-05 | Loss_b: 4.7764e-05\n",
      "Step: NaN | Loss: 4.8934e-06 | Loss_d: 1.7618e-04 Loss_e: 6.9710e-05 | Loss_b: 4.7289e-05\n",
      "Step: NaN | Loss: 4.8869e-06 | Loss_d: 1.7607e-04 Loss_e: 6.9590e-05 | Loss_b: 4.7129e-05\n",
      "Step: NaN | Loss: 4.8724e-06 | Loss_d: 1.7575e-04 Loss_e: 6.9498e-05 | Loss_b: 4.6676e-05\n",
      "Step: NaN | Loss: 5.0709e-06 | Loss_d: 1.7676e-04 Loss_e: 7.8285e-05 | Loss_b: 4.8773e-05\n",
      "Step: NaN | Loss: 4.8716e-06 | Loss_d: 1.7569e-04 Loss_e: 6.9592e-05 | Loss_b: 4.6596e-05\n",
      "Step: NaN | Loss: 4.8527e-06 | Loss_d: 1.7358e-04 Loss_e: 7.0490e-05 | Loss_b: 4.6677e-05\n",
      "Step: NaN | Loss: 4.8521e-06 | Loss_d: 1.7384e-04 Loss_e: 7.0294e-05 | Loss_b: 4.6571e-05\n",
      "Step: NaN | Loss: 4.8500e-06 | Loss_d: 1.7306e-04 Loss_e: 6.9957e-05 | Loss_b: 4.7568e-05\n",
      "Step: NaN | Loss: 4.8467e-06 | Loss_d: 1.7335e-04 Loss_e: 7.0059e-05 | Loss_b: 4.6978e-05\n",
      "Step: NaN | Loss: 4.8435e-06 | Loss_d: 1.7354e-04 Loss_e: 6.9954e-05 | Loss_b: 4.6696e-05\n",
      "Step: NaN | Loss: 4.8438e-06 | Loss_d: 1.7444e-04 Loss_e: 6.9733e-05 | Loss_b: 4.6041e-05\n",
      "Step: NaN | Loss: 4.8409e-06 | Loss_d: 1.7395e-04 Loss_e: 6.9808e-05 | Loss_b: 4.6283e-05\n",
      "Step: NaN | Loss: 4.8378e-06 | Loss_d: 1.7411e-04 Loss_e: 6.9637e-05 | Loss_b: 4.6107e-05\n",
      "Step: NaN | Loss: 4.8339e-06 | Loss_d: 1.7487e-04 Loss_e: 6.9057e-05 | Loss_b: 4.5700e-05\n",
      "Step: NaN | Loss: 4.8337e-06 | Loss_d: 1.7470e-04 Loss_e: 6.9163e-05 | Loss_b: 4.5745e-05\n",
      "Step: NaN | Loss: 4.8278e-06 | Loss_d: 1.7424e-04 Loss_e: 6.9015e-05 | Loss_b: 4.5998e-05\n",
      "Step: NaN | Loss: 4.8424e-06 | Loss_d: 1.7266e-04 Loss_e: 6.9380e-05 | Loss_b: 4.8084e-05\n",
      "Step: NaN | Loss: 4.8258e-06 | Loss_d: 1.7380e-04 Loss_e: 6.8963e-05 | Loss_b: 4.6378e-05\n",
      "Step: NaN | Loss: 4.8216e-06 | Loss_d: 1.7241e-04 Loss_e: 6.9189e-05 | Loss_b: 4.7278e-05\n",
      "Step: NaN | Loss: 4.8768e-06 | Loss_d: 1.6802e-04 Loss_e: 7.0938e-05 | Loss_b: 5.3232e-05\n",
      "Step: NaN | Loss: 4.8215e-06 | Loss_d: 1.7228e-04 Loss_e: 6.9217e-05 | Loss_b: 4.7383e-05\n",
      "Step: NaN | Loss: 4.8192e-06 | Loss_d: 1.7227e-04 Loss_e: 6.9173e-05 | Loss_b: 4.7300e-05\n",
      "Step: NaN | Loss: 4.8138e-06 | Loss_d: 1.7224e-04 Loss_e: 6.9028e-05 | Loss_b: 4.7143e-05\n",
      "Step: NaN | Loss: 4.8752e-06 | Loss_d: 1.7262e-04 Loss_e: 6.9092e-05 | Loss_b: 5.0377e-05\n",
      "Step: NaN | Loss: 4.8133e-06 | Loss_d: 1.7224e-04 Loss_e: 6.8983e-05 | Loss_b: 4.7158e-05\n",
      "Step: NaN | Loss: 4.8062e-06 | Loss_d: 1.7229e-04 Loss_e: 6.8791e-05 | Loss_b: 4.6880e-05\n",
      "Step: NaN | Loss: 4.8040e-06 | Loss_d: 1.7280e-04 Loss_e: 6.8348e-05 | Loss_b: 4.6679e-05\n",
      "Step: NaN | Loss: 4.7996e-06 | Loss_d: 1.7250e-04 Loss_e: 6.8486e-05 | Loss_b: 4.6583e-05\n",
      "Step: NaN | Loss: 4.7870e-06 | Loss_d: 1.7207e-04 Loss_e: 6.7784e-05 | Loss_b: 4.6961e-05\n",
      "Step: NaN | Loss: 4.8148e-06 | Loss_d: 1.7121e-04 Loss_e: 6.6859e-05 | Loss_b: 5.0407e-05\n",
      "Step: NaN | Loss: 4.7819e-06 | Loss_d: 1.7170e-04 Loss_e: 6.7239e-05 | Loss_b: 4.7571e-05\n",
      "Step: NaN | Loss: 4.7715e-06 | Loss_d: 1.7137e-04 Loss_e: 6.7113e-05 | Loss_b: 4.7400e-05\n",
      "Step: NaN | Loss: 4.8693e-06 | Loss_d: 1.7147e-04 Loss_e: 6.8239e-05 | Loss_b: 5.2036e-05\n",
      "Step: NaN | Loss: 4.7711e-06 | Loss_d: 1.7131e-04 Loss_e: 6.7107e-05 | Loss_b: 4.7439e-05\n",
      "Step: NaN | Loss: 4.7672e-06 | Loss_d: 1.7165e-04 Loss_e: 6.7014e-05 | Loss_b: 4.6954e-05\n",
      "Step: NaN | Loss: 4.7670e-06 | Loss_d: 1.7159e-04 Loss_e: 6.7021e-05 | Loss_b: 4.7006e-05\n",
      "Step: NaN | Loss: 4.7657e-06 | Loss_d: 1.7152e-04 Loss_e: 6.7019e-05 | Loss_b: 4.6992e-05\n",
      "Step: NaN | Loss: 4.7651e-06 | Loss_d: 1.7129e-04 Loss_e: 6.7087e-05 | Loss_b: 4.7120e-05\n",
      "Step: NaN | Loss: 4.7645e-06 | Loss_d: 1.7138e-04 Loss_e: 6.7045e-05 | Loss_b: 4.7034e-05\n",
      "Step: NaN | Loss: 4.7600e-06 | Loss_d: 1.7135e-04 Loss_e: 6.7197e-05 | Loss_b: 4.6650e-05\n",
      "Step: NaN | Loss: 4.7737e-06 | Loss_d: 1.7179e-04 Loss_e: 6.8383e-05 | Loss_b: 4.5839e-05\n",
      "Step: NaN | Loss: 4.7587e-06 | Loss_d: 1.7137e-04 Loss_e: 6.7386e-05 | Loss_b: 4.6362e-05\n",
      "Step: NaN | Loss: 4.7503e-06 | Loss_d: 1.7120e-04 Loss_e: 6.7179e-05 | Loss_b: 4.6229e-05\n",
      "Step: NaN | Loss: 4.7728e-06 | Loss_d: 1.7114e-04 Loss_e: 6.7190e-05 | Loss_b: 4.7632e-05\n",
      "Step: NaN | Loss: 4.7475e-06 | Loss_d: 1.7109e-04 Loss_e: 6.7056e-05 | Loss_b: 4.6291e-05\n",
      "Step: NaN | Loss: 4.7451e-06 | Loss_d: 1.7128e-04 Loss_e: 6.6762e-05 | Loss_b: 4.6258e-05\n",
      "Step: NaN | Loss: 4.7447e-06 | Loss_d: 1.7122e-04 Loss_e: 6.6824e-05 | Loss_b: 4.6229e-05\n",
      "Step: NaN | Loss: 4.7434e-06 | Loss_d: 1.7093e-04 Loss_e: 6.6844e-05 | Loss_b: 4.6423e-05\n",
      "Step: NaN | Loss: 4.7413e-06 | Loss_d: 1.6981e-04 Loss_e: 6.6963e-05 | Loss_b: 4.7297e-05\n",
      "Step: NaN | Loss: 4.7413e-06 | Loss_d: 1.6986e-04 Loss_e: 6.6956e-05 | Loss_b: 4.7255e-05\n",
      "Step: NaN | Loss: 4.7395e-06 | Loss_d: 1.6963e-04 Loss_e: 6.7011e-05 | Loss_b: 4.7322e-05\n",
      "Step: NaN | Loss: 4.7439e-06 | Loss_d: 1.6879e-04 Loss_e: 6.7421e-05 | Loss_b: 4.8012e-05\n",
      "Step: NaN | Loss: 4.7388e-06 | Loss_d: 1.6940e-04 Loss_e: 6.7088e-05 | Loss_b: 4.7436e-05\n",
      "Step: NaN | Loss: 4.7370e-06 | Loss_d: 1.6943e-04 Loss_e: 6.7089e-05 | Loss_b: 4.7297e-05\n",
      "Step: NaN | Loss: 4.7309e-06 | Loss_d: 1.6955e-04 Loss_e: 6.7108e-05 | Loss_b: 4.6787e-05\n",
      "Step: NaN | Loss: 4.7287e-06 | Loss_d: 1.7042e-04 Loss_e: 6.7594e-05 | Loss_b: 4.5307e-05\n",
      "Step: NaN | Loss: 4.7239e-06 | Loss_d: 1.6998e-04 Loss_e: 6.7292e-05 | Loss_b: 4.5759e-05\n",
      "Step: NaN | Loss: 4.7159e-06 | Loss_d: 1.7050e-04 Loss_e: 6.7342e-05 | Loss_b: 4.4705e-05\n",
      "Step: NaN | Loss: 4.7742e-06 | Loss_d: 1.7308e-04 Loss_e: 6.8842e-05 | Loss_b: 4.4113e-05\n",
      "Step: NaN | Loss: 4.7152e-06 | Loss_d: 1.7072e-04 Loss_e: 6.7396e-05 | Loss_b: 4.4395e-05\n",
      "Step: NaN | Loss: 4.7129e-06 | Loss_d: 1.7072e-04 Loss_e: 6.7417e-05 | Loss_b: 4.4231e-05\n",
      "Step: NaN | Loss: 4.7102e-06 | Loss_d: 1.7078e-04 Loss_e: 6.7576e-05 | Loss_b: 4.3852e-05\n",
      "Step: NaN | Loss: 4.7099e-06 | Loss_d: 1.7076e-04 Loss_e: 6.7526e-05 | Loss_b: 4.3904e-05\n",
      "Step: NaN | Loss: 4.7061e-06 | Loss_d: 1.7049e-04 Loss_e: 6.7407e-05 | Loss_b: 4.4065e-05\n",
      "Step: NaN | Loss: 4.7026e-06 | Loss_d: 1.6984e-04 Loss_e: 6.7100e-05 | Loss_b: 4.4810e-05\n",
      "Step: NaN | Loss: 4.7017e-06 | Loss_d: 1.6997e-04 Loss_e: 6.7167e-05 | Loss_b: 4.4560e-05\n",
      "Step: NaN | Loss: 4.6936e-06 | Loss_d: 1.7009e-04 Loss_e: 6.6938e-05 | Loss_b: 4.4191e-05\n",
      "Step: NaN | Loss: 4.7230e-06 | Loss_d: 1.7079e-04 Loss_e: 6.6884e-05 | Loss_b: 4.5304e-05\n",
      "Step: NaN | Loss: 4.6916e-06 | Loss_d: 1.7019e-04 Loss_e: 6.6816e-05 | Loss_b: 4.4084e-05\n",
      "Step: NaN | Loss: 4.6860e-06 | Loss_d: 1.7035e-04 Loss_e: 6.6731e-05 | Loss_b: 4.3681e-05\n",
      "Step: NaN | Loss: 4.6910e-06 | Loss_d: 1.7156e-04 Loss_e: 6.6976e-05 | Loss_b: 4.2525e-05\n",
      "Step: NaN | Loss: 4.6827e-06 | Loss_d: 1.7069e-04 Loss_e: 6.6714e-05 | Loss_b: 4.3151e-05\n",
      "Step: NaN | Loss: 4.6779e-06 | Loss_d: 1.7020e-04 Loss_e: 6.6597e-05 | Loss_b: 4.3477e-05\n",
      "Step: NaN | Loss: 4.6777e-06 | Loss_d: 1.7028e-04 Loss_e: 6.6592e-05 | Loss_b: 4.3395e-05\n",
      "Step: NaN | Loss: 4.6817e-06 | Loss_d: 1.7016e-04 Loss_e: 6.6938e-05 | Loss_b: 4.3406e-05\n",
      "Step: NaN | Loss: 4.6758e-06 | Loss_d: 1.7021e-04 Loss_e: 6.6662e-05 | Loss_b: 4.3281e-05\n",
      "Step: NaN | Loss: 4.6749e-06 | Loss_d: 1.7007e-04 Loss_e: 6.6739e-05 | Loss_b: 4.3282e-05\n",
      "Step: NaN | Loss: 4.6875e-06 | Loss_d: 1.6965e-04 Loss_e: 6.7209e-05 | Loss_b: 4.3987e-05\n",
      "Step: NaN | Loss: 4.6749e-06 | Loss_d: 1.7006e-04 Loss_e: 6.6745e-05 | Loss_b: 4.3285e-05\n",
      "Step: NaN | Loss: 4.6740e-06 | Loss_d: 1.6980e-04 Loss_e: 6.6816e-05 | Loss_b: 4.3421e-05\n",
      "Step: NaN | Loss: 4.6735e-06 | Loss_d: 1.6882e-04 Loss_e: 6.7167e-05 | Loss_b: 4.4021e-05\n",
      "Step: NaN | Loss: 4.6731e-06 | Loss_d: 1.6919e-04 Loss_e: 6.7018e-05 | Loss_b: 4.3777e-05\n",
      "Step: NaN | Loss: 4.6698e-06 | Loss_d: 1.6900e-04 Loss_e: 6.7116e-05 | Loss_b: 4.3671e-05\n",
      "Step: NaN | Loss: 4.6704e-06 | Loss_d: 1.6841e-04 Loss_e: 6.7762e-05 | Loss_b: 4.3650e-05\n",
      "Step: NaN | Loss: 4.6673e-06 | Loss_d: 1.6869e-04 Loss_e: 6.7371e-05 | Loss_b: 4.3581e-05\n",
      "Step: NaN | Loss: 4.6662e-06 | Loss_d: 1.6951e-04 Loss_e: 6.7739e-05 | Loss_b: 4.2326e-05\n",
      "Step: NaN | Loss: 4.6644e-06 | Loss_d: 1.6912e-04 Loss_e: 6.7552e-05 | Loss_b: 4.2795e-05\n",
      "Step: NaN | Loss: 4.6631e-06 | Loss_d: 1.6912e-04 Loss_e: 6.7507e-05 | Loss_b: 4.2759e-05\n",
      "Step: NaN | Loss: 4.6587e-06 | Loss_d: 1.6915e-04 Loss_e: 6.7349e-05 | Loss_b: 4.2624e-05\n",
      "Step: NaN | Loss: 4.6605e-06 | Loss_d: 1.6995e-04 Loss_e: 6.7053e-05 | Loss_b: 4.2230e-05\n",
      "Step: NaN | Loss: 4.6547e-06 | Loss_d: 1.6939e-04 Loss_e: 6.7112e-05 | Loss_b: 4.2388e-05\n",
      "Step: NaN | Loss: 4.6749e-06 | Loss_d: 1.6961e-04 Loss_e: 6.6716e-05 | Loss_b: 4.3766e-05\n",
      "Step: NaN | Loss: 4.6503e-06 | Loss_d: 1.6933e-04 Loss_e: 6.6921e-05 | Loss_b: 4.2367e-05\n",
      "Step: NaN | Loss: 4.6362e-06 | Loss_d: 1.6849e-04 Loss_e: 6.7002e-05 | Loss_b: 4.2279e-05\n",
      "Step: NaN | Loss: 4.6514e-06 | Loss_d: 1.6580e-04 Loss_e: 6.9204e-05 | Loss_b: 4.3686e-05\n",
      "Step: NaN | Loss: 4.6283e-06 | Loss_d: 1.6739e-04 Loss_e: 6.7451e-05 | Loss_b: 4.2460e-05\n",
      "Step: NaN | Loss: 4.6279e-06 | Loss_d: 1.6714e-04 Loss_e: 6.7992e-05 | Loss_b: 4.2143e-05\n",
      "Step: NaN | Loss: 4.6260e-06 | Loss_d: 1.6725e-04 Loss_e: 6.7712e-05 | Loss_b: 4.2204e-05\n",
      "Step: NaN | Loss: 4.6245e-06 | Loss_d: 1.6715e-04 Loss_e: 6.7659e-05 | Loss_b: 4.2263e-05\n",
      "Step: NaN | Loss: 4.6248e-06 | Loss_d: 1.6680e-04 Loss_e: 6.7587e-05 | Loss_b: 4.2709e-05\n",
      "Step: NaN | Loss: 4.6234e-06 | Loss_d: 1.6698e-04 Loss_e: 6.7597e-05 | Loss_b: 4.2430e-05\n",
      "Step: NaN | Loss: 4.6211e-06 | Loss_d: 1.6683e-04 Loss_e: 6.7628e-05 | Loss_b: 4.2414e-05\n",
      "Step: NaN | Loss: 4.6211e-06 | Loss_d: 1.6627e-04 Loss_e: 6.7919e-05 | Loss_b: 4.2686e-05\n",
      "Step: NaN | Loss: 4.6193e-06 | Loss_d: 1.6654e-04 Loss_e: 6.7737e-05 | Loss_b: 4.2481e-05\n",
      "Step: NaN | Loss: 4.6174e-06 | Loss_d: 1.6662e-04 Loss_e: 6.7534e-05 | Loss_b: 4.2494e-05\n",
      "Step: NaN | Loss: 4.6154e-06 | Loss_d: 1.6701e-04 Loss_e: 6.6818e-05 | Loss_b: 4.2703e-05\n",
      "Step: NaN | Loss: 4.6151e-06 | Loss_d: 1.6689e-04 Loss_e: 6.6996e-05 | Loss_b: 4.2623e-05\n",
      "Step: NaN | Loss: 4.6127e-06 | Loss_d: 1.6694e-04 Loss_e: 6.7132e-05 | Loss_b: 4.2290e-05\n",
      "Step: NaN | Loss: 4.6127e-06 | Loss_d: 1.6694e-04 Loss_e: 6.7123e-05 | Loss_b: 4.2303e-05\n",
      "Step: NaN | Loss: 4.6090e-06 | Loss_d: 1.6712e-04 Loss_e: 6.7100e-05 | Loss_b: 4.1921e-05\n",
      "Step: NaN | Loss: 4.6311e-06 | Loss_d: 1.6821e-04 Loss_e: 6.7396e-05 | Loss_b: 4.1863e-05\n",
      "Step: NaN | Loss: 4.6085e-06 | Loss_d: 1.6722e-04 Loss_e: 6.7104e-05 | Loss_b: 4.1787e-05\n",
      "Step: NaN | Loss: 4.6070e-06 | Loss_d: 1.6731e-04 Loss_e: 6.7025e-05 | Loss_b: 4.1688e-05\n",
      "Step: NaN | Loss: 4.6043e-06 | Loss_d: 1.6770e-04 Loss_e: 6.6783e-05 | Loss_b: 4.1375e-05\n",
      "Step: NaN | Loss: 4.6679e-06 | Loss_d: 1.7057e-04 Loss_e: 6.7352e-05 | Loss_b: 4.1750e-05\n",
      "Step: NaN | Loss: 4.6043e-06 | Loss_d: 1.6772e-04 Loss_e: 6.6777e-05 | Loss_b: 4.1369e-05\n",
      "Step: NaN | Loss: 4.5940e-06 | Loss_d: 1.6649e-04 Loss_e: 6.6811e-05 | Loss_b: 4.1945e-05\n",
      "Step: NaN | Loss: 4.6151e-06 | Loss_d: 1.6278e-04 Loss_e: 6.8042e-05 | Loss_b: 4.5691e-05\n",
      "Step: NaN | Loss: 4.5899e-06 | Loss_d: 1.6523e-04 Loss_e: 6.6986e-05 | Loss_b: 4.2781e-05\n",
      "Step: NaN | Loss: 4.5864e-06 | Loss_d: 1.6419e-04 Loss_e: 6.7344e-05 | Loss_b: 4.3257e-05\n",
      "Step: NaN | Loss: 4.5806e-06 | Loss_d: 1.6460e-04 Loss_e: 6.7071e-05 | Loss_b: 4.2779e-05\n",
      "Step: NaN | Loss: 4.5764e-06 | Loss_d: 1.6462e-04 Loss_e: 6.6839e-05 | Loss_b: 4.2725e-05\n",
      "Step: NaN | Loss: 4.5710e-06 | Loss_d: 1.6482e-04 Loss_e: 6.6212e-05 | Loss_b: 4.2838e-05\n",
      "Step: NaN | Loss: 4.5706e-06 | Loss_d: 1.6477e-04 Loss_e: 6.6304e-05 | Loss_b: 4.2771e-05\n",
      "Step: NaN | Loss: 4.5648e-06 | Loss_d: 1.6463e-04 Loss_e: 6.6466e-05 | Loss_b: 4.2404e-05\n",
      "Step: NaN | Loss: 4.6015e-06 | Loss_d: 1.6468e-04 Loss_e: 6.7609e-05 | Loss_b: 4.3408e-05\n",
      "Step: NaN | Loss: 4.5640e-06 | Loss_d: 1.6458e-04 Loss_e: 6.6560e-05 | Loss_b: 4.2308e-05\n",
      "Step: NaN | Loss: 4.5614e-06 | Loss_d: 1.6461e-04 Loss_e: 6.6339e-05 | Loss_b: 4.2345e-05\n",
      "Step: NaN | Loss: 4.5588e-06 | Loss_d: 1.6481e-04 Loss_e: 6.5710e-05 | Loss_b: 4.2611e-05\n",
      "Step: NaN | Loss: 4.5582e-06 | Loss_d: 1.6473e-04 Loss_e: 6.5862e-05 | Loss_b: 4.2506e-05\n",
      "Step: NaN | Loss: 4.5524e-06 | Loss_d: 1.6390e-04 Loss_e: 6.5995e-05 | Loss_b: 4.2853e-05\n",
      "Step: NaN | Loss: 4.6121e-06 | Loss_d: 1.6119e-04 Loss_e: 6.9594e-05 | Loss_b: 4.5551e-05\n",
      "Step: NaN | Loss: 4.5522e-06 | Loss_d: 1.6375e-04 Loss_e: 6.6058e-05 | Loss_b: 4.2938e-05\n",
      "Step: NaN | Loss: 4.5458e-06 | Loss_d: 1.6351e-04 Loss_e: 6.6339e-05 | Loss_b: 4.2514e-05\n",
      "Step: NaN | Loss: 4.5697e-06 | Loss_d: 1.6345e-04 Loss_e: 6.8282e-05 | Loss_b: 4.2061e-05\n",
      "Step: NaN | Loss: 4.5443e-06 | Loss_d: 1.6338e-04 Loss_e: 6.6620e-05 | Loss_b: 4.2268e-05\n",
      "Step: NaN | Loss: 4.5379e-06 | Loss_d: 1.6357e-04 Loss_e: 6.6050e-05 | Loss_b: 4.2259e-05\n",
      "Step: NaN | Loss: 4.6289e-06 | Loss_d: 1.6558e-04 Loss_e: 6.5225e-05 | Loss_b: 4.6532e-05\n",
      "Step: NaN | Loss: 4.5379e-06 | Loss_d: 1.6359e-04 Loss_e: 6.6025e-05 | Loss_b: 4.2271e-05\n",
      "Step: NaN | Loss: 4.5334e-06 | Loss_d: 1.6362e-04 Loss_e: 6.5731e-05 | Loss_b: 4.2261e-05\n",
      "Step: NaN | Loss: 4.5420e-06 | Loss_d: 1.6388e-04 Loss_e: 6.5251e-05 | Loss_b: 4.3006e-05\n",
      "Step: NaN | Loss: 4.5316e-06 | Loss_d: 1.6368e-04 Loss_e: 6.5473e-05 | Loss_b: 4.2353e-05\n",
      "Step: NaN | Loss: 4.5499e-06 | Loss_d: 1.6351e-04 Loss_e: 6.5297e-05 | Loss_b: 4.3802e-05\n",
      "Step: NaN | Loss: 4.5295e-06 | Loss_d: 1.6362e-04 Loss_e: 6.5386e-05 | Loss_b: 4.2378e-05\n",
      "Step: NaN | Loss: 4.5279e-06 | Loss_d: 1.6371e-04 Loss_e: 6.5391e-05 | Loss_b: 4.2184e-05\n",
      "Step: NaN | Loss: 4.5243e-06 | Loss_d: 1.6413e-04 Loss_e: 6.5464e-05 | Loss_b: 4.1479e-05\n",
      "Step: NaN | Loss: 4.5751e-06 | Loss_d: 1.6721e-04 Loss_e: 6.7108e-05 | Loss_b: 3.9796e-05\n",
      "Step: NaN | Loss: 4.5241e-06 | Loss_d: 1.6426e-04 Loss_e: 6.5501e-05 | Loss_b: 4.1299e-05\n",
      "Step: NaN | Loss: 4.5188e-06 | Loss_d: 1.6392e-04 Loss_e: 6.5506e-05 | Loss_b: 4.1321e-05\n",
      "Step: NaN | Loss: 4.5166e-06 | Loss_d: 1.6261e-04 Loss_e: 6.5764e-05 | Loss_b: 4.2238e-05\n",
      "Step: NaN | Loss: 4.5139e-06 | Loss_d: 1.6315e-04 Loss_e: 6.5607e-05 | Loss_b: 4.1694e-05\n",
      "Step: NaN | Loss: 4.5100e-06 | Loss_d: 1.6257e-04 Loss_e: 6.5779e-05 | Loss_b: 4.1867e-05\n",
      "Step: NaN | Loss: 4.5122e-06 | Loss_d: 1.6040e-04 Loss_e: 6.6739e-05 | Loss_b: 4.3209e-05\n",
      "Step: NaN | Loss: 4.5074e-06 | Loss_d: 1.6163e-04 Loss_e: 6.6128e-05 | Loss_b: 4.2300e-05\n",
      "Step: NaN | Loss: 4.5042e-06 | Loss_d: 1.6165e-04 Loss_e: 6.5888e-05 | Loss_b: 4.2328e-05\n",
      "Step: NaN | Loss: 4.5016e-06 | Loss_d: 1.6187e-04 Loss_e: 6.5168e-05 | Loss_b: 4.2672e-05\n",
      "Step: NaN | Loss: 4.5007e-06 | Loss_d: 1.6177e-04 Loss_e: 6.5365e-05 | Loss_b: 4.2521e-05\n",
      "Step: NaN | Loss: 4.5019e-06 | Loss_d: 1.6232e-04 Loss_e: 6.5101e-05 | Loss_b: 4.2308e-05\n",
      "Step: NaN | Loss: 4.4979e-06 | Loss_d: 1.6197e-04 Loss_e: 6.5187e-05 | Loss_b: 4.2326e-05\n",
      "Step: NaN | Loss: 4.4953e-06 | Loss_d: 1.6208e-04 Loss_e: 6.5009e-05 | Loss_b: 4.2240e-05\n",
      "Step: NaN | Loss: 4.5092e-06 | Loss_d: 1.6285e-04 Loss_e: 6.4723e-05 | Loss_b: 4.2590e-05\n",
      "Step: NaN | Loss: 4.4949e-06 | Loss_d: 1.6216e-04 Loss_e: 6.4927e-05 | Loss_b: 4.2221e-05\n",
      "Step: NaN | Loss: 4.4933e-06 | Loss_d: 1.6210e-04 Loss_e: 6.4939e-05 | Loss_b: 4.2174e-05\n",
      "Step: NaN | Loss: 4.4884e-06 | Loss_d: 1.6189e-04 Loss_e: 6.5018e-05 | Loss_b: 4.2013e-05\n",
      "Step: NaN | Loss: 4.4921e-06 | Loss_d: 1.6121e-04 Loss_e: 6.6080e-05 | Loss_b: 4.1856e-05\n",
      "Step: NaN | Loss: 4.4843e-06 | Loss_d: 1.6152e-04 Loss_e: 6.5335e-05 | Loss_b: 4.1819e-05\n",
      "Step: NaN | Loss: 4.4745e-06 | Loss_d: 1.6097e-04 Loss_e: 6.4823e-05 | Loss_b: 4.2297e-05\n",
      "Step: NaN | Loss: 4.5394e-06 | Loss_d: 1.6069e-04 Loss_e: 6.5338e-05 | Loss_b: 4.5943e-05\n",
      "Step: NaN | Loss: 4.4735e-06 | Loss_d: 1.6078e-04 Loss_e: 6.4679e-05 | Loss_b: 4.2563e-05\n",
      "Step: NaN | Loss: 4.4659e-06 | Loss_d: 1.6060e-04 Loss_e: 6.4563e-05 | Loss_b: 4.2412e-05\n",
      "Step: NaN | Loss: 4.4583e-06 | Loss_d: 1.5997e-04 Loss_e: 6.4757e-05 | Loss_b: 4.2392e-05\n",
      "Step: NaN | Loss: 4.4568e-06 | Loss_d: 1.6013e-04 Loss_e: 6.4593e-05 | Loss_b: 4.2302e-05\n",
      "Step: NaN | Loss: 4.4459e-06 | Loss_d: 1.5971e-04 Loss_e: 6.4412e-05 | Loss_b: 4.2251e-05\n",
      "Step: NaN | Loss: 4.5933e-06 | Loss_d: 1.5925e-04 Loss_e: 6.7024e-05 | Loss_b: 4.8927e-05\n",
      "Step: NaN | Loss: 4.4459e-06 | Loss_d: 1.5968e-04 Loss_e: 6.4412e-05 | Loss_b: 4.2274e-05\n",
      "Step: NaN | Loss: 4.4312e-06 | Loss_d: 1.5908e-04 Loss_e: 6.4416e-05 | Loss_b: 4.1996e-05\n",
      "Step: NaN | Loss: 4.4397e-06 | Loss_d: 1.5706e-04 Loss_e: 6.5458e-05 | Loss_b: 4.3490e-05\n",
      "Step: NaN | Loss: 4.4217e-06 | Loss_d: 1.5815e-04 Loss_e: 6.4656e-05 | Loss_b: 4.2119e-05\n",
      "Step: NaN | Loss: 4.4115e-06 | Loss_d: 1.5648e-04 Loss_e: 6.5326e-05 | Loss_b: 4.2509e-05\n",
      "Step: NaN | Loss: 4.4063e-06 | Loss_d: 1.5697e-04 Loss_e: 6.5003e-05 | Loss_b: 4.2028e-05\n",
      "Step: NaN | Loss: 4.4050e-06 | Loss_d: 1.5706e-04 Loss_e: 6.4941e-05 | Loss_b: 4.1917e-05\n",
      "Step: NaN | Loss: 4.4025e-06 | Loss_d: 1.5746e-04 Loss_e: 6.4749e-05 | Loss_b: 4.1566e-05\n",
      "Step: NaN | Loss: 4.4581e-06 | Loss_d: 1.5999e-04 Loss_e: 6.5025e-05 | Loss_b: 4.2088e-05\n",
      "Step: NaN | Loss: 4.4025e-06 | Loss_d: 1.5748e-04 Loss_e: 6.4739e-05 | Loss_b: 4.1548e-05\n",
      "Step: NaN | Loss: 4.3987e-06 | Loss_d: 1.5778e-04 Loss_e: 6.4768e-05 | Loss_b: 4.0990e-05\n",
      "Step: NaN | Loss: 4.3985e-06 | Loss_d: 1.5920e-04 Loss_e: 6.5052e-05 | Loss_b: 3.9287e-05\n",
      "Step: NaN | Loss: 4.3955e-06 | Loss_d: 1.5845e-04 Loss_e: 6.4876e-05 | Loss_b: 4.0025e-05\n",
      "Step: NaN | Loss: 4.3913e-06 | Loss_d: 1.5898e-04 Loss_e: 6.4568e-05 | Loss_b: 3.9554e-05\n",
      "Step: NaN | Loss: 4.3913e-06 | Loss_d: 1.5894e-04 Loss_e: 6.4586e-05 | Loss_b: 3.9574e-05\n",
      "Step: NaN | Loss: 4.3871e-06 | Loss_d: 1.5870e-04 Loss_e: 6.4586e-05 | Loss_b: 3.9562e-05\n",
      "Step: NaN | Loss: 4.3793e-06 | Loss_d: 1.5783e-04 Loss_e: 6.4741e-05 | Loss_b: 3.9808e-05\n",
      "Step: NaN | Loss: 4.5889e-06 | Loss_d: 1.5556e-04 Loss_e: 6.9879e-05 | Loss_b: 4.9498e-05\n",
      "Step: NaN | Loss: 4.3793e-06 | Loss_d: 1.5781e-04 Loss_e: 6.4749e-05 | Loss_b: 3.9823e-05\n",
      "Step: NaN | Loss: 4.3748e-06 | Loss_d: 1.5722e-04 Loss_e: 6.4864e-05 | Loss_b: 4.0027e-05\n",
      "Step: NaN | Loss: 4.3743e-06 | Loss_d: 1.5735e-04 Loss_e: 6.4822e-05 | Loss_b: 3.9912e-05\n",
      "Step: NaN | Loss: 4.3702e-06 | Loss_d: 1.5703e-04 Loss_e: 6.4822e-05 | Loss_b: 3.9983e-05\n",
      "Step: NaN | Loss: 4.3664e-06 | Loss_d: 1.5608e-04 Loss_e: 6.4953e-05 | Loss_b: 4.0579e-05\n",
      "Step: NaN | Loss: 4.3655e-06 | Loss_d: 1.5632e-04 Loss_e: 6.4890e-05 | Loss_b: 4.0344e-05\n",
      "Step: NaN | Loss: 4.3602e-06 | Loss_d: 1.5635e-04 Loss_e: 6.4700e-05 | Loss_b: 4.0185e-05\n",
      "Step: NaN | Loss: 4.3436e-06 | Loss_d: 1.5650e-04 Loss_e: 6.4078e-05 | Loss_b: 3.9662e-05\n",
      "Step: NaN | Loss: 4.3742e-06 | Loss_d: 1.5801e-04 Loss_e: 6.4246e-05 | Loss_b: 3.9824e-05\n",
      "Step: NaN | Loss: 4.3323e-06 | Loss_d: 1.5686e-04 Loss_e: 6.3532e-05 | Loss_b: 3.9171e-05\n",
      "Step: NaN | Loss: 4.3182e-06 | Loss_d: 1.5672e-04 Loss_e: 6.3028e-05 | Loss_b: 3.8973e-05\n",
      "Step: NaN | Loss: 4.4311e-06 | Loss_d: 1.5704e-04 Loss_e: 6.6256e-05 | Loss_b: 4.2192e-05\n",
      "Step: NaN | Loss: 4.3173e-06 | Loss_d: 1.5669e-04 Loss_e: 6.2977e-05 | Loss_b: 3.8995e-05\n",
      "Step: NaN | Loss: 4.3141e-06 | Loss_d: 1.5623e-04 Loss_e: 6.3106e-05 | Loss_b: 3.9135e-05\n",
      "Step: NaN | Loss: 4.3287e-06 | Loss_d: 1.5483e-04 Loss_e: 6.4333e-05 | Loss_b: 4.0186e-05\n",
      "Step: NaN | Loss: 4.3134e-06 | Loss_d: 1.5595e-04 Loss_e: 6.3231e-05 | Loss_b: 3.9252e-05\n",
      "Step: NaN | Loss: 4.3107e-06 | Loss_d: 1.5594e-04 Loss_e: 6.3086e-05 | Loss_b: 3.9248e-05\n",
      "Step: NaN | Loss: 4.3105e-06 | Loss_d: 1.5606e-04 Loss_e: 6.2803e-05 | Loss_b: 3.9401e-05\n",
      "Step: NaN | Loss: 4.3086e-06 | Loss_d: 1.5597e-04 Loss_e: 6.2880e-05 | Loss_b: 3.9295e-05\n",
      "Step: NaN | Loss: 4.3019e-06 | Loss_d: 1.5601e-04 Loss_e: 6.2493e-05 | Loss_b: 3.9240e-05\n",
      "Step: NaN | Loss: 4.4071e-06 | Loss_d: 1.5645e-04 Loss_e: 6.2609e-05 | Loss_b: 4.4993e-05\n",
      "Step: NaN | Loss: 4.3019e-06 | Loss_d: 1.5601e-04 Loss_e: 6.2493e-05 | Loss_b: 3.9240e-05\n",
      "Step: NaN | Loss: 4.2925e-06 | Loss_d: 1.5620e-04 Loss_e: 6.2232e-05 | Loss_b: 3.8753e-05\n",
      "Step: NaN | Loss: 4.3318e-06 | Loss_d: 1.5740e-04 Loss_e: 6.1840e-05 | Loss_b: 4.0299e-05\n",
      "Step: NaN | Loss: 4.2904e-06 | Loss_d: 1.5636e-04 Loss_e: 6.2085e-05 | Loss_b: 3.8618e-05\n",
      "Step: NaN | Loss: 4.2846e-06 | Loss_d: 1.5629e-04 Loss_e: 6.1931e-05 | Loss_b: 3.8487e-05\n",
      "Step: NaN | Loss: 4.2791e-06 | Loss_d: 1.5615e-04 Loss_e: 6.1502e-05 | Loss_b: 3.8728e-05\n",
      "Step: NaN | Loss: 4.2778e-06 | Loss_d: 1.5618e-04 Loss_e: 6.1601e-05 | Loss_b: 3.8526e-05\n",
      "Step: NaN | Loss: 4.2713e-06 | Loss_d: 1.5533e-04 Loss_e: 6.1550e-05 | Loss_b: 3.9026e-05\n",
      "Step: NaN | Loss: 4.2756e-06 | Loss_d: 1.5228e-04 Loss_e: 6.1940e-05 | Loss_b: 4.1946e-05\n",
      "Step: NaN | Loss: 4.2672e-06 | Loss_d: 1.5401e-04 Loss_e: 6.1595e-05 | Loss_b: 4.0056e-05\n",
      "Step: NaN | Loss: 4.2626e-06 | Loss_d: 1.5390e-04 Loss_e: 6.1339e-05 | Loss_b: 4.0151e-05\n",
      "Step: NaN | Loss: 4.2695e-06 | Loss_d: 1.5373e-04 Loss_e: 6.0695e-05 | Loss_b: 4.1380e-05\n",
      "Step: NaN | Loss: 4.2604e-06 | Loss_d: 1.5379e-04 Loss_e: 6.1060e-05 | Loss_b: 4.0402e-05\n",
      "Step: NaN | Loss: 4.2553e-06 | Loss_d: 1.5368e-04 Loss_e: 6.0818e-05 | Loss_b: 4.0450e-05\n",
      "Step: NaN | Loss: 4.2433e-06 | Loss_d: 1.5342e-04 Loss_e: 5.9989e-05 | Loss_b: 4.0829e-05\n",
      "Step: NaN | Loss: 4.3782e-06 | Loss_d: 1.5630e-04 Loss_e: 5.8916e-05 | Loss_b: 4.7096e-05\n",
      "Step: NaN | Loss: 4.2422e-06 | Loss_d: 1.5339e-04 Loss_e: 5.9709e-05 | Loss_b: 4.1071e-05\n",
      "Step: NaN | Loss: 4.2611e-06 | Loss_d: 1.5499e-04 Loss_e: 5.8474e-05 | Loss_b: 4.1836e-05\n",
      "Step: NaN | Loss: 4.2348e-06 | Loss_d: 1.5377e-04 Loss_e: 5.9112e-05 | Loss_b: 4.0848e-05\n",
      "Step: NaN | Loss: 4.2259e-06 | Loss_d: 1.5320e-04 Loss_e: 5.8980e-05 | Loss_b: 4.1013e-05\n",
      "Step: NaN | Loss: 4.2543e-06 | Loss_d: 1.5202e-04 Loss_e: 6.0331e-05 | Loss_b: 4.2548e-05\n",
      "Step: NaN | Loss: 4.2232e-06 | Loss_d: 1.5279e-04 Loss_e: 5.9017e-05 | Loss_b: 4.1228e-05\n",
      "Step: NaN | Loss: 4.2166e-06 | Loss_d: 1.5273e-04 Loss_e: 5.8777e-05 | Loss_b: 4.1125e-05\n",
      "Step: NaN | Loss: 4.2318e-06 | Loss_d: 1.5288e-04 Loss_e: 5.9097e-05 | Loss_b: 4.1571e-05\n",
      "Step: NaN | Loss: 4.2141e-06 | Loss_d: 1.5272e-04 Loss_e: 5.8660e-05 | Loss_b: 4.1107e-05\n",
      "Step: NaN | Loss: 4.2124e-06 | Loss_d: 1.5391e-04 Loss_e: 5.8011e-05 | Loss_b: 4.0463e-05\n",
      "Step: NaN | Loss: 4.2095e-06 | Loss_d: 1.5335e-04 Loss_e: 5.8247e-05 | Loss_b: 4.0618e-05\n",
      "Step: NaN | Loss: 4.2058e-06 | Loss_d: 1.5344e-04 Loss_e: 5.8014e-05 | Loss_b: 4.0538e-05\n",
      "Step: NaN | Loss: 4.2036e-06 | Loss_d: 1.5384e-04 Loss_e: 5.7246e-05 | Loss_b: 4.0768e-05\n",
      "Step: NaN | Loss: 4.2021e-06 | Loss_d: 1.5368e-04 Loss_e: 5.7512e-05 | Loss_b: 4.0574e-05\n",
      "Step: NaN | Loss: 4.1987e-06 | Loss_d: 1.5335e-04 Loss_e: 5.7404e-05 | Loss_b: 4.0809e-05\n",
      "Step: NaN | Loss: 4.2106e-06 | Loss_d: 1.5213e-04 Loss_e: 5.7237e-05 | Loss_b: 4.2903e-05\n",
      "Step: NaN | Loss: 4.1978e-06 | Loss_d: 1.5308e-04 Loss_e: 5.7334e-05 | Loss_b: 4.1092e-05\n",
      "Step: NaN | Loss: 4.2009e-06 | Loss_d: 1.5254e-04 Loss_e: 5.7013e-05 | Loss_b: 4.2135e-05\n",
      "Step: NaN | Loss: 4.1960e-06 | Loss_d: 1.5287e-04 Loss_e: 5.7203e-05 | Loss_b: 4.1329e-05\n",
      "Step: NaN | Loss: 4.1951e-06 | Loss_d: 1.5292e-04 Loss_e: 5.7131e-05 | Loss_b: 4.1293e-05\n",
      "Step: NaN | Loss: 4.1940e-06 | Loss_d: 1.5319e-04 Loss_e: 5.6877e-05 | Loss_b: 4.1206e-05\n",
      "Step: NaN | Loss: 4.1939e-06 | Loss_d: 1.5313e-04 Loss_e: 5.6928e-05 | Loss_b: 4.1217e-05\n",
      "Step: NaN | Loss: 4.1902e-06 | Loss_d: 1.5304e-04 Loss_e: 5.6722e-05 | Loss_b: 4.1291e-05\n",
      "Step: NaN | Loss: 4.1898e-06 | Loss_d: 1.5305e-04 Loss_e: 5.6732e-05 | Loss_b: 4.1248e-05\n",
      "Step: NaN | Loss: 4.1861e-06 | Loss_d: 1.5369e-04 Loss_e: 5.6410e-05 | Loss_b: 4.0712e-05\n",
      "Step: NaN | Loss: 4.2170e-06 | Loss_d: 1.5686e-04 Loss_e: 5.6039e-05 | Loss_b: 3.9753e-05\n",
      "Step: NaN | Loss: 4.1860e-06 | Loss_d: 1.5389e-04 Loss_e: 5.6331e-05 | Loss_b: 4.0577e-05\n",
      "Step: NaN | Loss: 4.1819e-06 | Loss_d: 1.5391e-04 Loss_e: 5.6247e-05 | Loss_b: 4.0400e-05\n",
      "Step: NaN | Loss: 4.1818e-06 | Loss_d: 1.5390e-04 Loss_e: 5.6249e-05 | Loss_b: 4.0397e-05\n",
      "Step: NaN | Loss: 4.1774e-06 | Loss_d: 1.5410e-04 Loss_e: 5.6100e-05 | Loss_b: 4.0087e-05\n",
      "Step: NaN | Loss: 4.1800e-06 | Loss_d: 1.5519e-04 Loss_e: 5.5591e-05 | Loss_b: 3.9657e-05\n",
      "Step: NaN | Loss: 4.1746e-06 | Loss_d: 1.5450e-04 Loss_e: 5.5869e-05 | Loss_b: 3.9750e-05\n",
      "Step: NaN | Loss: 4.1701e-06 | Loss_d: 1.5425e-04 Loss_e: 5.5628e-05 | Loss_b: 3.9973e-05\n",
      "Step: NaN | Loss: 4.1669e-06 | Loss_d: 1.5345e-04 Loss_e: 5.4991e-05 | Loss_b: 4.1218e-05\n",
      "Step: NaN | Loss: 4.1654e-06 | Loss_d: 1.5370e-04 Loss_e: 5.5162e-05 | Loss_b: 4.0702e-05\n",
      "Step: NaN | Loss: 4.1587e-06 | Loss_d: 1.5348e-04 Loss_e: 5.4961e-05 | Loss_b: 4.0725e-05\n",
      "Step: NaN | Loss: 4.1455e-06 | Loss_d: 1.5268e-04 Loss_e: 5.4424e-05 | Loss_b: 4.1269e-05\n",
      "Step: NaN | Loss: 4.3939e-06 | Loss_d: 1.5053e-04 Loss_e: 5.8216e-05 | Loss_b: 5.4514e-05\n",
      "Step: NaN | Loss: 4.1453e-06 | Loss_d: 1.5258e-04 Loss_e: 5.4384e-05 | Loss_b: 4.1395e-05\n",
      "Step: NaN | Loss: 4.1500e-06 | Loss_d: 1.5434e-04 Loss_e: 5.3620e-05 | Loss_b: 4.0682e-05\n",
      "Step: NaN | Loss: 4.1400e-06 | Loss_d: 1.5328e-04 Loss_e: 5.3936e-05 | Loss_b: 4.0826e-05\n",
      "Step: NaN | Loss: 4.1386e-06 | Loss_d: 1.5328e-04 Loss_e: 5.3923e-05 | Loss_b: 4.0758e-05\n",
      "Step: NaN | Loss: 4.1366e-06 | Loss_d: 1.5331e-04 Loss_e: 5.3896e-05 | Loss_b: 4.0636e-05\n",
      "Step: NaN | Loss: 4.1365e-06 | Loss_d: 1.5330e-04 Loss_e: 5.3897e-05 | Loss_b: 4.0639e-05\n",
      "Step: NaN | Loss: 4.1337e-06 | Loss_d: 1.5313e-04 Loss_e: 5.3879e-05 | Loss_b: 4.0654e-05\n",
      "Step: NaN | Loss: 4.1329e-06 | Loss_d: 1.5256e-04 Loss_e: 5.4100e-05 | Loss_b: 4.0966e-05\n",
      "Step: NaN | Loss: 4.1311e-06 | Loss_d: 1.5280e-04 Loss_e: 5.3941e-05 | Loss_b: 4.0775e-05\n",
      "Step: NaN | Loss: 4.1290e-06 | Loss_d: 1.5224e-04 Loss_e: 5.4036e-05 | Loss_b: 4.1109e-05\n",
      "Step: NaN | Loss: 4.1290e-06 | Loss_d: 1.5229e-04 Loss_e: 5.4021e-05 | Loss_b: 4.1073e-05\n",
      "Step: NaN | Loss: 4.1277e-06 | Loss_d: 1.5216e-04 Loss_e: 5.4042e-05 | Loss_b: 4.1107e-05\n",
      "Step: NaN | Loss: 4.1277e-06 | Loss_d: 1.5217e-04 Loss_e: 5.4039e-05 | Loss_b: 4.1096e-05\n",
      "Step: NaN | Loss: 4.1256e-06 | Loss_d: 1.5207e-04 Loss_e: 5.4053e-05 | Loss_b: 4.1062e-05\n",
      "Step: NaN | Loss: 4.1198e-06 | Loss_d: 1.5169e-04 Loss_e: 5.4146e-05 | Loss_b: 4.0992e-05\n",
      "Step: NaN | Loss: 4.1449e-06 | Loss_d: 1.5063e-04 Loss_e: 5.5489e-05 | Loss_b: 4.2219e-05\n",
      "Step: NaN | Loss: 4.1174e-06 | Loss_d: 1.5134e-04 Loss_e: 5.4320e-05 | Loss_b: 4.1034e-05\n",
      "Step: NaN | Loss: 4.1114e-06 | Loss_d: 1.5077e-04 Loss_e: 5.4194e-05 | Loss_b: 4.1362e-05\n",
      "Step: NaN | Loss: 4.1205e-06 | Loss_d: 1.4922e-04 Loss_e: 5.4470e-05 | Loss_b: 4.3184e-05\n",
      "Step: NaN | Loss: 4.1085e-06 | Loss_d: 1.5014e-04 Loss_e: 5.4148e-05 | Loss_b: 4.1874e-05\n",
      "Step: NaN | Loss: 4.1206e-06 | Loss_d: 1.5089e-04 Loss_e: 5.3775e-05 | Loss_b: 4.2217e-05\n",
      "Step: NaN | Loss: 4.1077e-06 | Loss_d: 1.5028e-04 Loss_e: 5.4034e-05 | Loss_b: 4.1793e-05\n",
      "Step: NaN | Loss: 4.1068e-06 | Loss_d: 1.5014e-04 Loss_e: 5.4037e-05 | Loss_b: 4.1882e-05\n",
      "Step: NaN | Loss: 4.1062e-06 | Loss_d: 1.4960e-04 Loss_e: 5.4060e-05 | Loss_b: 4.2356e-05\n",
      "Step: NaN | Loss: 4.1059e-06 | Loss_d: 1.4979e-04 Loss_e: 5.4049e-05 | Loss_b: 4.2160e-05\n",
      "Step: NaN | Loss: 4.1042e-06 | Loss_d: 1.4972e-04 Loss_e: 5.3925e-05 | Loss_b: 4.2258e-05\n",
      "Step: NaN | Loss: 4.1016e-06 | Loss_d: 1.4949e-04 Loss_e: 5.3480e-05 | Loss_b: 4.2772e-05\n",
      "Step: NaN | Loss: 4.1015e-06 | Loss_d: 1.4951e-04 Loss_e: 5.3535e-05 | Loss_b: 4.2692e-05\n",
      "Step: NaN | Loss: 4.0941e-06 | Loss_d: 1.4923e-04 Loss_e: 5.3260e-05 | Loss_b: 4.2803e-05\n",
      "Step: NaN | Loss: 4.0807e-06 | Loss_d: 1.4817e-04 Loss_e: 5.2302e-05 | Loss_b: 4.4016e-05\n",
      "Step: NaN | Loss: 4.4022e-06 | Loss_d: 1.4479e-04 Loss_e: 5.0983e-05 | Loss_b: 6.7984e-05\n",
      "Step: NaN | Loss: 4.0807e-06 | Loss_d: 1.4816e-04 Loss_e: 5.2294e-05 | Loss_b: 4.4033e-05\n",
      "Step: NaN | Loss: 4.0582e-06 | Loss_d: 1.4863e-04 Loss_e: 5.1205e-05 | Loss_b: 4.3309e-05\n",
      "Step: NaN | Loss: 4.1269e-06 | Loss_d: 1.5330e-04 Loss_e: 4.8914e-05 | Loss_b: 4.5047e-05\n",
      "Step: NaN | Loss: 4.0514e-06 | Loss_d: 1.4930e-04 Loss_e: 5.0388e-05 | Loss_b: 4.3053e-05\n",
      "Step: NaN | Loss: 4.0343e-06 | Loss_d: 1.4877e-04 Loss_e: 4.9353e-05 | Loss_b: 4.3592e-05\n",
      "Step: NaN | Loss: 4.2595e-06 | Loss_d: 1.4785e-04 Loss_e: 4.8149e-05 | Loss_b: 5.9204e-05\n",
      "Step: NaN | Loss: 4.0341e-06 | Loss_d: 1.4872e-04 Loss_e: 4.9274e-05 | Loss_b: 4.3704e-05\n",
      "Step: NaN | Loss: 4.0259e-06 | Loss_d: 1.4872e-04 Loss_e: 4.8998e-05 | Loss_b: 4.3491e-05\n",
      "Step: NaN | Loss: 3.9993e-06 | Loss_d: 1.4880e-04 Loss_e: 4.8021e-05 | Loss_b: 4.2794e-05\n",
      "Step: NaN | Loss: 4.0170e-06 | Loss_d: 1.5124e-04 Loss_e: 4.6152e-05 | Loss_b: 4.3280e-05\n",
      "Step: NaN | Loss: 3.9758e-06 | Loss_d: 1.4943e-04 Loss_e: 4.6606e-05 | Loss_b: 4.2176e-05\n",
      "Step: NaN | Loss: 3.9654e-06 | Loss_d: 1.4865e-04 Loss_e: 4.6504e-05 | Loss_b: 4.2431e-05\n",
      "Step: NaN | Loss: 4.0750e-06 | Loss_d: 1.4722e-04 Loss_e: 4.7943e-05 | Loss_b: 4.8985e-05\n",
      "Step: NaN | Loss: 3.9651e-06 | Loss_d: 1.4852e-04 Loss_e: 4.6506e-05 | Loss_b: 4.2542e-05\n",
      "Step: NaN | Loss: 3.9600e-06 | Loss_d: 1.4890e-04 Loss_e: 4.6374e-05 | Loss_b: 4.1988e-05\n",
      "Step: NaN | Loss: 3.9869e-06 | Loss_d: 1.5094e-04 Loss_e: 4.6234e-05 | Loss_b: 4.1698e-05\n",
      "Step: NaN | Loss: 3.9591e-06 | Loss_d: 1.4914e-04 Loss_e: 4.6317e-05 | Loss_b: 4.1747e-05\n",
      "Step: NaN | Loss: 3.9572e-06 | Loss_d: 1.4950e-04 Loss_e: 4.6274e-05 | Loss_b: 4.1323e-05\n",
      "Step: NaN | Loss: 3.9572e-06 | Loss_d: 1.4945e-04 Loss_e: 4.6276e-05 | Loss_b: 4.1366e-05\n",
      "Step: NaN | Loss: 3.9557e-06 | Loss_d: 1.4986e-04 Loss_e: 4.6123e-05 | Loss_b: 4.1021e-05\n",
      "Step: NaN | Loss: 3.9635e-06 | Loss_d: 1.5179e-04 Loss_e: 4.5597e-05 | Loss_b: 4.0084e-05\n",
      "Step: NaN | Loss: 3.9555e-06 | Loss_d: 1.5011e-04 Loss_e: 4.6038e-05 | Loss_b: 4.0843e-05\n",
      "Step: NaN | Loss: 3.9540e-06 | Loss_d: 1.5006e-04 Loss_e: 4.6029e-05 | Loss_b: 4.0816e-05\n",
      "Step: NaN | Loss: 3.9501e-06 | Loss_d: 1.4986e-04 Loss_e: 4.6043e-05 | Loss_b: 4.0762e-05\n",
      "Step: NaN | Loss: 3.9750e-06 | Loss_d: 1.4917e-04 Loss_e: 4.7359e-05 | Loss_b: 4.1631e-05\n",
      "Step: NaN | Loss: 3.9491e-06 | Loss_d: 1.4971e-04 Loss_e: 4.6117e-05 | Loss_b: 4.0774e-05\n",
      "Step: NaN | Loss: 3.9415e-06 | Loss_d: 1.4981e-04 Loss_e: 4.6047e-05 | Loss_b: 4.0299e-05\n",
      "Step: NaN | Loss: 3.9512e-06 | Loss_d: 1.5061e-04 Loss_e: 4.6376e-05 | Loss_b: 3.9752e-05\n",
      "Step: NaN | Loss: 3.9376e-06 | Loss_d: 1.5001e-04 Loss_e: 4.6051e-05 | Loss_b: 3.9860e-05\n",
      "Step: NaN | Loss: 3.9360e-06 | Loss_d: 1.4979e-04 Loss_e: 4.5869e-05 | Loss_b: 4.0162e-05\n",
      "Step: NaN | Loss: 3.9359e-06 | Loss_d: 1.4982e-04 Loss_e: 4.5895e-05 | Loss_b: 4.0103e-05\n",
      "Step: NaN | Loss: 3.9338e-06 | Loss_d: 1.4970e-04 Loss_e: 4.5808e-05 | Loss_b: 4.0183e-05\n",
      "Step: NaN | Loss: 3.9316e-06 | Loss_d: 1.4926e-04 Loss_e: 4.5542e-05 | Loss_b: 4.0756e-05\n",
      "Step: NaN | Loss: 3.9313e-06 | Loss_d: 1.4938e-04 Loss_e: 4.5600e-05 | Loss_b: 4.0564e-05\n",
      "Step: NaN | Loss: 3.9276e-06 | Loss_d: 1.4919e-04 Loss_e: 4.5387e-05 | Loss_b: 4.0740e-05\n",
      "Step: NaN | Loss: 3.9319e-06 | Loss_d: 1.4869e-04 Loss_e: 4.4785e-05 | Loss_b: 4.2107e-05\n",
      "Step: NaN | Loss: 3.9258e-06 | Loss_d: 1.4897e-04 Loss_e: 4.5124e-05 | Loss_b: 4.1111e-05\n",
      "Step: NaN | Loss: 3.9229e-06 | Loss_d: 1.4916e-04 Loss_e: 4.5037e-05 | Loss_b: 4.0839e-05\n",
      "Step: NaN | Loss: 3.9153e-06 | Loss_d: 1.4995e-04 Loss_e: 4.4742e-05 | Loss_b: 3.9887e-05\n",
      "Step: NaN | Loss: 3.9762e-06 | Loss_d: 1.5523e-04 Loss_e: 4.4554e-05 | Loss_b: 3.8452e-05\n",
      "Step: NaN | Loss: 3.9139e-06 | Loss_d: 1.5052e-04 Loss_e: 4.4596e-05 | Loss_b: 3.9387e-05\n",
      "Step: NaN | Loss: 3.9092e-06 | Loss_d: 1.5051e-04 Loss_e: 4.4758e-05 | Loss_b: 3.8948e-05\n",
      "Step: NaN | Loss: 3.9539e-06 | Loss_d: 1.5091e-04 Loss_e: 4.7189e-05 | Loss_b: 3.8792e-05\n",
      "Step: NaN | Loss: 3.9091e-06 | Loss_d: 1.5052e-04 Loss_e: 4.4824e-05 | Loss_b: 3.8867e-05\n",
      "Step: NaN | Loss: 3.9071e-06 | Loss_d: 1.5063e-04 Loss_e: 4.4812e-05 | Loss_b: 3.8651e-05\n",
      "Step: NaN | Loss: 3.9071e-06 | Loss_d: 1.5108e-04 Loss_e: 4.4810e-05 | Loss_b: 3.8202e-05\n",
      "Step: NaN | Loss: 3.9055e-06 | Loss_d: 1.5085e-04 Loss_e: 4.4802e-05 | Loss_b: 3.8346e-05\n",
      "Step: NaN | Loss: 3.9033e-06 | Loss_d: 1.5066e-04 Loss_e: 4.4836e-05 | Loss_b: 3.8368e-05\n",
      "Step: NaN | Loss: 3.9009e-06 | Loss_d: 1.4993e-04 Loss_e: 4.5039e-05 | Loss_b: 3.8747e-05\n",
      "Step: NaN | Loss: 3.9005e-06 | Loss_d: 1.5012e-04 Loss_e: 4.4972e-05 | Loss_b: 3.8599e-05\n",
      "Step: NaN | Loss: 3.8957e-06 | Loss_d: 1.5003e-04 Loss_e: 4.4907e-05 | Loss_b: 3.8469e-05\n",
      "Step: NaN | Loss: 3.8872e-06 | Loss_d: 1.4979e-04 Loss_e: 4.4817e-05 | Loss_b: 3.8298e-05\n",
      "Step: NaN | Loss: 4.0825e-06 | Loss_d: 1.5116e-04 Loss_e: 4.8521e-05 | Loss_b: 4.4923e-05\n",
      "Step: NaN | Loss: 3.8872e-06 | Loss_d: 1.4978e-04 Loss_e: 4.4818e-05 | Loss_b: 3.8300e-05\n",
      "Step: NaN | Loss: 3.8875e-06 | Loss_d: 1.4974e-04 Loss_e: 4.4332e-05 | Loss_b: 3.8851e-05\n",
      "Step: NaN | Loss: 3.8841e-06 | Loss_d: 1.4974e-04 Loss_e: 4.4513e-05 | Loss_b: 3.8458e-05\n",
      "Step: NaN | Loss: 3.8811e-06 | Loss_d: 1.4978e-04 Loss_e: 4.4496e-05 | Loss_b: 3.8256e-05\n",
      "Step: NaN | Loss: 3.8943e-06 | Loss_d: 1.5006e-04 Loss_e: 4.4558e-05 | Loss_b: 3.8707e-05\n",
      "Step: NaN | Loss: 3.8805e-06 | Loss_d: 1.4982e-04 Loss_e: 4.4493e-05 | Loss_b: 3.8190e-05\n",
      "Step: NaN | Loss: 3.8796e-06 | Loss_d: 1.4972e-04 Loss_e: 4.4502e-05 | Loss_b: 3.8218e-05\n",
      "Step: NaN | Loss: 3.8772e-06 | Loss_d: 1.4937e-04 Loss_e: 4.4547e-05 | Loss_b: 3.8381e-05\n",
      "Step: NaN | Loss: 3.8982e-06 | Loss_d: 1.4818e-04 Loss_e: 4.5009e-05 | Loss_b: 4.0367e-05\n",
      "Step: NaN | Loss: 3.8769e-06 | Loss_d: 1.4919e-04 Loss_e: 4.4581e-05 | Loss_b: 3.8513e-05\n",
      "Step: NaN | Loss: 3.8736e-06 | Loss_d: 1.4856e-04 Loss_e: 4.4411e-05 | Loss_b: 3.9113e-05\n",
      "Step: NaN | Loss: 3.9310e-06 | Loss_d: 1.4701e-04 Loss_e: 4.4566e-05 | Loss_b: 4.3948e-05\n",
      "Step: NaN | Loss: 3.8736e-06 | Loss_d: 1.4856e-04 Loss_e: 4.4410e-05 | Loss_b: 3.9115e-05\n",
      "Step: NaN | Loss: 3.8716e-06 | Loss_d: 1.4852e-04 Loss_e: 4.4350e-05 | Loss_b: 3.9093e-05\n",
      "Step: NaN | Loss: 3.8698e-06 | Loss_d: 1.4848e-04 Loss_e: 4.4225e-05 | Loss_b: 3.9148e-05\n",
      "Step: NaN | Loss: 3.8694e-06 | Loss_d: 1.4848e-04 Loss_e: 4.4245e-05 | Loss_b: 3.9106e-05\n",
      "Step: NaN | Loss: 3.8665e-06 | Loss_d: 1.4860e-04 Loss_e: 4.3917e-05 | Loss_b: 3.9147e-05\n",
      "Step: NaN | Loss: 3.8717e-06 | Loss_d: 1.4920e-04 Loss_e: 4.3029e-05 | Loss_b: 3.9739e-05\n",
      "Step: NaN | Loss: 3.8653e-06 | Loss_d: 1.4876e-04 Loss_e: 4.3577e-05 | Loss_b: 3.9253e-05\n",
      "Step: NaN | Loss: 3.8637e-06 | Loss_d: 1.4882e-04 Loss_e: 4.3516e-05 | Loss_b: 3.9156e-05\n",
      "Step: NaN | Loss: 3.8586e-06 | Loss_d: 1.4906e-04 Loss_e: 4.3319e-05 | Loss_b: 3.8803e-05\n",
      "Step: NaN | Loss: 3.8703e-06 | Loss_d: 1.5061e-04 Loss_e: 4.3458e-05 | Loss_b: 3.7825e-05\n",
      "Step: NaN | Loss: 3.8556e-06 | Loss_d: 1.4949e-04 Loss_e: 4.3161e-05 | Loss_b: 3.8359e-05\n",
      "Step: NaN | Loss: 3.8527e-06 | Loss_d: 1.4906e-04 Loss_e: 4.3074e-05 | Loss_b: 3.8698e-05\n",
      "Step: NaN | Loss: 3.8882e-06 | Loss_d: 1.4755e-04 Loss_e: 4.3059e-05 | Loss_b: 4.2347e-05\n",
      "Step: NaN | Loss: 3.8526e-06 | Loss_d: 1.4901e-04 Loss_e: 4.3066e-05 | Loss_b: 3.8755e-05\n",
      "Step: NaN | Loss: 3.8516e-06 | Loss_d: 1.4892e-04 Loss_e: 4.3016e-05 | Loss_b: 3.8827e-05\n",
      "Step: NaN | Loss: 3.8507e-06 | Loss_d: 1.4861e-04 Loss_e: 4.2832e-05 | Loss_b: 3.9272e-05\n",
      "Step: NaN | Loss: 3.8505e-06 | Loss_d: 1.4870e-04 Loss_e: 4.2886e-05 | Loss_b: 3.9108e-05\n",
      "Step: NaN | Loss: 3.8471e-06 | Loss_d: 1.4886e-04 Loss_e: 4.2743e-05 | Loss_b: 3.8897e-05\n",
      "Step: NaN | Loss: 3.8403e-06 | Loss_d: 1.4954e-04 Loss_e: 4.2339e-05 | Loss_b: 3.8209e-05\n",
      "Step: NaN | Loss: 3.9604e-06 | Loss_d: 1.5471e-04 Loss_e: 4.4331e-05 | Loss_b: 3.8245e-05\n",
      "Step: NaN | Loss: 3.8402e-06 | Loss_d: 1.4966e-04 Loss_e: 4.2299e-05 | Loss_b: 3.8121e-05\n",
      "Step: NaN | Loss: 3.8331e-06 | Loss_d: 1.4888e-04 Loss_e: 4.2248e-05 | Loss_b: 3.8528e-05\n",
      "Step: NaN | Loss: 3.9411e-06 | Loss_d: 1.4756e-04 Loss_e: 4.4161e-05 | Loss_b: 4.4408e-05\n",
      "Step: NaN | Loss: 3.8331e-06 | Loss_d: 1.4885e-04 Loss_e: 4.2250e-05 | Loss_b: 3.8554e-05\n",
      "Step: NaN | Loss: 3.8313e-06 | Loss_d: 1.4910e-04 Loss_e: 4.2451e-05 | Loss_b: 3.7992e-05\n",
      "Step: NaN | Loss: 3.8298e-06 | Loss_d: 1.4899e-04 Loss_e: 4.2341e-05 | Loss_b: 3.8126e-05\n",
      "Step: NaN | Loss: 3.8267e-06 | Loss_d: 1.4884e-04 Loss_e: 4.2316e-05 | Loss_b: 3.8115e-05\n",
      "Step: NaN | Loss: 3.8350e-06 | Loss_d: 1.4856e-04 Loss_e: 4.2324e-05 | Loss_b: 3.8886e-05\n",
      "Step: NaN | Loss: 3.8257e-06 | Loss_d: 1.4872e-04 Loss_e: 4.2301e-05 | Loss_b: 3.8192e-05\n",
      "Step: NaN | Loss: 3.8223e-06 | Loss_d: 1.4877e-04 Loss_e: 4.2248e-05 | Loss_b: 3.8000e-05\n",
      "Step: NaN | Loss: 3.8157e-06 | Loss_d: 1.4899e-04 Loss_e: 4.2104e-05 | Loss_b: 3.7520e-05\n",
      "Step: NaN | Loss: 3.9536e-06 | Loss_d: 1.5143e-04 Loss_e: 4.3133e-05 | Loss_b: 4.2314e-05\n",
      "Step: NaN | Loss: 3.8156e-06 | Loss_d: 1.4902e-04 Loss_e: 4.2096e-05 | Loss_b: 3.7496e-05\n",
      "Step: NaN | Loss: 3.8124e-06 | Loss_d: 1.4885e-04 Loss_e: 4.2080e-05 | Loss_b: 3.7491e-05\n",
      "Step: NaN | Loss: 3.8151e-06 | Loss_d: 1.4838e-04 Loss_e: 4.2331e-05 | Loss_b: 3.7865e-05\n",
      "Step: NaN | Loss: 3.8105e-06 | Loss_d: 1.4862e-04 Loss_e: 4.2119e-05 | Loss_b: 3.7564e-05\n",
      "Step: NaN | Loss: 3.8079e-06 | Loss_d: 1.4838e-04 Loss_e: 4.2185e-05 | Loss_b: 3.7581e-05\n",
      "Step: NaN | Loss: 3.8178e-06 | Loss_d: 1.4786e-04 Loss_e: 4.2608e-05 | Loss_b: 3.8267e-05\n",
      "Step: NaN | Loss: 3.8072e-06 | Loss_d: 1.4822e-04 Loss_e: 4.2249e-05 | Loss_b: 3.7637e-05\n",
      "Step: NaN | Loss: 3.8057e-06 | Loss_d: 1.4783e-04 Loss_e: 4.2450e-05 | Loss_b: 3.7739e-05\n",
      "Step: NaN | Loss: 3.8057e-06 | Loss_d: 1.4783e-04 Loss_e: 4.2450e-05 | Loss_b: 3.7739e-05\n",
      "Step: NaN | Loss: 3.8047e-06 | Loss_d: 1.4788e-04 Loss_e: 4.2377e-05 | Loss_b: 3.7700e-05\n",
      "Step: NaN | Loss: 3.8042e-06 | Loss_d: 1.4812e-04 Loss_e: 4.2155e-05 | Loss_b: 3.7658e-05\n",
      "Step: NaN | Loss: 3.8038e-06 | Loss_d: 1.4802e-04 Loss_e: 4.2232e-05 | Loss_b: 3.7653e-05\n",
      "Step: NaN | Loss: 3.8016e-06 | Loss_d: 1.4802e-04 Loss_e: 4.2147e-05 | Loss_b: 3.7605e-05\n",
      "Step: NaN | Loss: 3.8042e-06 | Loss_d: 1.4811e-04 Loss_e: 4.2008e-05 | Loss_b: 3.7807e-05\n",
      "Step: NaN | Loss: 3.8005e-06 | Loss_d: 1.4804e-04 Loss_e: 4.2061e-05 | Loss_b: 3.7601e-05\n",
      "Step: NaN | Loss: 3.7984e-06 | Loss_d: 1.4780e-04 Loss_e: 4.1966e-05 | Loss_b: 3.7813e-05\n",
      "Step: NaN | Loss: 3.7987e-06 | Loss_d: 1.4697e-04 Loss_e: 4.1672e-05 | Loss_b: 3.8958e-05\n",
      "Step: NaN | Loss: 3.7969e-06 | Loss_d: 1.4737e-04 Loss_e: 4.1806e-05 | Loss_b: 3.8311e-05\n",
      "Step: NaN | Loss: 3.7935e-06 | Loss_d: 1.4733e-04 Loss_e: 4.1753e-05 | Loss_b: 3.8201e-05\n",
      "Step: NaN | Loss: 3.7851e-06 | Loss_d: 1.4725e-04 Loss_e: 4.1652e-05 | Loss_b: 3.7881e-05\n",
      "Step: NaN | Loss: 3.8816e-06 | Loss_d: 1.4894e-04 Loss_e: 4.3884e-05 | Loss_b: 3.9743e-05\n",
      "Step: NaN | Loss: 3.7842e-06 | Loss_d: 1.4726e-04 Loss_e: 4.1664e-05 | Loss_b: 3.7805e-05\n",
      "Step: NaN | Loss: 3.7788e-06 | Loss_d: 1.4766e-04 Loss_e: 4.1643e-05 | Loss_b: 3.7102e-05\n",
      "Step: NaN | Loss: 3.8005e-06 | Loss_d: 1.4965e-04 Loss_e: 4.1899e-05 | Loss_b: 3.6160e-05\n",
      "Step: NaN | Loss: 3.7776e-06 | Loss_d: 1.4798e-04 Loss_e: 4.1650e-05 | Loss_b: 3.6698e-05\n",
      "Step: NaN | Loss: 3.7748e-06 | Loss_d: 1.4793e-04 Loss_e: 4.1624e-05 | Loss_b: 3.6615e-05\n",
      "Step: NaN | Loss: 3.7731e-06 | Loss_d: 1.4778e-04 Loss_e: 4.1620e-05 | Loss_b: 3.6662e-05\n",
      "Step: NaN | Loss: 3.7720e-06 | Loss_d: 1.4782e-04 Loss_e: 4.1603e-05 | Loss_b: 3.6572e-05\n",
      "Step: NaN | Loss: 3.7643e-06 | Loss_d: 1.4764e-04 Loss_e: 4.1210e-05 | Loss_b: 3.6684e-05\n",
      "Step: NaN | Loss: 3.7821e-06 | Loss_d: 1.4714e-04 Loss_e: 4.1178e-05 | Loss_b: 3.8288e-05\n",
      "Step: NaN | Loss: 3.7614e-06 | Loss_d: 1.4747e-04 Loss_e: 4.0961e-05 | Loss_b: 3.6930e-05\n",
      "Step: NaN | Loss: 3.7587e-06 | Loss_d: 1.4727e-04 Loss_e: 4.0877e-05 | Loss_b: 3.7050e-05\n",
      "Step: NaN | Loss: 3.7854e-06 | Loss_d: 1.4678e-04 Loss_e: 4.1063e-05 | Loss_b: 3.8954e-05\n",
      "Step: NaN | Loss: 3.7586e-06 | Loss_d: 1.4723e-04 Loss_e: 4.0866e-05 | Loss_b: 3.7097e-05\n",
      "Step: NaN | Loss: 3.7568e-06 | Loss_d: 1.4711e-04 Loss_e: 4.0771e-05 | Loss_b: 3.7199e-05\n",
      "Step: NaN | Loss: 3.7849e-06 | Loss_d: 1.4698e-04 Loss_e: 4.1117e-05 | Loss_b: 3.8673e-05\n",
      "Step: NaN | Loss: 3.7568e-06 | Loss_d: 1.4711e-04 Loss_e: 4.0768e-05 | Loss_b: 3.7206e-05\n",
      "Step: NaN | Loss: 3.7555e-06 | Loss_d: 1.4715e-04 Loss_e: 4.0717e-05 | Loss_b: 3.7137e-05\n",
      "Step: NaN | Loss: 3.7599e-06 | Loss_d: 1.4741e-04 Loss_e: 4.0551e-05 | Loss_b: 3.7307e-05\n",
      "Step: NaN | Loss: 3.7552e-06 | Loss_d: 1.4720e-04 Loss_e: 4.0677e-05 | Loss_b: 3.7115e-05\n",
      "Step: NaN | Loss: 3.7534e-06 | Loss_d: 1.4742e-04 Loss_e: 4.0597e-05 | Loss_b: 3.6868e-05\n",
      "Step: NaN | Loss: 3.7550e-06 | Loss_d: 1.4841e-04 Loss_e: 4.0353e-05 | Loss_b: 3.6217e-05\n",
      "Step: NaN | Loss: 3.7524e-06 | Loss_d: 1.4778e-04 Loss_e: 4.0488e-05 | Loss_b: 3.6556e-05\n",
      "Step: NaN | Loss: 3.7509e-06 | Loss_d: 1.4770e-04 Loss_e: 4.0465e-05 | Loss_b: 3.6562e-05\n",
      "Step: NaN | Loss: 3.7468e-06 | Loss_d: 1.4745e-04 Loss_e: 4.0412e-05 | Loss_b: 3.6621e-05\n",
      "Step: NaN | Loss: 3.7790e-06 | Loss_d: 1.4731e-04 Loss_e: 4.1034e-05 | Loss_b: 3.8078e-05\n",
      "Step: NaN | Loss: 3.7460e-06 | Loss_d: 1.4733e-04 Loss_e: 4.0410e-05 | Loss_b: 3.6694e-05\n",
      "Step: NaN | Loss: 3.7640e-06 | Loss_d: 1.4713e-04 Loss_e: 4.0318e-05 | Loss_b: 3.8067e-05\n",
      "Step: NaN | Loss: 3.7441e-06 | Loss_d: 1.4727e-04 Loss_e: 4.0343e-05 | Loss_b: 3.6712e-05\n",
      "Step: NaN | Loss: 3.7395e-06 | Loss_d: 1.4688e-04 Loss_e: 4.0341e-05 | Loss_b: 3.6825e-05\n",
      "Step: NaN | Loss: 3.7373e-06 | Loss_d: 1.4585e-04 Loss_e: 4.0619e-05 | Loss_b: 3.7450e-05\n",
      "Step: NaN | Loss: 3.7351e-06 | Loss_d: 1.4617e-04 Loss_e: 4.0448e-05 | Loss_b: 3.7163e-05\n",
      "Step: NaN | Loss: 3.7334e-06 | Loss_d: 1.4606e-04 Loss_e: 4.0447e-05 | Loss_b: 3.7178e-05\n",
      "Step: NaN | Loss: 3.7316e-06 | Loss_d: 1.4568e-04 Loss_e: 4.0554e-05 | Loss_b: 3.7341e-05\n",
      "Step: NaN | Loss: 3.7313e-06 | Loss_d: 1.4576e-04 Loss_e: 4.0510e-05 | Loss_b: 3.7285e-05\n",
      "Step: NaN | Loss: 3.7238e-06 | Loss_d: 1.4553e-04 Loss_e: 4.0442e-05 | Loss_b: 3.7142e-05\n",
      "Step: NaN | Loss: 3.7184e-06 | Loss_d: 1.4480e-04 Loss_e: 4.0571e-05 | Loss_b: 3.7416e-05\n",
      "Step: NaN | Loss: 3.7156e-06 | Loss_d: 1.4504e-04 Loss_e: 4.0446e-05 | Loss_b: 3.7137e-05\n",
      "Step: NaN | Loss: 3.7049e-06 | Loss_d: 1.4466e-04 Loss_e: 4.0603e-05 | Loss_b: 3.6719e-05\n",
      "Step: NaN | Loss: 3.7706e-06 | Loss_d: 1.4386e-04 Loss_e: 4.3887e-05 | Loss_b: 3.8168e-05\n",
      "Step: NaN | Loss: 3.7038e-06 | Loss_d: 1.4450e-04 Loss_e: 4.0774e-05 | Loss_b: 3.6635e-05\n",
      "Step: NaN | Loss: 3.7026e-06 | Loss_d: 1.4390e-04 Loss_e: 4.1094e-05 | Loss_b: 3.6841e-05\n",
      "Step: NaN | Loss: 3.7022e-06 | Loss_d: 1.4411e-04 Loss_e: 4.0961e-05 | Loss_b: 3.6742e-05\n",
      "Step: NaN | Loss: 3.7016e-06 | Loss_d: 1.4411e-04 Loss_e: 4.0946e-05 | Loss_b: 3.6716e-05\n",
      "Step: NaN | Loss: 3.7009e-06 | Loss_d: 1.4416e-04 Loss_e: 4.0891e-05 | Loss_b: 3.6690e-05\n",
      "Step: NaN | Loss: 3.7008e-06 | Loss_d: 1.4414e-04 Loss_e: 4.0904e-05 | Loss_b: 3.6686e-05\n",
      "Step: NaN | Loss: 3.6990e-06 | Loss_d: 1.4403e-04 Loss_e: 4.0818e-05 | Loss_b: 3.6774e-05\n",
      "Step: NaN | Loss: 3.6982e-06 | Loss_d: 1.4360e-04 Loss_e: 4.0550e-05 | Loss_b: 3.7425e-05\n",
      "Step: NaN | Loss: 3.6973e-06 | Loss_d: 1.4378e-04 Loss_e: 4.0651e-05 | Loss_b: 3.7089e-05\n",
      "Step: NaN | Loss: 3.6937e-06 | Loss_d: 1.4329e-04 Loss_e: 4.0671e-05 | Loss_b: 3.7339e-05\n",
      "Step: NaN | Loss: 3.7087e-06 | Loss_d: 1.4166e-04 Loss_e: 4.1056e-05 | Loss_b: 3.9493e-05\n",
      "Step: NaN | Loss: 3.6929e-06 | Loss_d: 1.4296e-04 Loss_e: 4.0704e-05 | Loss_b: 3.7591e-05\n",
      "Step: NaN | Loss: 3.6890e-06 | Loss_d: 1.4282e-04 Loss_e: 4.0688e-05 | Loss_b: 3.7520e-05\n",
      "Step: NaN | Loss: 3.6810e-06 | Loss_d: 1.4232e-04 Loss_e: 4.0745e-05 | Loss_b: 3.7477e-05\n",
      "Step: NaN | Loss: 3.9268e-06 | Loss_d: 1.4235e-04 Loss_e: 4.4355e-05 | Loss_b: 4.8567e-05\n",
      "Step: NaN | Loss: 3.6809e-06 | Loss_d: 1.4230e-04 Loss_e: 4.0755e-05 | Loss_b: 3.7487e-05\n",
      "Step: NaN | Loss: 3.6802e-06 | Loss_d: 1.4297e-04 Loss_e: 4.1052e-05 | Loss_b: 3.6471e-05\n",
      "Step: NaN | Loss: 3.6759e-06 | Loss_d: 1.4257e-04 Loss_e: 4.0815e-05 | Loss_b: 3.6859e-05\n",
      "Step: NaN | Loss: 3.6804e-06 | Loss_d: 1.4264e-04 Loss_e: 4.0841e-05 | Loss_b: 3.7028e-05\n",
      "Step: NaN | Loss: 3.6740e-06 | Loss_d: 1.4258e-04 Loss_e: 4.0807e-05 | Loss_b: 3.6739e-05\n",
      "Step: NaN | Loss: 3.6729e-06 | Loss_d: 1.4259e-04 Loss_e: 4.0746e-05 | Loss_b: 3.6722e-05\n",
      "Step: NaN | Loss: 3.6725e-06 | Loss_d: 1.4264e-04 Loss_e: 4.0541e-05 | Loss_b: 3.6860e-05\n",
      "Step: NaN | Loss: 3.6718e-06 | Loss_d: 1.4261e-04 Loss_e: 4.0625e-05 | Loss_b: 3.6756e-05\n",
      "Step: NaN | Loss: 3.6682e-06 | Loss_d: 1.4263e-04 Loss_e: 4.0558e-05 | Loss_b: 3.6590e-05\n",
      "Step: NaN | Loss: 3.6683e-06 | Loss_d: 1.4307e-04 Loss_e: 4.0576e-05 | Loss_b: 3.6140e-05\n",
      "Step: NaN | Loss: 3.6654e-06 | Loss_d: 1.4277e-04 Loss_e: 4.0509e-05 | Loss_b: 3.6326e-05\n",
      "Step: NaN | Loss: 3.6630e-06 | Loss_d: 1.4258e-04 Loss_e: 4.0537e-05 | Loss_b: 3.6342e-05\n",
      "Step: NaN | Loss: 3.6686e-06 | Loss_d: 1.4193e-04 Loss_e: 4.0819e-05 | Loss_b: 3.7046e-05\n",
      "Step: NaN | Loss: 3.6621e-06 | Loss_d: 1.4239e-04 Loss_e: 4.0585e-05 | Loss_b: 3.6432e-05\n",
      "Step: NaN | Loss: 3.6601e-06 | Loss_d: 1.4242e-04 Loss_e: 4.0491e-05 | Loss_b: 3.6380e-05\n",
      "Step: NaN | Loss: 3.6685e-06 | Loss_d: 1.4297e-04 Loss_e: 4.0330e-05 | Loss_b: 3.6495e-05\n",
      "Step: NaN | Loss: 3.6596e-06 | Loss_d: 1.4247e-04 Loss_e: 4.0436e-05 | Loss_b: 3.6357e-05\n",
      "Step: NaN | Loss: 3.6583e-06 | Loss_d: 1.4245e-04 Loss_e: 4.0363e-05 | Loss_b: 3.6372e-05\n",
      "Step: NaN | Loss: 3.6584e-06 | Loss_d: 1.4244e-04 Loss_e: 4.0134e-05 | Loss_b: 3.6620e-05\n",
      "Step: NaN | Loss: 3.6573e-06 | Loss_d: 1.4243e-04 Loss_e: 4.0240e-05 | Loss_b: 3.6455e-05\n",
      "Step: NaN | Loss: 3.6536e-06 | Loss_d: 1.4258e-04 Loss_e: 4.0044e-05 | Loss_b: 3.6276e-05\n",
      "Step: NaN | Loss: 3.6510e-06 | Loss_d: 1.4330e-04 Loss_e: 3.9499e-05 | Loss_b: 3.5948e-05\n",
      "Step: NaN | Loss: 3.6497e-06 | Loss_d: 1.4302e-04 Loss_e: 3.9654e-05 | Loss_b: 3.5997e-05\n",
      "Step: NaN | Loss: 3.6420e-06 | Loss_d: 1.4254e-04 Loss_e: 3.9311e-05 | Loss_b: 3.6358e-05\n",
      "Step: NaN | Loss: 3.6694e-06 | Loss_d: 1.4149e-04 Loss_e: 3.9001e-05 | Loss_b: 3.9355e-05\n",
      "Step: NaN | Loss: 3.6399e-06 | Loss_d: 1.4221e-04 Loss_e: 3.9109e-05 | Loss_b: 3.6766e-05\n",
      "Step: NaN | Loss: 3.6381e-06 | Loss_d: 1.4186e-04 Loss_e: 3.9047e-05 | Loss_b: 3.7064e-05\n",
      "Step: NaN | Loss: 3.6378e-06 | Loss_d: 1.4194e-04 Loss_e: 3.9059e-05 | Loss_b: 3.6963e-05\n",
      "Step: NaN | Loss: 3.6365e-06 | Loss_d: 1.4204e-04 Loss_e: 3.8975e-05 | Loss_b: 3.6860e-05\n",
      "Step: NaN | Loss: 3.6377e-06 | Loss_d: 1.4260e-04 Loss_e: 3.8697e-05 | Loss_b: 3.6648e-05\n",
      "Step: NaN | Loss: 3.6357e-06 | Loss_d: 1.4224e-04 Loss_e: 3.8854e-05 | Loss_b: 3.6739e-05\n",
      "Step: NaN | Loss: 3.6338e-06 | Loss_d: 1.4221e-04 Loss_e: 3.8837e-05 | Loss_b: 3.6667e-05\n",
      "Step: NaN | Loss: 3.6311e-06 | Loss_d: 1.4218e-04 Loss_e: 3.8908e-05 | Loss_b: 3.6461e-05\n",
      "Step: NaN | Loss: 3.6310e-06 | Loss_d: 1.4218e-04 Loss_e: 3.8888e-05 | Loss_b: 3.6477e-05\n",
      "Step: NaN | Loss: 3.6328e-06 | Loss_d: 1.4226e-04 Loss_e: 3.8852e-05 | Loss_b: 3.6545e-05\n",
      "Step: NaN | Loss: 3.6298e-06 | Loss_d: 1.4221e-04 Loss_e: 3.8861e-05 | Loss_b: 3.6412e-05\n",
      "Step: NaN | Loss: 3.6281e-06 | Loss_d: 1.4231e-04 Loss_e: 3.8791e-05 | Loss_b: 3.6272e-05\n",
      "Step: NaN | Loss: 3.6303e-06 | Loss_d: 1.4293e-04 Loss_e: 3.8616e-05 | Loss_b: 3.5959e-05\n",
      "Step: NaN | Loss: 3.6272e-06 | Loss_d: 1.4249e-04 Loss_e: 3.8710e-05 | Loss_b: 3.6121e-05\n",
      "Step: NaN | Loss: 3.6252e-06 | Loss_d: 1.4243e-04 Loss_e: 3.8683e-05 | Loss_b: 3.6088e-05\n",
      "Step: NaN | Loss: 3.6247e-06 | Loss_d: 1.4231e-04 Loss_e: 3.8783e-05 | Loss_b: 3.6078e-05\n",
      "Step: NaN | Loss: 3.6236e-06 | Loss_d: 1.4234e-04 Loss_e: 3.8696e-05 | Loss_b: 3.6063e-05\n",
      "Step: NaN | Loss: 3.6156e-06 | Loss_d: 1.4129e-04 Loss_e: 3.8268e-05 | Loss_b: 3.7067e-05\n",
      "Step: NaN | Loss: 3.7183e-06 | Loss_d: 1.3858e-04 Loss_e: 3.9687e-05 | Loss_b: 4.4512e-05\n",
      "Step: NaN | Loss: 3.6156e-06 | Loss_d: 1.4123e-04 Loss_e: 3.8251e-05 | Loss_b: 3.7142e-05\n",
      "Step: NaN | Loss: 3.6235e-06 | Loss_d: 1.4145e-04 Loss_e: 3.7822e-05 | Loss_b: 3.7829e-05\n",
      "Step: NaN | Loss: 3.6124e-06 | Loss_d: 1.4121e-04 Loss_e: 3.8038e-05 | Loss_b: 3.7193e-05\n",
      "Step: NaN | Loss: 3.6106e-06 | Loss_d: 1.4138e-04 Loss_e: 3.7951e-05 | Loss_b: 3.6998e-05\n",
      "Step: NaN | Loss: 3.6194e-06 | Loss_d: 1.4230e-04 Loss_e: 3.7882e-05 | Loss_b: 3.6672e-05\n",
      "Step: NaN | Loss: 3.6102e-06 | Loss_d: 1.4150e-04 Loss_e: 3.7910e-05 | Loss_b: 3.6897e-05\n",
      "Step: NaN | Loss: 3.6091e-06 | Loss_d: 1.4135e-04 Loss_e: 3.7916e-05 | Loss_b: 3.6978e-05\n",
      "Step: NaN | Loss: 3.6186e-06 | Loss_d: 1.4085e-04 Loss_e: 3.8055e-05 | Loss_b: 3.7903e-05\n",
      "Step: NaN | Loss: 3.6091e-06 | Loss_d: 1.4130e-04 Loss_e: 3.7920e-05 | Loss_b: 3.7013e-05\n",
      "Step: NaN | Loss: 3.6070e-06 | Loss_d: 1.4135e-04 Loss_e: 3.7932e-05 | Loss_b: 3.6825e-05\n",
      "Step: NaN | Loss: 3.6067e-06 | Loss_d: 1.4163e-04 Loss_e: 3.8035e-05 | Loss_b: 3.6425e-05\n",
      "Step: NaN | Loss: 3.6052e-06 | Loss_d: 1.4148e-04 Loss_e: 3.7975e-05 | Loss_b: 3.6547e-05\n",
      "Step: NaN | Loss: 3.6033e-06 | Loss_d: 1.4162e-04 Loss_e: 3.8040e-05 | Loss_b: 3.6232e-05\n",
      "Step: NaN | Loss: 3.6060e-06 | Loss_d: 1.4223e-04 Loss_e: 3.8389e-05 | Loss_b: 3.5432e-05\n",
      "Step: NaN | Loss: 3.6024e-06 | Loss_d: 1.4181e-04 Loss_e: 3.8142e-05 | Loss_b: 3.5881e-05\n",
      "Step: NaN | Loss: 3.6015e-06 | Loss_d: 1.4176e-04 Loss_e: 3.8185e-05 | Loss_b: 3.5839e-05\n",
      "Step: NaN | Loss: 3.6030e-06 | Loss_d: 1.4162e-04 Loss_e: 3.8444e-05 | Loss_b: 3.5810e-05\n",
      "Step: NaN | Loss: 3.6011e-06 | Loss_d: 1.4169e-04 Loss_e: 3.8256e-05 | Loss_b: 3.5807e-05\n",
      "Step: NaN | Loss: 3.5996e-06 | Loss_d: 1.4154e-04 Loss_e: 3.8187e-05 | Loss_b: 3.5938e-05\n",
      "Step: NaN | Loss: 3.5991e-06 | Loss_d: 1.4105e-04 Loss_e: 3.7994e-05 | Loss_b: 3.6596e-05\n",
      "Step: NaN | Loss: 3.5983e-06 | Loss_d: 1.4125e-04 Loss_e: 3.8063e-05 | Loss_b: 3.6278e-05\n",
      "Step: NaN | Loss: 3.5946e-06 | Loss_d: 1.4106e-04 Loss_e: 3.7897e-05 | Loss_b: 3.6414e-05\n",
      "Step: NaN | Loss: 3.6118e-06 | Loss_d: 1.4052e-04 Loss_e: 3.7507e-05 | Loss_b: 3.8370e-05\n",
      "Step: NaN | Loss: 3.5940e-06 | Loss_d: 1.4095e-04 Loss_e: 3.7805e-05 | Loss_b: 3.6578e-05\n",
      "Step: NaN | Loss: 3.5867e-06 | Loss_d: 1.4054e-04 Loss_e: 3.7724e-05 | Loss_b: 3.6632e-05\n",
      "Step: NaN | Loss: 3.5714e-06 | Loss_d: 1.3901e-04 Loss_e: 3.7656e-05 | Loss_b: 3.7313e-05\n",
      "Step: NaN | Loss: 3.8348e-06 | Loss_d: 1.3388e-04 Loss_e: 4.3579e-05 | Loss_b: 5.2304e-05\n",
      "Step: NaN | Loss: 3.5710e-06 | Loss_d: 1.3875e-04 Loss_e: 3.7687e-05 | Loss_b: 3.7513e-05\n",
      "Step: NaN | Loss: 3.5667e-06 | Loss_d: 1.3856e-04 Loss_e: 3.7610e-05 | Loss_b: 3.7526e-05\n",
      "Step: NaN | Loss: 3.5667e-06 | Loss_d: 1.3857e-04 Loss_e: 3.7613e-05 | Loss_b: 3.7514e-05\n",
      "Step: NaN | Loss: 3.5658e-06 | Loss_d: 1.3839e-04 Loss_e: 3.7586e-05 | Loss_b: 3.7672e-05\n",
      "Step: NaN | Loss: 3.5694e-06 | Loss_d: 1.3778e-04 Loss_e: 3.7502e-05 | Loss_b: 3.8577e-05\n",
      "Step: NaN | Loss: 3.5656e-06 | Loss_d: 1.3826e-04 Loss_e: 3.7567e-05 | Loss_b: 3.7810e-05\n",
      "Step: NaN | Loss: 3.5641e-06 | Loss_d: 1.3831e-04 Loss_e: 3.7468e-05 | Loss_b: 3.7761e-05\n",
      "Step: NaN | Loss: 3.5611e-06 | Loss_d: 1.3860e-04 Loss_e: 3.7115e-05 | Loss_b: 3.7649e-05\n",
      "Step: NaN | Loss: 3.6441e-06 | Loss_d: 1.4130e-04 Loss_e: 3.6592e-05 | Loss_b: 4.0441e-05\n",
      "Step: NaN | Loss: 3.5611e-06 | Loss_d: 1.3862e-04 Loss_e: 3.7095e-05 | Loss_b: 3.7648e-05\n",
      "Step: NaN | Loss: 3.5514e-06 | Loss_d: 1.3894e-04 Loss_e: 3.6584e-05 | Loss_b: 3.7252e-05\n",
      "Step: NaN | Loss: 3.6455e-06 | Loss_d: 1.4190e-04 Loss_e: 3.7612e-05 | Loss_b: 3.8910e-05\n",
      "Step: NaN | Loss: 3.5509e-06 | Loss_d: 1.3905e-04 Loss_e: 3.6506e-05 | Loss_b: 3.7196e-05\n",
      "Step: NaN | Loss: 3.5558e-06 | Loss_d: 1.3988e-04 Loss_e: 3.6156e-05 | Loss_b: 3.7008e-05\n",
      "Step: NaN | Loss: 3.5475e-06 | Loss_d: 1.3933e-04 Loss_e: 3.6333e-05 | Loss_b: 3.6891e-05\n",
      "Step: NaN | Loss: 3.5473e-06 | Loss_d: 1.4040e-04 Loss_e: 3.6110e-05 | Loss_b: 3.6019e-05\n",
      "Step: NaN | Loss: 3.5448e-06 | Loss_d: 1.3986e-04 Loss_e: 3.6195e-05 | Loss_b: 3.6328e-05\n",
      "Step: NaN | Loss: 3.5435e-06 | Loss_d: 1.3994e-04 Loss_e: 3.6164e-05 | Loss_b: 3.6205e-05\n",
      "Step: NaN | Loss: 3.5461e-06 | Loss_d: 1.4034e-04 Loss_e: 3.6155e-05 | Loss_b: 3.5967e-05\n",
      "Step: NaN | Loss: 3.5429e-06 | Loss_d: 1.4004e-04 Loss_e: 3.6142e-05 | Loss_b: 3.6092e-05\n",
      "Step: NaN | Loss: 3.5416e-06 | Loss_d: 1.3990e-04 Loss_e: 3.6098e-05 | Loss_b: 3.6197e-05\n",
      "Step: NaN | Loss: 3.5407e-06 | Loss_d: 1.3942e-04 Loss_e: 3.5987e-05 | Loss_b: 3.6732e-05\n",
      "Step: NaN | Loss: 3.5403e-06 | Loss_d: 1.3958e-04 Loss_e: 3.6016e-05 | Loss_b: 3.6517e-05\n",
      "Step: NaN | Loss: 3.5378e-06 | Loss_d: 1.3958e-04 Loss_e: 3.5961e-05 | Loss_b: 3.6430e-05\n",
      "Step: NaN | Loss: 3.5318e-06 | Loss_d: 1.3958e-04 Loss_e: 3.5842e-05 | Loss_b: 3.6182e-05\n",
      "Step: NaN | Loss: 3.5907e-06 | Loss_d: 1.4020e-04 Loss_e: 3.7595e-05 | Loss_b: 3.7341e-05\n",
      "Step: NaN | Loss: 3.5310e-06 | Loss_d: 1.3960e-04 Loss_e: 3.5841e-05 | Loss_b: 3.6115e-05\n",
      "Step: NaN | Loss: 3.5264e-06 | Loss_d: 1.3917e-04 Loss_e: 3.5834e-05 | Loss_b: 3.6280e-05\n",
      "Step: NaN | Loss: 3.5303e-06 | Loss_d: 1.3765e-04 Loss_e: 3.6256e-05 | Loss_b: 3.7614e-05\n",
      "Step: NaN | Loss: 3.5236e-06 | Loss_d: 1.3853e-04 Loss_e: 3.5912e-05 | Loss_b: 3.6668e-05\n",
      "Step: NaN | Loss: 3.5232e-06 | Loss_d: 1.3819e-04 Loss_e: 3.6051e-05 | Loss_b: 3.6846e-05\n",
      "Step: NaN | Loss: 3.5226e-06 | Loss_d: 1.3833e-04 Loss_e: 3.5986e-05 | Loss_b: 3.6739e-05\n",
      "Step: NaN | Loss: 3.5215e-06 | Loss_d: 1.3824e-04 Loss_e: 3.5984e-05 | Loss_b: 3.6767e-05\n",
      "Step: NaN | Loss: 3.5234e-06 | Loss_d: 1.3789e-04 Loss_e: 3.6005e-05 | Loss_b: 3.7205e-05\n",
      "Step: NaN | Loss: 3.5211e-06 | Loss_d: 1.3813e-04 Loss_e: 3.5987e-05 | Loss_b: 3.6846e-05\n",
      "Step: NaN | Loss: 3.5196e-06 | Loss_d: 1.3805e-04 Loss_e: 3.5949e-05 | Loss_b: 3.6875e-05\n",
      "Step: NaN | Loss: 3.5174e-06 | Loss_d: 1.3778e-04 Loss_e: 3.5866e-05 | Loss_b: 3.7093e-05\n",
      "Step: NaN | Loss: 3.5173e-06 | Loss_d: 1.3781e-04 Loss_e: 3.5871e-05 | Loss_b: 3.7055e-05\n",
      "Step: NaN | Loss: 3.5167e-06 | Loss_d: 1.3774e-04 Loss_e: 3.5758e-05 | Loss_b: 3.7206e-05\n",
      "Step: NaN | Loss: 3.5165e-06 | Loss_d: 1.3776e-04 Loss_e: 3.5795e-05 | Loss_b: 3.7130e-05\n",
      "Step: NaN | Loss: 3.5154e-06 | Loss_d: 1.3761e-04 Loss_e: 3.5771e-05 | Loss_b: 3.7244e-05\n",
      "Step: NaN | Loss: 3.5157e-06 | Loss_d: 1.3708e-04 Loss_e: 3.5741e-05 | Loss_b: 3.7816e-05\n",
      "Step: NaN | Loss: 3.5147e-06 | Loss_d: 1.3735e-04 Loss_e: 3.5745e-05 | Loss_b: 3.7486e-05\n",
      "Step: NaN | Loss: 3.5113e-06 | Loss_d: 1.3745e-04 Loss_e: 3.5560e-05 | Loss_b: 3.7365e-05\n",
      "Step: NaN | Loss: 3.5213e-06 | Loss_d: 1.3803e-04 Loss_e: 3.5415e-05 | Loss_b: 3.7528e-05\n",
      "Step: NaN | Loss: 3.5103e-06 | Loss_d: 1.3756e-04 Loss_e: 3.5440e-05 | Loss_b: 3.7310e-05\n",
      "Step: NaN | Loss: 3.5067e-06 | Loss_d: 1.3795e-04 Loss_e: 3.5256e-05 | Loss_b: 3.6890e-05\n",
      "Step: NaN | Loss: 3.5067e-06 | Loss_d: 1.3795e-04 Loss_e: 3.5256e-05 | Loss_b: 3.6890e-05\n",
      "Step: NaN | Loss: 3.5062e-06 | Loss_d: 1.3797e-04 Loss_e: 3.5231e-05 | Loss_b: 3.6863e-05\n",
      "Step: NaN | Loss: 3.5058e-06 | Loss_d: 1.3809e-04 Loss_e: 3.5167e-05 | Loss_b: 3.6796e-05\n",
      "Step: NaN | Loss: 3.5056e-06 | Loss_d: 1.3804e-04 Loss_e: 3.5186e-05 | Loss_b: 3.6812e-05\n",
      "Step: NaN | Loss: 3.5050e-06 | Loss_d: 1.3745e-04 Loss_e: 3.4946e-05 | Loss_b: 3.7604e-05\n",
      "Step: NaN | Loss: 3.5041e-06 | Loss_d: 1.3769e-04 Loss_e: 3.5033e-05 | Loss_b: 3.7224e-05\n",
      "Step: NaN | Loss: 3.5031e-06 | Loss_d: 1.3769e-04 Loss_e: 3.4978e-05 | Loss_b: 3.7216e-05\n",
      "Step: NaN | Loss: 3.5011e-06 | Loss_d: 1.3774e-04 Loss_e: 3.4805e-05 | Loss_b: 3.7225e-05\n",
      "Step: NaN | Loss: 3.5428e-06 | Loss_d: 1.3863e-04 Loss_e: 3.5009e-05 | Loss_b: 3.8632e-05\n",
      "Step: NaN | Loss: 3.5011e-06 | Loss_d: 1.3774e-04 Loss_e: 3.4792e-05 | Loss_b: 3.7230e-05\n",
      "Step: NaN | Loss: 3.4991e-06 | Loss_d: 1.3769e-04 Loss_e: 3.4760e-05 | Loss_b: 3.7197e-05\n",
      "Step: NaN | Loss: 3.4974e-06 | Loss_d: 1.3749e-04 Loss_e: 3.4684e-05 | Loss_b: 3.7364e-05\n",
      "Step: NaN | Loss: 3.4968e-06 | Loss_d: 1.3755e-04 Loss_e: 3.4700e-05 | Loss_b: 3.7257e-05\n",
      "Step: NaN | Loss: 3.4933e-06 | Loss_d: 1.3771e-04 Loss_e: 3.4676e-05 | Loss_b: 3.6910e-05\n",
      "Step: NaN | Loss: 3.4923e-06 | Loss_d: 1.3843e-04 Loss_e: 3.4811e-05 | Loss_b: 3.5996e-05\n",
      "Step: NaN | Loss: 3.4901e-06 | Loss_d: 1.3809e-04 Loss_e: 3.4703e-05 | Loss_b: 3.6320e-05\n",
      "Step: NaN | Loss: 3.4869e-06 | Loss_d: 1.3856e-04 Loss_e: 3.4576e-05 | Loss_b: 3.5784e-05\n",
      "Step: NaN | Loss: 3.5339e-06 | Loss_d: 1.4104e-04 Loss_e: 3.4974e-05 | Loss_b: 3.5720e-05\n",
      "Step: NaN | Loss: 3.4869e-06 | Loss_d: 1.3858e-04 Loss_e: 3.4573e-05 | Loss_b: 3.5767e-05\n",
      "Step: NaN | Loss: 3.4827e-06 | Loss_d: 1.3856e-04 Loss_e: 3.4551e-05 | Loss_b: 3.5556e-05\n",
      "Step: NaN | Loss: 3.4827e-06 | Loss_d: 1.3856e-04 Loss_e: 3.4548e-05 | Loss_b: 3.5559e-05\n",
      "Step: NaN | Loss: 3.4789e-06 | Loss_d: 1.3838e-04 Loss_e: 3.4598e-05 | Loss_b: 3.5456e-05\n",
      "Step: NaN | Loss: 3.4902e-06 | Loss_d: 1.3812e-04 Loss_e: 3.5505e-05 | Loss_b: 3.5484e-05\n",
      "Step: NaN | Loss: 3.4779e-06 | Loss_d: 1.3826e-04 Loss_e: 3.4708e-05 | Loss_b: 3.5406e-05\n",
      "Step: NaN | Loss: 3.4752e-06 | Loss_d: 1.3811e-04 Loss_e: 3.4730e-05 | Loss_b: 3.5371e-05\n",
      "Step: NaN | Loss: 3.5114e-06 | Loss_d: 1.3788e-04 Loss_e: 3.5266e-05 | Loss_b: 3.7233e-05\n",
      "Step: NaN | Loss: 3.4752e-06 | Loss_d: 1.3810e-04 Loss_e: 3.4733e-05 | Loss_b: 3.5377e-05\n",
      "Step: NaN | Loss: 3.4722e-06 | Loss_d: 1.3810e-04 Loss_e: 3.4683e-05 | Loss_b: 3.5248e-05\n",
      "Step: NaN | Loss: 3.4706e-06 | Loss_d: 1.3829e-04 Loss_e: 3.4669e-05 | Loss_b: 3.4976e-05\n",
      "Step: NaN | Loss: 3.4693e-06 | Loss_d: 1.3818e-04 Loss_e: 3.4637e-05 | Loss_b: 3.5040e-05\n",
      "Step: NaN | Loss: 3.4688e-06 | Loss_d: 1.3798e-04 Loss_e: 3.4692e-05 | Loss_b: 3.5163e-05\n",
      "Step: NaN | Loss: 3.4684e-06 | Loss_d: 1.3805e-04 Loss_e: 3.4662e-05 | Loss_b: 3.5091e-05\n",
      "Step: NaN | Loss: 3.4668e-06 | Loss_d: 1.3803e-04 Loss_e: 3.4696e-05 | Loss_b: 3.4985e-05\n",
      "Step: NaN | Loss: 3.4772e-06 | Loss_d: 1.3807e-04 Loss_e: 3.5041e-05 | Loss_b: 3.5223e-05\n",
      "Step: NaN | Loss: 3.4667e-06 | Loss_d: 1.3803e-04 Loss_e: 3.4718e-05 | Loss_b: 3.4961e-05\n",
      "Step: NaN | Loss: 3.4658e-06 | Loss_d: 1.3807e-04 Loss_e: 3.4696e-05 | Loss_b: 3.4881e-05\n",
      "Step: NaN | Loss: 3.4661e-06 | Loss_d: 1.3828e-04 Loss_e: 3.4672e-05 | Loss_b: 3.4715e-05\n",
      "Step: NaN | Loss: 3.4652e-06 | Loss_d: 1.3816e-04 Loss_e: 3.4674e-05 | Loss_b: 3.4779e-05\n",
      "Step: NaN | Loss: 3.4641e-06 | Loss_d: 1.3817e-04 Loss_e: 3.4660e-05 | Loss_b: 3.4719e-05\n",
      "Step: NaN | Loss: 3.4633e-06 | Loss_d: 1.3825e-04 Loss_e: 3.4727e-05 | Loss_b: 3.4527e-05\n",
      "Step: NaN | Loss: 3.4629e-06 | Loss_d: 1.3821e-04 Loss_e: 3.4679e-05 | Loss_b: 3.4588e-05\n",
      "Step: NaN | Loss: 3.4647e-06 | Loss_d: 1.3734e-04 Loss_e: 3.4749e-05 | Loss_b: 3.5494e-05\n",
      "Step: NaN | Loss: 3.4606e-06 | Loss_d: 1.3779e-04 Loss_e: 3.4672e-05 | Loss_b: 3.4874e-05\n",
      "Step: NaN | Loss: 3.4585e-06 | Loss_d: 1.3779e-04 Loss_e: 3.4675e-05 | Loss_b: 3.4748e-05\n",
      "Step: NaN | Loss: 3.4565e-06 | Loss_d: 1.3785e-04 Loss_e: 3.4746e-05 | Loss_b: 3.4499e-05\n",
      "Step: NaN | Loss: 3.4560e-06 | Loss_d: 1.3782e-04 Loss_e: 3.4713e-05 | Loss_b: 3.4533e-05\n",
      "Step: NaN | Loss: 3.4517e-06 | Loss_d: 1.3784e-04 Loss_e: 3.4686e-05 | Loss_b: 3.4280e-05\n",
      "Step: NaN | Loss: 3.4436e-06 | Loss_d: 1.3807e-04 Loss_e: 3.4728e-05 | Loss_b: 3.3524e-05\n",
      "Step: NaN | Loss: 3.6193e-06 | Loss_d: 1.4297e-04 Loss_e: 3.8472e-05 | Loss_b: 3.5401e-05\n",
      "Step: NaN | Loss: 3.4436e-06 | Loss_d: 1.3809e-04 Loss_e: 3.4737e-05 | Loss_b: 3.3494e-05\n",
      "Step: NaN | Loss: 3.4394e-06 | Loss_d: 1.3782e-04 Loss_e: 3.4777e-05 | Loss_b: 3.3471e-05\n",
      "Step: NaN | Loss: 3.4930e-06 | Loss_d: 1.3697e-04 Loss_e: 3.6387e-05 | Loss_b: 3.5922e-05\n",
      "Step: NaN | Loss: 3.4394e-06 | Loss_d: 1.3780e-04 Loss_e: 3.4788e-05 | Loss_b: 3.3481e-05\n",
      "Step: NaN | Loss: 3.4368e-06 | Loss_d: 1.3772e-04 Loss_e: 3.4932e-05 | Loss_b: 3.3261e-05\n",
      "Step: NaN | Loss: 3.4366e-06 | Loss_d: 1.3773e-04 Loss_e: 3.4885e-05 | Loss_b: 3.3286e-05\n",
      "Step: NaN | Loss: 3.4353e-06 | Loss_d: 1.3763e-04 Loss_e: 3.4898e-05 | Loss_b: 3.3301e-05\n",
      "Step: NaN | Loss: 3.4343e-06 | Loss_d: 1.3724e-04 Loss_e: 3.5022e-05 | Loss_b: 3.3502e-05\n",
      "Step: NaN | Loss: 3.4339e-06 | Loss_d: 1.3736e-04 Loss_e: 3.4969e-05 | Loss_b: 3.3409e-05\n",
      "Step: NaN | Loss: 3.4305e-06 | Loss_d: 1.3730e-04 Loss_e: 3.4890e-05 | Loss_b: 3.3348e-05\n",
      "Step: NaN | Loss: 3.4278e-06 | Loss_d: 1.3715e-04 Loss_e: 3.4848e-05 | Loss_b: 3.3378e-05\n",
      "Step: NaN | Loss: 3.4267e-06 | Loss_d: 1.3718e-04 Loss_e: 3.4812e-05 | Loss_b: 3.3314e-05\n",
      "Step: NaN | Loss: 3.4248e-06 | Loss_d: 1.3707e-04 Loss_e: 3.4758e-05 | Loss_b: 3.3366e-05\n",
      "Step: NaN | Loss: 3.4247e-06 | Loss_d: 1.3708e-04 Loss_e: 3.4762e-05 | Loss_b: 3.3344e-05\n",
      "Step: NaN | Loss: 3.4227e-06 | Loss_d: 1.3703e-04 Loss_e: 3.4643e-05 | Loss_b: 3.3391e-05\n",
      "Step: NaN | Loss: 3.4333e-06 | Loss_d: 1.3697e-04 Loss_e: 3.4348e-05 | Loss_b: 3.4386e-05\n",
      "Step: NaN | Loss: 3.4224e-06 | Loss_d: 1.3701e-04 Loss_e: 3.4582e-05 | Loss_b: 3.3455e-05\n",
      "Step: NaN | Loss: 3.4201e-06 | Loss_d: 1.3719e-04 Loss_e: 3.4513e-05 | Loss_b: 3.3217e-05\n",
      "Step: NaN | Loss: 3.4255e-06 | Loss_d: 1.3804e-04 Loss_e: 3.4468e-05 | Loss_b: 3.2732e-05\n",
      "Step: NaN | Loss: 3.4193e-06 | Loss_d: 1.3739e-04 Loss_e: 3.4464e-05 | Loss_b: 3.3013e-05\n",
      "Step: NaN | Loss: 3.4178e-06 | Loss_d: 1.3726e-04 Loss_e: 3.4437e-05 | Loss_b: 3.3079e-05\n",
      "Step: NaN | Loss: 3.4174e-06 | Loss_d: 1.3683e-04 Loss_e: 3.4403e-05 | Loss_b: 3.3515e-05\n",
      "Step: NaN | Loss: 3.4165e-06 | Loss_d: 1.3701e-04 Loss_e: 3.4403e-05 | Loss_b: 3.3288e-05\n",
      "Step: NaN | Loss: 3.4149e-06 | Loss_d: 1.3698e-04 Loss_e: 3.4436e-05 | Loss_b: 3.3189e-05\n",
      "Step: NaN | Loss: 3.4119e-06 | Loss_d: 1.3690e-04 Loss_e: 3.4630e-05 | Loss_b: 3.2897e-05\n",
      "Step: NaN | Loss: 3.4739e-06 | Loss_d: 1.3716e-04 Loss_e: 3.7174e-05 | Loss_b: 3.3799e-05\n",
      "Step: NaN | Loss: 3.4119e-06 | Loss_d: 1.3689e-04 Loss_e: 3.4653e-05 | Loss_b: 3.2876e-05\n",
      "Step: NaN | Loss: 3.4098e-06 | Loss_d: 1.3670e-04 Loss_e: 3.4616e-05 | Loss_b: 3.2976e-05\n",
      "Step: NaN | Loss: 3.4139e-06 | Loss_d: 1.3632e-04 Loss_e: 3.4668e-05 | Loss_b: 3.3556e-05\n",
      "Step: NaN | Loss: 3.4090e-06 | Loss_d: 1.3653e-04 Loss_e: 3.4598e-05 | Loss_b: 3.3120e-05\n",
      "Step: NaN | Loss: 3.4065e-06 | Loss_d: 1.3629e-04 Loss_e: 3.4412e-05 | Loss_b: 3.3399e-05\n",
      "Step: NaN | Loss: 3.4064e-06 | Loss_d: 1.3631e-04 Loss_e: 3.4428e-05 | Loss_b: 3.3358e-05\n",
      "Step: NaN | Loss: 3.4027e-06 | Loss_d: 1.3588e-04 Loss_e: 3.4490e-05 | Loss_b: 3.3506e-05\n",
      "Step: NaN | Loss: 3.4129e-06 | Loss_d: 1.3436e-04 Loss_e: 3.5369e-05 | Loss_b: 3.4749e-05\n",
      "Step: NaN | Loss: 3.4015e-06 | Loss_d: 1.3547e-04 Loss_e: 3.4613e-05 | Loss_b: 3.3710e-05\n",
      "Step: NaN | Loss: 3.3998e-06 | Loss_d: 1.3514e-04 Loss_e: 3.5058e-05 | Loss_b: 3.3495e-05\n",
      "Step: NaN | Loss: 3.3997e-06 | Loss_d: 1.3520e-04 Loss_e: 3.4975e-05 | Loss_b: 3.3520e-05\n",
      "Step: NaN | Loss: 3.3984e-06 | Loss_d: 1.3493e-04 Loss_e: 3.5159e-05 | Loss_b: 3.3527e-05\n",
      "Step: NaN | Loss: 3.4091e-06 | Loss_d: 1.3398e-04 Loss_e: 3.6225e-05 | Loss_b: 3.4054e-05\n",
      "Step: NaN | Loss: 3.3984e-06 | Loss_d: 1.3485e-04 Loss_e: 3.5224e-05 | Loss_b: 3.3540e-05\n",
      "Step: NaN | Loss: 3.3970e-06 | Loss_d: 1.3479e-04 Loss_e: 3.5139e-05 | Loss_b: 3.3597e-05\n",
      "Step: NaN | Loss: 3.3975e-06 | Loss_d: 1.3459e-04 Loss_e: 3.4928e-05 | Loss_b: 3.4044e-05\n",
      "Step: NaN | Loss: 3.3960e-06 | Loss_d: 1.3470e-04 Loss_e: 3.5021e-05 | Loss_b: 3.3753e-05\n",
      "Step: NaN | Loss: 3.3938e-06 | Loss_d: 1.3480e-04 Loss_e: 3.4970e-05 | Loss_b: 3.3572e-05\n",
      "Step: NaN | Loss: 3.3911e-06 | Loss_d: 1.3524e-04 Loss_e: 3.4848e-05 | Loss_b: 3.3084e-05\n",
      "Step: NaN | Loss: 3.3909e-06 | Loss_d: 1.3515e-04 Loss_e: 3.4863e-05 | Loss_b: 3.3153e-05\n",
      "Step: NaN | Loss: 3.3878e-06 | Loss_d: 1.3501e-04 Loss_e: 3.4949e-05 | Loss_b: 3.3020e-05\n",
      "Step: NaN | Loss: 3.3910e-06 | Loss_d: 1.3453e-04 Loss_e: 3.5842e-05 | Loss_b: 3.2797e-05\n",
      "Step: NaN | Loss: 3.3861e-06 | Loss_d: 1.3482e-04 Loss_e: 3.5179e-05 | Loss_b: 3.2877e-05\n",
      "Step: NaN | Loss: 3.5228e-06 | Loss_d: 1.3489e-04 Loss_e: 3.5234e-05 | Loss_b: 4.0942e-05\n",
      "Step: NaN | Loss: 3.3850e-06 | Loss_d: 1.3477e-04 Loss_e: 3.5106e-05 | Loss_b: 3.2928e-05\n",
      "Step: NaN | Loss: 3.3846e-06 | Loss_d: 1.3475e-04 Loss_e: 3.5095e-05 | Loss_b: 3.2940e-05\n",
      "Step: NaN | Loss: 3.3837e-06 | Loss_d: 1.3466e-04 Loss_e: 3.5059e-05 | Loss_b: 3.3015e-05\n",
      "Step: NaN | Loss: 3.3997e-06 | Loss_d: 1.3436e-04 Loss_e: 3.5114e-05 | Loss_b: 3.4215e-05\n",
      "Step: NaN | Loss: 3.3837e-06 | Loss_d: 1.3465e-04 Loss_e: 3.5055e-05 | Loss_b: 3.3029e-05\n",
      "Step: NaN | Loss: 3.3818e-06 | Loss_d: 1.3477e-04 Loss_e: 3.5020e-05 | Loss_b: 3.2825e-05\n",
      "Step: NaN | Loss: 3.3903e-06 | Loss_d: 1.3548e-04 Loss_e: 3.5178e-05 | Loss_b: 3.2467e-05\n",
      "Step: NaN | Loss: 3.3814e-06 | Loss_d: 1.3487e-04 Loss_e: 3.5013e-05 | Loss_b: 3.2709e-05\n",
      "Step: NaN | Loss: 3.3792e-06 | Loss_d: 1.3470e-04 Loss_e: 3.4993e-05 | Loss_b: 3.2768e-05\n",
      "Step: NaN | Loss: 3.3820e-06 | Loss_d: 1.3418e-04 Loss_e: 3.5131e-05 | Loss_b: 3.3320e-05\n",
      "Step: NaN | Loss: 3.3781e-06 | Loss_d: 1.3450e-04 Loss_e: 3.5001e-05 | Loss_b: 3.2903e-05\n",
      "Step: NaN | Loss: 3.3766e-06 | Loss_d: 1.3454e-04 Loss_e: 3.4913e-05 | Loss_b: 3.2848e-05\n",
      "Step: NaN | Loss: 3.3778e-06 | Loss_d: 1.3483e-04 Loss_e: 3.4682e-05 | Loss_b: 3.2862e-05\n",
      "Step: NaN | Loss: 3.3756e-06 | Loss_d: 1.3464e-04 Loss_e: 3.4798e-05 | Loss_b: 3.2807e-05\n",
      "Step: NaN | Loss: 3.3746e-06 | Loss_d: 1.3454e-04 Loss_e: 3.4801e-05 | Loss_b: 3.2845e-05\n",
      "Step: NaN | Loss: 3.3715e-06 | Loss_d: 1.3415e-04 Loss_e: 3.4834e-05 | Loss_b: 3.3013e-05\n",
      "Step: NaN | Loss: 3.3880e-06 | Loss_d: 1.3282e-04 Loss_e: 3.5500e-05 | Loss_b: 3.4672e-05\n",
      "Step: NaN | Loss: 3.3706e-06 | Loss_d: 1.3383e-04 Loss_e: 3.4895e-05 | Loss_b: 3.3219e-05\n",
      "Step: NaN | Loss: 3.3652e-06 | Loss_d: 1.3392e-04 Loss_e: 3.4401e-05 | Loss_b: 3.3307e-05\n",
      "Step: NaN | Loss: 3.3983e-06 | Loss_d: 1.3453e-04 Loss_e: 3.3805e-05 | Loss_b: 3.5264e-05\n",
      "Step: NaN | Loss: 3.3646e-06 | Loss_d: 1.3397e-04 Loss_e: 3.4212e-05 | Loss_b: 3.3409e-05\n",
      "Step: NaN | Loss: 3.3712e-06 | Loss_d: 1.3378e-04 Loss_e: 3.3966e-05 | Loss_b: 3.4241e-05\n",
      "Step: NaN | Loss: 3.3639e-06 | Loss_d: 1.3391e-04 Loss_e: 3.4123e-05 | Loss_b: 3.3512e-05\n",
      "Step: NaN | Loss: 3.3636e-06 | Loss_d: 1.3397e-04 Loss_e: 3.4119e-05 | Loss_b: 3.3446e-05\n",
      "Step: NaN | Loss: 3.3633e-06 | Loss_d: 1.3418e-04 Loss_e: 3.4109e-05 | Loss_b: 3.3218e-05\n",
      "Step: NaN | Loss: 3.3632e-06 | Loss_d: 1.3412e-04 Loss_e: 3.4110e-05 | Loss_b: 3.3274e-05\n",
      "Step: NaN | Loss: 3.3620e-06 | Loss_d: 1.3399e-04 Loss_e: 3.4132e-05 | Loss_b: 3.3308e-05\n",
      "Step: NaN | Loss: 3.3637e-06 | Loss_d: 1.3350e-04 Loss_e: 3.4371e-05 | Loss_b: 3.3662e-05\n",
      "Step: NaN | Loss: 3.3613e-06 | Loss_d: 1.3382e-04 Loss_e: 3.4186e-05 | Loss_b: 3.3390e-05\n",
      "Step: NaN | Loss: 3.3597e-06 | Loss_d: 1.3370e-04 Loss_e: 3.4325e-05 | Loss_b: 3.3274e-05\n",
      "Step: NaN | Loss: 3.3616e-06 | Loss_d: 1.3328e-04 Loss_e: 3.5103e-05 | Loss_b: 3.3019e-05\n",
      "Step: NaN | Loss: 3.3588e-06 | Loss_d: 1.3354e-04 Loss_e: 3.4563e-05 | Loss_b: 3.3143e-05\n",
      "Step: NaN | Loss: 3.3579e-06 | Loss_d: 1.3351e-04 Loss_e: 3.4636e-05 | Loss_b: 3.3046e-05\n",
      "Step: NaN | Loss: 3.3659e-06 | Loss_d: 1.3346e-04 Loss_e: 3.5040e-05 | Loss_b: 3.3167e-05\n",
      "Step: NaN | Loss: 3.3579e-06 | Loss_d: 1.3350e-04 Loss_e: 3.4658e-05 | Loss_b: 3.3031e-05\n",
      "Step: NaN | Loss: 3.3574e-06 | Loss_d: 1.3356e-04 Loss_e: 3.4675e-05 | Loss_b: 3.2921e-05\n",
      "Step: NaN | Loss: 3.3570e-06 | Loss_d: 1.3382e-04 Loss_e: 3.4749e-05 | Loss_b: 3.2562e-05\n",
      "Step: NaN | Loss: 3.3568e-06 | Loss_d: 1.3372e-04 Loss_e: 3.4723e-05 | Loss_b: 3.2674e-05\n",
      "Step: NaN | Loss: 3.3558e-06 | Loss_d: 1.3366e-04 Loss_e: 3.4722e-05 | Loss_b: 3.2683e-05\n",
      "Step: NaN | Loss: 3.3530e-06 | Loss_d: 1.3340e-04 Loss_e: 3.4744e-05 | Loss_b: 3.2749e-05\n",
      "Step: NaN | Loss: 3.3663e-06 | Loss_d: 1.3230e-04 Loss_e: 3.5448e-05 | Loss_b: 3.3940e-05\n",
      "Step: NaN | Loss: 3.3520e-06 | Loss_d: 1.3314e-04 Loss_e: 3.4809e-05 | Loss_b: 3.2879e-05\n",
      "Step: NaN | Loss: 3.3465e-06 | Loss_d: 1.3307e-04 Loss_e: 3.4737e-05 | Loss_b: 3.2691e-05\n",
      "Step: NaN | Loss: 3.4022e-06 | Loss_d: 1.3358e-04 Loss_e: 3.5868e-05 | Loss_b: 3.4389e-05\n",
      "Step: NaN | Loss: 3.3463e-06 | Loss_d: 1.3307e-04 Loss_e: 3.4740e-05 | Loss_b: 3.2683e-05\n",
      "Step: NaN | Loss: 3.3431e-06 | Loss_d: 1.3301e-04 Loss_e: 3.4801e-05 | Loss_b: 3.2489e-05\n",
      "Step: NaN | Loss: 3.3728e-06 | Loss_d: 1.3340e-04 Loss_e: 3.5494e-05 | Loss_b: 3.3183e-05\n",
      "Step: NaN | Loss: 3.3430e-06 | Loss_d: 1.3301e-04 Loss_e: 3.4822e-05 | Loss_b: 3.2463e-05\n",
      "Step: NaN | Loss: 3.3419e-06 | Loss_d: 1.3300e-04 Loss_e: 3.4818e-05 | Loss_b: 3.2409e-05\n",
      "Step: NaN | Loss: 3.3396e-06 | Loss_d: 1.3298e-04 Loss_e: 3.4830e-05 | Loss_b: 3.2273e-05\n",
      "Step: NaN | Loss: 3.3772e-06 | Loss_d: 1.3325e-04 Loss_e: 3.5586e-05 | Loss_b: 3.3507e-05\n",
      "Step: NaN | Loss: 3.3395e-06 | Loss_d: 1.3298e-04 Loss_e: 3.4839e-05 | Loss_b: 3.2259e-05\n",
      "Step: NaN | Loss: 3.3368e-06 | Loss_d: 1.3270e-04 Loss_e: 3.4881e-05 | Loss_b: 3.2343e-05\n",
      "Step: NaN | Loss: 3.3337e-06 | Loss_d: 1.3160e-04 Loss_e: 3.5212e-05 | Loss_b: 3.2919e-05\n",
      "Step: NaN | Loss: 3.3333e-06 | Loss_d: 1.3186e-04 Loss_e: 3.5107e-05 | Loss_b: 3.2742e-05\n",
      "Step: NaN | Loss: 3.3290e-06 | Loss_d: 1.3100e-04 Loss_e: 3.5567e-05 | Loss_b: 3.2891e-05\n",
      "Step: NaN | Loss: 3.3750e-06 | Loss_d: 1.2783e-04 Loss_e: 3.8375e-05 | Loss_b: 3.6003e-05\n",
      "Step: NaN | Loss: 3.3289e-06 | Loss_d: 1.3084e-04 Loss_e: 3.5661e-05 | Loss_b: 3.2946e-05\n",
      "Step: NaN | Loss: 3.3255e-06 | Loss_d: 1.3030e-04 Loss_e: 3.6248e-05 | Loss_b: 3.2690e-05\n",
      "Step: NaN | Loss: 3.3809e-06 | Loss_d: 1.2854e-04 Loss_e: 4.0791e-05 | Loss_b: 3.3229e-05\n",
      "Step: NaN | Loss: 3.3255e-06 | Loss_d: 1.3030e-04 Loss_e: 3.6249e-05 | Loss_b: 3.2690e-05\n",
      "Step: NaN | Loss: 3.3250e-06 | Loss_d: 1.3035e-04 Loss_e: 3.6223e-05 | Loss_b: 3.2641e-05\n",
      "Step: NaN | Loss: 3.3243e-06 | Loss_d: 1.3055e-04 Loss_e: 3.6143e-05 | Loss_b: 3.2476e-05\n",
      "Step: NaN | Loss: 3.3243e-06 | Loss_d: 1.3054e-04 Loss_e: 3.6147e-05 | Loss_b: 3.2485e-05\n",
      "Step: NaN | Loss: 3.3231e-06 | Loss_d: 1.3046e-04 Loss_e: 3.6025e-05 | Loss_b: 3.2619e-05\n",
      "Step: NaN | Loss: 3.3221e-06 | Loss_d: 1.3015e-04 Loss_e: 3.5628e-05 | Loss_b: 3.3267e-05\n",
      "Step: NaN | Loss: 3.3218e-06 | Loss_d: 1.3025e-04 Loss_e: 3.5745e-05 | Loss_b: 3.3031e-05\n",
      "Step: NaN | Loss: 3.3214e-06 | Loss_d: 1.2996e-04 Loss_e: 3.5722e-05 | Loss_b: 3.3316e-05\n",
      "Step: NaN | Loss: 3.3210e-06 | Loss_d: 1.3007e-04 Loss_e: 3.5727e-05 | Loss_b: 3.3177e-05\n",
      "Step: NaN | Loss: 3.3205e-06 | Loss_d: 1.3000e-04 Loss_e: 3.5716e-05 | Loss_b: 3.3225e-05\n",
      "Step: NaN | Loss: 3.3201e-06 | Loss_d: 1.2975e-04 Loss_e: 3.5674e-05 | Loss_b: 3.3501e-05\n",
      "Step: NaN | Loss: 3.3200e-06 | Loss_d: 1.2984e-04 Loss_e: 3.5688e-05 | Loss_b: 3.3386e-05\n",
      "Step: NaN | Loss: 3.3190e-06 | Loss_d: 1.2978e-04 Loss_e: 3.5703e-05 | Loss_b: 3.3373e-05\n",
      "Step: NaN | Loss: 3.3164e-06 | Loss_d: 1.2955e-04 Loss_e: 3.5779e-05 | Loss_b: 3.3367e-05\n",
      "Step: NaN | Loss: 3.3319e-06 | Loss_d: 1.2872e-04 Loss_e: 3.6514e-05 | Loss_b: 3.4395e-05\n",
      "Step: NaN | Loss: 3.3156e-06 | Loss_d: 1.2937e-04 Loss_e: 3.5865e-05 | Loss_b: 3.3419e-05\n",
      "Step: NaN | Loss: 3.3135e-06 | Loss_d: 1.2921e-04 Loss_e: 3.5835e-05 | Loss_b: 3.3485e-05\n",
      "Step: NaN | Loss: 3.3270e-06 | Loss_d: 1.2890e-04 Loss_e: 3.6043e-05 | Loss_b: 3.4393e-05\n",
      "Step: NaN | Loss: 3.3133e-06 | Loss_d: 1.2915e-04 Loss_e: 3.5832e-05 | Loss_b: 3.3536e-05\n",
      "Step: NaN | Loss: 3.3124e-06 | Loss_d: 1.2919e-04 Loss_e: 3.5747e-05 | Loss_b: 3.3523e-05\n",
      "Step: NaN | Loss: 3.3140e-06 | Loss_d: 1.2942e-04 Loss_e: 3.5545e-05 | Loss_b: 3.3595e-05\n",
      "Step: NaN | Loss: 3.3119e-06 | Loss_d: 1.2925e-04 Loss_e: 3.5659e-05 | Loss_b: 3.3523e-05\n",
      "Step: NaN | Loss: 3.3105e-06 | Loss_d: 1.2900e-04 Loss_e: 3.5741e-05 | Loss_b: 3.3608e-05\n",
      "Step: NaN | Loss: 3.3105e-06 | Loss_d: 1.2802e-04 Loss_e: 3.6137e-05 | Loss_b: 3.4194e-05\n",
      "Step: NaN | Loss: 3.3094e-06 | Loss_d: 1.2851e-04 Loss_e: 3.5922e-05 | Loss_b: 3.3850e-05\n",
      "Step: NaN | Loss: 3.3069e-06 | Loss_d: 1.2830e-04 Loss_e: 3.6006e-05 | Loss_b: 3.3825e-05\n",
      "Step: NaN | Loss: 3.2997e-06 | Loss_d: 1.2754e-04 Loss_e: 3.6402e-05 | Loss_b: 3.3756e-05\n",
      "Step: NaN | Loss: 3.3354e-06 | Loss_d: 1.2504e-04 Loss_e: 3.9983e-05 | Loss_b: 3.4812e-05\n",
      "Step: NaN | Loss: 3.2967e-06 | Loss_d: 1.2690e-04 Loss_e: 3.6874e-05 | Loss_b: 3.3747e-05\n",
      "Step: NaN | Loss: 3.3097e-06 | Loss_d: 1.2830e-04 Loss_e: 3.6154e-05 | Loss_b: 3.3844e-05\n",
      "Step: NaN | Loss: 3.2936e-06 | Loss_d: 1.2728e-04 Loss_e: 3.6538e-05 | Loss_b: 3.3512e-05\n",
      "Step: NaN | Loss: 3.2925e-06 | Loss_d: 1.2712e-04 Loss_e: 3.6418e-05 | Loss_b: 3.3726e-05\n",
      "Step: NaN | Loss: 3.2922e-06 | Loss_d: 1.2717e-04 Loss_e: 3.6440e-05 | Loss_b: 3.3637e-05\n",
      "Step: NaN | Loss: 3.2917e-06 | Loss_d: 1.2699e-04 Loss_e: 3.6545e-05 | Loss_b: 3.3679e-05\n",
      "Step: NaN | Loss: 3.2913e-06 | Loss_d: 1.2630e-04 Loss_e: 3.7011e-05 | Loss_b: 3.3882e-05\n",
      "Step: NaN | Loss: 3.2911e-06 | Loss_d: 1.2655e-04 Loss_e: 3.6830e-05 | Loss_b: 3.3802e-05\n",
      "Step: NaN | Loss: 3.2895e-06 | Loss_d: 1.2665e-04 Loss_e: 3.6879e-05 | Loss_b: 3.3558e-05\n",
      "Step: NaN | Loss: 3.2911e-06 | Loss_d: 1.2710e-04 Loss_e: 3.7147e-05 | Loss_b: 3.2940e-05\n",
      "Step: NaN | Loss: 3.2887e-06 | Loss_d: 1.2681e-04 Loss_e: 3.6966e-05 | Loss_b: 3.3263e-05\n",
      "Step: NaN | Loss: 3.2881e-06 | Loss_d: 1.2722e-04 Loss_e: 3.6704e-05 | Loss_b: 3.3084e-05\n",
      "Step: NaN | Loss: 3.2880e-06 | Loss_d: 1.2710e-04 Loss_e: 3.6773e-05 | Loss_b: 3.3127e-05\n",
      "Step: NaN | Loss: 3.2876e-06 | Loss_d: 1.2720e-04 Loss_e: 3.6744e-05 | Loss_b: 3.3028e-05\n",
      "Step: NaN | Loss: 3.2910e-06 | Loss_d: 1.2762e-04 Loss_e: 3.6640e-05 | Loss_b: 3.2913e-05\n",
      "Step: NaN | Loss: 3.2876e-06 | Loss_d: 1.2724e-04 Loss_e: 3.6734e-05 | Loss_b: 3.2997e-05\n",
      "Step: NaN | Loss: 3.2873e-06 | Loss_d: 1.2727e-04 Loss_e: 3.6693e-05 | Loss_b: 3.2994e-05\n",
      "Step: NaN | Loss: 3.2865e-06 | Loss_d: 1.2738e-04 Loss_e: 3.6537e-05 | Loss_b: 3.2986e-05\n",
      "Step: NaN | Loss: 3.2905e-06 | Loss_d: 1.2810e-04 Loss_e: 3.5957e-05 | Loss_b: 3.3095e-05\n",
      "Step: NaN | Loss: 3.2862e-06 | Loss_d: 1.2751e-04 Loss_e: 3.6392e-05 | Loss_b: 3.2989e-05\n",
      "Step: NaN | Loss: 3.2841e-06 | Loss_d: 1.2737e-04 Loss_e: 3.6497e-05 | Loss_b: 3.2899e-05\n",
      "Step: NaN | Loss: 3.3001e-06 | Loss_d: 1.2712e-04 Loss_e: 3.7173e-05 | Loss_b: 3.3432e-05\n",
      "Step: NaN | Loss: 3.2840e-06 | Loss_d: 1.2733e-04 Loss_e: 3.6541e-05 | Loss_b: 3.2887e-05\n",
      "Step: NaN | Loss: 3.2806e-06 | Loss_d: 1.2718e-04 Loss_e: 3.6443e-05 | Loss_b: 3.2935e-05\n",
      "Step: NaN | Loss: 3.2928e-06 | Loss_d: 1.2686e-04 Loss_e: 3.6326e-05 | Loss_b: 3.4100e-05\n",
      "Step: NaN | Loss: 3.2797e-06 | Loss_d: 1.2707e-04 Loss_e: 3.6384e-05 | Loss_b: 3.3045e-05\n",
      "Step: NaN | Loss: 3.2745e-06 | Loss_d: 1.2667e-04 Loss_e: 3.6369e-05 | Loss_b: 3.3150e-05\n",
      "Step: NaN | Loss: 3.2708e-06 | Loss_d: 1.2524e-04 Loss_e: 3.6610e-05 | Loss_b: 3.4120e-05\n",
      "Step: NaN | Loss: 3.2690e-06 | Loss_d: 1.2573e-04 Loss_e: 3.6466e-05 | Loss_b: 3.3666e-05\n",
      "Step: NaN | Loss: 3.2578e-06 | Loss_d: 1.2538e-04 Loss_e: 3.6322e-05 | Loss_b: 3.3489e-05\n",
      "Step: NaN | Loss: 3.2531e-06 | Loss_d: 1.2429e-04 Loss_e: 3.6514e-05 | Loss_b: 3.4100e-05\n",
      "Step: NaN | Loss: 3.2472e-06 | Loss_d: 1.2469e-04 Loss_e: 3.6283e-05 | Loss_b: 3.3580e-05\n",
      "Step: NaN | Loss: 3.2439e-06 | Loss_d: 1.2507e-04 Loss_e: 3.5986e-05 | Loss_b: 3.3304e-05\n",
      "Step: NaN | Loss: 3.2420e-06 | Loss_d: 1.2488e-04 Loss_e: 3.6044e-05 | Loss_b: 3.3312e-05\n",
      "Step: NaN | Loss: 3.2422e-06 | Loss_d: 1.2401e-04 Loss_e: 3.6386e-05 | Loss_b: 3.3857e-05\n",
      "Step: NaN | Loss: 3.2395e-06 | Loss_d: 1.2444e-04 Loss_e: 3.6154e-05 | Loss_b: 3.3497e-05\n",
      "Step: NaN | Loss: 3.2372e-06 | Loss_d: 1.2391e-04 Loss_e: 3.6518e-05 | Loss_b: 3.3529e-05\n",
      "Step: NaN | Loss: 3.2427e-06 | Loss_d: 1.2196e-04 Loss_e: 3.8341e-05 | Loss_b: 3.3987e-05\n",
      "Step: NaN | Loss: 3.2364e-06 | Loss_d: 1.2337e-04 Loss_e: 3.6937e-05 | Loss_b: 3.3599e-05\n",
      "Step: NaN | Loss: 3.2346e-06 | Loss_d: 1.2341e-04 Loss_e: 3.6962e-05 | Loss_b: 3.3433e-05\n",
      "Step: NaN | Loss: 3.2512e-06 | Loss_d: 1.2368e-04 Loss_e: 3.7145e-05 | Loss_b: 3.3971e-05\n",
      "Step: NaN | Loss: 3.2346e-06 | Loss_d: 1.2342e-04 Loss_e: 3.6970e-05 | Loss_b: 3.3410e-05\n",
      "Step: NaN | Loss: 3.2334e-06 | Loss_d: 1.2342e-04 Loss_e: 3.7120e-05 | Loss_b: 3.3184e-05\n",
      "Step: NaN | Loss: 3.2517e-06 | Loss_d: 1.2385e-04 Loss_e: 3.7866e-05 | Loss_b: 3.3101e-05\n",
      "Step: NaN | Loss: 3.2334e-06 | Loss_d: 1.2342e-04 Loss_e: 3.7130e-05 | Loss_b: 3.3171e-05\n",
      "Step: NaN | Loss: 3.2322e-06 | Loss_d: 1.2358e-04 Loss_e: 3.6945e-05 | Loss_b: 3.3128e-05\n",
      "Step: NaN | Loss: 3.2333e-06 | Loss_d: 1.2431e-04 Loss_e: 3.6312e-05 | Loss_b: 3.3100e-05\n",
      "Step: NaN | Loss: 3.2315e-06 | Loss_d: 1.2384e-04 Loss_e: 3.6687e-05 | Loss_b: 3.3090e-05\n",
      "Step: NaN | Loss: 3.2288e-06 | Loss_d: 1.2393e-04 Loss_e: 3.6402e-05 | Loss_b: 3.3114e-05\n",
      "Step: NaN | Loss: 3.2311e-06 | Loss_d: 1.2439e-04 Loss_e: 3.5457e-05 | Loss_b: 3.3742e-05\n",
      "Step: NaN | Loss: 3.2271e-06 | Loss_d: 1.2410e-04 Loss_e: 3.5996e-05 | Loss_b: 3.3257e-05\n",
      "Step: NaN | Loss: 3.2231e-06 | Loss_d: 1.2379e-04 Loss_e: 3.5960e-05 | Loss_b: 3.3358e-05\n",
      "Step: NaN | Loss: 3.2538e-06 | Loss_d: 1.2356e-04 Loss_e: 3.6626e-05 | Loss_b: 3.4768e-05\n",
      "Step: NaN | Loss: 3.2228e-06 | Loss_d: 1.2371e-04 Loss_e: 3.5967e-05 | Loss_b: 3.3417e-05\n",
      "Step: NaN | Loss: 3.2212e-06 | Loss_d: 1.2352e-04 Loss_e: 3.5866e-05 | Loss_b: 3.3610e-05\n",
      "Step: NaN | Loss: 3.2227e-06 | Loss_d: 1.2280e-04 Loss_e: 3.5603e-05 | Loss_b: 3.4682e-05\n",
      "Step: NaN | Loss: 3.2203e-06 | Loss_d: 1.2324e-04 Loss_e: 3.5739e-05 | Loss_b: 3.3959e-05\n",
      "Step: NaN | Loss: 3.2163e-06 | Loss_d: 1.2300e-04 Loss_e: 3.5678e-05 | Loss_b: 3.4025e-05\n",
      "Step: NaN | Loss: 3.2205e-06 | Loss_d: 1.2246e-04 Loss_e: 3.5816e-05 | Loss_b: 3.4677e-05\n",
      "Step: NaN | Loss: 3.2141e-06 | Loss_d: 1.2272e-04 Loss_e: 3.5657e-05 | Loss_b: 3.4192e-05\n",
      "Step: NaN | Loss: 3.2108e-06 | Loss_d: 1.2274e-04 Loss_e: 3.5620e-05 | Loss_b: 3.4016e-05\n",
      "Step: NaN | Loss: 3.2140e-06 | Loss_d: 1.2286e-04 Loss_e: 3.5766e-05 | Loss_b: 3.3937e-05\n",
      "Step: NaN | Loss: 3.2090e-06 | Loss_d: 1.2277e-04 Loss_e: 3.5621e-05 | Loss_b: 3.3870e-05\n",
      "Step: NaN | Loss: 3.2083e-06 | Loss_d: 1.2280e-04 Loss_e: 3.5535e-05 | Loss_b: 3.3887e-05\n",
      "Step: NaN | Loss: 3.2088e-06 | Loss_d: 1.2292e-04 Loss_e: 3.5217e-05 | Loss_b: 3.4117e-05\n",
      "Step: NaN | Loss: 3.2078e-06 | Loss_d: 1.2284e-04 Loss_e: 3.5401e-05 | Loss_b: 3.3949e-05\n",
      "Step: NaN | Loss: 3.2071e-06 | Loss_d: 1.2277e-04 Loss_e: 3.5427e-05 | Loss_b: 3.3951e-05\n",
      "Step: NaN | Loss: 3.2051e-06 | Loss_d: 1.2250e-04 Loss_e: 3.5544e-05 | Loss_b: 3.3981e-05\n",
      "Step: NaN | Loss: 3.2136e-06 | Loss_d: 1.2133e-04 Loss_e: 3.6434e-05 | Loss_b: 3.4772e-05\n",
      "Step: NaN | Loss: 3.2041e-06 | Loss_d: 1.2222e-04 Loss_e: 3.5699e-05 | Loss_b: 3.4057e-05\n",
      "Step: NaN | Loss: 3.1993e-06 | Loss_d: 1.2206e-04 Loss_e: 3.5465e-05 | Loss_b: 3.4160e-05\n",
      "Step: NaN | Loss: 3.2238e-06 | Loss_d: 1.2158e-04 Loss_e: 3.5415e-05 | Loss_b: 3.6155e-05\n",
      "Step: NaN | Loss: 3.1985e-06 | Loss_d: 1.2197e-04 Loss_e: 3.5367e-05 | Loss_b: 3.4298e-05\n",
      "Step: NaN | Loss: 3.1962e-06 | Loss_d: 1.2225e-04 Loss_e: 3.5211e-05 | Loss_b: 3.4039e-05\n",
      "Step: NaN | Loss: 3.2016e-06 | Loss_d: 1.2359e-04 Loss_e: 3.4856e-05 | Loss_b: 3.3370e-05\n",
      "Step: NaN | Loss: 3.1954e-06 | Loss_d: 1.2257e-04 Loss_e: 3.5073e-05 | Loss_b: 3.3801e-05\n",
      "Step: NaN | Loss: 3.1930e-06 | Loss_d: 1.2300e-04 Loss_e: 3.4524e-05 | Loss_b: 3.3789e-05\n",
      "Step: NaN | Loss: 3.2130e-06 | Loss_d: 1.2505e-04 Loss_e: 3.2958e-05 | Loss_b: 3.4500e-05\n",
      "Step: NaN | Loss: 3.1929e-06 | Loss_d: 1.2314e-04 Loss_e: 3.4361e-05 | Loss_b: 3.3799e-05\n",
      "Step: NaN | Loss: 3.1909e-06 | Loss_d: 1.2306e-04 Loss_e: 3.4318e-05 | Loss_b: 3.3802e-05\n",
      "Step: NaN | Loss: 3.1963e-06 | Loss_d: 1.2293e-04 Loss_e: 3.4303e-05 | Loss_b: 3.4271e-05\n",
      "Step: NaN | Loss: 3.1903e-06 | Loss_d: 1.2300e-04 Loss_e: 3.4292e-05 | Loss_b: 3.3848e-05\n",
      "Step: NaN | Loss: 3.1902e-06 | Loss_d: 1.2318e-04 Loss_e: 3.4129e-05 | Loss_b: 3.3835e-05\n",
      "Step: NaN | Loss: 3.1900e-06 | Loss_d: 1.2309e-04 Loss_e: 3.4207e-05 | Loss_b: 3.3831e-05\n",
      "Step: NaN | Loss: 3.1896e-06 | Loss_d: 1.2306e-04 Loss_e: 3.4254e-05 | Loss_b: 3.3789e-05\n",
      "Step: NaN | Loss: 3.1894e-06 | Loss_d: 1.2298e-04 Loss_e: 3.4465e-05 | Loss_b: 3.3645e-05\n",
      "Step: NaN | Loss: 3.1893e-06 | Loss_d: 1.2301e-04 Loss_e: 3.4380e-05 | Loss_b: 3.3695e-05\n",
      "Step: NaN | Loss: 3.1888e-06 | Loss_d: 1.2310e-04 Loss_e: 3.4332e-05 | Loss_b: 3.3625e-05\n",
      "Step: NaN | Loss: 3.1878e-06 | Loss_d: 1.2345e-04 Loss_e: 3.4160e-05 | Loss_b: 3.3385e-05\n",
      "Step: NaN | Loss: 3.2107e-06 | Loss_d: 1.2543e-04 Loss_e: 3.3673e-05 | Loss_b: 3.3265e-05\n",
      "Step: NaN | Loss: 3.1878e-06 | Loss_d: 1.2346e-04 Loss_e: 3.4155e-05 | Loss_b: 3.3378e-05\n",
      "Step: NaN | Loss: 3.1868e-06 | Loss_d: 1.2346e-04 Loss_e: 3.4166e-05 | Loss_b: 3.3308e-05\n",
      "Step: NaN | Loss: 3.1849e-06 | Loss_d: 1.2347e-04 Loss_e: 3.4259e-05 | Loss_b: 3.3093e-05\n",
      "Step: NaN | Loss: 3.2269e-06 | Loss_d: 1.2389e-04 Loss_e: 3.5856e-05 | Loss_b: 3.3594e-05\n",
      "Step: NaN | Loss: 3.1849e-06 | Loss_d: 1.2347e-04 Loss_e: 3.4265e-05 | Loss_b: 3.3085e-05\n",
      "Step: NaN | Loss: 3.1825e-06 | Loss_d: 1.2329e-04 Loss_e: 3.4174e-05 | Loss_b: 3.3209e-05\n",
      "Step: NaN | Loss: 3.1785e-06 | Loss_d: 1.2262e-04 Loss_e: 3.3950e-05 | Loss_b: 3.3864e-05\n",
      "Step: NaN | Loss: 3.1784e-06 | Loss_d: 1.2266e-04 Loss_e: 3.3958e-05 | Loss_b: 3.3812e-05\n",
      "Step: NaN | Loss: 3.1753e-06 | Loss_d: 1.2303e-04 Loss_e: 3.3269e-05 | Loss_b: 3.3948e-05\n",
      "Step: NaN | Loss: 3.1752e-06 | Loss_d: 1.2297e-04 Loss_e: 3.3373e-05 | Loss_b: 3.3897e-05\n",
      "Step: NaN | Loss: 3.1717e-06 | Loss_d: 1.2286e-04 Loss_e: 3.3266e-05 | Loss_b: 3.3900e-05\n",
      "Step: NaN | Loss: 3.1626e-06 | Loss_d: 1.2249e-04 Loss_e: 3.2906e-05 | Loss_b: 3.4094e-05\n",
      "Step: NaN | Loss: 3.2301e-06 | Loss_d: 1.2205e-04 Loss_e: 3.2718e-05 | Loss_b: 3.8755e-05\n",
      "Step: NaN | Loss: 3.1610e-06 | Loss_d: 1.2228e-04 Loss_e: 3.2720e-05 | Loss_b: 3.4386e-05\n",
      "Step: NaN | Loss: 3.1567e-06 | Loss_d: 1.2249e-04 Loss_e: 3.2298e-05 | Loss_b: 3.4344e-05\n",
      "Step: NaN | Loss: 3.1991e-06 | Loss_d: 1.2435e-04 Loss_e: 3.2099e-05 | Loss_b: 3.5221e-05\n",
      "Step: NaN | Loss: 3.1566e-06 | Loss_d: 1.2254e-04 Loss_e: 3.2241e-05 | Loss_b: 3.4349e-05\n",
      "Step: NaN | Loss: 3.1581e-06 | Loss_d: 1.2194e-04 Loss_e: 3.2854e-05 | Loss_b: 3.4426e-05\n",
      "Step: NaN | Loss: 3.1548e-06 | Loss_d: 1.2227e-04 Loss_e: 3.2476e-05 | Loss_b: 3.4273e-05\n",
      "Step: NaN | Loss: 3.1539e-06 | Loss_d: 1.2230e-04 Loss_e: 3.2459e-05 | Loss_b: 3.4209e-05\n",
      "Step: NaN | Loss: 3.1519e-06 | Loss_d: 1.2242e-04 Loss_e: 3.2418e-05 | Loss_b: 3.4003e-05\n",
      "Step: NaN | Loss: 3.1744e-06 | Loss_d: 1.2329e-04 Loss_e: 3.2842e-05 | Loss_b: 3.4061e-05\n",
      "Step: NaN | Loss: 3.1517e-06 | Loss_d: 1.2248e-04 Loss_e: 3.2414e-05 | Loss_b: 3.3935e-05\n",
      "Step: NaN | Loss: 3.1493e-06 | Loss_d: 1.2239e-04 Loss_e: 3.2481e-05 | Loss_b: 3.3820e-05\n",
      "Step: NaN | Loss: 3.1520e-06 | Loss_d: 1.2205e-04 Loss_e: 3.3079e-05 | Loss_b: 3.3717e-05\n",
      "Step: NaN | Loss: 3.1480e-06 | Loss_d: 1.2226e-04 Loss_e: 3.2639e-05 | Loss_b: 3.3718e-05\n",
      "Step: NaN | Loss: 3.1472e-06 | Loss_d: 1.2225e-04 Loss_e: 3.2599e-05 | Loss_b: 3.3714e-05\n",
      "Step: NaN | Loss: 3.1469e-06 | Loss_d: 1.2223e-04 Loss_e: 3.2489e-05 | Loss_b: 3.3826e-05\n",
      "Step: NaN | Loss: 3.1464e-06 | Loss_d: 1.2224e-04 Loss_e: 3.2528e-05 | Loss_b: 3.3750e-05\n",
      "Step: NaN | Loss: 3.1451e-06 | Loss_d: 1.2213e-04 Loss_e: 3.2576e-05 | Loss_b: 3.3726e-05\n",
      "Step: NaN | Loss: 3.1441e-06 | Loss_d: 1.2174e-04 Loss_e: 3.2869e-05 | Loss_b: 3.3765e-05\n",
      "Step: NaN | Loss: 3.1437e-06 | Loss_d: 1.2188e-04 Loss_e: 3.2749e-05 | Loss_b: 3.3725e-05\n",
      "Step: NaN | Loss: 3.1427e-06 | Loss_d: 1.2197e-04 Loss_e: 3.2656e-05 | Loss_b: 3.3668e-05\n",
      "Step: NaN | Loss: 3.1416e-06 | Loss_d: 1.2235e-04 Loss_e: 3.2333e-05 | Loss_b: 3.3542e-05\n",
      "Step: NaN | Loss: 3.1414e-06 | Loss_d: 1.2225e-04 Loss_e: 3.2412e-05 | Loss_b: 3.3559e-05\n",
      "Step: NaN | Loss: 3.1402e-06 | Loss_d: 1.2210e-04 Loss_e: 3.2574e-05 | Loss_b: 3.3471e-05\n",
      "Step: NaN | Loss: 3.1394e-06 | Loss_d: 1.2154e-04 Loss_e: 3.3350e-05 | Loss_b: 3.3201e-05\n",
      "Step: NaN | Loss: 3.1389e-06 | Loss_d: 1.2175e-04 Loss_e: 3.3031e-05 | Loss_b: 3.3289e-05\n",
      "Step: NaN | Loss: 3.1350e-06 | Loss_d: 1.2142e-04 Loss_e: 3.3061e-05 | Loss_b: 3.3352e-05\n",
      "Step: NaN | Loss: 3.1355e-06 | Loss_d: 1.2024e-04 Loss_e: 3.3404e-05 | Loss_b: 3.4218e-05\n",
      "Step: NaN | Loss: 3.1320e-06 | Loss_d: 1.2083e-04 Loss_e: 3.3180e-05 | Loss_b: 3.3638e-05\n",
      "Step: NaN | Loss: 3.1226e-06 | Loss_d: 1.2088e-04 Loss_e: 3.2623e-05 | Loss_b: 3.3589e-05\n",
      "Step: NaN | Loss: 3.2576e-06 | Loss_d: 1.2266e-04 Loss_e: 3.3515e-05 | Loss_b: 3.9001e-05\n",
      "Step: NaN | Loss: 3.1226e-06 | Loss_d: 1.2088e-04 Loss_e: 3.2605e-05 | Loss_b: 3.3600e-05\n",
      "Step: NaN | Loss: 3.1173e-06 | Loss_d: 1.2040e-04 Loss_e: 3.2613e-05 | Loss_b: 3.3759e-05\n",
      "Step: NaN | Loss: 3.1741e-06 | Loss_d: 1.1971e-04 Loss_e: 3.3714e-05 | Loss_b: 3.6753e-05\n",
      "Step: NaN | Loss: 3.1170e-06 | Loss_d: 1.2031e-04 Loss_e: 3.2628e-05 | Loss_b: 3.3818e-05\n",
      "Step: NaN | Loss: 3.1105e-06 | Loss_d: 1.2014e-04 Loss_e: 3.2376e-05 | Loss_b: 3.3845e-05\n",
      "Step: NaN | Loss: 3.1165e-06 | Loss_d: 1.1973e-04 Loss_e: 3.1637e-05 | Loss_b: 3.5362e-05\n",
      "Step: NaN | Loss: 3.1068e-06 | Loss_d: 1.1994e-04 Loss_e: 3.2042e-05 | Loss_b: 3.4159e-05\n",
      "Step: NaN | Loss: 3.0979e-06 | Loss_d: 1.1966e-04 Loss_e: 3.2333e-05 | Loss_b: 3.3614e-05\n",
      "Step: NaN | Loss: 3.1200e-06 | Loss_d: 1.1883e-04 Loss_e: 3.4336e-05 | Loss_b: 3.3770e-05\n",
      "Step: NaN | Loss: 3.0946e-06 | Loss_d: 1.1940e-04 Loss_e: 3.2721e-05 | Loss_b: 3.3292e-05\n",
      "Step: NaN | Loss: 3.0911e-06 | Loss_d: 1.1954e-04 Loss_e: 3.2418e-05 | Loss_b: 3.3246e-05\n",
      "Step: NaN | Loss: 3.0896e-06 | Loss_d: 1.2037e-04 Loss_e: 3.1512e-05 | Loss_b: 3.3231e-05\n",
      "Step: NaN | Loss: 3.0878e-06 | Loss_d: 1.1995e-04 Loss_e: 3.1852e-05 | Loss_b: 3.3198e-05\n",
      "Step: NaN | Loss: 3.0757e-06 | Loss_d: 1.1918e-04 Loss_e: 3.2061e-05 | Loss_b: 3.3035e-05\n",
      "Step: NaN | Loss: 3.1512e-06 | Loss_d: 1.1687e-04 Loss_e: 3.4543e-05 | Loss_b: 3.7392e-05\n",
      "Step: NaN | Loss: 3.0741e-06 | Loss_d: 1.1884e-04 Loss_e: 3.2217e-05 | Loss_b: 3.3127e-05\n",
      "Step: NaN | Loss: 3.0646e-06 | Loss_d: 1.1839e-04 Loss_e: 3.2422e-05 | Loss_b: 3.2797e-05\n",
      "Step: NaN | Loss: 3.1171e-06 | Loss_d: 1.1718e-04 Loss_e: 3.5071e-05 | Loss_b: 3.4511e-05\n",
      "Step: NaN | Loss: 3.0632e-06 | Loss_d: 1.1817e-04 Loss_e: 3.2613e-05 | Loss_b: 3.2747e-05\n",
      "Step: NaN | Loss: 3.0605e-06 | Loss_d: 1.1781e-04 Loss_e: 3.3036e-05 | Loss_b: 3.2520e-05\n",
      "Step: NaN | Loss: 3.0970e-06 | Loss_d: 1.1654e-04 Loss_e: 3.5365e-05 | Loss_b: 3.3652e-05\n",
      "Step: NaN | Loss: 3.0605e-06 | Loss_d: 1.1778e-04 Loss_e: 3.3076e-05 | Loss_b: 3.2511e-05\n",
      "Step: NaN | Loss: 3.0582e-06 | Loss_d: 1.1756e-04 Loss_e: 3.3135e-05 | Loss_b: 3.2536e-05\n",
      "Step: NaN | Loss: 3.0538e-06 | Loss_d: 1.1674e-04 Loss_e: 3.3487e-05 | Loss_b: 3.2737e-05\n",
      "Step: NaN | Loss: 3.1373e-06 | Loss_d: 1.1385e-04 Loss_e: 3.8067e-05 | Loss_b: 3.6057e-05\n",
      "Step: NaN | Loss: 3.0537e-06 | Loss_d: 1.1663e-04 Loss_e: 3.3552e-05 | Loss_b: 3.2776e-05\n",
      "Step: NaN | Loss: 3.0472e-06 | Loss_d: 1.1634e-04 Loss_e: 3.3587e-05 | Loss_b: 3.2649e-05\n",
      "Step: NaN | Loss: 3.0446e-06 | Loss_d: 1.1538e-04 Loss_e: 3.4105e-05 | Loss_b: 3.2935e-05\n",
      "Step: NaN | Loss: 3.0412e-06 | Loss_d: 1.1575e-04 Loss_e: 3.3809e-05 | Loss_b: 3.2657e-05\n",
      "Step: NaN | Loss: 3.0363e-06 | Loss_d: 1.1561e-04 Loss_e: 3.3697e-05 | Loss_b: 3.2605e-05\n",
      "Step: NaN | Loss: 3.0363e-06 | Loss_d: 1.1528e-04 Loss_e: 3.3631e-05 | Loss_b: 3.3004e-05\n",
      "Step: NaN | Loss: 3.0323e-06 | Loss_d: 1.1541e-04 Loss_e: 3.3589e-05 | Loss_b: 3.2680e-05\n",
      "Step: NaN | Loss: 3.0277e-06 | Loss_d: 1.1519e-04 Loss_e: 3.3695e-05 | Loss_b: 3.2520e-05\n",
      "Step: NaN | Loss: 3.0359e-06 | Loss_d: 1.1452e-04 Loss_e: 3.4540e-05 | Loss_b: 3.2836e-05\n",
      "Step: NaN | Loss: 3.0258e-06 | Loss_d: 1.1494e-04 Loss_e: 3.3885e-05 | Loss_b: 3.2459e-05\n",
      "Step: NaN | Loss: 3.0220e-06 | Loss_d: 1.1458e-04 Loss_e: 3.3959e-05 | Loss_b: 3.2527e-05\n",
      "Step: NaN | Loss: 3.0195e-06 | Loss_d: 1.1336e-04 Loss_e: 3.4544e-05 | Loss_b: 3.3012e-05\n",
      "Step: NaN | Loss: 3.0179e-06 | Loss_d: 1.1381e-04 Loss_e: 3.4245e-05 | Loss_b: 3.2755e-05\n",
      "Step: NaN | Loss: 3.0140e-06 | Loss_d: 1.1368e-04 Loss_e: 3.3646e-05 | Loss_b: 3.3254e-05\n",
      "Step: NaN | Loss: 3.0466e-06 | Loss_d: 1.1365e-04 Loss_e: 3.2736e-05 | Loss_b: 3.6146e-05\n",
      "Step: NaN | Loss: 3.0139e-06 | Loss_d: 1.1366e-04 Loss_e: 3.3502e-05 | Loss_b: 3.3415e-05\n",
      "Step: NaN | Loss: 3.0117e-06 | Loss_d: 1.1388e-04 Loss_e: 3.3333e-05 | Loss_b: 3.3232e-05\n",
      "Step: NaN | Loss: 3.0328e-06 | Loss_d: 1.1486e-04 Loss_e: 3.2981e-05 | Loss_b: 3.3869e-05\n",
      "Step: NaN | Loss: 3.0117e-06 | Loss_d: 1.1393e-04 Loss_e: 3.3300e-05 | Loss_b: 3.3211e-05\n",
      "Step: NaN | Loss: 3.0102e-06 | Loss_d: 1.1415e-04 Loss_e: 3.3121e-05 | Loss_b: 3.3085e-05\n",
      "Step: NaN | Loss: 3.0136e-06 | Loss_d: 1.1508e-04 Loss_e: 3.2524e-05 | Loss_b: 3.2956e-05\n",
      "Step: NaN | Loss: 3.0096e-06 | Loss_d: 1.1439e-04 Loss_e: 3.2937e-05 | Loss_b: 3.2989e-05\n",
      "Step: NaN | Loss: 3.0084e-06 | Loss_d: 1.1439e-04 Loss_e: 3.2961e-05 | Loss_b: 3.2894e-05\n",
      "Step: NaN | Loss: 3.0079e-06 | Loss_d: 1.1443e-04 Loss_e: 3.3129e-05 | Loss_b: 3.2658e-05\n",
      "Step: NaN | Loss: 3.0073e-06 | Loss_d: 1.1441e-04 Loss_e: 3.3046e-05 | Loss_b: 3.2726e-05\n",
      "Step: NaN | Loss: 3.0064e-06 | Loss_d: 1.1431e-04 Loss_e: 3.3111e-05 | Loss_b: 3.2704e-05\n",
      "Step: NaN | Loss: 3.0052e-06 | Loss_d: 1.1397e-04 Loss_e: 3.3436e-05 | Loss_b: 3.2654e-05\n",
      "Step: NaN | Loss: 3.0052e-06 | Loss_d: 1.1403e-04 Loss_e: 3.3365e-05 | Loss_b: 3.2660e-05\n",
      "Step: NaN | Loss: 2.9997e-06 | Loss_d: 1.1305e-04 Loss_e: 3.3912e-05 | Loss_b: 3.2762e-05\n",
      "Step: NaN | Loss: 3.0506e-06 | Loss_d: 1.1009e-04 Loss_e: 3.7316e-05 | Loss_b: 3.5364e-05\n",
      "Step: NaN | Loss: 2.9995e-06 | Loss_d: 1.1282e-04 Loss_e: 3.4069e-05 | Loss_b: 3.2823e-05\n",
      "Step: NaN | Loss: 2.9919e-06 | Loss_d: 1.1223e-04 Loss_e: 3.4161e-05 | Loss_b: 3.2870e-05\n",
      "Step: NaN | Loss: 3.0444e-06 | Loss_d: 1.1038e-04 Loss_e: 3.6570e-05 | Loss_b: 3.5454e-05\n",
      "Step: NaN | Loss: 2.9912e-06 | Loss_d: 1.1200e-04 Loss_e: 3.4258e-05 | Loss_b: 3.2957e-05\n",
      "Step: NaN | Loss: 2.9831e-06 | Loss_d: 1.1143e-04 Loss_e: 3.4402e-05 | Loss_b: 3.2902e-05\n",
      "Step: NaN | Loss: 3.0353e-06 | Loss_d: 1.0959e-04 Loss_e: 3.5735e-05 | Loss_b: 3.6532e-05\n",
      "Step: NaN | Loss: 2.9822e-06 | Loss_d: 1.1118e-04 Loss_e: 3.4492e-05 | Loss_b: 3.3005e-05\n",
      "Step: NaN | Loss: 2.9727e-06 | Loss_d: 1.1094e-04 Loss_e: 3.4626e-05 | Loss_b: 3.2547e-05\n",
      "Step: NaN | Loss: 2.9593e-06 | Loss_d: 1.1040e-04 Loss_e: 3.5480e-05 | Loss_b: 3.1426e-05\n",
      "Step: NaN | Loss: 2.9585e-06 | Loss_d: 1.1045e-04 Loss_e: 3.5252e-05 | Loss_b: 3.1552e-05\n",
      "Step: NaN | Loss: 2.9532e-06 | Loss_d: 1.1107e-04 Loss_e: 3.4362e-05 | Loss_b: 3.1505e-05\n",
      "Step: NaN | Loss: 2.9522e-06 | Loss_d: 1.1088e-04 Loss_e: 3.4584e-05 | Loss_b: 3.1412e-05\n",
      "Step: NaN | Loss: 2.9507e-06 | Loss_d: 1.1080e-04 Loss_e: 3.4688e-05 | Loss_b: 3.1300e-05\n",
      "Step: NaN | Loss: 2.9515e-06 | Loss_d: 1.1054e-04 Loss_e: 3.5164e-05 | Loss_b: 3.1132e-05\n",
      "Step: NaN | Loss: 2.9498e-06 | Loss_d: 1.1068e-04 Loss_e: 3.4879e-05 | Loss_b: 3.1173e-05\n",
      "Step: NaN | Loss: 2.9462e-06 | Loss_d: 1.1068e-04 Loss_e: 3.4775e-05 | Loss_b: 3.1068e-05\n",
      "Step: NaN | Loss: 2.9353e-06 | Loss_d: 1.1068e-04 Loss_e: 3.4462e-05 | Loss_b: 3.0726e-05\n",
      "Step: NaN | Loss: 2.9639e-06 | Loss_d: 1.1121e-04 Loss_e: 3.5408e-05 | Loss_b: 3.0966e-05\n",
      "Step: NaN | Loss: 2.9291e-06 | Loss_d: 1.1074e-04 Loss_e: 3.4306e-05 | Loss_b: 3.0445e-05\n",
      "Step: NaN | Loss: 2.9269e-06 | Loss_d: 1.0913e-04 Loss_e: 3.5870e-05 | Loss_b: 3.0368e-05\n",
      "Step: NaN | Loss: 2.9230e-06 | Loss_d: 1.0975e-04 Loss_e: 3.5105e-05 | Loss_b: 3.0278e-05\n",
      "Step: NaN | Loss: 2.9187e-06 | Loss_d: 1.0923e-04 Loss_e: 3.5111e-05 | Loss_b: 3.0528e-05\n",
      "Step: NaN | Loss: 2.9186e-06 | Loss_d: 1.0929e-04 Loss_e: 3.5105e-05 | Loss_b: 3.0476e-05\n",
      "Step: NaN | Loss: 2.9169e-06 | Loss_d: 1.0924e-04 Loss_e: 3.4941e-05 | Loss_b: 3.0582e-05\n",
      "Step: NaN | Loss: 2.9257e-06 | Loss_d: 1.0911e-04 Loss_e: 3.4478e-05 | Loss_b: 3.1700e-05\n",
      "Step: NaN | Loss: 2.9166e-06 | Loss_d: 1.0921e-04 Loss_e: 3.4849e-05 | Loss_b: 3.0683e-05\n",
      "Step: NaN | Loss: 2.9156e-06 | Loss_d: 1.0916e-04 Loss_e: 3.4881e-05 | Loss_b: 3.0639e-05\n",
      "Step: NaN | Loss: 2.9131e-06 | Loss_d: 1.0898e-04 Loss_e: 3.5025e-05 | Loss_b: 3.0532e-05\n",
      "Step: NaN | Loss: 2.9388e-06 | Loss_d: 1.0828e-04 Loss_e: 3.6022e-05 | Loss_b: 3.1769e-05\n",
      "Step: NaN | Loss: 2.9128e-06 | Loss_d: 1.0890e-04 Loss_e: 3.5100e-05 | Loss_b: 3.0521e-05\n",
      "Step: NaN | Loss: 2.9078e-06 | Loss_d: 1.0881e-04 Loss_e: 3.5045e-05 | Loss_b: 3.0364e-05\n",
      "Step: NaN | Loss: 2.8991e-06 | Loss_d: 1.0862e-04 Loss_e: 3.5089e-05 | Loss_b: 2.9987e-05\n",
      "Step: NaN | Loss: 2.8991e-06 | Loss_d: 1.0862e-04 Loss_e: 3.5084e-05 | Loss_b: 2.9990e-05\n",
      "Step: NaN | Loss: 2.8935e-06 | Loss_d: 1.0807e-04 Loss_e: 3.5427e-05 | Loss_b: 2.9868e-05\n",
      "Step: NaN | Loss: 2.9214e-06 | Loss_d: 1.0635e-04 Loss_e: 3.7380e-05 | Loss_b: 3.1305e-05\n",
      "Step: NaN | Loss: 2.8926e-06 | Loss_d: 1.0775e-04 Loss_e: 3.5665e-05 | Loss_b: 2.9888e-05\n",
      "Step: NaN | Loss: 2.8870e-06 | Loss_d: 1.0719e-04 Loss_e: 3.6095e-05 | Loss_b: 2.9691e-05\n",
      "Step: NaN | Loss: 2.8937e-06 | Loss_d: 1.0522e-04 Loss_e: 3.8598e-05 | Loss_b: 2.9553e-05\n",
      "Step: NaN | Loss: 2.8839e-06 | Loss_d: 1.0645e-04 Loss_e: 3.6817e-05 | Loss_b: 2.9517e-05\n",
      "Step: NaN | Loss: 2.8766e-06 | Loss_d: 1.0616e-04 Loss_e: 3.6940e-05 | Loss_b: 2.9242e-05\n",
      "Step: NaN | Loss: 2.9018e-06 | Loss_d: 1.0527e-04 Loss_e: 3.8958e-05 | Loss_b: 2.9631e-05\n",
      "Step: NaN | Loss: 2.8747e-06 | Loss_d: 1.0594e-04 Loss_e: 3.7162e-05 | Loss_b: 2.9128e-05\n",
      "Step: NaN | Loss: 2.8682e-06 | Loss_d: 1.0612e-04 Loss_e: 3.6703e-05 | Loss_b: 2.9027e-05\n",
      "Step: NaN | Loss: 2.9765e-06 | Loss_d: 1.0943e-04 Loss_e: 3.6573e-05 | Loss_b: 3.2337e-05\n",
      "Step: NaN | Loss: 2.8682e-06 | Loss_d: 1.0612e-04 Loss_e: 3.6701e-05 | Loss_b: 2.9029e-05\n",
      "Step: NaN | Loss: 2.8608e-06 | Loss_d: 1.0576e-04 Loss_e: 3.6691e-05 | Loss_b: 2.8956e-05\n",
      "Step: NaN | Loss: 2.8593e-06 | Loss_d: 1.0447e-04 Loss_e: 3.6844e-05 | Loss_b: 3.0002e-05\n",
      "Step: NaN | Loss: 2.8543e-06 | Loss_d: 1.0504e-04 Loss_e: 3.6734e-05 | Loss_b: 2.9242e-05\n",
      "Step: NaN | Loss: 2.8493e-06 | Loss_d: 1.0448e-04 Loss_e: 3.6916e-05 | Loss_b: 2.9311e-05\n",
      "Step: NaN | Loss: 2.8657e-06 | Loss_d: 1.0254e-04 Loss_e: 3.7794e-05 | Loss_b: 3.1364e-05\n",
      "Step: NaN | Loss: 2.8479e-06 | Loss_d: 1.0402e-04 Loss_e: 3.7089e-05 | Loss_b: 2.9523e-05\n",
      "Step: NaN | Loss: 2.8466e-06 | Loss_d: 1.0399e-04 Loss_e: 3.7089e-05 | Loss_b: 2.9470e-05\n",
      "Step: NaN | Loss: 2.8432e-06 | Loss_d: 1.0390e-04 Loss_e: 3.7133e-05 | Loss_b: 2.9320e-05\n",
      "Step: NaN | Loss: 2.8739e-06 | Loss_d: 1.0370e-04 Loss_e: 3.8390e-05 | Loss_b: 3.0094e-05\n",
      "Step: NaN | Loss: 2.8428e-06 | Loss_d: 1.0385e-04 Loss_e: 3.7186e-05 | Loss_b: 2.9283e-05\n",
      "Step: NaN | Loss: 2.8365e-06 | Loss_d: 1.0387e-04 Loss_e: 3.6985e-05 | Loss_b: 2.9095e-05\n",
      "Step: NaN | Loss: 2.8317e-06 | Loss_d: 1.0410e-04 Loss_e: 3.6611e-05 | Loss_b: 2.8951e-05\n",
      "Step: NaN | Loss: 2.8297e-06 | Loss_d: 1.0399e-04 Loss_e: 3.6664e-05 | Loss_b: 2.8892e-05\n",
      "Step: NaN | Loss: 2.8322e-06 | Loss_d: 1.0365e-04 Loss_e: 3.6905e-05 | Loss_b: 2.9132e-05\n",
      "Step: NaN | Loss: 2.8273e-06 | Loss_d: 1.0383e-04 Loss_e: 3.6705e-05 | Loss_b: 2.8856e-05\n",
      "Step: NaN | Loss: 2.8252e-06 | Loss_d: 1.0364e-04 Loss_e: 3.6810e-05 | Loss_b: 2.8822e-05\n",
      "Step: NaN | Loss: 2.8206e-06 | Loss_d: 1.0294e-04 Loss_e: 3.7298e-05 | Loss_b: 2.8759e-05\n",
      "Step: NaN | Loss: 2.8809e-06 | Loss_d: 1.0114e-04 Loss_e: 4.1329e-05 | Loss_b: 3.0133e-05\n",
      "Step: NaN | Loss: 2.8202e-06 | Loss_d: 1.0272e-04 Loss_e: 3.7486e-05 | Loss_b: 2.8762e-05\n",
      "Step: NaN | Loss: 2.8127e-06 | Loss_d: 1.0201e-04 Loss_e: 3.7777e-05 | Loss_b: 2.8727e-05\n",
      "Step: NaN | Loss: 2.8604e-06 | Loss_d: 9.9926e-05 Loss_e: 3.9956e-05 | Loss_b: 3.1497e-05\n",
      "Step: NaN | Loss: 2.8118e-06 | Loss_d: 1.0171e-04 Loss_e: 3.7948e-05 | Loss_b: 2.8815e-05\n",
      "Step: NaN | Loss: 2.8085e-06 | Loss_d: 1.0185e-04 Loss_e: 3.7750e-05 | Loss_b: 2.8665e-05\n",
      "Step: NaN | Loss: 2.8084e-06 | Loss_d: 1.0184e-04 Loss_e: 3.7758e-05 | Loss_b: 2.8663e-05\n",
      "Step: NaN | Loss: 2.8067e-06 | Loss_d: 1.0171e-04 Loss_e: 3.7904e-05 | Loss_b: 2.8543e-05\n",
      "Step: NaN | Loss: 2.8031e-06 | Loss_d: 1.0124e-04 Loss_e: 3.8558e-05 | Loss_b: 2.8149e-05\n",
      "Step: NaN | Loss: 2.9083e-06 | Loss_d: 1.0029e-04 Loss_e: 4.3814e-05 | Loss_b: 3.0149e-05\n",
      "Step: NaN | Loss: 2.8031e-06 | Loss_d: 1.0121e-04 Loss_e: 3.8599e-05 | Loss_b: 2.8132e-05\n",
      "Step: NaN | Loss: 2.7959e-06 | Loss_d: 1.0067e-04 Loss_e: 3.8897e-05 | Loss_b: 2.7946e-05\n",
      "Step: NaN | Loss: 2.7852e-06 | Loss_d: 9.8646e-05 Loss_e: 4.0397e-05 | Loss_b: 2.7830e-05\n",
      "Step: NaN | Loss: 2.7850e-06 | Loss_d: 9.8878e-05 Loss_e: 4.0189e-05 | Loss_b: 2.7793e-05\n",
      "Step: NaN | Loss: 2.7808e-06 | Loss_d: 9.8090e-05 Loss_e: 4.0893e-05 | Loss_b: 2.7625e-05\n",
      "Step: NaN | Loss: 2.8170e-06 | Loss_d: 9.5570e-05 Loss_e: 4.4568e-05 | Loss_b: 2.8642e-05\n",
      "Step: NaN | Loss: 2.7805e-06 | Loss_d: 9.7865e-05 Loss_e: 4.1122e-05 | Loss_b: 2.7605e-05\n",
      "Step: NaN | Loss: 2.7788e-06 | Loss_d: 9.8115e-05 Loss_e: 4.0757e-05 | Loss_b: 2.7617e-05\n",
      "Step: NaN | Loss: 2.7804e-06 | Loss_d: 9.9264e-05 Loss_e: 3.9590e-05 | Loss_b: 2.7730e-05\n",
      "Step: NaN | Loss: 2.7778e-06 | Loss_d: 9.8533e-05 Loss_e: 4.0251e-05 | Loss_b: 2.7645e-05\n",
      "Step: NaN | Loss: 2.7720e-06 | Loss_d: 9.8333e-05 Loss_e: 4.0121e-05 | Loss_b: 2.7629e-05\n",
      "Step: NaN | Loss: 2.7692e-06 | Loss_d: 9.7716e-05 Loss_e: 3.9989e-05 | Loss_b: 2.8211e-05\n",
      "Step: NaN | Loss: 2.7664e-06 | Loss_d: 9.7936e-05 Loss_e: 3.9968e-05 | Loss_b: 2.7842e-05\n",
      "Step: NaN | Loss: 2.7620e-06 | Loss_d: 9.8142e-05 Loss_e: 3.9620e-05 | Loss_b: 2.7720e-05\n",
      "Step: NaN | Loss: 2.8092e-06 | Loss_d: 9.9490e-05 Loss_e: 3.9040e-05 | Loss_b: 2.9785e-05\n",
      "Step: NaN | Loss: 2.7618e-06 | Loss_d: 9.8186e-05 Loss_e: 3.9565e-05 | Loss_b: 2.7723e-05\n",
      "Step: NaN | Loss: 2.7590e-06 | Loss_d: 9.7650e-05 Loss_e: 3.9895e-05 | Loss_b: 2.7757e-05\n",
      "Step: NaN | Loss: 2.7721e-06 | Loss_d: 9.5720e-05 Loss_e: 4.1512e-05 | Loss_b: 2.8856e-05\n",
      "Step: NaN | Loss: 2.7585e-06 | Loss_d: 9.7306e-05 Loss_e: 4.0131e-05 | Loss_b: 2.7836e-05\n",
      "Step: NaN | Loss: 2.7558e-06 | Loss_d: 9.7335e-05 Loss_e: 3.9955e-05 | Loss_b: 2.7822e-05\n",
      "Step: NaN | Loss: 2.7578e-06 | Loss_d: 9.7518e-05 Loss_e: 3.9468e-05 | Loss_b: 2.8246e-05\n",
      "Step: NaN | Loss: 2.7542e-06 | Loss_d: 9.7396e-05 Loss_e: 3.9717e-05 | Loss_b: 2.7902e-05\n",
      "Step: NaN | Loss: 2.7489e-06 | Loss_d: 9.7573e-05 Loss_e: 3.9180e-05 | Loss_b: 2.7943e-05\n",
      "Step: NaN | Loss: 2.7511e-06 | Loss_d: 9.8549e-05 Loss_e: 3.7384e-05 | Loss_b: 2.8900e-05\n",
      "Step: NaN | Loss: 2.7452e-06 | Loss_d: 9.7950e-05 Loss_e: 3.8322e-05 | Loss_b: 2.8206e-05\n",
      "Step: NaN | Loss: 2.7369e-06 | Loss_d: 9.6892e-05 Loss_e: 3.8637e-05 | Loss_b: 2.8452e-05\n",
      "Step: NaN | Loss: 2.7828e-06 | Loss_d: 9.3220e-05 Loss_e: 4.2285e-05 | Loss_b: 3.1223e-05\n",
      "Step: NaN | Loss: 2.7357e-06 | Loss_d: 9.6336e-05 Loss_e: 3.8910e-05 | Loss_b: 2.8662e-05\n",
      "Step: NaN | Loss: 2.7229e-06 | Loss_d: 9.5962e-05 Loss_e: 3.9546e-05 | Loss_b: 2.7632e-05\n",
      "Step: NaN | Loss: 2.8851e-06 | Loss_d: 9.6306e-05 Loss_e: 4.7513e-05 | Loss_b: 2.9039e-05\n",
      "Step: NaN | Loss: 2.7227e-06 | Loss_d: 9.5930e-05 Loss_e: 3.9649e-05 | Loss_b: 2.7552e-05\n",
      "Step: NaN | Loss: 2.7128e-06 | Loss_d: 9.5893e-05 Loss_e: 3.9309e-05 | Loss_b: 2.7330e-05\n",
      "Step: NaN | Loss: 2.7186e-06 | Loss_d: 9.6337e-05 Loss_e: 3.8489e-05 | Loss_b: 2.8058e-05\n",
      "Step: NaN | Loss: 2.7063e-06 | Loss_d: 9.5965e-05 Loss_e: 3.8860e-05 | Loss_b: 2.7323e-05\n",
      "Step: NaN | Loss: 2.6813e-06 | Loss_d: 9.5427e-05 Loss_e: 3.8713e-05 | Loss_b: 2.6510e-05\n",
      "Step: NaN | Loss: 2.7370e-06 | Loss_d: 9.5373e-05 Loss_e: 4.0967e-05 | Loss_b: 2.7646e-05\n",
      "Step: NaN | Loss: 2.6715e-06 | Loss_d: 9.5080e-05 Loss_e: 3.8877e-05 | Loss_b: 2.6106e-05\n",
      "Step: NaN | Loss: 2.6582e-06 | Loss_d: 9.4878e-05 Loss_e: 3.9163e-05 | Loss_b: 2.5223e-05\n",
      "Step: NaN | Loss: 2.8627e-06 | Loss_d: 9.6177e-05 Loss_e: 4.3830e-05 | Loss_b: 3.1510e-05\n",
      "Step: NaN | Loss: 2.6579e-06 | Loss_d: 9.4866e-05 Loss_e: 3.9222e-05 | Loss_b: 2.5156e-05\n",
      "Step: NaN | Loss: 2.6534e-06 | Loss_d: 9.5393e-05 Loss_e: 3.8843e-05 | Loss_b: 2.4741e-05\n",
      "Step: NaN | Loss: 2.7141e-06 | Loss_d: 9.8409e-05 Loss_e: 3.8361e-05 | Loss_b: 2.5847e-05\n",
      "Step: NaN | Loss: 2.6534e-06 | Loss_d: 9.5430e-05 Loss_e: 3.8823e-05 | Loss_b: 2.4725e-05\n",
      "Step: NaN | Loss: 2.6519e-06 | Loss_d: 9.5180e-05 Loss_e: 3.9055e-05 | Loss_b: 2.4648e-05\n",
      "Step: NaN | Loss: 2.6550e-06 | Loss_d: 9.4290e-05 Loss_e: 4.0103e-05 | Loss_b: 2.4678e-05\n",
      "Step: NaN | Loss: 2.6512e-06 | Loss_d: 9.4901e-05 Loss_e: 3.9342e-05 | Loss_b: 2.4600e-05\n",
      "Step: NaN | Loss: 2.6496e-06 | Loss_d: 9.4799e-05 Loss_e: 3.9308e-05 | Loss_b: 2.4642e-05\n",
      "Step: NaN | Loss: 2.6461e-06 | Loss_d: 9.4431e-05 Loss_e: 3.9201e-05 | Loss_b: 2.4905e-05\n",
      "Step: NaN | Loss: 2.6941e-06 | Loss_d: 9.3595e-05 Loss_e: 3.9417e-05 | Loss_b: 2.8404e-05\n",
      "Step: NaN | Loss: 2.6458e-06 | Loss_d: 9.4330e-05 Loss_e: 3.9178e-05 | Loss_b: 2.5014e-05\n",
      "Step: NaN | Loss: 2.6414e-06 | Loss_d: 9.4297e-05 Loss_e: 3.9126e-05 | Loss_b: 2.4837e-05\n",
      "Step: NaN | Loss: 2.6399e-06 | Loss_d: 9.4388e-05 Loss_e: 3.9227e-05 | Loss_b: 2.4551e-05\n",
      "Step: NaN | Loss: 2.6374e-06 | Loss_d: 9.4304e-05 Loss_e: 3.9121e-05 | Loss_b: 2.4591e-05\n",
      "Step: NaN | Loss: 2.6351e-06 | Loss_d: 9.4769e-05 Loss_e: 3.8199e-05 | Loss_b: 2.4914e-05\n",
      "Step: NaN | Loss: 2.6348e-06 | Loss_d: 9.4632e-05 Loss_e: 3.8423e-05 | Loss_b: 2.4807e-05\n",
      "Step: NaN | Loss: 2.6312e-06 | Loss_d: 9.4566e-05 Loss_e: 3.8280e-05 | Loss_b: 2.4798e-05\n",
      "Step: NaN | Loss: 2.6243e-06 | Loss_d: 9.4352e-05 Loss_e: 3.7745e-05 | Loss_b: 2.5134e-05\n",
      "Step: NaN | Loss: 2.7713e-06 | Loss_d: 9.4449e-05 Loss_e: 3.5901e-05 | Loss_b: 3.5691e-05\n",
      "Step: NaN | Loss: 2.6243e-06 | Loss_d: 9.4340e-05 Loss_e: 3.7710e-05 | Loss_b: 2.5181e-05\n",
      "Step: NaN | Loss: 2.6174e-06 | Loss_d: 9.3445e-05 Loss_e: 3.8114e-05 | Loss_b: 2.5263e-05\n",
      "Step: NaN | Loss: 2.6306e-06 | Loss_d: 9.0629e-05 Loss_e: 4.0371e-05 | Loss_b: 2.6609e-05\n",
      "Step: NaN | Loss: 2.6146e-06 | Loss_d: 9.2488e-05 Loss_e: 3.8671e-05 | Loss_b: 2.5491e-05\n",
      "Step: NaN | Loss: 2.6105e-06 | Loss_d: 9.2341e-05 Loss_e: 3.8427e-05 | Loss_b: 2.5636e-05\n",
      "Step: NaN | Loss: 2.6145e-06 | Loss_d: 9.1879e-05 Loss_e: 3.7801e-05 | Loss_b: 2.6966e-05\n",
      "Step: NaN | Loss: 2.6082e-06 | Loss_d: 9.2144e-05 Loss_e: 3.8126e-05 | Loss_b: 2.5998e-05\n",
      "Step: NaN | Loss: 2.5989e-06 | Loss_d: 9.1722e-05 Loss_e: 3.7800e-05 | Loss_b: 2.6190e-05\n",
      "Step: NaN | Loss: 2.6454e-06 | Loss_d: 9.0367e-05 Loss_e: 3.8083e-05 | Loss_b: 3.0044e-05\n",
      "Step: NaN | Loss: 2.5973e-06 | Loss_d: 9.1480e-05 Loss_e: 3.7679e-05 | Loss_b: 2.6458e-05\n",
      "Step: NaN | Loss: 2.5834e-06 | Loss_d: 9.1072e-05 Loss_e: 3.7593e-05 | Loss_b: 2.6117e-05\n",
      "Step: NaN | Loss: 2.6054e-06 | Loss_d: 8.9913e-05 Loss_e: 3.9277e-05 | Loss_b: 2.6909e-05\n",
      "Step: NaN | Loss: 2.5769e-06 | Loss_d: 9.0615e-05 Loss_e: 3.7784e-05 | Loss_b: 2.5994e-05\n",
      "Step: NaN | Loss: 2.5687e-06 | Loss_d: 9.0337e-05 Loss_e: 3.7727e-05 | Loss_b: 2.5839e-05\n",
      "Step: NaN | Loss: 2.5642e-06 | Loss_d: 8.9515e-05 Loss_e: 3.8196e-05 | Loss_b: 2.5924e-05\n",
      "Step: NaN | Loss: 2.5606e-06 | Loss_d: 8.9785e-05 Loss_e: 3.7875e-05 | Loss_b: 2.5759e-05\n",
      "Step: NaN | Loss: 2.5470e-06 | Loss_d: 8.8499e-05 Loss_e: 3.7674e-05 | Loss_b: 2.6427e-05\n",
      "Step: NaN | Loss: 2.6159e-06 | Loss_d: 8.4233e-05 Loss_e: 3.9184e-05 | Loss_b: 3.3313e-05\n",
      "Step: NaN | Loss: 2.5446e-06 | Loss_d: 8.7763e-05 Loss_e: 3.7665e-05 | Loss_b: 2.7031e-05\n",
      "Step: NaN | Loss: 2.5363e-06 | Loss_d: 8.7902e-05 Loss_e: 3.6862e-05 | Loss_b: 2.7195e-05\n",
      "Step: NaN | Loss: 2.5349e-06 | Loss_d: 8.7796e-05 Loss_e: 3.7007e-05 | Loss_b: 2.7073e-05\n",
      "Step: NaN | Loss: 2.5341e-06 | Loss_d: 8.7928e-05 Loss_e: 3.7033e-05 | Loss_b: 2.6865e-05\n",
      "Step: NaN | Loss: 2.5339e-06 | Loss_d: 8.7887e-05 Loss_e: 3.7020e-05 | Loss_b: 2.6910e-05\n",
      "Step: NaN | Loss: 2.5332e-06 | Loss_d: 8.7738e-05 Loss_e: 3.7065e-05 | Loss_b: 2.6971e-05\n",
      "Step: NaN | Loss: 2.5324e-06 | Loss_d: 8.7161e-05 Loss_e: 3.7286e-05 | Loss_b: 2.7278e-05\n",
      "Step: NaN | Loss: 2.5323e-06 | Loss_d: 8.7308e-05 Loss_e: 3.7223e-05 | Loss_b: 2.7189e-05\n",
      "Step: NaN | Loss: 2.5292e-06 | Loss_d: 8.7084e-05 Loss_e: 3.7329e-05 | Loss_b: 2.7124e-05\n",
      "Step: NaN | Loss: 2.5198e-06 | Loss_d: 8.6241e-05 Loss_e: 3.7795e-05 | Loss_b: 2.6934e-05\n",
      "Step: NaN | Loss: 2.5364e-06 | Loss_d: 8.3272e-05 Loss_e: 4.1028e-05 | Loss_b: 2.7666e-05\n",
      "Step: NaN | Loss: 2.5134e-06 | Loss_d: 8.4996e-05 Loss_e: 3.8729e-05 | Loss_b: 2.6861e-05\n",
      "Step: NaN | Loss: 2.5264e-06 | Loss_d: 8.3460e-05 Loss_e: 3.8819e-05 | Loss_b: 2.9090e-05\n",
      "Step: NaN | Loss: 2.5107e-06 | Loss_d: 8.4522e-05 Loss_e: 3.8711e-05 | Loss_b: 2.7195e-05\n",
      "Step: NaN | Loss: 2.5076e-06 | Loss_d: 8.4107e-05 Loss_e: 3.8600e-05 | Loss_b: 2.7532e-05\n",
      "Step: NaN | Loss: 2.5258e-06 | Loss_d: 8.2727e-05 Loss_e: 3.8702e-05 | Loss_b: 2.9904e-05\n",
      "Step: NaN | Loss: 2.5072e-06 | Loss_d: 8.3905e-05 Loss_e: 3.8565e-05 | Loss_b: 2.7745e-05\n",
      "Step: NaN | Loss: 2.5060e-06 | Loss_d: 8.3730e-05 Loss_e: 3.8572e-05 | Loss_b: 2.7845e-05\n",
      "Step: NaN | Loss: 2.5136e-06 | Loss_d: 8.3104e-05 Loss_e: 3.8683e-05 | Loss_b: 2.8812e-05\n",
      "Step: NaN | Loss: 2.5059e-06 | Loss_d: 8.3653e-05 Loss_e: 3.8577e-05 | Loss_b: 2.7908e-05\n",
      "Step: NaN | Loss: 2.5055e-06 | Loss_d: 8.3699e-05 Loss_e: 3.8531e-05 | Loss_b: 2.7883e-05\n",
      "Step: NaN | Loss: 2.5049e-06 | Loss_d: 8.3887e-05 Loss_e: 3.8368e-05 | Loss_b: 2.7821e-05\n",
      "Step: NaN | Loss: 2.5048e-06 | Loss_d: 8.3858e-05 Loss_e: 3.8391e-05 | Loss_b: 2.7826e-05\n",
      "Step: NaN | Loss: 2.5038e-06 | Loss_d: 8.3807e-05 Loss_e: 3.8420e-05 | Loss_b: 2.7783e-05\n",
      "Step: NaN | Loss: 2.5021e-06 | Loss_d: 8.3617e-05 Loss_e: 3.8576e-05 | Loss_b: 2.7718e-05\n",
      "Step: NaN | Loss: 2.5021e-06 | Loss_d: 8.3637e-05 Loss_e: 3.8555e-05 | Loss_b: 2.7717e-05\n",
      "Step: NaN | Loss: 2.4996e-06 | Loss_d: 8.3513e-05 Loss_e: 3.8645e-05 | Loss_b: 2.7602e-05\n",
      "Step: NaN | Loss: 2.5050e-06 | Loss_d: 8.3092e-05 Loss_e: 3.9153e-05 | Loss_b: 2.7842e-05\n",
      "Step: NaN | Loss: 2.4986e-06 | Loss_d: 8.3383e-05 Loss_e: 3.8764e-05 | Loss_b: 2.7553e-05\n",
      "Step: NaN | Loss: 2.4959e-06 | Loss_d: 8.3452e-05 Loss_e: 3.8642e-05 | Loss_b: 2.7445e-05\n",
      "Step: NaN | Loss: 2.5170e-06 | Loss_d: 8.4190e-05 Loss_e: 3.8699e-05 | Loss_b: 2.7912e-05\n",
      "Step: NaN | Loss: 2.4957e-06 | Loss_d: 8.3488e-05 Loss_e: 3.8612e-05 | Loss_b: 2.7427e-05\n",
      "Step: NaN | Loss: 2.4935e-06 | Loss_d: 8.3477e-05 Loss_e: 3.8655e-05 | Loss_b: 2.7263e-05\n",
      "Step: NaN | Loss: 2.4967e-06 | Loss_d: 8.3659e-05 Loss_e: 3.8969e-05 | Loss_b: 2.6958e-05\n",
      "Step: NaN | Loss: 2.4924e-06 | Loss_d: 8.3498e-05 Loss_e: 3.8734e-05 | Loss_b: 2.7101e-05\n",
      "Step: NaN | Loss: 2.4898e-06 | Loss_d: 8.3106e-05 Loss_e: 3.8877e-05 | Loss_b: 2.7194e-05\n",
      "Step: NaN | Loss: 2.4913e-06 | Loss_d: 8.1699e-05 Loss_e: 3.9851e-05 | Loss_b: 2.7715e-05\n",
      "Step: NaN | Loss: 2.4882e-06 | Loss_d: 8.2479e-05 Loss_e: 3.9211e-05 | Loss_b: 2.7388e-05\n",
      "Step: NaN | Loss: 2.4857e-06 | Loss_d: 8.2632e-05 Loss_e: 3.9133e-05 | Loss_b: 2.7162e-05\n",
      "Step: NaN | Loss: 2.5199e-06 | Loss_d: 8.3734e-05 Loss_e: 3.9424e-05 | Loss_b: 2.7818e-05\n",
      "Step: NaN | Loss: 2.4857e-06 | Loss_d: 8.2644e-05 Loss_e: 3.9130e-05 | Loss_b: 2.7153e-05\n",
      "Step: NaN | Loss: 2.4842e-06 | Loss_d: 8.2582e-05 Loss_e: 3.9132e-05 | Loss_b: 2.7127e-05\n",
      "Step: NaN | Loss: 2.4851e-06 | Loss_d: 8.2387e-05 Loss_e: 3.9273e-05 | Loss_b: 2.7232e-05\n",
      "Step: NaN | Loss: 2.4833e-06 | Loss_d: 8.2490e-05 Loss_e: 3.9164e-05 | Loss_b: 2.7128e-05\n",
      "Step: NaN | Loss: 2.4818e-06 | Loss_d: 8.2450e-05 Loss_e: 3.9125e-05 | Loss_b: 2.7120e-05\n",
      "Step: NaN | Loss: 2.4849e-06 | Loss_d: 8.2350e-05 Loss_e: 3.9096e-05 | Loss_b: 2.7435e-05\n",
      "Step: NaN | Loss: 2.4812e-06 | Loss_d: 8.2412e-05 Loss_e: 3.9097e-05 | Loss_b: 2.7153e-05\n",
      "Step: NaN | Loss: 2.4805e-06 | Loss_d: 8.2384e-05 Loss_e: 3.9058e-05 | Loss_b: 2.7175e-05\n",
      "Step: NaN | Loss: 2.4790e-06 | Loss_d: 8.2281e-05 Loss_e: 3.8911e-05 | Loss_b: 2.7333e-05\n",
      "Step: NaN | Loss: 2.5049e-06 | Loss_d: 8.1950e-05 Loss_e: 3.8320e-05 | Loss_b: 2.9807e-05\n",
      "Step: NaN | Loss: 2.4789e-06 | Loss_d: 8.2263e-05 Loss_e: 3.8883e-05 | Loss_b: 2.7376e-05\n",
      "Step: NaN | Loss: 2.4770e-06 | Loss_d: 8.2113e-05 Loss_e: 3.8794e-05 | Loss_b: 2.7502e-05\n",
      "Step: NaN | Loss: 2.4921e-06 | Loss_d: 8.1753e-05 Loss_e: 3.8727e-05 | Loss_b: 2.8831e-05\n",
      "Step: NaN | Loss: 2.4769e-06 | Loss_d: 8.2068e-05 Loss_e: 3.8772e-05 | Loss_b: 2.7563e-05\n",
      "Step: NaN | Loss: 2.4759e-06 | Loss_d: 8.2295e-05 Loss_e: 3.8592e-05 | Loss_b: 2.7455e-05\n",
      "Step: NaN | Loss: 2.4853e-06 | Loss_d: 8.3332e-05 Loss_e: 3.8175e-05 | Loss_b: 2.7399e-05\n",
      "Step: NaN | Loss: 2.4758e-06 | Loss_d: 8.2352e-05 Loss_e: 3.8553e-05 | Loss_b: 2.7433e-05\n",
      "Step: NaN | Loss: 2.4749e-06 | Loss_d: 8.2328e-05 Loss_e: 3.8570e-05 | Loss_b: 2.7384e-05\n",
      "Step: NaN | Loss: 2.4728e-06 | Loss_d: 8.2253e-05 Loss_e: 3.8670e-05 | Loss_b: 2.7231e-05\n",
      "Step: NaN | Loss: 2.5004e-06 | Loss_d: 8.2405e-05 Loss_e: 3.9899e-05 | Loss_b: 2.7505e-05\n",
      "Step: NaN | Loss: 2.4726e-06 | Loss_d: 8.2235e-05 Loss_e: 3.8715e-05 | Loss_b: 2.7196e-05\n",
      "Step: NaN | Loss: 2.4694e-06 | Loss_d: 8.2194e-05 Loss_e: 3.8713e-05 | Loss_b: 2.7043e-05\n",
      "Step: NaN | Loss: 2.4756e-06 | Loss_d: 8.2165e-05 Loss_e: 3.9260e-05 | Loss_b: 2.6898e-05\n",
      "Step: NaN | Loss: 2.4680e-06 | Loss_d: 8.2163e-05 Loss_e: 3.8782e-05 | Loss_b: 2.6922e-05\n",
      "Step: NaN | Loss: 2.4668e-06 | Loss_d: 8.2286e-05 Loss_e: 3.8706e-05 | Loss_b: 2.6804e-05\n",
      "Step: NaN | Loss: 2.4748e-06 | Loss_d: 8.2845e-05 Loss_e: 3.8550e-05 | Loss_b: 2.6880e-05\n",
      "Step: NaN | Loss: 2.4667e-06 | Loss_d: 8.2340e-05 Loss_e: 3.8678e-05 | Loss_b: 2.6770e-05\n",
      "Step: NaN | Loss: 2.4660e-06 | Loss_d: 8.2340e-05 Loss_e: 3.8685e-05 | Loss_b: 2.6725e-05\n",
      "Step: NaN | Loss: 2.4641e-06 | Loss_d: 8.2346e-05 Loss_e: 3.8722e-05 | Loss_b: 2.6567e-05\n",
      "Step: NaN | Loss: 2.4713e-06 | Loss_d: 8.2592e-05 Loss_e: 3.9145e-05 | Loss_b: 2.6326e-05\n",
      "Step: NaN | Loss: 2.4633e-06 | Loss_d: 8.2373e-05 Loss_e: 3.8788e-05 | Loss_b: 2.6426e-05\n",
      "Step: NaN | Loss: 2.4595e-06 | Loss_d: 8.2011e-05 Loss_e: 3.8910e-05 | Loss_b: 2.6439e-05\n",
      "Step: NaN | Loss: 2.4512e-06 | Loss_d: 8.0670e-05 Loss_e: 3.9537e-05 | Loss_b: 2.6658e-05\n",
      "Step: NaN | Loss: 2.5709e-06 | Loss_d: 7.6631e-05 Loss_e: 4.5905e-05 | Loss_b: 3.1500e-05\n",
      "Step: NaN | Loss: 2.4508e-06 | Loss_d: 8.0337e-05 Loss_e: 3.9744e-05 | Loss_b: 2.6760e-05\n",
      "Step: NaN | Loss: 2.4381e-06 | Loss_d: 7.9921e-05 Loss_e: 3.9631e-05 | Loss_b: 2.6523e-05\n",
      "Step: NaN | Loss: 2.4790e-06 | Loss_d: 7.9187e-05 Loss_e: 4.0783e-05 | Loss_b: 2.8557e-05\n",
      "Step: NaN | Loss: 2.4344e-06 | Loss_d: 7.9630e-05 Loss_e: 3.9667e-05 | Loss_b: 2.6556e-05\n",
      "Step: NaN | Loss: 2.4311e-06 | Loss_d: 7.9466e-05 Loss_e: 4.0123e-05 | Loss_b: 2.6070e-05\n",
      "Step: NaN | Loss: 2.4307e-06 | Loss_d: 7.9498e-05 Loss_e: 3.9967e-05 | Loss_b: 2.6167e-05\n",
      "Step: NaN | Loss: 2.4288e-06 | Loss_d: 7.9503e-05 Loss_e: 3.9908e-05 | Loss_b: 2.6107e-05\n",
      "Step: NaN | Loss: 2.4285e-06 | Loss_d: 7.9498e-05 Loss_e: 3.9915e-05 | Loss_b: 2.6088e-05\n",
      "Step: NaN | Loss: 2.4270e-06 | Loss_d: 7.9490e-05 Loss_e: 3.9854e-05 | Loss_b: 2.6066e-05\n",
      "Step: NaN | Loss: 2.4221e-06 | Loss_d: 7.9464e-05 Loss_e: 3.9625e-05 | Loss_b: 2.6029e-05\n",
      "Step: NaN | Loss: 2.4264e-06 | Loss_d: 7.9488e-05 Loss_e: 3.8795e-05 | Loss_b: 2.7092e-05\n",
      "Step: NaN | Loss: 2.4181e-06 | Loss_d: 7.9443e-05 Loss_e: 3.9221e-05 | Loss_b: 2.6212e-05\n",
      "Step: NaN | Loss: 2.4067e-06 | Loss_d: 7.9318e-05 Loss_e: 3.8807e-05 | Loss_b: 2.6069e-05\n",
      "Step: NaN | Loss: 2.5055e-06 | Loss_d: 7.9627e-05 Loss_e: 3.8942e-05 | Loss_b: 3.1547e-05\n",
      "Step: NaN | Loss: 2.4060e-06 | Loss_d: 7.9296e-05 Loss_e: 3.8719e-05 | Loss_b: 2.6139e-05\n",
      "Step: NaN | Loss: 2.3869e-06 | Loss_d: 8.0084e-05 Loss_e: 3.7636e-05 | Loss_b: 2.5292e-05\n",
      "Step: NaN | Loss: 2.5589e-06 | Loss_d: 8.5722e-05 Loss_e: 3.9224e-05 | Loss_b: 2.8369e-05\n",
      "Step: NaN | Loss: 2.3859e-06 | Loss_d: 8.0335e-05 Loss_e: 3.7450e-05 | Loss_b: 2.5165e-05\n",
      "Step: NaN | Loss: 2.3834e-06 | Loss_d: 8.0232e-05 Loss_e: 3.7570e-05 | Loss_b: 2.4997e-05\n",
      "Step: NaN | Loss: 2.3837e-06 | Loss_d: 7.9858e-05 Loss_e: 3.8269e-05 | Loss_b: 2.4688e-05\n",
      "Step: NaN | Loss: 2.3814e-06 | Loss_d: 8.0045e-05 Loss_e: 3.7861e-05 | Loss_b: 2.4775e-05\n",
      "Step: NaN | Loss: 2.3785e-06 | Loss_d: 8.0044e-05 Loss_e: 3.7845e-05 | Loss_b: 2.4620e-05\n",
      "Step: NaN | Loss: 2.3771e-06 | Loss_d: 8.0261e-05 Loss_e: 3.7967e-05 | Loss_b: 2.4193e-05\n",
      "Step: NaN | Loss: 2.3757e-06 | Loss_d: 8.0129e-05 Loss_e: 3.7881e-05 | Loss_b: 2.4329e-05\n",
      "Step: NaN | Loss: 2.3741e-06 | Loss_d: 8.0026e-05 Loss_e: 3.8009e-05 | Loss_b: 2.4207e-05\n",
      "Step: NaN | Loss: 2.3734e-06 | Loss_d: 7.9658e-05 Loss_e: 3.8603e-05 | Loss_b: 2.3936e-05\n",
      "Step: NaN | Loss: 2.3726e-06 | Loss_d: 7.9801e-05 Loss_e: 3.8341e-05 | Loss_b: 2.4008e-05\n",
      "Step: NaN | Loss: 2.3673e-06 | Loss_d: 7.9664e-05 Loss_e: 3.8241e-05 | Loss_b: 2.3932e-05\n",
      "Step: NaN | Loss: 2.3605e-06 | Loss_d: 7.9200e-05 Loss_e: 3.8104e-05 | Loss_b: 2.4123e-05\n",
      "Step: NaN | Loss: 2.3601e-06 | Loss_d: 7.9281e-05 Loss_e: 3.8097e-05 | Loss_b: 2.4023e-05\n",
      "Step: NaN | Loss: 2.3519e-06 | Loss_d: 7.8625e-05 Loss_e: 3.8013e-05 | Loss_b: 2.4272e-05\n",
      "Step: NaN | Loss: 2.3515e-06 | Loss_d: 7.8713e-05 Loss_e: 3.7960e-05 | Loss_b: 2.4217e-05\n",
      "Step: NaN | Loss: 2.3518e-06 | Loss_d: 7.9107e-05 Loss_e: 3.8270e-05 | Loss_b: 2.3528e-05\n",
      "Step: NaN | Loss: 2.3487e-06 | Loss_d: 7.8875e-05 Loss_e: 3.8059e-05 | Loss_b: 2.3787e-05\n",
      "Step: NaN | Loss: 2.3473e-06 | Loss_d: 7.8836e-05 Loss_e: 3.8071e-05 | Loss_b: 2.3731e-05\n",
      "Step: NaN | Loss: 2.3428e-06 | Loss_d: 7.8690e-05 Loss_e: 3.8131e-05 | Loss_b: 2.3548e-05\n",
      "Step: NaN | Loss: 2.3449e-06 | Loss_d: 7.8243e-05 Loss_e: 3.8702e-05 | Loss_b: 2.3550e-05\n",
      "Step: NaN | Loss: 2.3386e-06 | Loss_d: 7.8435e-05 Loss_e: 3.8325e-05 | Loss_b: 2.3356e-05\n",
      "Step: NaN | Loss: 2.3299e-06 | Loss_d: 7.8400e-05 Loss_e: 3.7845e-05 | Loss_b: 2.3348e-05\n",
      "Step: NaN | Loss: 2.3491e-06 | Loss_d: 7.8886e-05 Loss_e: 3.7321e-05 | Loss_b: 2.4535e-05\n",
      "Step: NaN | Loss: 2.3266e-06 | Loss_d: 7.8435e-05 Loss_e: 3.7474e-05 | Loss_b: 2.3489e-05\n",
      "Step: NaN | Loss: 2.3220e-06 | Loss_d: 7.8357e-05 Loss_e: 3.7477e-05 | Loss_b: 2.3288e-05\n",
      "Step: NaN | Loss: 2.3245e-06 | Loss_d: 7.8125e-05 Loss_e: 3.7623e-05 | Loss_b: 2.3521e-05\n",
      "Step: NaN | Loss: 2.3190e-06 | Loss_d: 7.8241e-05 Loss_e: 3.7513e-05 | Loss_b: 2.3186e-05\n",
      "Step: NaN | Loss: 2.3116e-06 | Loss_d: 7.7972e-05 Loss_e: 3.7420e-05 | Loss_b: 2.3106e-05\n",
      "Step: NaN | Loss: 2.2885e-06 | Loss_d: 7.7076e-05 Loss_e: 3.7144e-05 | Loss_b: 2.2891e-05\n",
      "Step: NaN | Loss: 2.3313e-06 | Loss_d: 7.6872e-05 Loss_e: 3.7776e-05 | Loss_b: 2.5028e-05\n",
      "Step: NaN | Loss: 2.2727e-06 | Loss_d: 7.6229e-05 Loss_e: 3.7008e-05 | Loss_b: 2.2930e-05\n",
      "Step: NaN | Loss: 2.2606e-06 | Loss_d: 7.5226e-05 Loss_e: 3.7240e-05 | Loss_b: 2.2977e-05\n",
      "Step: NaN | Loss: 2.4427e-06 | Loss_d: 7.2406e-05 Loss_e: 3.8905e-05 | Loss_b: 3.5040e-05\n",
      "Step: NaN | Loss: 2.2606e-06 | Loss_d: 7.5217e-05 Loss_e: 3.7242e-05 | Loss_b: 2.2985e-05\n",
      "Step: NaN | Loss: 2.2546e-06 | Loss_d: 7.4583e-05 Loss_e: 3.7443e-05 | Loss_b: 2.3053e-05\n",
      "Step: NaN | Loss: 2.3080e-06 | Loss_d: 7.3043e-05 Loss_e: 3.9389e-05 | Loss_b: 2.5852e-05\n",
      "Step: NaN | Loss: 2.2542e-06 | Loss_d: 7.4420e-05 Loss_e: 3.7522e-05 | Loss_b: 2.3117e-05\n",
      "Step: NaN | Loss: 2.2518e-06 | Loss_d: 7.4081e-05 Loss_e: 3.8163e-05 | Loss_b: 2.2670e-05\n",
      "Step: NaN | Loss: 2.2502e-06 | Loss_d: 7.4184e-05 Loss_e: 3.7878e-05 | Loss_b: 2.2756e-05\n",
      "Step: NaN | Loss: 2.2475e-06 | Loss_d: 7.3953e-05 Loss_e: 3.7949e-05 | Loss_b: 2.2754e-05\n",
      "Step: NaN | Loss: 2.2436e-06 | Loss_d: 7.3087e-05 Loss_e: 3.8343e-05 | Loss_b: 2.2992e-05\n",
      "Step: NaN | Loss: 2.2435e-06 | Loss_d: 7.3204e-05 Loss_e: 3.8277e-05 | Loss_b: 2.2935e-05\n",
      "Step: NaN | Loss: 2.2370e-06 | Loss_d: 7.2849e-05 Loss_e: 3.8223e-05 | Loss_b: 2.2954e-05\n",
      "Step: NaN | Loss: 2.2251e-06 | Loss_d: 7.1665e-05 Loss_e: 3.8335e-05 | Loss_b: 2.3316e-05\n",
      "Step: NaN | Loss: 2.5069e-06 | Loss_d: 7.1204e-05 Loss_e: 4.6507e-05 | Loss_b: 3.2488e-05\n",
      "Step: NaN | Loss: 2.2252e-06 | Loss_d: 7.1641e-05 Loss_e: 3.8344e-05 | Loss_b: 2.3333e-05\n",
      "Step: NaN | Loss: 2.2141e-06 | Loss_d: 7.0957e-05 Loss_e: 3.9125e-05 | Loss_b: 2.2574e-05\n",
      "Step: NaN | Loss: 2.3942e-06 | Loss_d: 7.1891e-05 Loss_e: 4.7303e-05 | Loss_b: 2.4250e-05\n",
      "Step: NaN | Loss: 2.2139e-06 | Loss_d: 7.0905e-05 Loss_e: 3.9232e-05 | Loss_b: 2.2506e-05\n",
      "Step: NaN | Loss: 2.2056e-06 | Loss_d: 7.0920e-05 Loss_e: 3.9117e-05 | Loss_b: 2.2110e-05\n",
      "Step: NaN | Loss: 2.2390e-06 | Loss_d: 7.1829e-05 Loss_e: 3.9405e-05 | Loss_b: 2.2916e-05\n",
      "Step: NaN | Loss: 2.2038e-06 | Loss_d: 7.0987e-05 Loss_e: 3.9081e-05 | Loss_b: 2.1969e-05\n",
      "Step: NaN | Loss: 2.1949e-06 | Loss_d: 7.0592e-05 Loss_e: 3.8919e-05 | Loss_b: 2.1993e-05\n",
      "Step: NaN | Loss: 2.1842e-06 | Loss_d: 6.9397e-05 Loss_e: 3.8709e-05 | Loss_b: 2.2761e-05\n",
      "Step: NaN | Loss: 2.1829e-06 | Loss_d: 6.9651e-05 Loss_e: 3.8697e-05 | Loss_b: 2.2441e-05\n",
      "Step: NaN | Loss: 2.1722e-06 | Loss_d: 6.9335e-05 Loss_e: 3.8410e-05 | Loss_b: 2.2401e-05\n",
      "Step: NaN | Loss: 2.2529e-06 | Loss_d: 6.9303e-05 Loss_e: 3.9705e-05 | Loss_b: 2.5972e-05\n",
      "Step: NaN | Loss: 2.1714e-06 | Loss_d: 6.9251e-05 Loss_e: 3.8366e-05 | Loss_b: 2.2479e-05\n",
      "Step: NaN | Loss: 2.1655e-06 | Loss_d: 6.9296e-05 Loss_e: 3.8521e-05 | Loss_b: 2.1929e-05\n",
      "Step: NaN | Loss: 2.1877e-06 | Loss_d: 6.9897e-05 Loss_e: 3.9479e-05 | Loss_b: 2.1698e-05\n",
      "Step: NaN | Loss: 2.1640e-06 | Loss_d: 6.9359e-05 Loss_e: 3.8665e-05 | Loss_b: 2.1632e-05\n",
      "Step: NaN | Loss: 2.1599e-06 | Loss_d: 6.9225e-05 Loss_e: 3.9106e-05 | Loss_b: 2.1077e-05\n",
      "Step: NaN | Loss: 2.2128e-06 | Loss_d: 6.9483e-05 Loss_e: 4.1651e-05 | Loss_b: 2.1442e-05\n",
      "Step: NaN | Loss: 2.1598e-06 | Loss_d: 6.9211e-05 Loss_e: 3.9183e-05 | Loss_b: 2.1007e-05\n",
      "Step: NaN | Loss: 2.1571e-06 | Loss_d: 6.9300e-05 Loss_e: 3.9193e-05 | Loss_b: 2.0746e-05\n",
      "Step: NaN | Loss: 2.1709e-06 | Loss_d: 6.9780e-05 Loss_e: 3.9505e-05 | Loss_b: 2.0782e-05\n",
      "Step: NaN | Loss: 2.1566e-06 | Loss_d: 6.9358e-05 Loss_e: 3.9212e-05 | Loss_b: 2.0642e-05\n",
      "Step: NaN | Loss: 2.1544e-06 | Loss_d: 6.9411e-05 Loss_e: 3.9146e-05 | Loss_b: 2.0521e-05\n",
      "Step: NaN | Loss: 2.1512e-06 | Loss_d: 6.9649e-05 Loss_e: 3.9032e-05 | Loss_b: 2.0209e-05\n",
      "Step: NaN | Loss: 2.1511e-06 | Loss_d: 6.9609e-05 Loss_e: 3.9035e-05 | Loss_b: 2.0239e-05\n",
      "Step: NaN | Loss: 2.1468e-06 | Loss_d: 6.9456e-05 Loss_e: 3.9150e-05 | Loss_b: 2.0018e-05\n",
      "Step: NaN | Loss: 2.1694e-06 | Loss_d: 6.9443e-05 Loss_e: 4.0705e-05 | Loss_b: 1.9832e-05\n",
      "Step: NaN | Loss: 2.1461e-06 | Loss_d: 6.9395e-05 Loss_e: 3.9266e-05 | Loss_b: 1.9920e-05\n",
      "Step: NaN | Loss: 2.1422e-06 | Loss_d: 6.9246e-05 Loss_e: 3.9245e-05 | Loss_b: 1.9858e-05\n",
      "Step: NaN | Loss: 2.1436e-06 | Loss_d: 6.8711e-05 Loss_e: 3.9631e-05 | Loss_b: 2.0089e-05\n",
      "Step: NaN | Loss: 2.1395e-06 | Loss_d: 6.8994e-05 Loss_e: 3.9326e-05 | Loss_b: 1.9867e-05\n",
      "Step: NaN | Loss: 2.1360e-06 | Loss_d: 6.8937e-05 Loss_e: 3.9413e-05 | Loss_b: 1.9629e-05\n",
      "Step: NaN | Loss: 2.1350e-06 | Loss_d: 6.9054e-05 Loss_e: 3.9835e-05 | Loss_b: 1.9028e-05\n",
      "Step: NaN | Loss: 2.1327e-06 | Loss_d: 6.8928e-05 Loss_e: 3.9619e-05 | Loss_b: 1.9235e-05\n",
      "Step: NaN | Loss: 2.1260e-06 | Loss_d: 6.9226e-05 Loss_e: 3.9045e-05 | Loss_b: 1.9108e-05\n",
      "Step: NaN | Loss: 2.1535e-06 | Loss_d: 7.1488e-05 Loss_e: 3.7719e-05 | Loss_b: 1.9817e-05\n",
      "Step: NaN | Loss: 2.1245e-06 | Loss_d: 6.9510e-05 Loss_e: 3.8687e-05 | Loss_b: 1.9093e-05\n",
      "Step: NaN | Loss: 2.1233e-06 | Loss_d: 7.0128e-05 Loss_e: 3.8447e-05 | Loss_b: 1.8641e-05\n",
      "Step: NaN | Loss: 2.1228e-06 | Loss_d: 6.9905e-05 Loss_e: 3.8516e-05 | Loss_b: 1.8766e-05\n",
      "Step: NaN | Loss: 2.1216e-06 | Loss_d: 6.9908e-05 Loss_e: 3.8519e-05 | Loss_b: 1.8688e-05\n",
      "Step: NaN | Loss: 2.1253e-06 | Loss_d: 7.0018e-05 Loss_e: 3.8653e-05 | Loss_b: 1.8664e-05\n",
      "Step: NaN | Loss: 2.1213e-06 | Loss_d: 6.9919e-05 Loss_e: 3.8533e-05 | Loss_b: 1.8643e-05\n",
      "Step: NaN | Loss: 2.1259e-06 | Loss_d: 6.9647e-05 Loss_e: 3.8457e-05 | Loss_b: 1.9267e-05\n",
      "Step: NaN | Loss: 2.1205e-06 | Loss_d: 6.9839e-05 Loss_e: 3.8491e-05 | Loss_b: 1.8720e-05\n",
      "Step: NaN | Loss: 2.1200e-06 | Loss_d: 6.9807e-05 Loss_e: 3.8521e-05 | Loss_b: 1.8691e-05\n",
      "Step: NaN | Loss: 2.1203e-06 | Loss_d: 6.9690e-05 Loss_e: 3.8665e-05 | Loss_b: 1.8680e-05\n",
      "Step: NaN | Loss: 2.1196e-06 | Loss_d: 6.9754e-05 Loss_e: 3.8578e-05 | Loss_b: 1.8665e-05\n",
      "Step: NaN | Loss: 2.1188e-06 | Loss_d: 6.9746e-05 Loss_e: 3.8522e-05 | Loss_b: 1.8677e-05\n",
      "Step: NaN | Loss: 2.1166e-06 | Loss_d: 6.9733e-05 Loss_e: 3.8316e-05 | Loss_b: 1.8766e-05\n",
      "Step: NaN | Loss: 2.1355e-06 | Loss_d: 7.0120e-05 Loss_e: 3.7725e-05 | Loss_b: 2.0104e-05\n",
      "Step: NaN | Loss: 2.1162e-06 | Loss_d: 6.9739e-05 Loss_e: 3.8208e-05 | Loss_b: 1.8846e-05\n",
      "Step: NaN | Loss: 2.1198e-06 | Loss_d: 7.0245e-05 Loss_e: 3.8064e-05 | Loss_b: 1.8695e-05\n",
      "Step: NaN | Loss: 2.1158e-06 | Loss_d: 6.9861e-05 Loss_e: 3.8163e-05 | Loss_b: 1.8741e-05\n",
      "Step: NaN | Loss: 2.1152e-06 | Loss_d: 6.9781e-05 Loss_e: 3.8254e-05 | Loss_b: 1.8697e-05\n",
      "Step: NaN | Loss: 2.1165e-06 | Loss_d: 6.9523e-05 Loss_e: 3.8686e-05 | Loss_b: 1.8600e-05\n",
      "Step: NaN | Loss: 2.1150e-06 | Loss_d: 6.9702e-05 Loss_e: 3.8359e-05 | Loss_b: 1.8658e-05\n",
      "Step: NaN | Loss: 2.1138e-06 | Loss_d: 6.9690e-05 Loss_e: 3.8339e-05 | Loss_b: 1.8619e-05\n",
      "Step: NaN | Loss: 2.1100e-06 | Loss_d: 6.9656e-05 Loss_e: 3.8280e-05 | Loss_b: 1.8484e-05\n",
      "Step: NaN | Loss: 2.1142e-06 | Loss_d: 6.9805e-05 Loss_e: 3.8571e-05 | Loss_b: 1.8292e-05\n",
      "Step: NaN | Loss: 2.1069e-06 | Loss_d: 6.9648e-05 Loss_e: 3.8274e-05 | Loss_b: 1.8309e-05\n",
      "Step: NaN | Loss: 2.1023e-06 | Loss_d: 6.9656e-05 Loss_e: 3.8061e-05 | Loss_b: 1.8238e-05\n",
      "Step: NaN | Loss: 2.1160e-06 | Loss_d: 6.9993e-05 Loss_e: 3.7561e-05 | Loss_b: 1.9226e-05\n",
      "Step: NaN | Loss: 2.1009e-06 | Loss_d: 6.9691e-05 Loss_e: 3.7895e-05 | Loss_b: 1.8288e-05\n",
      "Step: NaN | Loss: 2.0982e-06 | Loss_d: 6.9522e-05 Loss_e: 3.7886e-05 | Loss_b: 1.8304e-05\n",
      "Step: NaN | Loss: 2.1041e-06 | Loss_d: 6.8928e-05 Loss_e: 3.8215e-05 | Loss_b: 1.8920e-05\n",
      "Step: NaN | Loss: 2.0971e-06 | Loss_d: 6.9341e-05 Loss_e: 3.7920e-05 | Loss_b: 1.8388e-05\n",
      "Step: NaN | Loss: 2.0940e-06 | Loss_d: 6.9386e-05 Loss_e: 3.7887e-05 | Loss_b: 1.8190e-05\n",
      "Step: NaN | Loss: 2.1093e-06 | Loss_d: 7.0250e-05 Loss_e: 3.8285e-05 | Loss_b: 1.7842e-05\n",
      "Step: NaN | Loss: 2.0935e-06 | Loss_d: 6.9449e-05 Loss_e: 3.7893e-05 | Loss_b: 1.8087e-05\n",
      "Step: NaN | Loss: 2.0913e-06 | Loss_d: 6.9610e-05 Loss_e: 3.7701e-05 | Loss_b: 1.7985e-05\n",
      "Step: NaN | Loss: 2.0963e-06 | Loss_d: 7.0379e-05 Loss_e: 3.7301e-05 | Loss_b: 1.7920e-05\n",
      "Step: NaN | Loss: 2.0904e-06 | Loss_d: 6.9800e-05 Loss_e: 3.7533e-05 | Loss_b: 1.7912e-05\n",
      "Step: NaN | Loss: 2.0866e-06 | Loss_d: 6.9370e-05 Loss_e: 3.7371e-05 | Loss_b: 1.8274e-05\n",
      "Step: NaN | Loss: 2.1110e-06 | Loss_d: 6.8022e-05 Loss_e: 3.7220e-05 | Loss_b: 2.1240e-05\n",
      "Step: NaN | Loss: 2.0861e-06 | Loss_d: 6.9185e-05 Loss_e: 3.7313e-05 | Loss_b: 1.8492e-05\n",
      "Step: NaN | Loss: 2.0814e-06 | Loss_d: 6.9052e-05 Loss_e: 3.7237e-05 | Loss_b: 1.8419e-05\n",
      "Step: NaN | Loss: 2.0867e-06 | Loss_d: 6.8801e-05 Loss_e: 3.7231e-05 | Loss_b: 1.8992e-05\n",
      "Step: NaN | Loss: 2.0789e-06 | Loss_d: 6.8910e-05 Loss_e: 3.7179e-05 | Loss_b: 1.8468e-05\n",
      "Step: NaN | Loss: 2.4556e-06 | Loss_d: 6.9055e-05 Loss_e: 3.6512e-05 | Loss_b: 4.1561e-05\n",
      "Step: NaN | Loss: 2.0784e-06 | Loss_d: 6.8873e-05 Loss_e: 3.7115e-05 | Loss_b: 1.8540e-05\n",
      "Step: NaN | Loss: 2.0783e-06 | Loss_d: 6.8856e-05 Loss_e: 3.7117e-05 | Loss_b: 1.8545e-05\n",
      "Step: NaN | Loss: 2.0780e-06 | Loss_d: 6.8792e-05 Loss_e: 3.7126e-05 | Loss_b: 1.8584e-05\n",
      "Step: NaN | Loss: 2.0780e-06 | Loss_d: 6.8802e-05 Loss_e: 3.7125e-05 | Loss_b: 1.8577e-05\n",
      "Step: NaN | Loss: 2.0775e-06 | Loss_d: 6.8820e-05 Loss_e: 3.7108e-05 | Loss_b: 1.8545e-05\n",
      "Step: NaN | Loss: 2.0762e-06 | Loss_d: 6.8895e-05 Loss_e: 3.7051e-05 | Loss_b: 1.8445e-05\n",
      "Step: NaN | Loss: 2.0859e-06 | Loss_d: 6.9390e-05 Loss_e: 3.6975e-05 | Loss_b: 1.8608e-05\n",
      "Step: NaN | Loss: 2.0759e-06 | Loss_d: 6.8956e-05 Loss_e: 3.7018e-05 | Loss_b: 1.8400e-05\n",
      "Step: NaN | Loss: 2.0744e-06 | Loss_d: 6.8794e-05 Loss_e: 3.6931e-05 | Loss_b: 1.8561e-05\n",
      "Step: NaN | Loss: 2.0890e-06 | Loss_d: 6.8266e-05 Loss_e: 3.6775e-05 | Loss_b: 2.0121e-05\n",
      "Step: NaN | Loss: 2.0743e-06 | Loss_d: 6.8759e-05 Loss_e: 3.6913e-05 | Loss_b: 1.8609e-05\n",
      "Step: NaN | Loss: 2.0730e-06 | Loss_d: 6.8803e-05 Loss_e: 3.6812e-05 | Loss_b: 1.8586e-05\n",
      "Step: NaN | Loss: 2.0714e-06 | Loss_d: 6.9057e-05 Loss_e: 3.6492e-05 | Loss_b: 1.8557e-05\n",
      "Step: NaN | Loss: 2.0712e-06 | Loss_d: 6.8986e-05 Loss_e: 3.6555e-05 | Loss_b: 1.8556e-05\n",
      "Step: NaN | Loss: 2.0667e-06 | Loss_d: 6.8778e-05 Loss_e: 3.6504e-05 | Loss_b: 1.8541e-05\n",
      "Step: NaN | Loss: 2.0667e-06 | Loss_d: 6.8778e-05 Loss_e: 3.6504e-05 | Loss_b: 1.8542e-05\n",
      "Step: NaN | Loss: 2.0603e-06 | Loss_d: 6.8668e-05 Loss_e: 3.6425e-05 | Loss_b: 1.8347e-05\n",
      "Step: NaN | Loss: 2.0465e-06 | Loss_d: 6.8372e-05 Loss_e: 3.6383e-05 | Loss_b: 1.7857e-05\n",
      "Step: NaN | Loss: 2.2634e-06 | Loss_d: 7.0260e-05 Loss_e: 4.2843e-05 | Loss_b: 2.2507e-05\n",
      "Step: NaN | Loss: 2.0459e-06 | Loss_d: 6.8337e-05 Loss_e: 3.6435e-05 | Loss_b: 1.7809e-05\n",
      "Step: NaN | Loss: 2.0385e-06 | Loss_d: 6.8271e-05 Loss_e: 3.6475e-05 | Loss_b: 1.7389e-05\n",
      "Step: NaN | Loss: 2.0569e-06 | Loss_d: 6.8245e-05 Loss_e: 3.7206e-05 | Loss_b: 1.7787e-05\n",
      "Step: NaN | Loss: 2.0358e-06 | Loss_d: 6.8227e-05 Loss_e: 3.6577e-05 | Loss_b: 1.7171e-05\n",
      "Step: NaN | Loss: 2.0348e-06 | Loss_d: 6.8234e-05 Loss_e: 3.6441e-05 | Loss_b: 1.7236e-05\n",
      "Step: NaN | Loss: 2.0339e-06 | Loss_d: 6.8316e-05 Loss_e: 3.5947e-05 | Loss_b: 1.7599e-05\n",
      "Step: NaN | Loss: 2.0336e-06 | Loss_d: 6.8277e-05 Loss_e: 3.6112e-05 | Loss_b: 1.7452e-05\n",
      "Step: NaN | Loss: 2.0294e-06 | Loss_d: 6.8578e-05 Loss_e: 3.5931e-05 | Loss_b: 1.7079e-05\n",
      "Step: NaN | Loss: 2.0544e-06 | Loss_d: 7.0625e-05 Loss_e: 3.5609e-05 | Loss_b: 1.6853e-05\n",
      "Step: NaN | Loss: 2.0288e-06 | Loss_d: 6.8765e-05 Loss_e: 3.5854e-05 | Loss_b: 1.6935e-05\n",
      "Step: NaN | Loss: 2.0207e-06 | Loss_d: 6.8227e-05 Loss_e: 3.5890e-05 | Loss_b: 1.6954e-05\n",
      "Step: NaN | Loss: 2.0324e-06 | Loss_d: 6.6718e-05 Loss_e: 3.6869e-05 | Loss_b: 1.8184e-05\n",
      "Step: NaN | Loss: 2.0168e-06 | Loss_d: 6.7620e-05 Loss_e: 3.6064e-05 | Loss_b: 1.7148e-05\n",
      "Step: NaN | Loss: 2.0076e-06 | Loss_d: 6.7858e-05 Loss_e: 3.5446e-05 | Loss_b: 1.6982e-05\n",
      "Step: NaN | Loss: 2.0040e-06 | Loss_d: 6.7687e-05 Loss_e: 3.5422e-05 | Loss_b: 1.6961e-05\n",
      "Step: NaN | Loss: 2.0027e-06 | Loss_d: 6.7483e-05 Loss_e: 3.5507e-05 | Loss_b: 1.7001e-05\n",
      "Step: NaN | Loss: 2.0013e-06 | Loss_d: 6.7548e-05 Loss_e: 3.5454e-05 | Loss_b: 1.6907e-05\n",
      "Step: NaN | Loss: 1.9985e-06 | Loss_d: 6.7552e-05 Loss_e: 3.5478e-05 | Loss_b: 1.6708e-05\n",
      "Step: NaN | Loss: 2.0178e-06 | Loss_d: 6.7811e-05 Loss_e: 3.5680e-05 | Loss_b: 1.7401e-05\n",
      "Step: NaN | Loss: 1.9982e-06 | Loss_d: 6.7561e-05 Loss_e: 3.5491e-05 | Loss_b: 1.6670e-05\n",
      "Step: NaN | Loss: 1.9966e-06 | Loss_d: 6.7455e-05 Loss_e: 3.5418e-05 | Loss_b: 1.6753e-05\n",
      "Step: NaN | Loss: 1.9999e-06 | Loss_d: 6.7202e-05 Loss_e: 3.5226e-05 | Loss_b: 1.7395e-05\n",
      "Step: NaN | Loss: 1.9960e-06 | Loss_d: 6.7354e-05 Loss_e: 3.5346e-05 | Loss_b: 1.6889e-05\n",
      "Step: NaN | Loss: 1.9933e-06 | Loss_d: 6.7358e-05 Loss_e: 3.5273e-05 | Loss_b: 1.6799e-05\n",
      "Step: NaN | Loss: 1.9867e-06 | Loss_d: 6.7427e-05 Loss_e: 3.5069e-05 | Loss_b: 1.6538e-05\n",
      "Step: NaN | Loss: 2.0502e-06 | Loss_d: 6.9115e-05 Loss_e: 3.6069e-05 | Loss_b: 1.7651e-05\n",
      "Step: NaN | Loss: 1.9858e-06 | Loss_d: 6.7499e-05 Loss_e: 3.5016e-05 | Loss_b: 1.6465e-05\n",
      "Step: NaN | Loss: 1.9825e-06 | Loss_d: 6.7165e-05 Loss_e: 3.5299e-05 | Loss_b: 1.6318e-05\n",
      "Step: NaN | Loss: 1.9790e-06 | Loss_d: 6.7277e-05 Loss_e: 3.5121e-05 | Loss_b: 1.6170e-05\n",
      "Step: NaN | Loss: 1.9778e-06 | Loss_d: 6.7161e-05 Loss_e: 3.5217e-05 | Loss_b: 1.6118e-05\n",
      "Step: NaN | Loss: 1.9910e-06 | Loss_d: 6.6891e-05 Loss_e: 3.6089e-05 | Loss_b: 1.6312e-05\n",
      "Step: NaN | Loss: 1.9777e-06 | Loss_d: 6.7144e-05 Loss_e: 3.5238e-05 | Loss_b: 1.6113e-05\n",
      "Step: NaN | Loss: 1.9769e-06 | Loss_d: 6.7135e-05 Loss_e: 3.5200e-05 | Loss_b: 1.6111e-05\n",
      "Step: NaN | Loss: 1.9757e-06 | Loss_d: 6.7112e-05 Loss_e: 3.5060e-05 | Loss_b: 1.6197e-05\n",
      "Step: NaN | Loss: 1.9756e-06 | Loss_d: 6.7114e-05 Loss_e: 3.5072e-05 | Loss_b: 1.6184e-05\n",
      "Step: NaN | Loss: 1.9718e-06 | Loss_d: 6.6898e-05 Loss_e: 3.4971e-05 | Loss_b: 1.6272e-05\n",
      "Step: NaN | Loss: 1.9702e-06 | Loss_d: 6.6219e-05 Loss_e: 3.4685e-05 | Loss_b: 1.7139e-05\n",
      "Step: NaN | Loss: 1.9683e-06 | Loss_d: 6.6471e-05 Loss_e: 3.4784e-05 | Loss_b: 1.6672e-05\n",
      "Step: NaN | Loss: 1.9655e-06 | Loss_d: 6.6428e-05 Loss_e: 3.4803e-05 | Loss_b: 1.6528e-05\n",
      "Step: NaN | Loss: 1.9655e-06 | Loss_d: 6.6428e-05 Loss_e: 3.4803e-05 | Loss_b: 1.6529e-05\n",
      "Step: NaN | Loss: 1.9650e-06 | Loss_d: 6.6413e-05 Loss_e: 3.4767e-05 | Loss_b: 1.6554e-05\n",
      "Step: NaN | Loss: 1.9646e-06 | Loss_d: 6.6357e-05 Loss_e: 3.4659e-05 | Loss_b: 1.6694e-05\n",
      "Step: NaN | Loss: 1.9645e-06 | Loss_d: 6.6373e-05 Loss_e: 3.4685e-05 | Loss_b: 1.6644e-05\n",
      "Step: NaN | Loss: 1.9631e-06 | Loss_d: 6.6322e-05 Loss_e: 3.4686e-05 | Loss_b: 1.6613e-05\n",
      "Step: NaN | Loss: 1.9620e-06 | Loss_d: 6.6258e-05 Loss_e: 3.4742e-05 | Loss_b: 1.6552e-05\n",
      "Step: NaN | Loss: 1.9616e-06 | Loss_d: 6.6254e-05 Loss_e: 3.4713e-05 | Loss_b: 1.6559e-05\n",
      "Step: NaN | Loss: 1.9601e-06 | Loss_d: 6.6248e-05 Loss_e: 3.4737e-05 | Loss_b: 1.6455e-05\n",
      "Step: NaN | Loss: 1.9696e-06 | Loss_d: 6.6322e-05 Loss_e: 3.5061e-05 | Loss_b: 1.6627e-05\n",
      "Step: NaN | Loss: 1.9600e-06 | Loss_d: 6.6249e-05 Loss_e: 3.4755e-05 | Loss_b: 1.6428e-05\n",
      "Step: NaN | Loss: 1.9590e-06 | Loss_d: 6.6235e-05 Loss_e: 3.4790e-05 | Loss_b: 1.6345e-05\n",
      "Step: NaN | Loss: 1.9587e-06 | Loss_d: 6.6248e-05 Loss_e: 3.4960e-05 | Loss_b: 1.6147e-05\n",
      "Step: NaN | Loss: 1.9581e-06 | Loss_d: 6.6229e-05 Loss_e: 3.4877e-05 | Loss_b: 1.6212e-05\n",
      "Step: NaN | Loss: 1.9565e-06 | Loss_d: 6.6077e-05 Loss_e: 3.4874e-05 | Loss_b: 1.6272e-05\n",
      "Step: NaN | Loss: 1.9737e-06 | Loss_d: 6.5714e-05 Loss_e: 3.5240e-05 | Loss_b: 1.7298e-05\n",
      "Step: NaN | Loss: 1.9565e-06 | Loss_d: 6.6054e-05 Loss_e: 3.4877e-05 | Loss_b: 1.6291e-05\n",
      "Step: NaN | Loss: 1.9545e-06 | Loss_d: 6.6069e-05 Loss_e: 3.4799e-05 | Loss_b: 1.6234e-05\n",
      "Step: NaN | Loss: 1.9594e-06 | Loss_d: 6.6304e-05 Loss_e: 3.4753e-05 | Loss_b: 1.6340e-05\n",
      "Step: NaN | Loss: 1.9538e-06 | Loss_d: 6.6104e-05 Loss_e: 3.4747e-05 | Loss_b: 1.6208e-05\n",
      "Step: NaN | Loss: 1.9542e-06 | Loss_d: 6.5729e-05 Loss_e: 3.4754e-05 | Loss_b: 1.6601e-05\n",
      "Step: NaN | Loss: 1.9519e-06 | Loss_d: 6.5910e-05 Loss_e: 3.4740e-05 | Loss_b: 1.6297e-05\n",
      "Step: NaN | Loss: 1.9498e-06 | Loss_d: 6.5841e-05 Loss_e: 3.4691e-05 | Loss_b: 1.6288e-05\n",
      "Step: NaN | Loss: 1.9512e-06 | Loss_d: 6.5670e-05 Loss_e: 3.4760e-05 | Loss_b: 1.6475e-05\n",
      "Step: NaN | Loss: 1.9485e-06 | Loss_d: 6.5751e-05 Loss_e: 3.4669e-05 | Loss_b: 1.6321e-05\n",
      "Step: NaN | Loss: 1.9467e-06 | Loss_d: 6.5702e-05 Loss_e: 3.4639e-05 | Loss_b: 1.6297e-05\n",
      "Step: NaN | Loss: 1.9433e-06 | Loss_d: 6.5535e-05 Loss_e: 3.4591e-05 | Loss_b: 1.6305e-05\n",
      "Step: NaN | Loss: 2.0067e-06 | Loss_d: 6.5378e-05 Loss_e: 3.6054e-05 | Loss_b: 1.8798e-05\n",
      "Step: NaN | Loss: 1.9432e-06 | Loss_d: 6.5515e-05 Loss_e: 3.4593e-05 | Loss_b: 1.6320e-05\n",
      "Step: NaN | Loss: 1.9496e-06 | Loss_d: 6.5781e-05 Loss_e: 3.4743e-05 | Loss_b: 1.6287e-05\n",
      "Step: NaN | Loss: 1.9420e-06 | Loss_d: 6.5557e-05 Loss_e: 3.4600e-05 | Loss_b: 1.6199e-05\n",
      "Step: NaN | Loss: 1.9416e-06 | Loss_d: 6.5552e-05 Loss_e: 3.4572e-05 | Loss_b: 1.6207e-05\n",
      "Step: NaN | Loss: 1.9450e-06 | Loss_d: 6.5614e-05 Loss_e: 3.4590e-05 | Loss_b: 1.6328e-05\n",
      "Step: NaN | Loss: 1.9416e-06 | Loss_d: 6.5552e-05 Loss_e: 3.4566e-05 | Loss_b: 1.6211e-05\n",
      "Step: NaN | Loss: 1.9410e-06 | Loss_d: 6.5540e-05 Loss_e: 3.4577e-05 | Loss_b: 1.6179e-05\n",
      "Step: NaN | Loss: 1.9402e-06 | Loss_d: 6.5515e-05 Loss_e: 3.4630e-05 | Loss_b: 1.6102e-05\n",
      "Step: NaN | Loss: 1.9402e-06 | Loss_d: 6.5516e-05 Loss_e: 3.4624e-05 | Loss_b: 1.6107e-05\n",
      "Step: NaN | Loss: 1.9384e-06 | Loss_d: 6.5382e-05 Loss_e: 3.4658e-05 | Loss_b: 1.6097e-05\n",
      "Step: NaN | Loss: 1.9395e-06 | Loss_d: 6.4983e-05 Loss_e: 3.4940e-05 | Loss_b: 1.6279e-05\n",
      "Step: NaN | Loss: 1.9372e-06 | Loss_d: 6.5188e-05 Loss_e: 3.4748e-05 | Loss_b: 1.6130e-05\n",
      "Step: NaN | Loss: 1.9365e-06 | Loss_d: 6.5072e-05 Loss_e: 3.4706e-05 | Loss_b: 1.6247e-05\n",
      "Step: NaN | Loss: 1.9363e-06 | Loss_d: 6.5106e-05 Loss_e: 3.4716e-05 | Loss_b: 1.6189e-05\n",
      "Step: NaN | Loss: 1.9350e-06 | Loss_d: 6.5066e-05 Loss_e: 3.4722e-05 | Loss_b: 1.6145e-05\n",
      "Step: NaN | Loss: 1.9331e-06 | Loss_d: 6.4943e-05 Loss_e: 3.4796e-05 | Loss_b: 1.6082e-05\n",
      "Step: NaN | Loss: 1.9331e-06 | Loss_d: 6.4957e-05 Loss_e: 3.4780e-05 | Loss_b: 1.6080e-05\n",
      "Step: NaN | Loss: 1.9312e-06 | Loss_d: 6.4752e-05 Loss_e: 3.4794e-05 | Loss_b: 1.6159e-05\n",
      "Step: NaN | Loss: 1.9375e-06 | Loss_d: 6.4088e-05 Loss_e: 3.4951e-05 | Loss_b: 1.7046e-05\n",
      "Step: NaN | Loss: 1.9307e-06 | Loss_d: 6.4589e-05 Loss_e: 3.4814e-05 | Loss_b: 1.6271e-05\n",
      "Step: NaN | Loss: 1.9298e-06 | Loss_d: 6.4573e-05 Loss_e: 3.4783e-05 | Loss_b: 1.6264e-05\n",
      "Step: NaN | Loss: 1.9270e-06 | Loss_d: 6.4519e-05 Loss_e: 3.4686e-05 | Loss_b: 1.6253e-05\n",
      "Step: NaN | Loss: 1.9371e-06 | Loss_d: 6.4579e-05 Loss_e: 3.4805e-05 | Loss_b: 1.6677e-05\n",
      "Step: NaN | Loss: 1.9259e-06 | Loss_d: 6.4483e-05 Loss_e: 3.4621e-05 | Loss_b: 1.6282e-05\n",
      "Step: NaN | Loss: 1.9219e-06 | Loss_d: 6.4155e-05 Loss_e: 3.4567e-05 | Loss_b: 1.6425e-05\n",
      "Step: NaN | Loss: 1.9710e-06 | Loss_d: 6.3212e-05 Loss_e: 3.4897e-05 | Loss_b: 1.9979e-05\n",
      "Step: NaN | Loss: 1.9218e-06 | Loss_d: 6.4119e-05 Loss_e: 3.4564e-05 | Loss_b: 1.6461e-05\n",
      "Step: NaN | Loss: 1.9203e-06 | Loss_d: 6.4053e-05 Loss_e: 3.4657e-05 | Loss_b: 1.6344e-05\n",
      "Step: NaN | Loss: 1.9320e-06 | Loss_d: 6.3944e-05 Loss_e: 3.5364e-05 | Loss_b: 1.6444e-05\n",
      "Step: NaN | Loss: 1.9202e-06 | Loss_d: 6.4033e-05 Loss_e: 3.4698e-05 | Loss_b: 1.6314e-05\n",
      "Step: NaN | Loss: 1.9189e-06 | Loss_d: 6.4074e-05 Loss_e: 3.4656e-05 | Loss_b: 1.6241e-05\n",
      "Step: NaN | Loss: 1.9182e-06 | Loss_d: 6.4265e-05 Loss_e: 3.4535e-05 | Loss_b: 1.6125e-05\n",
      "Step: NaN | Loss: 1.9176e-06 | Loss_d: 6.4184e-05 Loss_e: 3.4573e-05 | Loss_b: 1.6136e-05\n",
      "Step: NaN | Loss: 1.9184e-06 | Loss_d: 6.4110e-05 Loss_e: 3.4628e-05 | Loss_b: 1.6201e-05\n",
      "Step: NaN | Loss: 1.9168e-06 | Loss_d: 6.4146e-05 Loss_e: 3.4580e-05 | Loss_b: 1.6115e-05\n",
      "Step: NaN | Loss: 1.9161e-06 | Loss_d: 6.4165e-05 Loss_e: 3.4602e-05 | Loss_b: 1.6037e-05\n",
      "Step: NaN | Loss: 1.9180e-06 | Loss_d: 6.4255e-05 Loss_e: 3.4721e-05 | Loss_b: 1.5939e-05\n",
      "Step: NaN | Loss: 1.9160e-06 | Loss_d: 6.4185e-05 Loss_e: 3.4625e-05 | Loss_b: 1.5984e-05\n",
      "Step: NaN | Loss: 1.9156e-06 | Loss_d: 6.4188e-05 Loss_e: 3.4610e-05 | Loss_b: 1.5975e-05\n",
      "Step: NaN | Loss: 1.9146e-06 | Loss_d: 6.4207e-05 Loss_e: 3.4555e-05 | Loss_b: 1.5952e-05\n",
      "Step: NaN | Loss: 1.9188e-06 | Loss_d: 6.4446e-05 Loss_e: 3.4412e-05 | Loss_b: 1.6107e-05\n",
      "Step: NaN | Loss: 1.9142e-06 | Loss_d: 6.4240e-05 Loss_e: 3.4503e-05 | Loss_b: 1.5946e-05\n",
      "Step: NaN | Loss: 1.9125e-06 | Loss_d: 6.4137e-05 Loss_e: 3.4486e-05 | Loss_b: 1.5964e-05\n",
      "Step: NaN | Loss: 1.9121e-06 | Loss_d: 6.3847e-05 Loss_e: 3.4472e-05 | Loss_b: 1.6240e-05\n",
      "Step: NaN | Loss: 1.9110e-06 | Loss_d: 6.3954e-05 Loss_e: 3.4468e-05 | Loss_b: 1.6074e-05\n",
      "Step: NaN | Loss: 1.9063e-06 | Loss_d: 6.4006e-05 Loss_e: 3.4295e-05 | Loss_b: 1.5913e-05\n",
      "Step: NaN | Loss: 1.9041e-06 | Loss_d: 6.4440e-05 Loss_e: 3.3761e-05 | Loss_b: 1.5881e-05\n",
      "Step: NaN | Loss: 1.9018e-06 | Loss_d: 6.4214e-05 Loss_e: 3.3954e-05 | Loss_b: 1.5775e-05\n",
      "Step: NaN | Loss: 1.8973e-06 | Loss_d: 6.3409e-05 Loss_e: 3.4234e-05 | Loss_b: 1.6031e-05\n",
      "Step: NaN | Loss: 1.8966e-06 | Loss_d: 6.3613e-05 Loss_e: 3.4098e-05 | Loss_b: 1.5923e-05\n",
      "Step: NaN | Loss: 1.8972e-06 | Loss_d: 6.3586e-05 Loss_e: 3.4196e-05 | Loss_b: 1.5888e-05\n",
      "Step: NaN | Loss: 1.8954e-06 | Loss_d: 6.3590e-05 Loss_e: 3.4131e-05 | Loss_b: 1.5842e-05\n",
      "Step: NaN | Loss: 1.8951e-06 | Loss_d: 6.3596e-05 Loss_e: 3.4104e-05 | Loss_b: 1.5842e-05\n",
      "Step: NaN | Loss: 1.8946e-06 | Loss_d: 6.3635e-05 Loss_e: 3.4012e-05 | Loss_b: 1.5866e-05\n",
      "Step: NaN | Loss: 1.8946e-06 | Loss_d: 6.3630e-05 Loss_e: 3.4022e-05 | Loss_b: 1.5862e-05\n",
      "Step: NaN | Loss: 1.8930e-06 | Loss_d: 6.3599e-05 Loss_e: 3.3985e-05 | Loss_b: 1.5834e-05\n",
      "Step: NaN | Loss: 1.8886e-06 | Loss_d: 6.3492e-05 Loss_e: 3.3893e-05 | Loss_b: 1.5769e-05\n",
      "Step: NaN | Loss: 1.9137e-06 | Loss_d: 6.3418e-05 Loss_e: 3.4778e-05 | Loss_b: 1.6464e-05\n",
      "Step: NaN | Loss: 1.8874e-06 | Loss_d: 6.3422e-05 Loss_e: 3.3887e-05 | Loss_b: 1.5774e-05\n",
      "Step: NaN | Loss: 1.8845e-06 | Loss_d: 6.3454e-05 Loss_e: 3.3769e-05 | Loss_b: 1.5683e-05\n",
      "Step: NaN | Loss: 1.9188e-06 | Loss_d: 6.3901e-05 Loss_e: 3.3860e-05 | Loss_b: 1.7202e-05\n",
      "Step: NaN | Loss: 1.8844e-06 | Loss_d: 6.3461e-05 Loss_e: 3.3757e-05 | Loss_b: 1.5685e-05\n",
      "Step: NaN | Loss: 1.8828e-06 | Loss_d: 6.3391e-05 Loss_e: 3.3715e-05 | Loss_b: 1.5698e-05\n",
      "Step: NaN | Loss: 1.8799e-06 | Loss_d: 6.3136e-05 Loss_e: 3.3658e-05 | Loss_b: 1.5837e-05\n",
      "Step: NaN | Loss: 1.8799e-06 | Loss_d: 6.3139e-05 Loss_e: 3.3657e-05 | Loss_b: 1.5835e-05\n",
      "Step: NaN | Loss: 1.8806e-06 | Loss_d: 6.3035e-05 Loss_e: 3.3702e-05 | Loss_b: 1.5940e-05\n",
      "Step: NaN | Loss: 1.8791e-06 | Loss_d: 6.3084e-05 Loss_e: 3.3661e-05 | Loss_b: 1.5842e-05\n",
      "Step: NaN | Loss: 1.8785e-06 | Loss_d: 6.3107e-05 Loss_e: 3.3688e-05 | Loss_b: 1.5754e-05\n",
      "Step: NaN | Loss: 1.8785e-06 | Loss_d: 6.3106e-05 Loss_e: 3.3686e-05 | Loss_b: 1.5755e-05\n",
      "Step: NaN | Loss: 1.8782e-06 | Loss_d: 6.3106e-05 Loss_e: 3.3674e-05 | Loss_b: 1.5750e-05\n",
      "Step: NaN | Loss: 1.8789e-06 | Loss_d: 6.3116e-05 Loss_e: 3.3657e-05 | Loss_b: 1.5799e-05\n",
      "Step: NaN | Loss: 1.8780e-06 | Loss_d: 6.3107e-05 Loss_e: 3.3663e-05 | Loss_b: 1.5752e-05\n",
      "Step: NaN | Loss: 1.8775e-06 | Loss_d: 6.3029e-05 Loss_e: 3.3688e-05 | Loss_b: 1.5773e-05\n",
      "Step: NaN | Loss: 1.8766e-06 | Loss_d: 6.2742e-05 Loss_e: 3.3813e-05 | Loss_b: 1.5882e-05\n",
      "Step: NaN | Loss: 1.8766e-06 | Loss_d: 6.2761e-05 Loss_e: 3.3803e-05 | Loss_b: 1.5874e-05\n",
      "Step: NaN | Loss: 1.8732e-06 | Loss_d: 6.2784e-05 Loss_e: 3.3667e-05 | Loss_b: 1.5780e-05\n",
      "Step: NaN | Loss: 1.8732e-06 | Loss_d: 6.2779e-05 Loss_e: 3.3671e-05 | Loss_b: 1.5781e-05\n",
      "Step: NaN | Loss: 1.8718e-06 | Loss_d: 6.2958e-05 Loss_e: 3.3353e-05 | Loss_b: 1.5834e-05\n",
      "Step: NaN | Loss: 1.8711e-06 | Loss_d: 6.2888e-05 Loss_e: 3.3441e-05 | Loss_b: 1.5778e-05\n",
      "Step: NaN | Loss: 1.8705e-06 | Loss_d: 6.2812e-05 Loss_e: 3.3402e-05 | Loss_b: 1.5853e-05\n",
      "Step: NaN | Loss: 1.8705e-06 | Loss_d: 6.2816e-05 Loss_e: 3.3404e-05 | Loss_b: 1.5847e-05\n",
      "Step: NaN | Loss: 1.8696e-06 | Loss_d: 6.2814e-05 Loss_e: 3.3383e-05 | Loss_b: 1.5819e-05\n",
      "Step: NaN | Loss: 1.8676e-06 | Loss_d: 6.2816e-05 Loss_e: 3.3321e-05 | Loss_b: 1.5760e-05\n",
      "Step: NaN | Loss: 1.8903e-06 | Loss_d: 6.3053e-05 Loss_e: 3.3528e-05 | Loss_b: 1.6672e-05\n",
      "Step: NaN | Loss: 1.8674e-06 | Loss_d: 6.2821e-05 Loss_e: 3.3305e-05 | Loss_b: 1.5760e-05\n",
      "Step: NaN | Loss: 1.8656e-06 | Loss_d: 6.2824e-05 Loss_e: 3.3176e-05 | Loss_b: 1.5779e-05\n",
      "Step: NaN | Loss: 1.8845e-06 | Loss_d: 6.3120e-05 Loss_e: 3.2841e-05 | Loss_b: 1.6947e-05\n",
      "Step: NaN | Loss: 1.8656e-06 | Loss_d: 6.2828e-05 Loss_e: 3.3153e-05 | Loss_b: 1.5794e-05\n",
      "Step: NaN | Loss: 1.8648e-06 | Loss_d: 6.2757e-05 Loss_e: 3.3207e-05 | Loss_b: 1.5767e-05\n",
      "Step: NaN | Loss: 1.8655e-06 | Loss_d: 6.2512e-05 Loss_e: 3.3526e-05 | Loss_b: 1.5734e-05\n",
      "Step: NaN | Loss: 1.8644e-06 | Loss_d: 6.2659e-05 Loss_e: 3.3305e-05 | Loss_b: 1.5740e-05\n",
      "Step: NaN | Loss: 1.8625e-06 | Loss_d: 6.2532e-05 Loss_e: 3.3288e-05 | Loss_b: 1.5768e-05\n",
      "Step: NaN | Loss: 1.8660e-06 | Loss_d: 6.2258e-05 Loss_e: 3.3354e-05 | Loss_b: 1.6188e-05\n",
      "Step: NaN | Loss: 1.8616e-06 | Loss_d: 6.2408e-05 Loss_e: 3.3285e-05 | Loss_b: 1.5845e-05\n",
      "Step: NaN | Loss: 1.8615e-06 | Loss_d: 6.2542e-05 Loss_e: 3.3108e-05 | Loss_b: 1.5883e-05\n",
      "Step: NaN | Loss: 1.8605e-06 | Loss_d: 6.2466e-05 Loss_e: 3.3180e-05 | Loss_b: 1.5826e-05\n",
      "Step: NaN | Loss: 1.8599e-06 | Loss_d: 6.2433e-05 Loss_e: 3.3139e-05 | Loss_b: 1.5863e-05\n",
      "Step: NaN | Loss: 1.8599e-06 | Loss_d: 6.2435e-05 Loss_e: 3.3141e-05 | Loss_b: 1.5858e-05\n",
      "Step: NaN | Loss: 1.8593e-06 | Loss_d: 6.2466e-05 Loss_e: 3.3106e-05 | Loss_b: 1.5826e-05\n",
      "Step: NaN | Loss: 1.8638e-06 | Loss_d: 6.2614e-05 Loss_e: 3.2994e-05 | Loss_b: 1.6062e-05\n",
      "Step: NaN | Loss: 1.8592e-06 | Loss_d: 6.2479e-05 Loss_e: 3.3094e-05 | Loss_b: 1.5822e-05\n",
      "Step: NaN | Loss: 1.8588e-06 | Loss_d: 6.2493e-05 Loss_e: 3.3070e-05 | Loss_b: 1.5806e-05\n",
      "Step: NaN | Loss: 1.8576e-06 | Loss_d: 6.2552e-05 Loss_e: 3.2989e-05 | Loss_b: 1.5754e-05\n",
      "Step: NaN | Loss: 1.8606e-06 | Loss_d: 6.2877e-05 Loss_e: 3.2878e-05 | Loss_b: 1.5723e-05\n",
      "Step: NaN | Loss: 1.8568e-06 | Loss_d: 6.2645e-05 Loss_e: 3.2903e-05 | Loss_b: 1.5703e-05\n",
      "Step: NaN | Loss: 1.8554e-06 | Loss_d: 6.2634e-05 Loss_e: 3.2879e-05 | Loss_b: 1.5652e-05\n",
      "Step: NaN | Loss: 1.8599e-06 | Loss_d: 6.2700e-05 Loss_e: 3.2954e-05 | Loss_b: 1.5779e-05\n",
      "Step: NaN | Loss: 1.8550e-06 | Loss_d: 6.2634e-05 Loss_e: 3.2871e-05 | Loss_b: 1.5634e-05\n",
      "Step: NaN | Loss: 1.8534e-06 | Loss_d: 6.2671e-05 Loss_e: 3.2746e-05 | Loss_b: 1.5631e-05\n",
      "Step: NaN | Loss: 1.8581e-06 | Loss_d: 6.2917e-05 Loss_e: 3.2555e-05 | Loss_b: 1.5854e-05\n",
      "Step: NaN | Loss: 1.8530e-06 | Loss_d: 6.2714e-05 Loss_e: 3.2657e-05 | Loss_b: 1.5648e-05\n",
      "Step: NaN | Loss: 1.8519e-06 | Loss_d: 6.2692e-05 Loss_e: 3.2583e-05 | Loss_b: 1.5679e-05\n",
      "Step: NaN | Loss: 1.8510e-06 | Loss_d: 6.2629e-05 Loss_e: 3.2334e-05 | Loss_b: 1.5941e-05\n",
      "Step: NaN | Loss: 1.8507e-06 | Loss_d: 6.2647e-05 Loss_e: 3.2413e-05 | Loss_b: 1.5823e-05\n",
      "Step: NaN | Loss: 1.8480e-06 | Loss_d: 6.2610e-05 Loss_e: 3.2316e-05 | Loss_b: 1.5798e-05\n",
      "Step: NaN | Loss: 1.8665e-06 | Loss_d: 6.3001e-05 Loss_e: 3.2220e-05 | Loss_b: 1.6610e-05\n",
      "Step: NaN | Loss: 1.8478e-06 | Loss_d: 6.2611e-05 Loss_e: 3.2285e-05 | Loss_b: 1.5815e-05\n",
      "Step: NaN | Loss: 1.8455e-06 | Loss_d: 6.2410e-05 Loss_e: 3.2246e-05 | Loss_b: 1.5918e-05\n",
      "Step: NaN | Loss: 1.8722e-06 | Loss_d: 6.1890e-05 Loss_e: 3.2779e-05 | Loss_b: 1.7503e-05\n",
      "Step: NaN | Loss: 1.8455e-06 | Loss_d: 6.2385e-05 Loss_e: 3.2246e-05 | Loss_b: 1.5941e-05\n",
      "Step: NaN | Loss: 1.8449e-06 | Loss_d: 6.2346e-05 Loss_e: 3.2266e-05 | Loss_b: 1.5922e-05\n",
      "Step: NaN | Loss: 1.8533e-06 | Loss_d: 6.2246e-05 Loss_e: 3.2575e-05 | Loss_b: 1.6216e-05\n",
      "Step: NaN | Loss: 1.8449e-06 | Loss_d: 6.2343e-05 Loss_e: 3.2269e-05 | Loss_b: 1.5922e-05\n",
      "Step: NaN | Loss: 1.8446e-06 | Loss_d: 6.2352e-05 Loss_e: 3.2247e-05 | Loss_b: 1.5917e-05\n",
      "Step: NaN | Loss: 1.8437e-06 | Loss_d: 6.2395e-05 Loss_e: 3.2167e-05 | Loss_b: 1.5902e-05\n",
      "Step: NaN | Loss: 1.8458e-06 | Loss_d: 6.2675e-05 Loss_e: 3.1974e-05 | Loss_b: 1.5943e-05\n",
      "Step: NaN | Loss: 1.8432e-06 | Loss_d: 6.2467e-05 Loss_e: 3.2072e-05 | Loss_b: 1.5895e-05\n",
      "Step: NaN | Loss: 1.8424e-06 | Loss_d: 6.2435e-05 Loss_e: 3.2050e-05 | Loss_b: 1.5901e-05\n",
      "Step: NaN | Loss: 1.8424e-06 | Loss_d: 6.2360e-05 Loss_e: 3.1997e-05 | Loss_b: 1.6031e-05\n",
      "Step: NaN | Loss: 1.8418e-06 | Loss_d: 6.2388e-05 Loss_e: 3.2017e-05 | Loss_b: 1.5945e-05\n",
      "Step: NaN | Loss: 1.8403e-06 | Loss_d: 6.2549e-05 Loss_e: 3.1794e-05 | Loss_b: 1.5917e-05\n",
      "Step: NaN | Loss: 1.8403e-06 | Loss_d: 6.2536e-05 Loss_e: 3.1808e-05 | Loss_b: 1.5916e-05\n",
      "Step: NaN | Loss: 1.8388e-06 | Loss_d: 6.2669e-05 Loss_e: 3.1739e-05 | Loss_b: 1.5760e-05\n",
      "Step: NaN | Loss: 1.8387e-06 | Loss_d: 6.2643e-05 Loss_e: 3.1747e-05 | Loss_b: 1.5773e-05\n",
      "Step: NaN | Loss: 1.8378e-06 | Loss_d: 6.2629e-05 Loss_e: 3.1792e-05 | Loss_b: 1.5688e-05\n",
      "Step: NaN | Loss: 1.8425e-06 | Loss_d: 6.2654e-05 Loss_e: 3.2087e-05 | Loss_b: 1.5649e-05\n",
      "Step: NaN | Loss: 1.8376e-06 | Loss_d: 6.2625e-05 Loss_e: 3.1824e-05 | Loss_b: 1.5651e-05\n",
      "Step: NaN | Loss: 1.8373e-06 | Loss_d: 6.2618e-05 Loss_e: 3.1807e-05 | Loss_b: 1.5657e-05\n",
      "Step: NaN | Loss: 1.8363e-06 | Loss_d: 6.2590e-05 Loss_e: 3.1741e-05 | Loss_b: 1.5689e-05\n",
      "Step: NaN | Loss: 1.8366e-06 | Loss_d: 6.2522e-05 Loss_e: 3.1486e-05 | Loss_b: 1.6030e-05\n",
      "Step: NaN | Loss: 1.8353e-06 | Loss_d: 6.2544e-05 Loss_e: 3.1606e-05 | Loss_b: 1.5812e-05\n",
      "Step: NaN | Loss: 1.8321e-06 | Loss_d: 6.2290e-05 Loss_e: 3.1714e-05 | Loss_b: 1.5764e-05\n",
      "Step: NaN | Loss: 1.8683e-06 | Loss_d: 6.1556e-05 Loss_e: 3.3399e-05 | Loss_b: 1.6986e-05\n",
      "Step: NaN | Loss: 1.8320e-06 | Loss_d: 6.2251e-05 Loss_e: 3.1743e-05 | Loss_b: 1.5769e-05\n",
      "Step: NaN | Loss: 1.8312e-06 | Loss_d: 6.2157e-05 Loss_e: 3.1787e-05 | Loss_b: 1.5773e-05\n",
      "Step: NaN | Loss: 1.8350e-06 | Loss_d: 6.1830e-05 Loss_e: 3.2082e-05 | Loss_b: 1.6032e-05\n",
      "Step: NaN | Loss: 1.8311e-06 | Loss_d: 6.2099e-05 Loss_e: 3.1821e-05 | Loss_b: 1.5788e-05\n",
      "Step: NaN | Loss: 1.8297e-06 | Loss_d: 6.2185e-05 Loss_e: 3.1709e-05 | Loss_b: 1.5732e-05\n",
      "Step: NaN | Loss: 1.8314e-06 | Loss_d: 6.2596e-05 Loss_e: 3.1403e-05 | Loss_b: 1.5729e-05\n",
      "Step: NaN | Loss: 1.8290e-06 | Loss_d: 6.2318e-05 Loss_e: 3.1573e-05 | Loss_b: 1.5690e-05\n",
      "Step: NaN | Loss: 1.8264e-06 | Loss_d: 6.2353e-05 Loss_e: 3.1502e-05 | Loss_b: 1.5574e-05\n",
      "Step: NaN | Loss: 1.8210e-06 | Loss_d: 6.2526e-05 Loss_e: 3.1284e-05 | Loss_b: 1.5291e-05\n",
      "Step: NaN | Loss: 1.9025e-06 | Loss_d: 6.4216e-05 Loss_e: 3.1798e-05 | Loss_b: 1.7972e-05\n",
      "Step: NaN | Loss: 1.8208e-06 | Loss_d: 6.2575e-05 Loss_e: 3.1248e-05 | Loss_b: 1.5267e-05\n",
      "Step: NaN | Loss: 1.8145e-06 | Loss_d: 6.2794e-05 Loss_e: 3.0797e-05 | Loss_b: 1.5125e-05\n",
      "Step: NaN | Loss: 1.8172e-06 | Loss_d: 6.4045e-05 Loss_e: 2.9804e-05 | Loss_b: 1.5025e-05\n",
      "Step: NaN | Loss: 1.8103e-06 | Loss_d: 6.3273e-05 Loss_e: 3.0198e-05 | Loss_b: 1.4992e-05\n",
      "Step: NaN | Loss: 1.8067e-06 | Loss_d: 6.3247e-05 Loss_e: 3.0037e-05 | Loss_b: 1.4964e-05\n",
      "Step: NaN | Loss: 1.8012e-06 | Loss_d: 6.3252e-05 Loss_e: 2.9606e-05 | Loss_b: 1.5062e-05\n",
      "Step: NaN | Loss: 1.8012e-06 | Loss_d: 6.3243e-05 Loss_e: 2.9638e-05 | Loss_b: 1.5034e-05\n",
      "Step: NaN | Loss: 1.8004e-06 | Loss_d: 6.3173e-05 Loss_e: 2.9478e-05 | Loss_b: 1.5220e-05\n",
      "Step: NaN | Loss: 1.7988e-06 | Loss_d: 6.3184e-05 Loss_e: 2.9503e-05 | Loss_b: 1.5089e-05\n",
      "Step: NaN | Loss: 1.7974e-06 | Loss_d: 6.3202e-05 Loss_e: 2.9374e-05 | Loss_b: 1.5113e-05\n",
      "Step: NaN | Loss: 1.8194e-06 | Loss_d: 6.3694e-05 Loss_e: 2.9134e-05 | Loss_b: 1.6181e-05\n",
      "Step: NaN | Loss: 1.7974e-06 | Loss_d: 6.3203e-05 Loss_e: 2.9372e-05 | Loss_b: 1.5115e-05\n",
      "Step: NaN | Loss: 1.7964e-06 | Loss_d: 6.3163e-05 Loss_e: 2.9353e-05 | Loss_b: 1.5115e-05\n",
      "Step: NaN | Loss: 1.7947e-06 | Loss_d: 6.3020e-05 Loss_e: 2.9323e-05 | Loss_b: 1.5187e-05\n",
      "Step: NaN | Loss: 1.7947e-06 | Loss_d: 6.3021e-05 Loss_e: 2.9323e-05 | Loss_b: 1.5185e-05\n",
      "Step: NaN | Loss: 1.7918e-06 | Loss_d: 6.3032e-05 Loss_e: 2.9165e-05 | Loss_b: 1.5158e-05\n",
      "Step: NaN | Loss: 1.8106e-06 | Loss_d: 6.3197e-05 Loss_e: 2.8928e-05 | Loss_b: 1.6356e-05\n",
      "Step: NaN | Loss: 1.7915e-06 | Loss_d: 6.3041e-05 Loss_e: 2.9106e-05 | Loss_b: 1.5189e-05\n",
      "Step: NaN | Loss: 1.7907e-06 | Loss_d: 6.3118e-05 Loss_e: 2.9002e-05 | Loss_b: 1.5169e-05\n",
      "Step: NaN | Loss: 1.7944e-06 | Loss_d: 6.3482e-05 Loss_e: 2.8625e-05 | Loss_b: 1.5403e-05\n",
      "Step: NaN | Loss: 1.7906e-06 | Loss_d: 6.3172e-05 Loss_e: 2.8934e-05 | Loss_b: 1.5173e-05\n",
      "Step: NaN | Loss: 1.7900e-06 | Loss_d: 6.3167e-05 Loss_e: 2.8918e-05 | Loss_b: 1.5159e-05\n",
      "Step: NaN | Loss: 1.7896e-06 | Loss_d: 6.3163e-05 Loss_e: 2.8877e-05 | Loss_b: 1.5184e-05\n",
      "Step: NaN | Loss: 1.7894e-06 | Loss_d: 6.3162e-05 Loss_e: 2.8889e-05 | Loss_b: 1.5159e-05\n",
      "Step: NaN | Loss: 1.7884e-06 | Loss_d: 6.3231e-05 Loss_e: 2.8842e-05 | Loss_b: 1.5078e-05\n",
      "Step: NaN | Loss: 1.7878e-06 | Loss_d: 6.3546e-05 Loss_e: 2.8704e-05 | Loss_b: 1.4867e-05\n",
      "Step: NaN | Loss: 1.7874e-06 | Loss_d: 6.3416e-05 Loss_e: 2.8749e-05 | Loss_b: 1.4928e-05\n",
      "Step: NaN | Loss: 1.7867e-06 | Loss_d: 6.3379e-05 Loss_e: 2.8724e-05 | Loss_b: 1.4943e-05\n",
      "Step: NaN | Loss: 1.7853e-06 | Loss_d: 6.3243e-05 Loss_e: 2.8682e-05 | Loss_b: 1.5042e-05\n",
      "Step: NaN | Loss: 1.7853e-06 | Loss_d: 6.3248e-05 Loss_e: 2.8681e-05 | Loss_b: 1.5037e-05\n",
      "Step: NaN | Loss: 1.7842e-06 | Loss_d: 6.3242e-05 Loss_e: 2.8563e-05 | Loss_b: 1.5092e-05\n",
      "Step: NaN | Loss: 1.7885e-06 | Loss_d: 6.3327e-05 Loss_e: 2.8143e-05 | Loss_b: 1.5689e-05\n",
      "Step: NaN | Loss: 1.7839e-06 | Loss_d: 6.3244e-05 Loss_e: 2.8473e-05 | Loss_b: 1.5163e-05\n",
      "Step: NaN | Loss: 1.7835e-06 | Loss_d: 6.3312e-05 Loss_e: 2.8416e-05 | Loss_b: 1.5126e-05\n",
      "Step: NaN | Loss: 1.7828e-06 | Loss_d: 6.3598e-05 Loss_e: 2.8208e-05 | Loss_b: 1.5008e-05\n",
      "Step: NaN | Loss: 1.7828e-06 | Loss_d: 6.3559e-05 Loss_e: 2.8233e-05 | Loss_b: 1.5020e-05\n",
      "Step: NaN | Loss: 1.7816e-06 | Loss_d: 6.3549e-05 Loss_e: 2.8177e-05 | Loss_b: 1.5015e-05\n",
      "Step: NaN | Loss: 1.7816e-06 | Loss_d: 6.3530e-05 Loss_e: 2.8035e-05 | Loss_b: 1.5180e-05\n",
      "Step: NaN | Loss: 1.7806e-06 | Loss_d: 6.3536e-05 Loss_e: 2.8092e-05 | Loss_b: 1.5058e-05\n",
      "Step: NaN | Loss: 1.7799e-06 | Loss_d: 6.3414e-05 Loss_e: 2.8141e-05 | Loss_b: 1.5086e-05\n",
      "Step: NaN | Loss: 1.7790e-06 | Loss_d: 6.2958e-05 Loss_e: 2.8398e-05 | Loss_b: 1.5231e-05\n",
      "Step: NaN | Loss: 1.7789e-06 | Loss_d: 6.3051e-05 Loss_e: 2.8335e-05 | Loss_b: 1.5196e-05\n",
      "Step: NaN | Loss: 1.7780e-06 | Loss_d: 6.3058e-05 Loss_e: 2.8312e-05 | Loss_b: 1.5160e-05\n",
      "Step: NaN | Loss: 1.7764e-06 | Loss_d: 6.3098e-05 Loss_e: 2.8248e-05 | Loss_b: 1.5083e-05\n",
      "Step: NaN | Loss: 1.8083e-06 | Loss_d: 6.3578e-05 Loss_e: 2.8606e-05 | Loss_b: 1.6160e-05\n",
      "Step: NaN | Loss: 1.7763e-06 | Loss_d: 6.3104e-05 Loss_e: 2.8243e-05 | Loss_b: 1.5081e-05\n",
      "Step: NaN | Loss: 1.7756e-06 | Loss_d: 6.2955e-05 Loss_e: 2.8333e-05 | Loss_b: 1.5097e-05\n",
      "Step: NaN | Loss: 1.7828e-06 | Loss_d: 6.2444e-05 Loss_e: 2.8806e-05 | Loss_b: 1.5564e-05\n",
      "Step: NaN | Loss: 1.7756e-06 | Loss_d: 6.2923e-05 Loss_e: 2.8354e-05 | Loss_b: 1.5107e-05\n",
      "Step: NaN | Loss: 1.7755e-06 | Loss_d: 6.2925e-05 Loss_e: 2.8335e-05 | Loss_b: 1.5119e-05\n",
      "Step: NaN | Loss: 1.7758e-06 | Loss_d: 6.2935e-05 Loss_e: 2.8267e-05 | Loss_b: 1.5193e-05\n",
      "Step: NaN | Loss: 1.7755e-06 | Loss_d: 6.2927e-05 Loss_e: 2.8317e-05 | Loss_b: 1.5132e-05\n",
      "Step: NaN | Loss: 1.7752e-06 | Loss_d: 6.2927e-05 Loss_e: 2.8271e-05 | Loss_b: 1.5163e-05\n",
      "Step: NaN | Loss: 1.7770e-06 | Loss_d: 6.2940e-05 Loss_e: 2.8106e-05 | Loss_b: 1.5423e-05\n",
      "Step: NaN | Loss: 1.7752e-06 | Loss_d: 6.2927e-05 Loss_e: 2.8255e-05 | Loss_b: 1.5178e-05\n",
      "Step: NaN | Loss: 1.7748e-06 | Loss_d: 6.2930e-05 Loss_e: 2.8235e-05 | Loss_b: 1.5173e-05\n",
      "Step: NaN | Loss: 1.7739e-06 | Loss_d: 6.2944e-05 Loss_e: 2.8168e-05 | Loss_b: 1.5169e-05\n",
      "Step: NaN | Loss: 1.7811e-06 | Loss_d: 6.3089e-05 Loss_e: 2.8175e-05 | Loss_b: 1.5449e-05\n",
      "Step: NaN | Loss: 1.7737e-06 | Loss_d: 6.2957e-05 Loss_e: 2.8136e-05 | Loss_b: 1.5178e-05\n",
      "Step: NaN | Loss: 1.7703e-06 | Loss_d: 6.2788e-05 Loss_e: 2.8113e-05 | Loss_b: 1.5165e-05\n",
      "Step: NaN | Loss: 1.7799e-06 | Loss_d: 6.2562e-05 Loss_e: 2.8310e-05 | Loss_b: 1.5771e-05\n",
      "Step: NaN | Loss: 1.7692e-06 | Loss_d: 6.2668e-05 Loss_e: 2.8118e-05 | Loss_b: 1.5216e-05\n",
      "Step: NaN | Loss: 1.7663e-06 | Loss_d: 6.2636e-05 Loss_e: 2.7983e-05 | Loss_b: 1.5207e-05\n",
      "Step: NaN | Loss: 1.7872e-06 | Loss_d: 6.2964e-05 Loss_e: 2.8628e-05 | Loss_b: 1.5485e-05\n",
      "Step: NaN | Loss: 1.7660e-06 | Loss_d: 6.2636e-05 Loss_e: 2.7962e-05 | Loss_b: 1.5212e-05\n",
      "Step: NaN | Loss: 1.7660e-06 | Loss_d: 6.2759e-05 Loss_e: 2.7775e-05 | Loss_b: 1.5276e-05\n",
      "Step: NaN | Loss: 1.7654e-06 | Loss_d: 6.2696e-05 Loss_e: 2.7861e-05 | Loss_b: 1.5215e-05\n",
      "Step: NaN | Loss: 1.7648e-06 | Loss_d: 6.2717e-05 Loss_e: 2.7841e-05 | Loss_b: 1.5176e-05\n",
      "Step: NaN | Loss: 1.7653e-06 | Loss_d: 6.2810e-05 Loss_e: 2.7861e-05 | Loss_b: 1.5095e-05\n",
      "Step: NaN | Loss: 1.7644e-06 | Loss_d: 6.2751e-05 Loss_e: 2.7830e-05 | Loss_b: 1.5131e-05\n",
      "Step: NaN | Loss: 1.7638e-06 | Loss_d: 6.2631e-05 Loss_e: 2.7868e-05 | Loss_b: 1.5180e-05\n",
      "Step: NaN | Loss: 1.7658e-06 | Loss_d: 6.2229e-05 Loss_e: 2.8097e-05 | Loss_b: 1.5472e-05\n",
      "Step: NaN | Loss: 1.7637e-06 | Loss_d: 6.2540e-05 Loss_e: 2.7904e-05 | Loss_b: 1.5227e-05\n",
      "Step: NaN | Loss: 1.7632e-06 | Loss_d: 6.2265e-05 Loss_e: 2.8015e-05 | Loss_b: 1.5362e-05\n",
      "Step: NaN | Loss: 1.7632e-06 | Loss_d: 6.2266e-05 Loss_e: 2.8015e-05 | Loss_b: 1.5361e-05\n",
      "Step: NaN | Loss: 1.7627e-06 | Loss_d: 6.2254e-05 Loss_e: 2.8014e-05 | Loss_b: 1.5345e-05\n",
      "Step: NaN | Loss: 1.7616e-06 | Loss_d: 6.2214e-05 Loss_e: 2.8022e-05 | Loss_b: 1.5311e-05\n",
      "Step: NaN | Loss: 1.7764e-06 | Loss_d: 6.2179e-05 Loss_e: 2.8380e-05 | Loss_b: 1.5871e-05\n",
      "Step: NaN | Loss: 1.7616e-06 | Loss_d: 6.2204e-05 Loss_e: 2.8028e-05 | Loss_b: 1.5311e-05\n",
      "Step: NaN | Loss: 1.7610e-06 | Loss_d: 6.2176e-05 Loss_e: 2.8035e-05 | Loss_b: 1.5300e-05\n",
      "Step: NaN | Loss: 1.7607e-06 | Loss_d: 6.2075e-05 Loss_e: 2.8093e-05 | Loss_b: 1.5323e-05\n",
      "Step: NaN | Loss: 1.7605e-06 | Loss_d: 6.2112e-05 Loss_e: 2.8066e-05 | Loss_b: 1.5301e-05\n",
      "Step: NaN | Loss: 1.7598e-06 | Loss_d: 6.2122e-05 Loss_e: 2.7978e-05 | Loss_b: 1.5336e-05\n",
      "Step: NaN | Loss: 1.7615e-06 | Loss_d: 6.2190e-05 Loss_e: 2.7712e-05 | Loss_b: 1.5637e-05\n",
      "Step: NaN | Loss: 1.7595e-06 | Loss_d: 6.2136e-05 Loss_e: 2.7895e-05 | Loss_b: 1.5391e-05\n",
      "Step: NaN | Loss: 1.7797e-06 | Loss_d: 6.1249e-05 Loss_e: 2.8163e-05 | Loss_b: 1.7215e-05\n",
      "Step: NaN | Loss: 1.7591e-06 | Loss_d: 6.2014e-05 Loss_e: 2.7901e-05 | Loss_b: 1.5480e-05\n",
      "Step: NaN | Loss: 1.7587e-06 | Loss_d: 6.1994e-05 Loss_e: 2.7909e-05 | Loss_b: 1.5470e-05\n",
      "Step: NaN | Loss: 1.7583e-06 | Loss_d: 6.1922e-05 Loss_e: 2.7953e-05 | Loss_b: 1.5471e-05\n",
      "Step: NaN | Loss: 1.7583e-06 | Loss_d: 6.1936e-05 Loss_e: 2.7943e-05 | Loss_b: 1.5466e-05\n",
      "Step: NaN | Loss: 1.7576e-06 | Loss_d: 6.1870e-05 Loss_e: 2.7979e-05 | Loss_b: 1.5455e-05\n",
      "Step: NaN | Loss: 1.7671e-06 | Loss_d: 6.1649e-05 Loss_e: 2.8323e-05 | Loss_b: 1.5905e-05\n",
      "Step: NaN | Loss: 1.7576e-06 | Loss_d: 6.1867e-05 Loss_e: 2.7981e-05 | Loss_b: 1.5456e-05\n",
      "Step: NaN | Loss: 1.7570e-06 | Loss_d: 6.1920e-05 Loss_e: 2.7923e-05 | Loss_b: 1.5424e-05\n",
      "Step: NaN | Loss: 1.7564e-06 | Loss_d: 6.2148e-05 Loss_e: 2.7731e-05 | Loss_b: 1.5356e-05\n",
      "Step: NaN | Loss: 1.7563e-06 | Loss_d: 6.2069e-05 Loss_e: 2.7788e-05 | Loss_b: 1.5368e-05\n",
      "Step: NaN | Loss: 1.7557e-06 | Loss_d: 6.2021e-05 Loss_e: 2.7784e-05 | Loss_b: 1.5387e-05\n",
      "Step: NaN | Loss: 1.7542e-06 | Loss_d: 6.1844e-05 Loss_e: 2.7778e-05 | Loss_b: 1.5482e-05\n",
      "Step: NaN | Loss: 1.7628e-06 | Loss_d: 6.1292e-05 Loss_e: 2.7983e-05 | Loss_b: 1.6342e-05\n",
      "Step: NaN | Loss: 1.7538e-06 | Loss_d: 6.1704e-05 Loss_e: 2.7785e-05 | Loss_b: 1.5589e-05\n",
      "Step: NaN | Loss: 1.7516e-06 | Loss_d: 6.1790e-05 Loss_e: 2.7672e-05 | Loss_b: 1.5483e-05\n",
      "Step: NaN | Loss: 1.7503e-06 | Loss_d: 6.2314e-05 Loss_e: 2.7363e-05 | Loss_b: 1.5189e-05\n",
      "Step: NaN | Loss: 1.7493e-06 | Loss_d: 6.2076e-05 Loss_e: 2.7455e-05 | Loss_b: 1.5278e-05\n",
      "Step: NaN | Loss: 1.7472e-06 | Loss_d: 6.2084e-05 Loss_e: 2.7386e-05 | Loss_b: 1.5210e-05\n",
      "Step: NaN | Loss: 1.7471e-06 | Loss_d: 6.2082e-05 Loss_e: 2.7388e-05 | Loss_b: 1.5209e-05\n",
      "Step: NaN | Loss: 1.7458e-06 | Loss_d: 6.2294e-05 Loss_e: 2.7246e-05 | Loss_b: 1.5056e-05\n",
      "Step: NaN | Loss: 1.7578e-06 | Loss_d: 6.3356e-05 Loss_e: 2.7037e-05 | Loss_b: 1.4925e-05\n",
      "Step: NaN | Loss: 1.7457e-06 | Loss_d: 6.2359e-05 Loss_e: 2.7212e-05 | Loss_b: 1.5021e-05\n",
      "Step: NaN | Loss: 1.7452e-06 | Loss_d: 6.2279e-05 Loss_e: 2.7223e-05 | Loss_b: 1.5059e-05\n",
      "Step: NaN | Loss: 1.7475e-06 | Loss_d: 6.1975e-05 Loss_e: 2.7284e-05 | Loss_b: 1.5441e-05\n",
      "Step: NaN | Loss: 1.7451e-06 | Loss_d: 6.2225e-05 Loss_e: 2.7232e-05 | Loss_b: 1.5097e-05\n",
      "Step: NaN | Loss: 1.7446e-06 | Loss_d: 6.2218e-05 Loss_e: 2.7218e-05 | Loss_b: 1.5091e-05\n",
      "Step: NaN | Loss: 1.7431e-06 | Loss_d: 6.2195e-05 Loss_e: 2.7169e-05 | Loss_b: 1.5070e-05\n",
      "Step: NaN | Loss: 1.7408e-06 | Loss_d: 6.2156e-05 Loss_e: 2.7039e-05 | Loss_b: 1.5106e-05\n",
      "Step: NaN | Loss: 1.7405e-06 | Loss_d: 6.2153e-05 Loss_e: 2.7055e-05 | Loss_b: 1.5075e-05\n",
      "Step: NaN | Loss: 1.7385e-06 | Loss_d: 6.2145e-05 Loss_e: 2.6845e-05 | Loss_b: 1.5170e-05\n",
      "Step: NaN | Loss: 1.7382e-06 | Loss_d: 6.2134e-05 Loss_e: 2.6882e-05 | Loss_b: 1.5127e-05\n",
      "Step: NaN | Loss: 1.7384e-06 | Loss_d: 6.1882e-05 Loss_e: 2.6963e-05 | Loss_b: 1.5310e-05\n",
      "Step: NaN | Loss: 1.7378e-06 | Loss_d: 6.2020e-05 Loss_e: 2.6914e-05 | Loss_b: 1.5185e-05\n",
      "Step: NaN | Loss: 1.7374e-06 | Loss_d: 6.2023e-05 Loss_e: 2.6902e-05 | Loss_b: 1.5168e-05\n",
      "Step: NaN | Loss: 1.7368e-06 | Loss_d: 6.2052e-05 Loss_e: 2.6875e-05 | Loss_b: 1.5135e-05\n",
      "Step: NaN | Loss: 1.7368e-06 | Loss_d: 6.2044e-05 Loss_e: 2.6878e-05 | Loss_b: 1.5138e-05\n",
      "Step: NaN | Loss: 1.7390e-06 | Loss_d: 6.2197e-05 Loss_e: 2.6798e-05 | Loss_b: 1.5194e-05\n",
      "Step: NaN | Loss: 1.7360e-06 | Loss_d: 6.2087e-05 Loss_e: 2.6830e-05 | Loss_b: 1.5092e-05\n",
      "Step: NaN | Loss: 1.7338e-06 | Loss_d: 6.2016e-05 Loss_e: 2.6835e-05 | Loss_b: 1.5026e-05\n",
      "Step: NaN | Loss: 1.7319e-06 | Loss_d: 6.1814e-05 Loss_e: 2.6934e-05 | Loss_b: 1.5018e-05\n",
      "Step: NaN | Loss: 1.7313e-06 | Loss_d: 6.1869e-05 Loss_e: 2.6885e-05 | Loss_b: 1.4973e-05\n",
      "Step: NaN | Loss: 1.7300e-06 | Loss_d: 6.2002e-05 Loss_e: 2.6769e-05 | Loss_b: 1.4880e-05\n",
      "Step: NaN | Loss: 1.7405e-06 | Loss_d: 6.2615e-05 Loss_e: 2.6526e-05 | Loss_b: 1.5137e-05\n",
      "Step: NaN | Loss: 1.7299e-06 | Loss_d: 6.2046e-05 Loss_e: 2.6736e-05 | Loss_b: 1.4864e-05\n",
      "Step: NaN | Loss: 1.7288e-06 | Loss_d: 6.1967e-05 Loss_e: 2.6700e-05 | Loss_b: 1.4913e-05\n",
      "Step: NaN | Loss: 1.7267e-06 | Loss_d: 6.1683e-05 Loss_e: 2.6571e-05 | Loss_b: 1.5201e-05\n",
      "Step: NaN | Loss: 1.7732e-06 | Loss_d: 6.1084e-05 Loss_e: 2.6280e-05 | Loss_b: 1.8876e-05\n",
      "Step: NaN | Loss: 1.7267e-06 | Loss_d: 6.1672e-05 Loss_e: 2.6565e-05 | Loss_b: 1.5219e-05\n",
      "Step: NaN | Loss: 1.7234e-06 | Loss_d: 6.1748e-05 Loss_e: 2.6341e-05 | Loss_b: 1.5165e-05\n",
      "Step: NaN | Loss: 1.7154e-06 | Loss_d: 6.2127e-05 Loss_e: 2.5565e-05 | Loss_b: 1.5085e-05\n",
      "Step: NaN | Loss: 1.8121e-06 | Loss_d: 6.5801e-05 Loss_e: 2.4661e-05 | Loss_b: 1.8106e-05\n",
      "Step: NaN | Loss: 1.7147e-06 | Loss_d: 6.2302e-05 Loss_e: 2.5322e-05 | Loss_b: 1.5111e-05\n",
      "Step: NaN | Loss: 1.7132e-06 | Loss_d: 6.2356e-05 Loss_e: 2.5216e-05 | Loss_b: 1.5071e-05\n",
      "Step: NaN | Loss: 1.7148e-06 | Loss_d: 6.2770e-05 Loss_e: 2.4928e-05 | Loss_b: 1.5045e-05\n",
      "Step: NaN | Loss: 1.7124e-06 | Loss_d: 6.2472e-05 Loss_e: 2.5085e-05 | Loss_b: 1.5038e-05\n",
      "Step: NaN | Loss: 1.7130e-06 | Loss_d: 6.2225e-05 Loss_e: 2.5079e-05 | Loss_b: 1.5332e-05\n",
      "Step: NaN | Loss: 1.7119e-06 | Loss_d: 6.2371e-05 Loss_e: 2.5072e-05 | Loss_b: 1.5122e-05\n",
      "Step: NaN | Loss: 1.7113e-06 | Loss_d: 6.2376e-05 Loss_e: 2.4994e-05 | Loss_b: 1.5161e-05\n",
      "Step: NaN | Loss: 1.7136e-06 | Loss_d: 6.2429e-05 Loss_e: 2.4830e-05 | Loss_b: 1.5411e-05\n",
      "Step: NaN | Loss: 1.7112e-06 | Loss_d: 6.2383e-05 Loss_e: 2.4946e-05 | Loss_b: 1.5195e-05\n",
      "Step: NaN | Loss: 1.7098e-06 | Loss_d: 6.2567e-05 Loss_e: 2.4787e-05 | Loss_b: 1.5087e-05\n",
      "Step: NaN | Loss: 1.7105e-06 | Loss_d: 6.3428e-05 Loss_e: 2.4228e-05 | Loss_b: 1.4826e-05\n",
      "Step: NaN | Loss: 1.7088e-06 | Loss_d: 6.2913e-05 Loss_e: 2.4532e-05 | Loss_b: 1.4940e-05\n",
      "Step: NaN | Loss: 1.7079e-06 | Loss_d: 6.2913e-05 Loss_e: 2.4412e-05 | Loss_b: 1.5002e-05\n",
      "Step: NaN | Loss: 1.7079e-06 | Loss_d: 6.2913e-05 Loss_e: 2.4422e-05 | Loss_b: 1.4992e-05\n",
      "Step: NaN | Loss: 1.7076e-06 | Loss_d: 6.3071e-05 Loss_e: 2.4330e-05 | Loss_b: 1.4908e-05\n",
      "Step: NaN | Loss: 1.7075e-06 | Loss_d: 6.3012e-05 Loss_e: 2.4360e-05 | Loss_b: 1.4930e-05\n",
      "Step: NaN | Loss: 1.7071e-06 | Loss_d: 6.3008e-05 Loss_e: 2.4355e-05 | Loss_b: 1.4914e-05\n",
      "Step: NaN | Loss: 1.7069e-06 | Loss_d: 6.3002e-05 Loss_e: 2.4360e-05 | Loss_b: 1.4903e-05\n",
      "Step: NaN | Loss: 1.7067e-06 | Loss_d: 6.3002e-05 Loss_e: 2.4354e-05 | Loss_b: 1.4897e-05\n",
      "Step: NaN | Loss: 1.7056e-06 | Loss_d: 6.2946e-05 Loss_e: 2.4361e-05 | Loss_b: 1.4885e-05\n",
      "Step: NaN | Loss: 1.7061e-06 | Loss_d: 6.2766e-05 Loss_e: 2.4449e-05 | Loss_b: 1.5005e-05\n",
      "Step: NaN | Loss: 1.7049e-06 | Loss_d: 6.2858e-05 Loss_e: 2.4387e-05 | Loss_b: 1.4904e-05\n",
      "Step: NaN | Loss: 1.7041e-06 | Loss_d: 6.2965e-05 Loss_e: 2.4297e-05 | Loss_b: 1.4839e-05\n",
      "Step: NaN | Loss: 1.7047e-06 | Loss_d: 6.3458e-05 Loss_e: 2.3983e-05 | Loss_b: 1.4694e-05\n",
      "Step: NaN | Loss: 1.7036e-06 | Loss_d: 6.3151e-05 Loss_e: 2.4160e-05 | Loss_b: 1.4757e-05\n",
      "Step: NaN | Loss: 1.7021e-06 | Loss_d: 6.3011e-05 Loss_e: 2.4124e-05 | Loss_b: 1.4844e-05\n",
      "Step: NaN | Loss: 1.7098e-06 | Loss_d: 6.2611e-05 Loss_e: 2.4183e-05 | Loss_b: 1.5646e-05\n",
      "Step: NaN | Loss: 1.7018e-06 | Loss_d: 6.2935e-05 Loss_e: 2.4112e-05 | Loss_b: 1.4917e-05\n",
      "Step: NaN | Loss: 1.7013e-06 | Loss_d: 6.2939e-05 Loss_e: 2.4110e-05 | Loss_b: 1.4884e-05\n",
      "Step: NaN | Loss: 1.7008e-06 | Loss_d: 6.2966e-05 Loss_e: 2.4113e-05 | Loss_b: 1.4823e-05\n",
      "Step: NaN | Loss: 1.7007e-06 | Loss_d: 6.2956e-05 Loss_e: 2.4111e-05 | Loss_b: 1.4829e-05\n",
      "Step: NaN | Loss: 1.6990e-06 | Loss_d: 6.2861e-05 Loss_e: 2.4127e-05 | Loss_b: 1.4806e-05\n",
      "Step: NaN | Loss: 1.7025e-06 | Loss_d: 6.2615e-05 Loss_e: 2.4334e-05 | Loss_b: 1.5058e-05\n",
      "Step: NaN | Loss: 1.6983e-06 | Loss_d: 6.2768e-05 Loss_e: 2.4163e-05 | Loss_b: 1.4823e-05\n",
      "Step: NaN | Loss: 1.7007e-06 | Loss_d: 6.2308e-05 Loss_e: 2.4297e-05 | Loss_b: 1.5288e-05\n",
      "Step: NaN | Loss: 1.6981e-06 | Loss_d: 6.2664e-05 Loss_e: 2.4189e-05 | Loss_b: 1.4889e-05\n",
      "Step: NaN | Loss: 1.6980e-06 | Loss_d: 6.2673e-05 Loss_e: 2.4175e-05 | Loss_b: 1.4887e-05\n",
      "Step: NaN | Loss: 1.6981e-06 | Loss_d: 6.2713e-05 Loss_e: 2.4127e-05 | Loss_b: 1.4898e-05\n",
      "Step: NaN | Loss: 1.6980e-06 | Loss_d: 6.2690e-05 Loss_e: 2.4152e-05 | Loss_b: 1.4889e-05\n",
      "Step: NaN | Loss: 1.6976e-06 | Loss_d: 6.2655e-05 Loss_e: 2.4140e-05 | Loss_b: 1.4913e-05\n",
      "Step: NaN | Loss: 1.6972e-06 | Loss_d: 6.2540e-05 Loss_e: 2.4104e-05 | Loss_b: 1.5042e-05\n",
      "Step: NaN | Loss: 1.6971e-06 | Loss_d: 6.2571e-05 Loss_e: 2.4113e-05 | Loss_b: 1.4996e-05\n",
      "Step: NaN | Loss: 1.6967e-06 | Loss_d: 6.2568e-05 Loss_e: 2.4119e-05 | Loss_b: 1.4969e-05\n",
      "Step: NaN | Loss: 1.6957e-06 | Loss_d: 6.2557e-05 Loss_e: 2.4162e-05 | Loss_b: 1.4879e-05\n",
      "Step: NaN | Loss: 1.7058e-06 | Loss_d: 6.2575e-05 Loss_e: 2.4819e-05 | Loss_b: 1.4808e-05\n",
      "Step: NaN | Loss: 1.6956e-06 | Loss_d: 6.2553e-05 Loss_e: 2.4193e-05 | Loss_b: 1.4845e-05\n",
      "Step: NaN | Loss: 1.6940e-06 | Loss_d: 6.2360e-05 Loss_e: 2.4221e-05 | Loss_b: 1.4912e-05\n",
      "Step: NaN | Loss: 1.6935e-06 | Loss_d: 6.1633e-05 Loss_e: 2.4528e-05 | Loss_b: 1.5303e-05\n",
      "Step: NaN | Loss: 1.6925e-06 | Loss_d: 6.1949e-05 Loss_e: 2.4353e-05 | Loss_b: 1.5105e-05\n",
      "Step: NaN | Loss: 1.6910e-06 | Loss_d: 6.1614e-05 Loss_e: 2.4488e-05 | Loss_b: 1.5216e-05\n",
      "Step: NaN | Loss: 1.6910e-06 | Loss_d: 6.1664e-05 Loss_e: 2.4464e-05 | Loss_b: 1.5188e-05\n",
      "Step: NaN | Loss: 1.6916e-06 | Loss_d: 6.1514e-05 Loss_e: 2.4460e-05 | Loss_b: 1.5379e-05\n",
      "Step: NaN | Loss: 1.6907e-06 | Loss_d: 6.1604e-05 Loss_e: 2.4457e-05 | Loss_b: 1.5234e-05\n",
      "Step: NaN | Loss: 1.6905e-06 | Loss_d: 6.1609e-05 Loss_e: 2.4454e-05 | Loss_b: 1.5222e-05\n",
      "Step: NaN | Loss: 1.6899e-06 | Loss_d: 6.1630e-05 Loss_e: 2.4444e-05 | Loss_b: 1.5175e-05\n",
      "Step: NaN | Loss: 1.6897e-06 | Loss_d: 6.1782e-05 Loss_e: 2.4436e-05 | Loss_b: 1.5020e-05\n",
      "Step: NaN | Loss: 1.6893e-06 | Loss_d: 6.1703e-05 Loss_e: 2.4432e-05 | Loss_b: 1.5075e-05\n",
      "Step: NaN | Loss: 1.6877e-06 | Loss_d: 6.1480e-05 Loss_e: 2.4527e-05 | Loss_b: 1.5109e-05\n",
      "Step: NaN | Loss: 1.6928e-06 | Loss_d: 6.0708e-05 Loss_e: 2.5141e-05 | Loss_b: 1.5575e-05\n",
      "Step: NaN | Loss: 1.6872e-06 | Loss_d: 6.1292e-05 Loss_e: 2.4630e-05 | Loss_b: 1.5167e-05\n",
      "Step: NaN | Loss: 1.6861e-06 | Loss_d: 6.1261e-05 Loss_e: 2.4640e-05 | Loss_b: 1.5123e-05\n",
      "Step: NaN | Loss: 1.6871e-06 | Loss_d: 6.1165e-05 Loss_e: 2.4743e-05 | Loss_b: 1.5173e-05\n",
      "Step: NaN | Loss: 1.6855e-06 | Loss_d: 6.1218e-05 Loss_e: 2.4668e-05 | Loss_b: 1.5099e-05\n",
      "Step: NaN | Loss: 1.6840e-06 | Loss_d: 6.1157e-05 Loss_e: 2.4706e-05 | Loss_b: 1.5031e-05\n",
      "Step: NaN | Loss: 1.6843e-06 | Loss_d: 6.0978e-05 Loss_e: 2.4950e-05 | Loss_b: 1.4989e-05\n",
      "Step: NaN | Loss: 1.6828e-06 | Loss_d: 6.1063e-05 Loss_e: 2.4796e-05 | Loss_b: 1.4963e-05\n",
      "Step: NaN | Loss: 1.6920e-06 | Loss_d: 6.1631e-05 Loss_e: 2.4738e-05 | Loss_b: 1.5008e-05\n",
      "Step: NaN | Loss: 1.6826e-06 | Loss_d: 6.1133e-05 Loss_e: 2.4782e-05 | Loss_b: 1.4895e-05\n",
      "Step: NaN | Loss: 1.6823e-06 | Loss_d: 6.1168e-05 Loss_e: 2.4745e-05 | Loss_b: 1.4879e-05\n",
      "Step: NaN | Loss: 1.6843e-06 | Loss_d: 6.1381e-05 Loss_e: 2.4659e-05 | Loss_b: 1.4876e-05\n",
      "Step: NaN | Loss: 1.6823e-06 | Loss_d: 6.1184e-05 Loss_e: 2.4732e-05 | Loss_b: 1.4876e-05\n",
      "Step: NaN | Loss: 1.6816e-06 | Loss_d: 6.1162e-05 Loss_e: 2.4714e-05 | Loss_b: 1.4875e-05\n",
      "Step: NaN | Loss: 1.6813e-06 | Loss_d: 6.1168e-05 Loss_e: 2.4717e-05 | Loss_b: 1.4851e-05\n",
      "Step: NaN | Loss: 1.6802e-06 | Loss_d: 6.1102e-05 Loss_e: 2.4703e-05 | Loss_b: 1.4864e-05\n",
      "Step: NaN | Loss: 1.6781e-06 | Loss_d: 6.0864e-05 Loss_e: 2.4685e-05 | Loss_b: 1.4993e-05\n",
      "Step: NaN | Loss: 1.7234e-06 | Loss_d: 6.0287e-05 Loss_e: 2.5498e-05 | Loss_b: 1.7472e-05\n",
      "Step: NaN | Loss: 1.6781e-06 | Loss_d: 6.0849e-05 Loss_e: 2.4686e-05 | Loss_b: 1.5007e-05\n",
      "Step: NaN | Loss: 1.6766e-06 | Loss_d: 6.0868e-05 Loss_e: 2.4609e-05 | Loss_b: 1.4973e-05\n",
      "Step: NaN | Loss: 1.6749e-06 | Loss_d: 6.0972e-05 Loss_e: 2.4394e-05 | Loss_b: 1.4984e-05\n",
      "Step: NaN | Loss: 1.6746e-06 | Loss_d: 6.0940e-05 Loss_e: 2.4436e-05 | Loss_b: 1.4958e-05\n",
      "Step: NaN | Loss: 1.6729e-06 | Loss_d: 6.0929e-05 Loss_e: 2.4441e-05 | Loss_b: 1.4863e-05\n",
      "Step: NaN | Loss: 1.6722e-06 | Loss_d: 6.0964e-05 Loss_e: 2.4552e-05 | Loss_b: 1.4672e-05\n",
      "Step: NaN | Loss: 1.6713e-06 | Loss_d: 6.0933e-05 Loss_e: 2.4484e-05 | Loss_b: 1.4716e-05\n",
      "Step: NaN | Loss: 1.6699e-06 | Loss_d: 6.0948e-05 Loss_e: 2.4384e-05 | Loss_b: 1.4719e-05\n",
      "Step: NaN | Loss: 1.6754e-06 | Loss_d: 6.1277e-05 Loss_e: 2.4190e-05 | Loss_b: 1.4911e-05\n",
      "Step: NaN | Loss: 1.6696e-06 | Loss_d: 6.0977e-05 Loss_e: 2.4323e-05 | Loss_b: 1.4733e-05\n",
      "Step: NaN | Loss: 1.6688e-06 | Loss_d: 6.0706e-05 Loss_e: 2.4362e-05 | Loss_b: 1.4917e-05\n",
      "Step: NaN | Loss: 1.6688e-06 | Loss_d: 6.0710e-05 Loss_e: 2.4362e-05 | Loss_b: 1.4913e-05\n",
      "Step: NaN | Loss: 1.6674e-06 | Loss_d: 6.0676e-05 Loss_e: 2.4312e-05 | Loss_b: 1.4912e-05\n",
      "Step: NaN | Loss: 1.6649e-06 | Loss_d: 6.0580e-05 Loss_e: 2.4180e-05 | Loss_b: 1.4990e-05\n",
      "Step: NaN | Loss: 1.6649e-06 | Loss_d: 6.0581e-05 Loss_e: 2.4180e-05 | Loss_b: 1.4988e-05\n",
      "Step: NaN | Loss: 1.6605e-06 | Loss_d: 6.0378e-05 Loss_e: 2.4028e-05 | Loss_b: 1.5084e-05\n",
      "Step: NaN | Loss: 1.6730e-06 | Loss_d: 5.9872e-05 Loss_e: 2.4379e-05 | Loss_b: 1.5984e-05\n",
      "Step: NaN | Loss: 1.6592e-06 | Loss_d: 6.0213e-05 Loss_e: 2.3972e-05 | Loss_b: 1.5223e-05\n",
      "Step: NaN | Loss: 1.6566e-06 | Loss_d: 5.9934e-05 Loss_e: 2.4073e-05 | Loss_b: 1.5248e-05\n",
      "Step: NaN | Loss: 1.6677e-06 | Loss_d: 5.9036e-05 Loss_e: 2.4818e-05 | Loss_b: 1.6067e-05\n",
      "Step: NaN | Loss: 1.6562e-06 | Loss_d: 5.9753e-05 Loss_e: 2.4162e-05 | Loss_b: 1.5315e-05\n",
      "Step: NaN | Loss: 1.6561e-06 | Loss_d: 5.9828e-05 Loss_e: 2.4262e-05 | Loss_b: 1.5132e-05\n",
      "Step: NaN | Loss: 1.6555e-06 | Loss_d: 5.9790e-05 Loss_e: 2.4209e-05 | Loss_b: 1.5188e-05\n",
      "Step: NaN | Loss: 1.6544e-06 | Loss_d: 5.9732e-05 Loss_e: 2.4205e-05 | Loss_b: 1.5186e-05\n",
      "Step: NaN | Loss: 1.6532e-06 | Loss_d: 5.9514e-05 Loss_e: 2.4231e-05 | Loss_b: 1.5307e-05\n",
      "Step: NaN | Loss: 1.6531e-06 | Loss_d: 5.9568e-05 Loss_e: 2.4219e-05 | Loss_b: 1.5256e-05\n",
      "Step: NaN | Loss: 1.6509e-06 | Loss_d: 5.9510e-05 Loss_e: 2.4189e-05 | Loss_b: 1.5215e-05\n",
      "Step: NaN | Loss: 1.6478e-06 | Loss_d: 5.9349e-05 Loss_e: 2.4141e-05 | Loss_b: 1.5235e-05\n",
      "Step: NaN | Loss: 1.6477e-06 | Loss_d: 5.9364e-05 Loss_e: 2.4141e-05 | Loss_b: 1.5215e-05\n",
      "Step: NaN | Loss: 1.6443e-06 | Loss_d: 5.9166e-05 Loss_e: 2.4119e-05 | Loss_b: 1.5230e-05\n",
      "Step: NaN | Loss: 1.6481e-06 | Loss_d: 5.8483e-05 Loss_e: 2.4260e-05 | Loss_b: 1.6001e-05\n",
      "Step: NaN | Loss: 1.6423e-06 | Loss_d: 5.8902e-05 Loss_e: 2.4127e-05 | Loss_b: 1.5370e-05\n",
      "Step: NaN | Loss: 1.6390e-06 | Loss_d: 5.8967e-05 Loss_e: 2.3987e-05 | Loss_b: 1.5245e-05\n",
      "Step: NaN | Loss: 1.6729e-06 | Loss_d: 5.9472e-05 Loss_e: 2.4511e-05 | Loss_b: 1.6248e-05\n",
      "Step: NaN | Loss: 1.6389e-06 | Loss_d: 5.8980e-05 Loss_e: 2.3974e-05 | Loss_b: 1.5240e-05\n",
      "Step: NaN | Loss: 1.6359e-06 | Loss_d: 5.8689e-05 Loss_e: 2.4027e-05 | Loss_b: 1.5298e-05\n",
      "Step: NaN | Loss: 1.6441e-06 | Loss_d: 5.7744e-05 Loss_e: 2.4518e-05 | Loss_b: 1.6245e-05\n",
      "Step: NaN | Loss: 1.6349e-06 | Loss_d: 5.8424e-05 Loss_e: 2.4106e-05 | Loss_b: 1.5425e-05\n",
      "Step: NaN | Loss: 1.6348e-06 | Loss_d: 5.8662e-05 Loss_e: 2.4260e-05 | Loss_b: 1.5026e-05\n",
      "Step: NaN | Loss: 1.6342e-06 | Loss_d: 5.8539e-05 Loss_e: 2.4181e-05 | Loss_b: 1.5191e-05\n",
      "Step: NaN | Loss: 1.6336e-06 | Loss_d: 5.8573e-05 Loss_e: 2.4156e-05 | Loss_b: 1.5147e-05\n",
      "Step: NaN | Loss: 1.6331e-06 | Loss_d: 5.8718e-05 Loss_e: 2.4084e-05 | Loss_b: 1.5044e-05\n",
      "Step: NaN | Loss: 1.6329e-06 | Loss_d: 5.8668e-05 Loss_e: 2.4103e-05 | Loss_b: 1.5064e-05\n",
      "Step: NaN | Loss: 1.6314e-06 | Loss_d: 5.8590e-05 Loss_e: 2.4091e-05 | Loss_b: 1.5061e-05\n",
      "Step: NaN | Loss: 1.6293e-06 | Loss_d: 5.8330e-05 Loss_e: 2.4181e-05 | Loss_b: 1.5109e-05\n",
      "Step: NaN | Loss: 1.6292e-06 | Loss_d: 5.8378e-05 Loss_e: 2.4142e-05 | Loss_b: 1.5090e-05\n",
      "Step: NaN | Loss: 1.6275e-06 | Loss_d: 5.8400e-05 Loss_e: 2.4115e-05 | Loss_b: 1.4997e-05\n",
      "Step: NaN | Loss: 1.6334e-06 | Loss_d: 5.8585e-05 Loss_e: 2.4310e-05 | Loss_b: 1.4971e-05\n",
      "Step: NaN | Loss: 1.6271e-06 | Loss_d: 5.8425e-05 Loss_e: 2.4115e-05 | Loss_b: 1.4946e-05\n",
      "Step: NaN | Loss: 1.6260e-06 | Loss_d: 5.8599e-05 Loss_e: 2.3725e-05 | Loss_b: 1.5097e-05\n",
      "Step: NaN | Loss: 1.6238e-06 | Loss_d: 5.8510e-05 Loss_e: 2.3825e-05 | Loss_b: 1.4954e-05\n",
      "Step: NaN | Loss: 1.6216e-06 | Loss_d: 5.8179e-05 Loss_e: 2.3773e-05 | Loss_b: 1.5205e-05\n",
      "Step: NaN | Loss: 1.6215e-06 | Loss_d: 5.8221e-05 Loss_e: 2.3777e-05 | Loss_b: 1.5156e-05\n",
      "Step: NaN | Loss: 1.6203e-06 | Loss_d: 5.8284e-05 Loss_e: 2.3788e-05 | Loss_b: 1.5010e-05\n",
      "Step: NaN | Loss: 1.6347e-06 | Loss_d: 5.8612e-05 Loss_e: 2.3995e-05 | Loss_b: 1.5336e-05\n",
      "Step: NaN | Loss: 1.6203e-06 | Loss_d: 5.8293e-05 Loss_e: 2.3790e-05 | Loss_b: 1.4998e-05\n",
      "Step: NaN | Loss: 1.6199e-06 | Loss_d: 5.8276e-05 Loss_e: 2.3781e-05 | Loss_b: 1.5000e-05\n",
      "Step: NaN | Loss: 1.6191e-06 | Loss_d: 5.8222e-05 Loss_e: 2.3764e-05 | Loss_b: 1.5018e-05\n",
      "Step: NaN | Loss: 1.6309e-06 | Loss_d: 5.8255e-05 Loss_e: 2.4136e-05 | Loss_b: 1.5323e-05\n",
      "Step: NaN | Loss: 1.6190e-06 | Loss_d: 5.8210e-05 Loss_e: 2.3765e-05 | Loss_b: 1.5027e-05\n",
      "Step: NaN | Loss: 1.6169e-06 | Loss_d: 5.7993e-05 Loss_e: 2.3923e-05 | Loss_b: 1.4959e-05\n",
      "Step: NaN | Loss: 1.6486e-06 | Loss_d: 5.7772e-05 Loss_e: 2.5802e-05 | Loss_b: 1.5203e-05\n",
      "Step: NaN | Loss: 1.6169e-06 | Loss_d: 5.7989e-05 Loss_e: 2.3928e-05 | Loss_b: 1.4958e-05\n",
      "Step: NaN | Loss: 1.6146e-06 | Loss_d: 5.7767e-05 Loss_e: 2.3996e-05 | Loss_b: 1.4971e-05\n",
      "Step: NaN | Loss: 1.6179e-06 | Loss_d: 5.7001e-05 Loss_e: 2.4666e-05 | Loss_b: 1.5266e-05\n",
      "Step: NaN | Loss: 1.6134e-06 | Loss_d: 5.7494e-05 Loss_e: 2.4149e-05 | Loss_b: 1.5021e-05\n",
      "Step: NaN | Loss: 1.6107e-06 | Loss_d: 5.7334e-05 Loss_e: 2.4160e-05 | Loss_b: 1.5009e-05\n",
      "Step: NaN | Loss: 1.6103e-06 | Loss_d: 5.6783e-05 Loss_e: 2.4407e-05 | Loss_b: 1.5292e-05\n",
      "Step: NaN | Loss: 1.6085e-06 | Loss_d: 5.7028e-05 Loss_e: 2.4249e-05 | Loss_b: 1.5092e-05\n",
      "Step: NaN | Loss: 1.6064e-06 | Loss_d: 5.6936e-05 Loss_e: 2.4408e-05 | Loss_b: 1.4901e-05\n",
      "Step: NaN | Loss: 1.6360e-06 | Loss_d: 5.6778e-05 Loss_e: 2.5467e-05 | Loss_b: 1.5774e-05\n",
      "Step: NaN | Loss: 1.6063e-06 | Loss_d: 5.6926e-05 Loss_e: 2.4432e-05 | Loss_b: 1.4886e-05\n",
      "Step: NaN | Loss: 1.6037e-06 | Loss_d: 5.6815e-05 Loss_e: 2.4415e-05 | Loss_b: 1.4855e-05\n",
      "Step: NaN | Loss: 1.6102e-06 | Loss_d: 5.6468e-05 Loss_e: 2.4593e-05 | Loss_b: 1.5412e-05\n",
      "Step: NaN | Loss: 1.6028e-06 | Loss_d: 5.6709e-05 Loss_e: 2.4424e-05 | Loss_b: 1.4897e-05\n",
      "Step: NaN | Loss: 1.6004e-06 | Loss_d: 5.6602e-05 Loss_e: 2.4441e-05 | Loss_b: 1.4843e-05\n",
      "Step: NaN | Loss: 1.5951e-06 | Loss_d: 5.6227e-05 Loss_e: 2.4572e-05 | Loss_b: 1.4769e-05\n",
      "Step: NaN | Loss: 1.6699e-06 | Loss_d: 5.5603e-05 Loss_e: 2.6634e-05 | Loss_b: 1.7813e-05\n",
      "Step: NaN | Loss: 1.5948e-06 | Loss_d: 5.6134e-05 Loss_e: 2.4626e-05 | Loss_b: 1.4790e-05\n",
      "Step: NaN | Loss: 1.5962e-06 | Loss_d: 5.7045e-05 Loss_e: 2.4588e-05 | Loss_b: 1.4000e-05\n",
      "Step: NaN | Loss: 1.5925e-06 | Loss_d: 5.6504e-05 Loss_e: 2.4587e-05 | Loss_b: 1.4324e-05\n",
      "Step: NaN | Loss: 1.5915e-06 | Loss_d: 5.6509e-05 Loss_e: 2.4500e-05 | Loss_b: 1.4344e-05\n",
      "Step: NaN | Loss: 1.5955e-06 | Loss_d: 5.6701e-05 Loss_e: 2.4251e-05 | Loss_b: 1.4640e-05\n",
      "Step: NaN | Loss: 1.5912e-06 | Loss_d: 5.6524e-05 Loss_e: 2.4439e-05 | Loss_b: 1.4376e-05\n",
      "Step: NaN | Loss: 1.5902e-06 | Loss_d: 5.6386e-05 Loss_e: 2.4439e-05 | Loss_b: 1.4452e-05\n",
      "Step: NaN | Loss: 1.6042e-06 | Loss_d: 5.6022e-05 Loss_e: 2.4587e-05 | Loss_b: 1.5504e-05\n",
      "Step: NaN | Loss: 1.5902e-06 | Loss_d: 5.6378e-05 Loss_e: 2.4439e-05 | Loss_b: 1.4460e-05\n",
      "Step: NaN | Loss: 1.5890e-06 | Loss_d: 5.6468e-05 Loss_e: 2.4433e-05 | Loss_b: 1.4302e-05\n",
      "Step: NaN | Loss: 1.5943e-06 | Loss_d: 5.6893e-05 Loss_e: 2.4562e-05 | Loss_b: 1.4065e-05\n",
      "Step: NaN | Loss: 1.5887e-06 | Loss_d: 5.6536e-05 Loss_e: 2.4438e-05 | Loss_b: 1.4213e-05\n",
      "Step: NaN | Loss: 1.5881e-06 | Loss_d: 5.6488e-05 Loss_e: 2.4438e-05 | Loss_b: 1.4222e-05\n",
      "Step: NaN | Loss: 1.5919e-06 | Loss_d: 5.6332e-05 Loss_e: 2.4519e-05 | Loss_b: 1.4528e-05\n",
      "Step: NaN | Loss: 1.5880e-06 | Loss_d: 5.6464e-05 Loss_e: 2.4441e-05 | Loss_b: 1.4237e-05\n",
      "Step: NaN | Loss: 1.5877e-06 | Loss_d: 5.6461e-05 Loss_e: 2.4416e-05 | Loss_b: 1.4250e-05\n",
      "Step: NaN | Loss: 1.5873e-06 | Loss_d: 5.6449e-05 Loss_e: 2.4333e-05 | Loss_b: 1.4323e-05\n",
      "Step: NaN | Loss: 1.5873e-06 | Loss_d: 5.6450e-05 Loss_e: 2.4344e-05 | Loss_b: 1.4309e-05\n",
      "Step: NaN | Loss: 1.5867e-06 | Loss_d: 5.6431e-05 Loss_e: 2.4370e-05 | Loss_b: 1.4265e-05\n",
      "Step: NaN | Loss: 1.5856e-06 | Loss_d: 5.6367e-05 Loss_e: 2.4523e-05 | Loss_b: 1.4108e-05\n",
      "Step: NaN | Loss: 1.6154e-06 | Loss_d: 5.6357e-05 Loss_e: 2.6491e-05 | Loss_b: 1.3935e-05\n",
      "Step: NaN | Loss: 1.5856e-06 | Loss_d: 5.6365e-05 Loss_e: 2.4529e-05 | Loss_b: 1.4103e-05\n",
      "Step: NaN | Loss: 1.5834e-06 | Loss_d: 5.6488e-05 Loss_e: 2.4319e-05 | Loss_b: 1.4058e-05\n",
      "Step: NaN | Loss: 1.5943e-06 | Loss_d: 5.7175e-05 Loss_e: 2.3832e-05 | Loss_b: 1.4515e-05\n",
      "Step: NaN | Loss: 1.5828e-06 | Loss_d: 5.6573e-05 Loss_e: 2.4208e-05 | Loss_b: 1.4054e-05\n",
      "Step: NaN | Loss: 1.5802e-06 | Loss_d: 5.6518e-05 Loss_e: 2.4089e-05 | Loss_b: 1.4072e-05\n",
      "Step: NaN | Loss: 1.5802e-06 | Loss_d: 5.6518e-05 Loss_e: 2.4098e-05 | Loss_b: 1.4058e-05\n",
      "Step: NaN | Loss: 1.5796e-06 | Loss_d: 5.6500e-05 Loss_e: 2.4099e-05 | Loss_b: 1.4042e-05\n",
      "Step: NaN | Loss: 1.5782e-06 | Loss_d: 5.6433e-05 Loss_e: 2.4112e-05 | Loss_b: 1.4012e-05\n",
      "Step: NaN | Loss: 1.5917e-06 | Loss_d: 5.6239e-05 Loss_e: 2.4383e-05 | Loss_b: 1.4741e-05\n",
      "Step: NaN | Loss: 1.5780e-06 | Loss_d: 5.6402e-05 Loss_e: 2.4124e-05 | Loss_b: 1.4018e-05\n",
      "Step: NaN | Loss: 1.5752e-06 | Loss_d: 5.6397e-05 Loss_e: 2.4054e-05 | Loss_b: 1.3923e-05\n",
      "Step: NaN | Loss: 1.5664e-06 | Loss_d: 5.6393e-05 Loss_e: 2.3829e-05 | Loss_b: 1.3628e-05\n",
      "Step: NaN | Loss: 1.5846e-06 | Loss_d: 5.6691e-05 Loss_e: 2.4107e-05 | Loss_b: 1.4142e-05\n",
      "Step: NaN | Loss: 1.5609e-06 | Loss_d: 5.6430e-05 Loss_e: 2.3660e-05 | Loss_b: 1.3432e-05\n",
      "Step: NaN | Loss: 1.5679e-06 | Loss_d: 5.5316e-05 Loss_e: 2.4170e-05 | Loss_b: 1.4452e-05\n",
      "Step: NaN | Loss: 1.5576e-06 | Loss_d: 5.6010e-05 Loss_e: 2.3780e-05 | Loss_b: 1.3535e-05\n",
      "Step: NaN | Loss: 1.5556e-06 | Loss_d: 5.6028e-05 Loss_e: 2.3773e-05 | Loss_b: 1.3405e-05\n",
      "Step: NaN | Loss: 1.5721e-06 | Loss_d: 5.6141e-05 Loss_e: 2.3837e-05 | Loss_b: 1.4211e-05\n",
      "Step: NaN | Loss: 1.5555e-06 | Loss_d: 5.6035e-05 Loss_e: 2.3772e-05 | Loss_b: 1.3391e-05\n",
      "Step: NaN | Loss: 1.5550e-06 | Loss_d: 5.6078e-05 Loss_e: 2.3711e-05 | Loss_b: 1.3376e-05\n",
      "Step: NaN | Loss: 1.5547e-06 | Loss_d: 5.6279e-05 Loss_e: 2.3513e-05 | Loss_b: 1.3354e-05\n",
      "Step: NaN | Loss: 1.5544e-06 | Loss_d: 5.6196e-05 Loss_e: 2.3581e-05 | Loss_b: 1.3356e-05\n",
      "Step: NaN | Loss: 1.5585e-06 | Loss_d: 5.6717e-05 Loss_e: 2.3529e-05 | Loss_b: 1.3131e-05\n",
      "Step: NaN | Loss: 1.5536e-06 | Loss_d: 5.6332e-05 Loss_e: 2.3558e-05 | Loss_b: 1.3192e-05\n",
      "Step: NaN | Loss: 1.5515e-06 | Loss_d: 5.6225e-05 Loss_e: 2.3606e-05 | Loss_b: 1.3126e-05\n",
      "Step: NaN | Loss: 1.5524e-06 | Loss_d: 5.5956e-05 Loss_e: 2.3979e-05 | Loss_b: 1.3077e-05\n",
      "Step: NaN | Loss: 1.5501e-06 | Loss_d: 5.6077e-05 Loss_e: 2.3735e-05 | Loss_b: 1.3063e-05\n",
      "Step: NaN | Loss: 1.5483e-06 | Loss_d: 5.6115e-05 Loss_e: 2.3668e-05 | Loss_b: 1.2981e-05\n",
      "Step: NaN | Loss: 1.5551e-06 | Loss_d: 5.6401e-05 Loss_e: 2.3535e-05 | Loss_b: 1.3239e-05\n",
      "Step: NaN | Loss: 1.5478e-06 | Loss_d: 5.6154e-05 Loss_e: 2.3624e-05 | Loss_b: 1.2958e-05\n",
      "Step: NaN | Loss: 1.5485e-06 | Loss_d: 5.6081e-05 Loss_e: 2.3679e-05 | Loss_b: 1.3017e-05\n",
      "Step: NaN | Loss: 1.5473e-06 | Loss_d: 5.6119e-05 Loss_e: 2.3638e-05 | Loss_b: 1.2946e-05\n",
      "Step: NaN | Loss: 1.5467e-06 | Loss_d: 5.6112e-05 Loss_e: 2.3643e-05 | Loss_b: 1.2912e-05\n",
      "Step: NaN | Loss: 1.5468e-06 | Loss_d: 5.6109e-05 Loss_e: 2.3724e-05 | Loss_b: 1.2844e-05\n",
      "Step: NaN | Loss: 1.5462e-06 | Loss_d: 5.6105e-05 Loss_e: 2.3668e-05 | Loss_b: 1.2867e-05\n",
      "Step: NaN | Loss: 1.5456e-06 | Loss_d: 5.6102e-05 Loss_e: 2.3651e-05 | Loss_b: 1.2847e-05\n",
      "Step: NaN | Loss: 1.5441e-06 | Loss_d: 5.6092e-05 Loss_e: 2.3602e-05 | Loss_b: 1.2820e-05\n",
      "Step: NaN | Loss: 1.5674e-06 | Loss_d: 5.6114e-05 Loss_e: 2.3753e-05 | Loss_b: 1.4045e-05\n",
      "Step: NaN | Loss: 1.5441e-06 | Loss_d: 5.6091e-05 Loss_e: 2.3596e-05 | Loss_b: 1.2827e-05\n",
      "Step: NaN | Loss: 1.5424e-06 | Loss_d: 5.5992e-05 Loss_e: 2.3575e-05 | Loss_b: 1.2847e-05\n",
      "Step: NaN | Loss: 1.5412e-06 | Loss_d: 5.5656e-05 Loss_e: 2.3535e-05 | Loss_b: 1.3147e-05\n",
      "Step: NaN | Loss: 1.5406e-06 | Loss_d: 5.5767e-05 Loss_e: 2.3542e-05 | Loss_b: 1.2995e-05\n",
      "Step: NaN | Loss: 1.5384e-06 | Loss_d: 5.5824e-05 Loss_e: 2.3381e-05 | Loss_b: 1.2965e-05\n",
      "Step: NaN | Loss: 1.5397e-06 | Loss_d: 5.6126e-05 Loss_e: 2.2980e-05 | Loss_b: 1.3142e-05\n",
      "Step: NaN | Loss: 1.5370e-06 | Loss_d: 5.5938e-05 Loss_e: 2.3164e-05 | Loss_b: 1.2985e-05\n",
      "Step: NaN | Loss: 1.5347e-06 | Loss_d: 5.5900e-05 Loss_e: 2.3186e-05 | Loss_b: 1.2863e-05\n",
      "Step: NaN | Loss: 1.5463e-06 | Loss_d: 5.5958e-05 Loss_e: 2.3560e-05 | Loss_b: 1.3128e-05\n",
      "Step: NaN | Loss: 1.5342e-06 | Loss_d: 5.5887e-05 Loss_e: 2.3213e-05 | Loss_b: 1.2819e-05\n",
      "Step: NaN | Loss: 1.5321e-06 | Loss_d: 5.5769e-05 Loss_e: 2.3206e-05 | Loss_b: 1.2823e-05\n",
      "Step: NaN | Loss: 1.5297e-06 | Loss_d: 5.5377e-05 Loss_e: 2.3374e-05 | Loss_b: 1.2900e-05\n",
      "Step: NaN | Loss: 1.5295e-06 | Loss_d: 5.5450e-05 Loss_e: 2.3311e-05 | Loss_b: 1.2877e-05\n",
      "Step: NaN | Loss: 1.6200e-06 | Loss_d: 5.7815e-05 Loss_e: 2.3114e-05 | Loss_b: 1.6131e-05\n",
      "Step: NaN | Loss: 1.5277e-06 | Loss_d: 5.5543e-05 Loss_e: 2.3119e-05 | Loss_b: 1.2872e-05\n",
      "Step: NaN | Loss: 1.5269e-06 | Loss_d: 5.5607e-05 Loss_e: 2.3027e-05 | Loss_b: 1.2851e-05\n",
      "Step: NaN | Loss: 1.5385e-06 | Loss_d: 5.5975e-05 Loss_e: 2.2815e-05 | Loss_b: 1.3391e-05\n",
      "Step: NaN | Loss: 1.5269e-06 | Loss_d: 5.5609e-05 Loss_e: 2.3024e-05 | Loss_b: 1.2852e-05\n",
      "Step: NaN | Loss: 1.5266e-06 | Loss_d: 5.5560e-05 Loss_e: 2.3032e-05 | Loss_b: 1.2874e-05\n",
      "Step: NaN | Loss: 1.5262e-06 | Loss_d: 5.5370e-05 Loss_e: 2.3072e-05 | Loss_b: 1.2996e-05\n",
      "Step: NaN | Loss: 1.5261e-06 | Loss_d: 5.5393e-05 Loss_e: 2.3067e-05 | Loss_b: 1.2978e-05\n",
      "Step: NaN | Loss: 1.5243e-06 | Loss_d: 5.5301e-05 Loss_e: 2.3049e-05 | Loss_b: 1.2980e-05\n",
      "Step: NaN | Loss: 1.5187e-06 | Loss_d: 5.4957e-05 Loss_e: 2.3006e-05 | Loss_b: 1.3028e-05\n",
      "Step: NaN | Loss: 1.5251e-06 | Loss_d: 5.3728e-05 Loss_e: 2.3494e-05 | Loss_b: 1.4156e-05\n",
      "Step: NaN | Loss: 1.5144e-06 | Loss_d: 5.4376e-05 Loss_e: 2.3058e-05 | Loss_b: 1.3298e-05\n",
      "Step: NaN | Loss: 1.5426e-06 | Loss_d: 5.4009e-05 Loss_e: 2.4082e-05 | Loss_b: 1.4335e-05\n",
      "Step: NaN | Loss: 1.5112e-06 | Loss_d: 5.4236e-05 Loss_e: 2.3163e-05 | Loss_b: 1.3146e-05\n",
      "Step: NaN | Loss: 1.5093e-06 | Loss_d: 5.4159e-05 Loss_e: 2.3256e-05 | Loss_b: 1.3014e-05\n",
      "Step: NaN | Loss: 1.5280e-06 | Loss_d: 5.4008e-05 Loss_e: 2.4029e-05 | Loss_b: 1.3514e-05\n",
      "Step: NaN | Loss: 1.5092e-06 | Loss_d: 5.4143e-05 Loss_e: 2.3286e-05 | Loss_b: 1.2996e-05\n",
      "Step: NaN | Loss: 1.5082e-06 | Loss_d: 5.4144e-05 Loss_e: 2.3256e-05 | Loss_b: 1.2965e-05\n",
      "Step: NaN | Loss: 1.5136e-06 | Loss_d: 5.4245e-05 Loss_e: 2.3287e-05 | Loss_b: 1.3153e-05\n",
      "Step: NaN | Loss: 1.5081e-06 | Loss_d: 5.4149e-05 Loss_e: 2.3246e-05 | Loss_b: 1.2963e-05\n",
      "Step: NaN | Loss: 1.5067e-06 | Loss_d: 5.4179e-05 Loss_e: 2.3171e-05 | Loss_b: 1.2926e-05\n",
      "Step: NaN | Loss: 1.5177e-06 | Loss_d: 5.4451e-05 Loss_e: 2.3147e-05 | Loss_b: 1.3332e-05\n",
      "Step: NaN | Loss: 1.5067e-06 | Loss_d: 5.4193e-05 Loss_e: 2.3152e-05 | Loss_b: 1.2925e-05\n",
      "Step: NaN | Loss: 1.5055e-06 | Loss_d: 5.4082e-05 Loss_e: 2.3170e-05 | Loss_b: 1.2949e-05\n",
      "Step: NaN | Loss: 1.5107e-06 | Loss_d: 5.3723e-05 Loss_e: 2.3325e-05 | Loss_b: 1.3467e-05\n",
      "Step: NaN | Loss: 1.5053e-06 | Loss_d: 5.4013e-05 Loss_e: 2.3186e-05 | Loss_b: 1.2989e-05\n",
      "Step: NaN | Loss: 1.5044e-06 | Loss_d: 5.4007e-05 Loss_e: 2.3185e-05 | Loss_b: 1.2945e-05\n",
      "Step: NaN | Loss: 1.5052e-06 | Loss_d: 5.3996e-05 Loss_e: 2.3256e-05 | Loss_b: 1.2930e-05\n",
      "Step: NaN | Loss: 1.5039e-06 | Loss_d: 5.4001e-05 Loss_e: 2.3198e-05 | Loss_b: 1.2908e-05\n",
      "Step: NaN | Loss: 1.5032e-06 | Loss_d: 5.3961e-05 Loss_e: 2.3187e-05 | Loss_b: 1.2915e-05\n",
      "Step: NaN | Loss: 1.5036e-06 | Loss_d: 5.3822e-05 Loss_e: 2.3155e-05 | Loss_b: 1.3113e-05\n",
      "Step: NaN | Loss: 1.5028e-06 | Loss_d: 5.3899e-05 Loss_e: 2.3172e-05 | Loss_b: 1.2966e-05\n",
      "Step: NaN | Loss: 1.5022e-06 | Loss_d: 5.3853e-05 Loss_e: 2.3168e-05 | Loss_b: 1.2981e-05\n",
      "Step: NaN | Loss: 1.5006e-06 | Loss_d: 5.3682e-05 Loss_e: 2.3162e-05 | Loss_b: 1.3062e-05\n",
      "Step: NaN | Loss: 1.5102e-06 | Loss_d: 5.3091e-05 Loss_e: 2.3408e-05 | Loss_b: 1.3986e-05\n",
      "Step: NaN | Loss: 1.5000e-06 | Loss_d: 5.3552e-05 Loss_e: 2.3172e-05 | Loss_b: 1.3150e-05\n",
      "Step: NaN | Loss: 1.4994e-06 | Loss_d: 5.3486e-05 Loss_e: 2.3079e-05 | Loss_b: 1.3268e-05\n",
      "Step: NaN | Loss: 1.4984e-06 | Loss_d: 5.3511e-05 Loss_e: 2.3108e-05 | Loss_b: 1.3158e-05\n",
      "Step: NaN | Loss: 1.4975e-06 | Loss_d: 5.3459e-05 Loss_e: 2.3089e-05 | Loss_b: 1.3172e-05\n",
      "Step: NaN | Loss: 1.4962e-06 | Loss_d: 5.3282e-05 Loss_e: 2.3050e-05 | Loss_b: 1.3314e-05\n",
      "Step: NaN | Loss: 1.4962e-06 | Loss_d: 5.3311e-05 Loss_e: 2.3052e-05 | Loss_b: 1.3279e-05\n",
      "Step: NaN | Loss: 1.4952e-06 | Loss_d: 5.3257e-05 Loss_e: 2.3057e-05 | Loss_b: 1.3271e-05\n",
      "Step: NaN | Loss: 1.5022e-06 | Loss_d: 5.3108e-05 Loss_e: 2.3170e-05 | Loss_b: 1.3727e-05\n",
      "Step: NaN | Loss: 1.4951e-06 | Loss_d: 5.3238e-05 Loss_e: 2.3061e-05 | Loss_b: 1.3280e-05\n",
      "Step: NaN | Loss: 1.4945e-06 | Loss_d: 5.3328e-05 Loss_e: 2.2996e-05 | Loss_b: 1.3215e-05\n",
      "Step: NaN | Loss: 1.4972e-06 | Loss_d: 5.3791e-05 Loss_e: 2.2822e-05 | Loss_b: 1.3090e-05\n",
      "Step: NaN | Loss: 1.4943e-06 | Loss_d: 5.3402e-05 Loss_e: 2.2954e-05 | Loss_b: 1.3174e-05\n",
      "Step: NaN | Loss: 1.4926e-06 | Loss_d: 5.3398e-05 Loss_e: 2.2912e-05 | Loss_b: 1.3116e-05\n",
      "Step: NaN | Loss: 1.4912e-06 | Loss_d: 5.3471e-05 Loss_e: 2.2790e-05 | Loss_b: 1.3082e-05\n",
      "Step: NaN | Loss: 1.4907e-06 | Loss_d: 5.3430e-05 Loss_e: 2.2824e-05 | Loss_b: 1.3058e-05\n",
      "Step: NaN | Loss: 1.4887e-06 | Loss_d: 5.3337e-05 Loss_e: 2.2795e-05 | Loss_b: 1.3062e-05\n",
      "Step: NaN | Loss: 1.4902e-06 | Loss_d: 5.3083e-05 Loss_e: 2.2842e-05 | Loss_b: 1.3361e-05\n",
      "Step: NaN | Loss: 1.4875e-06 | Loss_d: 5.3212e-05 Loss_e: 2.2782e-05 | Loss_b: 1.3131e-05\n",
      "Step: NaN | Loss: 1.4857e-06 | Loss_d: 5.3141e-05 Loss_e: 2.2720e-05 | Loss_b: 1.3156e-05\n",
      "Step: NaN | Loss: 1.4918e-06 | Loss_d: 5.2927e-05 Loss_e: 2.2724e-05 | Loss_b: 1.3733e-05\n",
      "Step: NaN | Loss: 1.4853e-06 | Loss_d: 5.3086e-05 Loss_e: 2.2687e-05 | Loss_b: 1.3215e-05\n",
      "Step: NaN | Loss: 1.4831e-06 | Loss_d: 5.3006e-05 Loss_e: 2.2658e-05 | Loss_b: 1.3196e-05\n",
      "Step: NaN | Loss: 1.4817e-06 | Loss_d: 5.2739e-05 Loss_e: 2.2721e-05 | Loss_b: 1.3317e-05\n",
      "Step: NaN | Loss: 1.4809e-06 | Loss_d: 5.2830e-05 Loss_e: 2.2664e-05 | Loss_b: 1.3233e-05\n",
      "Step: NaN | Loss: 1.4785e-06 | Loss_d: 5.2803e-05 Loss_e: 2.2605e-05 | Loss_b: 1.3175e-05\n",
      "Step: NaN | Loss: 1.5057e-06 | Loss_d: 5.3083e-05 Loss_e: 2.3137e-05 | Loss_b: 1.3991e-05\n",
      "Step: NaN | Loss: 1.4785e-06 | Loss_d: 5.2802e-05 Loss_e: 2.2603e-05 | Loss_b: 1.3177e-05\n",
      "Step: NaN | Loss: 1.4791e-06 | Loss_d: 5.2948e-05 Loss_e: 2.2621e-05 | Loss_b: 1.3047e-05\n",
      "Step: NaN | Loss: 1.4779e-06 | Loss_d: 5.2857e-05 Loss_e: 2.2607e-05 | Loss_b: 1.3080e-05\n",
      "Step: NaN | Loss: 1.4776e-06 | Loss_d: 5.2858e-05 Loss_e: 2.2609e-05 | Loss_b: 1.3066e-05\n",
      "Step: NaN | Loss: 1.4777e-06 | Loss_d: 5.2862e-05 Loss_e: 2.2624e-05 | Loss_b: 1.3049e-05\n",
      "Step: NaN | Loss: 1.4775e-06 | Loss_d: 5.2859e-05 Loss_e: 2.2614e-05 | Loss_b: 1.3051e-05\n",
      "Step: NaN | Loss: 1.4770e-06 | Loss_d: 5.2868e-05 Loss_e: 2.2594e-05 | Loss_b: 1.3029e-05\n",
      "Step: NaN | Loss: 1.4758e-06 | Loss_d: 5.2910e-05 Loss_e: 2.2543e-05 | Loss_b: 1.2971e-05\n",
      "Step: NaN | Loss: 1.4938e-06 | Loss_d: 5.3303e-05 Loss_e: 2.2938e-05 | Loss_b: 1.3260e-05\n",
      "Step: NaN | Loss: 1.4758e-06 | Loss_d: 5.2919e-05 Loss_e: 2.2538e-05 | Loss_b: 1.2966e-05\n",
      "Step: NaN | Loss: 1.4754e-06 | Loss_d: 5.2717e-05 Loss_e: 2.2540e-05 | Loss_b: 1.3141e-05\n",
      "Step: NaN | Loss: 1.4752e-06 | Loss_d: 5.2794e-05 Loss_e: 2.2536e-05 | Loss_b: 1.3053e-05\n",
      "Step: NaN | Loss: 1.4744e-06 | Loss_d: 5.2700e-05 Loss_e: 2.2548e-05 | Loss_b: 1.3087e-05\n",
      "Step: NaN | Loss: 1.4747e-06 | Loss_d: 5.2375e-05 Loss_e: 2.2638e-05 | Loss_b: 1.3342e-05\n",
      "Step: NaN | Loss: 1.4738e-06 | Loss_d: 5.2545e-05 Loss_e: 2.2580e-05 | Loss_b: 1.3177e-05\n",
      "Step: NaN | Loss: 1.4719e-06 | Loss_d: 5.2467e-05 Loss_e: 2.2555e-05 | Loss_b: 1.3166e-05\n",
      "Step: NaN | Loss: 1.4682e-06 | Loss_d: 5.2193e-05 Loss_e: 2.2593e-05 | Loss_b: 1.3178e-05\n",
      "Step: NaN | Loss: 1.5412e-06 | Loss_d: 5.1629e-05 Loss_e: 2.6105e-05 | Loss_b: 1.4609e-05\n",
      "Step: NaN | Loss: 1.4681e-06 | Loss_d: 5.2166e-05 Loss_e: 2.2611e-05 | Loss_b: 1.3186e-05\n",
      "Step: NaN | Loss: 1.4878e-06 | Loss_d: 5.2729e-05 Loss_e: 2.2921e-05 | Loss_b: 1.3491e-05\n",
      "Step: NaN | Loss: 1.4673e-06 | Loss_d: 5.2167e-05 Loss_e: 2.2607e-05 | Loss_b: 1.3136e-05\n",
      "Step: NaN | Loss: 1.4665e-06 | Loss_d: 5.2135e-05 Loss_e: 2.2598e-05 | Loss_b: 1.3133e-05\n",
      "Step: NaN | Loss: 1.4656e-06 | Loss_d: 5.2035e-05 Loss_e: 2.2583e-05 | Loss_b: 1.3190e-05\n",
      "Step: NaN | Loss: 1.4655e-06 | Loss_d: 5.2050e-05 Loss_e: 2.2584e-05 | Loss_b: 1.3171e-05\n",
      "Step: NaN | Loss: 1.4642e-06 | Loss_d: 5.2071e-05 Loss_e: 2.2508e-05 | Loss_b: 1.3146e-05\n",
      "Step: NaN | Loss: 1.4655e-06 | Loss_d: 5.2276e-05 Loss_e: 2.2354e-05 | Loss_b: 1.3172e-05\n",
      "Step: NaN | Loss: 1.4635e-06 | Loss_d: 5.2128e-05 Loss_e: 2.2421e-05 | Loss_b: 1.3134e-05\n",
      "Step: NaN | Loss: 1.4618e-06 | Loss_d: 5.2030e-05 Loss_e: 2.2417e-05 | Loss_b: 1.3136e-05\n",
      "Step: NaN | Loss: 1.4635e-06 | Loss_d: 5.1673e-05 Loss_e: 2.2469e-05 | Loss_b: 1.3539e-05\n",
      "Step: NaN | Loss: 1.4608e-06 | Loss_d: 5.1896e-05 Loss_e: 2.2423e-05 | Loss_b: 1.3202e-05\n",
      "Step: NaN | Loss: 1.4576e-06 | Loss_d: 5.1872e-05 Loss_e: 2.2337e-05 | Loss_b: 1.3121e-05\n",
      "Step: NaN | Loss: 1.4539e-06 | Loss_d: 5.1847e-05 Loss_e: 2.2110e-05 | Loss_b: 1.3151e-05\n",
      "Step: NaN | Loss: 1.4534e-06 | Loss_d: 5.1843e-05 Loss_e: 2.2148e-05 | Loss_b: 1.3091e-05\n",
      "Step: NaN | Loss: 1.4504e-06 | Loss_d: 5.1600e-05 Loss_e: 2.2081e-05 | Loss_b: 1.3217e-05\n",
      "Step: NaN | Loss: 1.4941e-06 | Loss_d: 5.0939e-05 Loss_e: 2.2261e-05 | Loss_b: 1.6315e-05\n",
      "Step: NaN | Loss: 1.4504e-06 | Loss_d: 5.1596e-05 Loss_e: 2.2081e-05 | Loss_b: 1.3221e-05\n",
      "Step: NaN | Loss: 1.4493e-06 | Loss_d: 5.1523e-05 Loss_e: 2.2126e-05 | Loss_b: 1.3183e-05\n",
      "Step: NaN | Loss: 1.4652e-06 | Loss_d: 5.1288e-05 Loss_e: 2.2463e-05 | Loss_b: 1.4033e-05\n",
      "Step: NaN | Loss: 1.4493e-06 | Loss_d: 5.1522e-05 Loss_e: 2.2127e-05 | Loss_b: 1.3183e-05\n",
      "Step: NaN | Loss: 1.4487e-06 | Loss_d: 5.1491e-05 Loss_e: 2.2165e-05 | Loss_b: 1.3139e-05\n",
      "Step: NaN | Loss: 1.4494e-06 | Loss_d: 5.1399e-05 Loss_e: 2.2369e-05 | Loss_b: 1.3072e-05\n",
      "Step: NaN | Loss: 1.4483e-06 | Loss_d: 5.1454e-05 Loss_e: 2.2225e-05 | Loss_b: 1.3097e-05\n",
      "Step: NaN | Loss: 1.4467e-06 | Loss_d: 5.1558e-05 Loss_e: 2.2148e-05 | Loss_b: 1.2970e-05\n",
      "Step: NaN | Loss: 1.4477e-06 | Loss_d: 5.2049e-05 Loss_e: 2.1964e-05 | Loss_b: 1.2726e-05\n",
      "Step: NaN | Loss: 1.4456e-06 | Loss_d: 5.1749e-05 Loss_e: 2.2048e-05 | Loss_b: 1.2818e-05\n",
      "Step: NaN | Loss: 1.4439e-06 | Loss_d: 5.1626e-05 Loss_e: 2.1978e-05 | Loss_b: 1.2909e-05\n",
      "Step: NaN | Loss: 1.4711e-06 | Loss_d: 5.1407e-05 Loss_e: 2.1876e-05 | Loss_b: 1.4854e-05\n",
      "Step: NaN | Loss: 1.4439e-06 | Loss_d: 5.1626e-05 Loss_e: 2.1978e-05 | Loss_b: 1.2910e-05\n",
      "Step: NaN | Loss: 1.4433e-06 | Loss_d: 5.1724e-05 Loss_e: 2.1941e-05 | Loss_b: 1.2811e-05\n",
      "Step: NaN | Loss: 1.4466e-06 | Loss_d: 5.2141e-05 Loss_e: 2.1858e-05 | Loss_b: 1.2674e-05\n",
      "Step: NaN | Loss: 1.4432e-06 | Loss_d: 5.1781e-05 Loss_e: 2.1923e-05 | Loss_b: 1.2766e-05\n",
      "Step: NaN | Loss: 1.4427e-06 | Loss_d: 5.1787e-05 Loss_e: 2.1908e-05 | Loss_b: 1.2745e-05\n",
      "Step: NaN | Loss: 1.4418e-06 | Loss_d: 5.1834e-05 Loss_e: 2.1877e-05 | Loss_b: 1.2674e-05\n",
      "Step: NaN | Loss: 1.4637e-06 | Loss_d: 5.2614e-05 Loss_e: 2.2489e-05 | Loss_b: 1.2593e-05\n",
      "Step: NaN | Loss: 1.4418e-06 | Loss_d: 5.1836e-05 Loss_e: 2.1877e-05 | Loss_b: 1.2672e-05\n",
      "Step: NaN | Loss: 1.4546e-06 | Loss_d: 5.1877e-05 Loss_e: 2.1878e-05 | Loss_b: 1.3397e-05\n",
      "Step: NaN | Loss: 1.4415e-06 | Loss_d: 5.1831e-05 Loss_e: 2.1867e-05 | Loss_b: 1.2668e-05\n",
      "Step: NaN | Loss: 1.4412e-06 | Loss_d: 5.1782e-05 Loss_e: 2.1870e-05 | Loss_b: 1.2699e-05\n",
      "Step: NaN | Loss: 1.4410e-06 | Loss_d: 5.1595e-05 Loss_e: 2.1893e-05 | Loss_b: 1.2852e-05\n",
      "Step: NaN | Loss: 1.4410e-06 | Loss_d: 5.1661e-05 Loss_e: 2.1882e-05 | Loss_b: 1.2791e-05\n",
      "Step: NaN | Loss: 1.4399e-06 | Loss_d: 5.1642e-05 Loss_e: 2.1855e-05 | Loss_b: 1.2774e-05\n",
      "Step: NaN | Loss: 1.4364e-06 | Loss_d: 5.1575e-05 Loss_e: 2.1770e-05 | Loss_b: 1.2718e-05\n",
      "Step: NaN | Loss: 1.4374e-06 | Loss_d: 5.1485e-05 Loss_e: 2.1899e-05 | Loss_b: 1.2735e-05\n",
      "Step: NaN | Loss: 1.4331e-06 | Loss_d: 5.1483e-05 Loss_e: 2.1717e-05 | Loss_b: 1.2662e-05\n",
      "Step: NaN | Loss: 1.4359e-06 | Loss_d: 5.1016e-05 Loss_e: 2.1883e-05 | Loss_b: 1.3132e-05\n",
      "Step: NaN | Loss: 1.4319e-06 | Loss_d: 5.1295e-05 Loss_e: 2.1747e-05 | Loss_b: 1.2747e-05\n",
      "Step: NaN | Loss: 1.4314e-06 | Loss_d: 5.1260e-05 Loss_e: 2.1774e-05 | Loss_b: 1.2726e-05\n",
      "Step: NaN | Loss: 1.4319e-06 | Loss_d: 5.1143e-05 Loss_e: 2.1922e-05 | Loss_b: 1.2726e-05\n",
      "Step: NaN | Loss: 1.4311e-06 | Loss_d: 5.1213e-05 Loss_e: 2.1821e-05 | Loss_b: 1.2709e-05\n",
      "Step: NaN | Loss: 1.5039e-06 | Loss_d: 5.1376e-05 Loss_e: 2.1973e-05 | Loss_b: 1.6754e-05\n",
      "Step: NaN | Loss: 1.4310e-06 | Loss_d: 5.1215e-05 Loss_e: 2.1807e-05 | Loss_b: 1.2714e-05\n",
      "Step: NaN | Loss: 1.4307e-06 | Loss_d: 5.1226e-05 Loss_e: 2.1792e-05 | Loss_b: 1.2703e-05\n",
      "Step: NaN | Loss: 1.4307e-06 | Loss_d: 5.1279e-05 Loss_e: 2.1763e-05 | Loss_b: 1.2679e-05\n",
      "Step: NaN | Loss: 1.4305e-06 | Loss_d: 5.1251e-05 Loss_e: 2.1772e-05 | Loss_b: 1.2687e-05\n",
      "Step: NaN | Loss: 1.4302e-06 | Loss_d: 5.1140e-05 Loss_e: 2.1772e-05 | Loss_b: 1.2780e-05\n",
      "Step: NaN | Loss: 1.4302e-06 | Loss_d: 5.1160e-05 Loss_e: 2.1771e-05 | Loss_b: 1.2760e-05\n",
      "Step: NaN | Loss: 1.4300e-06 | Loss_d: 5.1149e-05 Loss_e: 2.1765e-05 | Loss_b: 1.2763e-05\n",
      "Step: NaN | Loss: 1.4292e-06 | Loss_d: 5.1107e-05 Loss_e: 2.1739e-05 | Loss_b: 1.2785e-05\n",
      "Step: NaN | Loss: 1.4280e-06 | Loss_d: 5.0916e-05 Loss_e: 2.1657e-05 | Loss_b: 1.2987e-05\n",
      "Step: NaN | Loss: 1.4279e-06 | Loss_d: 5.0957e-05 Loss_e: 2.1670e-05 | Loss_b: 1.2926e-05\n",
      "Step: NaN | Loss: 1.4263e-06 | Loss_d: 5.0895e-05 Loss_e: 2.1657e-05 | Loss_b: 1.2904e-05\n",
      "Step: NaN | Loss: 1.4291e-06 | Loss_d: 5.0795e-05 Loss_e: 2.1775e-05 | Loss_b: 1.3056e-05\n",
      "Step: NaN | Loss: 1.4256e-06 | Loss_d: 5.0839e-05 Loss_e: 2.1665e-05 | Loss_b: 1.2911e-05\n",
      "Step: NaN | Loss: 1.4252e-06 | Loss_d: 5.0837e-05 Loss_e: 2.1656e-05 | Loss_b: 1.2895e-05\n",
      "Step: NaN | Loss: 1.4251e-06 | Loss_d: 5.0841e-05 Loss_e: 2.1651e-05 | Loss_b: 1.2892e-05\n",
      "Step: NaN | Loss: 1.4248e-06 | Loss_d: 5.0836e-05 Loss_e: 2.1648e-05 | Loss_b: 1.2880e-05\n",
      "Step: NaN | Loss: 1.4240e-06 | Loss_d: 5.0802e-05 Loss_e: 2.1644e-05 | Loss_b: 1.2872e-05\n",
      "Step: NaN | Loss: 1.4300e-06 | Loss_d: 5.0742e-05 Loss_e: 2.1733e-05 | Loss_b: 1.3201e-05\n",
      "Step: NaN | Loss: 1.4240e-06 | Loss_d: 5.0792e-05 Loss_e: 2.1646e-05 | Loss_b: 1.2877e-05\n",
      "Step: NaN | Loss: 1.4231e-06 | Loss_d: 5.0822e-05 Loss_e: 2.1598e-05 | Loss_b: 1.2843e-05\n",
      "Step: NaN | Loss: 1.4217e-06 | Loss_d: 5.0971e-05 Loss_e: 2.1459e-05 | Loss_b: 1.2749e-05\n",
      "Step: NaN | Loss: 1.4217e-06 | Loss_d: 5.0956e-05 Loss_e: 2.1469e-05 | Loss_b: 1.2754e-05\n",
      "Step: NaN | Loss: 1.4185e-06 | Loss_d: 5.0640e-05 Loss_e: 2.1331e-05 | Loss_b: 1.3020e-05\n",
      "Step: NaN | Loss: 1.4414e-06 | Loss_d: 4.9578e-05 Loss_e: 2.1311e-05 | Loss_b: 1.5474e-05\n",
      "Step: NaN | Loss: 1.4183e-06 | Loss_d: 5.0526e-05 Loss_e: 2.1292e-05 | Loss_b: 1.3157e-05\n",
      "Step: NaN | Loss: 1.4166e-06 | Loss_d: 5.0285e-05 Loss_e: 2.1248e-05 | Loss_b: 1.3342e-05\n",
      "Step: NaN | Loss: 1.4164e-06 | Loss_d: 5.0346e-05 Loss_e: 2.1253e-05 | Loss_b: 1.3262e-05\n",
      "Step: NaN | Loss: 1.4159e-06 | Loss_d: 5.0335e-05 Loss_e: 2.1234e-05 | Loss_b: 1.3267e-05\n",
      "Step: NaN | Loss: 1.4150e-06 | Loss_d: 5.0304e-05 Loss_e: 2.1167e-05 | Loss_b: 1.3307e-05\n",
      "Step: NaN | Loss: 1.4291e-06 | Loss_d: 5.0423e-05 Loss_e: 2.1101e-05 | Loss_b: 1.4102e-05\n",
      "Step: NaN | Loss: 1.4150e-06 | Loss_d: 5.0298e-05 Loss_e: 2.1153e-05 | Loss_b: 1.3325e-05\n",
      "Step: NaN | Loss: 1.4140e-06 | Loss_d: 5.0342e-05 Loss_e: 2.1108e-05 | Loss_b: 1.3266e-05\n",
      "Step: NaN | Loss: 1.4140e-06 | Loss_d: 5.0341e-05 Loss_e: 2.1109e-05 | Loss_b: 1.3266e-05\n",
      "Step: NaN | Loss: 1.4123e-06 | Loss_d: 5.0429e-05 Loss_e: 2.1090e-05 | Loss_b: 1.3099e-05\n",
      "Step: NaN | Loss: 1.4164e-06 | Loss_d: 5.0880e-05 Loss_e: 2.1196e-05 | Loss_b: 1.2788e-05\n",
      "Step: NaN | Loss: 1.4118e-06 | Loss_d: 5.0530e-05 Loss_e: 2.1090e-05 | Loss_b: 1.2965e-05\n",
      "Step: NaN | Loss: 1.4107e-06 | Loss_d: 5.0478e-05 Loss_e: 2.1063e-05 | Loss_b: 1.2981e-05\n",
      "Step: NaN | Loss: 1.4087e-06 | Loss_d: 5.0310e-05 Loss_e: 2.0981e-05 | Loss_b: 1.3111e-05\n",
      "Step: NaN | Loss: 1.4525e-06 | Loss_d: 5.0439e-05 Loss_e: 2.1239e-05 | Loss_b: 1.5347e-05\n",
      "Step: NaN | Loss: 1.4087e-06 | Loss_d: 5.0300e-05 Loss_e: 2.0977e-05 | Loss_b: 1.3125e-05\n",
      "Step: NaN | Loss: 1.4061e-06 | Loss_d: 5.0448e-05 Loss_e: 2.0846e-05 | Loss_b: 1.2953e-05\n",
      "Step: NaN | Loss: 1.4060e-06 | Loss_d: 5.0417e-05 Loss_e: 2.0862e-05 | Loss_b: 1.2961e-05\n",
      "Step: NaN | Loss: 1.4044e-06 | Loss_d: 5.0317e-05 Loss_e: 2.0738e-05 | Loss_b: 1.3086e-05\n",
      "Step: NaN | Loss: 1.4275e-06 | Loss_d: 5.0403e-05 Loss_e: 2.0575e-05 | Loss_b: 1.4549e-05\n",
      "Step: NaN | Loss: 1.4043e-06 | Loss_d: 5.0311e-05 Loss_e: 2.0729e-05 | Loss_b: 1.3099e-05\n",
      "Step: NaN | Loss: 1.4034e-06 | Loss_d: 5.0255e-05 Loss_e: 2.0697e-05 | Loss_b: 1.3134e-05\n",
      "Step: NaN | Loss: 1.4014e-06 | Loss_d: 5.0041e-05 Loss_e: 2.0609e-05 | Loss_b: 1.3316e-05\n",
      "Step: NaN | Loss: 1.4210e-06 | Loss_d: 4.9258e-05 Loss_e: 2.1048e-05 | Loss_b: 1.4833e-05\n",
      "Step: NaN | Loss: 1.4013e-06 | Loss_d: 4.9952e-05 Loss_e: 2.0589e-05 | Loss_b: 1.3417e-05\n",
      "Step: NaN | Loss: 1.3992e-06 | Loss_d: 5.0019e-05 Loss_e: 2.0554e-05 | Loss_b: 1.3257e-05\n",
      "Step: NaN | Loss: 1.4019e-06 | Loss_d: 5.0376e-05 Loss_e: 2.0584e-05 | Loss_b: 1.3032e-05\n",
      "Step: NaN | Loss: 1.3981e-06 | Loss_d: 5.0128e-05 Loss_e: 2.0533e-05 | Loss_b: 1.3103e-05\n",
      "Step: NaN | Loss: 1.3975e-06 | Loss_d: 5.0160e-05 Loss_e: 2.0549e-05 | Loss_b: 1.3019e-05\n",
      "Step: NaN | Loss: 1.4020e-06 | Loss_d: 5.0359e-05 Loss_e: 2.0796e-05 | Loss_b: 1.2845e-05\n",
      "Step: NaN | Loss: 1.3974e-06 | Loss_d: 5.0172e-05 Loss_e: 2.0558e-05 | Loss_b: 1.2996e-05\n",
      "Step: NaN | Loss: 1.3968e-06 | Loss_d: 5.0130e-05 Loss_e: 2.0557e-05 | Loss_b: 1.2999e-05\n",
      "Step: NaN | Loss: 1.3977e-06 | Loss_d: 5.0041e-05 Loss_e: 2.0576e-05 | Loss_b: 1.3128e-05\n",
      "Step: NaN | Loss: 1.3964e-06 | Loss_d: 5.0086e-05 Loss_e: 2.0559e-05 | Loss_b: 1.3019e-05\n",
      "Step: NaN | Loss: 1.3957e-06 | Loss_d: 5.0095e-05 Loss_e: 2.0550e-05 | Loss_b: 1.2975e-05\n",
      "Step: NaN | Loss: 1.3953e-06 | Loss_d: 5.0171e-05 Loss_e: 2.0541e-05 | Loss_b: 1.2883e-05\n",
      "Step: NaN | Loss: 1.3949e-06 | Loss_d: 5.0131e-05 Loss_e: 2.0539e-05 | Loss_b: 1.2904e-05\n",
      "Step: NaN | Loss: 1.3943e-06 | Loss_d: 5.0136e-05 Loss_e: 2.0529e-05 | Loss_b: 1.2873e-05\n",
      "Step: NaN | Loss: 1.3943e-06 | Loss_d: 5.0165e-05 Loss_e: 2.0530e-05 | Loss_b: 1.2841e-05\n",
      "Step: NaN | Loss: 1.3938e-06 | Loss_d: 5.0149e-05 Loss_e: 2.0522e-05 | Loss_b: 1.2837e-05\n",
      "Step: NaN | Loss: 1.3938e-06 | Loss_d: 5.0070e-05 Loss_e: 2.0519e-05 | Loss_b: 1.2919e-05\n",
      "Step: NaN | Loss: 1.3935e-06 | Loss_d: 5.0109e-05 Loss_e: 2.0517e-05 | Loss_b: 1.2866e-05\n",
      "Step: NaN | Loss: 1.3931e-06 | Loss_d: 5.0052e-05 Loss_e: 2.0496e-05 | Loss_b: 1.2918e-05\n",
      "Step: NaN | Loss: 1.3936e-06 | Loss_d: 4.9845e-05 Loss_e: 2.0454e-05 | Loss_b: 1.3196e-05\n",
      "Step: NaN | Loss: 1.3928e-06 | Loss_d: 4.9975e-05 Loss_e: 2.0473e-05 | Loss_b: 1.3003e-05\n",
      "Step: NaN | Loss: 1.3921e-06 | Loss_d: 4.9965e-05 Loss_e: 2.0453e-05 | Loss_b: 1.2987e-05\n",
      "Step: NaN | Loss: 1.3917e-06 | Loss_d: 4.9944e-05 Loss_e: 2.0414e-05 | Loss_b: 1.3027e-05\n",
      "Step: NaN | Loss: 1.3913e-06 | Loss_d: 4.9949e-05 Loss_e: 2.0422e-05 | Loss_b: 1.2991e-05\n",
      "Step: NaN | Loss: 1.3897e-06 | Loss_d: 5.0089e-05 Loss_e: 2.0345e-05 | Loss_b: 1.2832e-05\n",
      "Step: NaN | Loss: 1.3913e-06 | Loss_d: 5.0731e-05 Loss_e: 2.0112e-05 | Loss_b: 1.2514e-05\n",
      "Step: NaN | Loss: 1.3888e-06 | Loss_d: 5.0317e-05 Loss_e: 2.0242e-05 | Loss_b: 1.2650e-05\n",
      "Step: NaN | Loss: 1.3873e-06 | Loss_d: 5.0327e-05 Loss_e: 2.0193e-05 | Loss_b: 1.2601e-05\n",
      "Step: NaN | Loss: 1.3873e-06 | Loss_d: 5.0327e-05 Loss_e: 2.0194e-05 | Loss_b: 1.2600e-05\n",
      "Step: NaN | Loss: 1.3869e-06 | Loss_d: 5.0306e-05 Loss_e: 2.0174e-05 | Loss_b: 1.2613e-05\n",
      "Step: NaN | Loss: 1.3859e-06 | Loss_d: 5.0231e-05 Loss_e: 2.0124e-05 | Loss_b: 1.2682e-05\n",
      "Step: NaN | Loss: 1.4044e-06 | Loss_d: 5.0098e-05 Loss_e: 2.0586e-05 | Loss_b: 1.3461e-05\n",
      "Step: NaN | Loss: 1.3859e-06 | Loss_d: 5.0223e-05 Loss_e: 2.0121e-05 | Loss_b: 1.2693e-05\n",
      "Step: NaN | Loss: 1.3843e-06 | Loss_d: 5.0186e-05 Loss_e: 2.0101e-05 | Loss_b: 1.2655e-05\n",
      "Step: NaN | Loss: 1.3813e-06 | Loss_d: 5.0101e-05 Loss_e: 2.0083e-05 | Loss_b: 1.2577e-05\n",
      "Step: NaN | Loss: 1.4546e-06 | Loss_d: 5.1240e-05 Loss_e: 2.1469e-05 | Loss_b: 1.4445e-05\n",
      "Step: NaN | Loss: 1.3813e-06 | Loss_d: 5.0100e-05 Loss_e: 2.0084e-05 | Loss_b: 1.2577e-05\n",
      "Step: NaN | Loss: 1.3818e-06 | Loss_d: 4.9965e-05 Loss_e: 2.0037e-05 | Loss_b: 1.2786e-05\n",
      "Step: NaN | Loss: 1.3804e-06 | Loss_d: 5.0025e-05 Loss_e: 2.0041e-05 | Loss_b: 1.2639e-05\n",
      "Step: NaN | Loss: 1.3793e-06 | Loss_d: 4.9959e-05 Loss_e: 2.0076e-05 | Loss_b: 1.2606e-05\n",
      "Step: NaN | Loss: 1.3912e-06 | Loss_d: 5.0093e-05 Loss_e: 2.0362e-05 | Loss_b: 1.2896e-05\n",
      "Step: NaN | Loss: 1.3793e-06 | Loss_d: 4.9952e-05 Loss_e: 2.0083e-05 | Loss_b: 1.2605e-05\n",
      "Step: NaN | Loss: 1.3791e-06 | Loss_d: 4.9920e-05 Loss_e: 2.0103e-05 | Loss_b: 1.2604e-05\n",
      "Step: NaN | Loss: 1.3802e-06 | Loss_d: 4.9796e-05 Loss_e: 2.0210e-05 | Loss_b: 1.2689e-05\n",
      "Step: NaN | Loss: 1.3791e-06 | Loss_d: 4.9902e-05 Loss_e: 2.0116e-05 | Loss_b: 1.2607e-05\n",
      "Step: NaN | Loss: 1.3789e-06 | Loss_d: 4.9894e-05 Loss_e: 2.0111e-05 | Loss_b: 1.2608e-05\n",
      "Step: NaN | Loss: 1.3780e-06 | Loss_d: 4.9861e-05 Loss_e: 2.0093e-05 | Loss_b: 1.2610e-05\n",
      "Step: NaN | Loss: 1.3760e-06 | Loss_d: 4.9723e-05 Loss_e: 2.0041e-05 | Loss_b: 1.2678e-05\n",
      "Step: NaN | Loss: 1.4620e-06 | Loss_d: 4.9794e-05 Loss_e: 2.0546e-05 | Loss_b: 1.7257e-05\n",
      "Step: NaN | Loss: 1.3760e-06 | Loss_d: 4.9721e-05 Loss_e: 2.0041e-05 | Loss_b: 1.2680e-05\n",
      "Step: NaN | Loss: 1.3936e-06 | Loss_d: 5.0302e-05 Loss_e: 1.9925e-05 | Loss_b: 1.3270e-05\n",
      "Step: NaN | Loss: 1.3754e-06 | Loss_d: 4.9782e-05 Loss_e: 1.9980e-05 | Loss_b: 1.2643e-05\n",
      "Step: NaN | Loss: 1.3736e-06 | Loss_d: 4.9589e-05 Loss_e: 1.9977e-05 | Loss_b: 1.2729e-05\n",
      "Step: NaN | Loss: 1.3892e-06 | Loss_d: 4.9214e-05 Loss_e: 2.0296e-05 | Loss_b: 1.3723e-05\n",
      "Step: NaN | Loss: 1.3734e-06 | Loss_d: 4.9539e-05 Loss_e: 1.9983e-05 | Loss_b: 1.2766e-05\n",
      "Step: NaN | Loss: 1.3734e-06 | Loss_d: 4.9571e-05 Loss_e: 1.9959e-05 | Loss_b: 1.2756e-05\n",
      "Step: NaN | Loss: 1.3723e-06 | Loss_d: 4.9547e-05 Loss_e: 1.9949e-05 | Loss_b: 1.2722e-05\n",
      "Step: NaN | Loss: 1.3718e-06 | Loss_d: 4.9505e-05 Loss_e: 1.9952e-05 | Loss_b: 1.2733e-05\n",
      "Step: NaN | Loss: 1.3709e-06 | Loss_d: 4.9351e-05 Loss_e: 1.9976e-05 | Loss_b: 1.2812e-05\n",
      "Step: NaN | Loss: 1.3877e-06 | Loss_d: 4.8863e-05 Loss_e: 2.0306e-05 | Loss_b: 1.3971e-05\n",
      "Step: NaN | Loss: 1.3709e-06 | Loss_d: 4.9334e-05 Loss_e: 1.9979e-05 | Loss_b: 1.2825e-05\n",
      "Step: NaN | Loss: 1.3697e-06 | Loss_d: 4.9309e-05 Loss_e: 1.9975e-05 | Loss_b: 1.2782e-05\n",
      "Step: NaN | Loss: 1.3707e-06 | Loss_d: 4.9238e-05 Loss_e: 2.0027e-05 | Loss_b: 1.2859e-05\n",
      "Step: NaN | Loss: 1.3690e-06 | Loss_d: 4.9275e-05 Loss_e: 1.9982e-05 | Loss_b: 1.2763e-05\n",
      "Step: NaN | Loss: 1.3678e-06 | Loss_d: 4.9198e-05 Loss_e: 1.9944e-05 | Loss_b: 1.2812e-05\n",
      "Step: NaN | Loss: 1.3704e-06 | Loss_d: 4.9038e-05 Loss_e: 1.9953e-05 | Loss_b: 1.3113e-05\n",
      "Step: NaN | Loss: 1.3674e-06 | Loss_d: 4.9132e-05 Loss_e: 1.9920e-05 | Loss_b: 1.2875e-05\n",
      "Step: NaN | Loss: 1.3887e-06 | Loss_d: 4.9814e-05 Loss_e: 2.0333e-05 | Loss_b: 1.3058e-05\n",
      "Step: NaN | Loss: 1.3666e-06 | Loss_d: 4.9211e-05 Loss_e: 1.9939e-05 | Loss_b: 1.2726e-05\n",
      "Step: NaN | Loss: 1.3653e-06 | Loss_d: 4.9269e-05 Loss_e: 1.9923e-05 | Loss_b: 1.2612e-05\n",
      "Step: NaN | Loss: 1.3684e-06 | Loss_d: 4.9620e-05 Loss_e: 1.9922e-05 | Loss_b: 1.2445e-05\n",
      "Step: NaN | Loss: 1.3649e-06 | Loss_d: 4.9341e-05 Loss_e: 1.9913e-05 | Loss_b: 1.2525e-05\n",
      "Step: NaN | Loss: 1.3643e-06 | Loss_d: 4.9415e-05 Loss_e: 1.9845e-05 | Loss_b: 1.2482e-05\n",
      "Step: NaN | Loss: 1.3643e-06 | Loss_d: 4.9400e-05 Loss_e: 1.9855e-05 | Loss_b: 1.2485e-05\n",
      "Step: NaN | Loss: 1.3639e-06 | Loss_d: 4.9395e-05 Loss_e: 1.9852e-05 | Loss_b: 1.2473e-05\n",
      "Step: NaN | Loss: 1.3633e-06 | Loss_d: 4.9384e-05 Loss_e: 1.9852e-05 | Loss_b: 1.2447e-05\n",
      "Step: NaN | Loss: 1.3793e-06 | Loss_d: 4.9521e-05 Loss_e: 2.0175e-05 | Loss_b: 1.2944e-05\n",
      "Step: NaN | Loss: 1.3633e-06 | Loss_d: 4.9384e-05 Loss_e: 1.9852e-05 | Loss_b: 1.2447e-05\n",
      "Step: NaN | Loss: 1.3620e-06 | Loss_d: 4.9310e-05 Loss_e: 1.9849e-05 | Loss_b: 1.2447e-05\n",
      "Step: NaN | Loss: 1.3604e-06 | Loss_d: 4.9028e-05 Loss_e: 1.9887e-05 | Loss_b: 1.2590e-05\n",
      "Step: NaN | Loss: 1.3602e-06 | Loss_d: 4.9082e-05 Loss_e: 1.9873e-05 | Loss_b: 1.2543e-05\n",
      "Step: NaN | Loss: 1.3601e-06 | Loss_d: 4.9056e-05 Loss_e: 1.9844e-05 | Loss_b: 1.2590e-05\n",
      "Step: NaN | Loss: 1.3599e-06 | Loss_d: 4.9066e-05 Loss_e: 1.9854e-05 | Loss_b: 1.2555e-05\n",
      "Step: NaN | Loss: 1.3596e-06 | Loss_d: 4.9059e-05 Loss_e: 1.9851e-05 | Loss_b: 1.2548e-05\n",
      "Step: NaN | Loss: 1.3591e-06 | Loss_d: 4.9040e-05 Loss_e: 1.9851e-05 | Loss_b: 1.2536e-05\n",
      "Step: NaN | Loss: 1.3711e-06 | Loss_d: 4.9121e-05 Loss_e: 2.0117e-05 | Loss_b: 1.2910e-05\n",
      "Step: NaN | Loss: 1.3591e-06 | Loss_d: 4.9039e-05 Loss_e: 1.9851e-05 | Loss_b: 1.2536e-05\n",
      "Step: NaN | Loss: 1.3586e-06 | Loss_d: 4.8956e-05 Loss_e: 1.9871e-05 | Loss_b: 1.2574e-05\n",
      "Step: NaN | Loss: 1.3659e-06 | Loss_d: 4.8695e-05 Loss_e: 2.0083e-05 | Loss_b: 1.3061e-05\n",
      "Step: NaN | Loss: 1.3586e-06 | Loss_d: 4.8955e-05 Loss_e: 1.9871e-05 | Loss_b: 1.2575e-05\n",
      "Step: NaN | Loss: 1.3581e-06 | Loss_d: 4.8924e-05 Loss_e: 1.9879e-05 | Loss_b: 1.2568e-05\n",
      "Step: NaN | Loss: 1.3617e-06 | Loss_d: 4.8846e-05 Loss_e: 1.9943e-05 | Loss_b: 1.2795e-05\n",
      "Step: NaN | Loss: 1.3581e-06 | Loss_d: 4.8914e-05 Loss_e: 1.9883e-05 | Loss_b: 1.2572e-05\n",
      "Step: NaN | Loss: 1.3578e-06 | Loss_d: 4.8903e-05 Loss_e: 1.9876e-05 | Loss_b: 1.2575e-05\n",
      "Step: NaN | Loss: 1.3573e-06 | Loss_d: 4.8865e-05 Loss_e: 1.9861e-05 | Loss_b: 1.2598e-05\n",
      "Step: NaN | Loss: 1.3573e-06 | Loss_d: 4.8865e-05 Loss_e: 1.9861e-05 | Loss_b: 1.2597e-05\n",
      "Step: NaN | Loss: 1.3566e-06 | Loss_d: 4.8859e-05 Loss_e: 1.9825e-05 | Loss_b: 1.2596e-05\n",
      "Step: NaN | Loss: 1.3550e-06 | Loss_d: 4.8858e-05 Loss_e: 1.9714e-05 | Loss_b: 1.2614e-05\n",
      "Step: NaN | Loss: 1.3938e-06 | Loss_d: 4.9582e-05 Loss_e: 1.9990e-05 | Loss_b: 1.3937e-05\n",
      "Step: NaN | Loss: 1.3550e-06 | Loss_d: 4.8861e-05 Loss_e: 1.9704e-05 | Loss_b: 1.2619e-05\n",
      "Step: NaN | Loss: 1.3542e-06 | Loss_d: 4.9076e-05 Loss_e: 1.9660e-05 | Loss_b: 1.2400e-05\n",
      "Step: NaN | Loss: 1.3541e-06 | Loss_d: 4.9019e-05 Loss_e: 1.9668e-05 | Loss_b: 1.2444e-05\n",
      "Step: NaN | Loss: 1.3536e-06 | Loss_d: 4.8986e-05 Loss_e: 1.9658e-05 | Loss_b: 1.2455e-05\n",
      "Step: NaN | Loss: 1.3595e-06 | Loss_d: 4.8948e-05 Loss_e: 1.9725e-05 | Loss_b: 1.2779e-05\n",
      "Step: NaN | Loss: 1.3535e-06 | Loss_d: 4.8981e-05 Loss_e: 1.9657e-05 | Loss_b: 1.2459e-05\n",
      "Step: NaN | Loss: 1.3532e-06 | Loss_d: 4.8978e-05 Loss_e: 1.9646e-05 | Loss_b: 1.2455e-05\n",
      "Step: NaN | Loss: 1.3535e-06 | Loss_d: 4.9003e-05 Loss_e: 1.9608e-05 | Loss_b: 1.2484e-05\n",
      "Step: NaN | Loss: 1.3531e-06 | Loss_d: 4.8980e-05 Loss_e: 1.9629e-05 | Loss_b: 1.2458e-05\n",
      "Step: NaN | Loss: 1.3528e-06 | Loss_d: 4.9009e-05 Loss_e: 1.9616e-05 | Loss_b: 1.2425e-05\n",
      "Step: NaN | Loss: 1.3527e-06 | Loss_d: 4.9130e-05 Loss_e: 1.9586e-05 | Loss_b: 1.2331e-05\n",
      "Step: NaN | Loss: 1.3525e-06 | Loss_d: 4.9072e-05 Loss_e: 1.9595e-05 | Loss_b: 1.2367e-05\n",
      "Step: NaN | Loss: 1.3520e-06 | Loss_d: 4.9057e-05 Loss_e: 1.9568e-05 | Loss_b: 1.2381e-05\n",
      "Step: NaN | Loss: 1.3515e-06 | Loss_d: 4.9015e-05 Loss_e: 1.9492e-05 | Loss_b: 1.2470e-05\n",
      "Step: NaN | Loss: 1.3514e-06 | Loss_d: 4.9024e-05 Loss_e: 1.9507e-05 | Loss_b: 1.2439e-05\n",
      "Step: NaN | Loss: 1.3502e-06 | Loss_d: 4.8873e-05 Loss_e: 1.9533e-05 | Loss_b: 1.2491e-05\n",
      "Step: NaN | Loss: 1.3761e-06 | Loss_d: 4.8677e-05 Loss_e: 2.0118e-05 | Loss_b: 1.3654e-05\n",
      "Step: NaN | Loss: 1.3502e-06 | Loss_d: 4.8869e-05 Loss_e: 1.9534e-05 | Loss_b: 1.2493e-05\n",
      "Step: NaN | Loss: 1.3473e-06 | Loss_d: 4.8767e-05 Loss_e: 1.9497e-05 | Loss_b: 1.2456e-05\n",
      "Step: NaN | Loss: 1.3428e-06 | Loss_d: 4.8503e-05 Loss_e: 1.9452e-05 | Loss_b: 1.2497e-05\n",
      "Step: NaN | Loss: 1.3427e-06 | Loss_d: 4.8519e-05 Loss_e: 1.9449e-05 | Loss_b: 1.2480e-05\n",
      "Step: NaN | Loss: 1.3460e-06 | Loss_d: 4.8218e-05 Loss_e: 1.9404e-05 | Loss_b: 1.3020e-05\n",
      "Step: NaN | Loss: 1.3411e-06 | Loss_d: 4.8401e-05 Loss_e: 1.9394e-05 | Loss_b: 1.2559e-05\n",
      "Step: NaN | Loss: 1.3395e-06 | Loss_d: 4.8318e-05 Loss_e: 1.9393e-05 | Loss_b: 1.2543e-05\n",
      "Step: NaN | Loss: 1.3527e-06 | Loss_d: 4.8234e-05 Loss_e: 1.9638e-05 | Loss_b: 1.3173e-05\n",
      "Step: NaN | Loss: 1.3394e-06 | Loss_d: 4.8295e-05 Loss_e: 1.9399e-05 | Loss_b: 1.2553e-05\n",
      "Step: NaN | Loss: 1.3380e-06 | Loss_d: 4.8222e-05 Loss_e: 1.9394e-05 | Loss_b: 1.2549e-05\n",
      "Step: NaN | Loss: 1.3441e-06 | Loss_d: 4.8053e-05 Loss_e: 1.9591e-05 | Loss_b: 1.2887e-05\n",
      "Step: NaN | Loss: 1.3377e-06 | Loss_d: 4.8178e-05 Loss_e: 1.9403e-05 | Loss_b: 1.2566e-05\n",
      "Step: NaN | Loss: 1.3365e-06 | Loss_d: 4.8106e-05 Loss_e: 1.9394e-05 | Loss_b: 1.2574e-05\n",
      "Step: NaN | Loss: 1.3361e-06 | Loss_d: 4.7906e-05 Loss_e: 1.9408e-05 | Loss_b: 1.2739e-05\n",
      "Step: NaN | Loss: 1.3354e-06 | Loss_d: 4.7976e-05 Loss_e: 1.9392e-05 | Loss_b: 1.2643e-05\n",
      "Step: NaN | Loss: 1.3336e-06 | Loss_d: 4.7927e-05 Loss_e: 1.9321e-05 | Loss_b: 1.2657e-05\n",
      "Step: NaN | Loss: 1.3383e-06 | Loss_d: 4.7787e-05 Loss_e: 1.9342e-05 | Loss_b: 1.3054e-05\n",
      "Step: NaN | Loss: 1.3331e-06 | Loss_d: 4.7883e-05 Loss_e: 1.9279e-05 | Loss_b: 1.2707e-05\n",
      "Step: NaN | Loss: 1.3330e-06 | Loss_d: 4.7979e-05 Loss_e: 1.9251e-05 | Loss_b: 1.2637e-05\n",
      "Step: NaN | Loss: 1.3328e-06 | Loss_d: 4.7929e-05 Loss_e: 1.9261e-05 | Loss_b: 1.2661e-05\n",
      "Step: NaN | Loss: 1.3327e-06 | Loss_d: 4.7935e-05 Loss_e: 1.9248e-05 | Loss_b: 1.2662e-05\n",
      "Step: NaN | Loss: 1.3329e-06 | Loss_d: 4.7968e-05 Loss_e: 1.9206e-05 | Loss_b: 1.2683e-05\n",
      "Step: NaN | Loss: 1.3326e-06 | Loss_d: 4.7945e-05 Loss_e: 1.9233e-05 | Loss_b: 1.2664e-05\n",
      "Step: NaN | Loss: 1.3322e-06 | Loss_d: 4.7854e-05 Loss_e: 1.9243e-05 | Loss_b: 1.2721e-05\n",
      "Step: NaN | Loss: 1.3336e-06 | Loss_d: 4.7517e-05 Loss_e: 1.9319e-05 | Loss_b: 1.3064e-05\n",
      "Step: NaN | Loss: 1.3321e-06 | Loss_d: 4.7777e-05 Loss_e: 1.9254e-05 | Loss_b: 1.2779e-05\n",
      "Step: NaN | Loss: 1.3315e-06 | Loss_d: 4.7767e-05 Loss_e: 1.9257e-05 | Loss_b: 1.2750e-05\n",
      "Step: NaN | Loss: 1.3324e-06 | Loss_d: 4.7746e-05 Loss_e: 1.9333e-05 | Loss_b: 1.2751e-05\n",
      "Step: NaN | Loss: 1.3312e-06 | Loss_d: 4.7757e-05 Loss_e: 1.9270e-05 | Loss_b: 1.2730e-05\n",
      "Step: NaN | Loss: 1.3309e-06 | Loss_d: 4.7737e-05 Loss_e: 1.9270e-05 | Loss_b: 1.2735e-05\n",
      "Step: NaN | Loss: 1.3305e-06 | Loss_d: 4.7664e-05 Loss_e: 1.9276e-05 | Loss_b: 1.2777e-05\n",
      "Step: NaN | Loss: 1.3407e-06 | Loss_d: 4.7449e-05 Loss_e: 1.9484e-05 | Loss_b: 1.3394e-05\n",
      "Step: NaN | Loss: 1.3305e-06 | Loss_d: 4.7663e-05 Loss_e: 1.9276e-05 | Loss_b: 1.2778e-05\n",
      "Step: NaN | Loss: 1.3300e-06 | Loss_d: 4.7632e-05 Loss_e: 1.9272e-05 | Loss_b: 1.2783e-05\n",
      "Step: NaN | Loss: 1.3289e-06 | Loss_d: 4.7521e-05 Loss_e: 1.9276e-05 | Loss_b: 1.2821e-05\n",
      "Step: NaN | Loss: 1.3454e-06 | Loss_d: 4.7313e-05 Loss_e: 1.9813e-05 | Loss_b: 1.3484e-05\n",
      "Step: NaN | Loss: 1.3288e-06 | Loss_d: 4.7493e-05 Loss_e: 1.9283e-05 | Loss_b: 1.2837e-05\n",
      "Step: NaN | Loss: 1.3276e-06 | Loss_d: 4.7283e-05 Loss_e: 1.9390e-05 | Loss_b: 1.2872e-05\n",
      "Step: NaN | Loss: 1.3419e-06 | Loss_d: 4.6623e-05 Loss_e: 2.0248e-05 | Loss_b: 1.3525e-05\n",
      "Step: NaN | Loss: 1.3276e-06 | Loss_d: 4.7263e-05 Loss_e: 1.9403e-05 | Loss_b: 1.2878e-05\n",
      "Step: NaN | Loss: 1.3262e-06 | Loss_d: 4.7115e-05 Loss_e: 1.9408e-05 | Loss_b: 1.2936e-05\n",
      "Step: NaN | Loss: 1.3440e-06 | Loss_d: 4.6575e-05 Loss_e: 1.9590e-05 | Loss_b: 1.4359e-05\n",
      "Step: NaN | Loss: 1.3262e-06 | Loss_d: 4.7101e-05 Loss_e: 1.9410e-05 | Loss_b: 1.2949e-05\n",
      "Step: NaN | Loss: 1.3256e-06 | Loss_d: 4.7049e-05 Loss_e: 1.9429e-05 | Loss_b: 1.2943e-05\n",
      "Step: NaN | Loss: 1.3244e-06 | Loss_d: 4.6860e-05 Loss_e: 1.9531e-05 | Loss_b: 1.2960e-05\n",
      "Step: NaN | Loss: 1.3244e-06 | Loss_d: 4.6874e-05 Loss_e: 1.9521e-05 | Loss_b: 1.2955e-05\n",
      "Step: NaN | Loss: 1.3229e-06 | Loss_d: 4.6958e-05 Loss_e: 1.9489e-05 | Loss_b: 1.2813e-05\n",
      "Step: NaN | Loss: 1.3254e-06 | Loss_d: 4.7424e-05 Loss_e: 1.9522e-05 | Loss_b: 1.2466e-05\n",
      "Step: NaN | Loss: 1.3222e-06 | Loss_d: 4.7083e-05 Loss_e: 1.9471e-05 | Loss_b: 1.2666e-05\n",
      "Step: NaN | Loss: 1.3200e-06 | Loss_d: 4.6911e-05 Loss_e: 1.9453e-05 | Loss_b: 1.2721e-05\n",
      "Step: NaN | Loss: 1.3214e-06 | Loss_d: 4.6348e-05 Loss_e: 1.9600e-05 | Loss_b: 1.3225e-05\n",
      "Step: NaN | Loss: 1.3184e-06 | Loss_d: 4.6671e-05 Loss_e: 1.9468e-05 | Loss_b: 1.2851e-05\n",
      "Step: NaN | Loss: 1.3204e-06 | Loss_d: 4.6517e-05 Loss_e: 1.9487e-05 | Loss_b: 1.3105e-05\n",
      "Step: NaN | Loss: 1.3169e-06 | Loss_d: 4.6589e-05 Loss_e: 1.9463e-05 | Loss_b: 1.2850e-05\n",
      "Step: NaN | Loss: 1.3159e-06 | Loss_d: 4.6484e-05 Loss_e: 1.9427e-05 | Loss_b: 1.2930e-05\n",
      "Step: NaN | Loss: 1.3302e-06 | Loss_d: 4.6187e-05 Loss_e: 1.9470e-05 | Loss_b: 1.4039e-05\n",
      "Step: NaN | Loss: 1.3159e-06 | Loss_d: 4.6479e-05 Loss_e: 1.9426e-05 | Loss_b: 1.2935e-05\n",
      "Step: NaN | Loss: 1.3150e-06 | Loss_d: 4.6310e-05 Loss_e: 1.9477e-05 | Loss_b: 1.2999e-05\n",
      "Step: NaN | Loss: 1.3258e-06 | Loss_d: 4.5795e-05 Loss_e: 1.9861e-05 | Loss_b: 1.3776e-05\n",
      "Step: NaN | Loss: 1.3149e-06 | Loss_d: 4.6278e-05 Loss_e: 1.9489e-05 | Loss_b: 1.3015e-05\n",
      "Step: NaN | Loss: 1.3146e-06 | Loss_d: 4.6232e-05 Loss_e: 1.9488e-05 | Loss_b: 1.3040e-05\n",
      "Step: NaN | Loss: 1.3157e-06 | Loss_d: 4.6066e-05 Loss_e: 1.9519e-05 | Loss_b: 1.3247e-05\n",
      "Step: NaN | Loss: 1.3145e-06 | Loss_d: 4.6194e-05 Loss_e: 1.9490e-05 | Loss_b: 1.3071e-05\n",
      "Step: NaN | Loss: 1.3139e-06 | Loss_d: 4.6214e-05 Loss_e: 1.9486e-05 | Loss_b: 1.3018e-05\n",
      "Step: NaN | Loss: 1.3145e-06 | Loss_d: 4.6306e-05 Loss_e: 1.9504e-05 | Loss_b: 1.2947e-05\n",
      "Step: NaN | Loss: 1.3135e-06 | Loss_d: 4.6246e-05 Loss_e: 1.9487e-05 | Loss_b: 1.2966e-05\n",
      "Step: NaN | Loss: 1.3123e-06 | Loss_d: 4.6171e-05 Loss_e: 1.9524e-05 | Loss_b: 1.2933e-05\n",
      "Step: NaN | Loss: 1.3243e-06 | Loss_d: 4.5941e-05 Loss_e: 2.0140e-05 | Loss_b: 1.3262e-05\n",
      "Step: NaN | Loss: 1.3123e-06 | Loss_d: 4.6155e-05 Loss_e: 1.9539e-05 | Loss_b: 1.2931e-05\n",
      "Step: NaN | Loss: 1.3118e-06 | Loss_d: 4.6139e-05 Loss_e: 1.9551e-05 | Loss_b: 1.2905e-05\n",
      "Step: NaN | Loss: 1.3127e-06 | Loss_d: 4.6116e-05 Loss_e: 1.9649e-05 | Loss_b: 1.2883e-05\n",
      "Step: NaN | Loss: 1.3116e-06 | Loss_d: 4.6125e-05 Loss_e: 1.9572e-05 | Loss_b: 1.2885e-05\n",
      "Step: NaN | Loss: 1.3108e-06 | Loss_d: 4.6063e-05 Loss_e: 1.9607e-05 | Loss_b: 1.2863e-05\n",
      "Step: NaN | Loss: 1.3108e-06 | Loss_d: 4.5844e-05 Loss_e: 1.9811e-05 | Loss_b: 1.2881e-05\n",
      "Step: NaN | Loss: 1.3101e-06 | Loss_d: 4.5947e-05 Loss_e: 1.9695e-05 | Loss_b: 1.2852e-05\n",
      "Step: NaN | Loss: 1.3094e-06 | Loss_d: 4.5834e-05 Loss_e: 1.9778e-05 | Loss_b: 1.2842e-05\n",
      "Step: NaN | Loss: 1.3195e-06 | Loss_d: 4.5555e-05 Loss_e: 2.0243e-05 | Loss_b: 1.3259e-05\n",
      "Step: NaN | Loss: 1.3094e-06 | Loss_d: 4.5819e-05 Loss_e: 1.9791e-05 | Loss_b: 1.2842e-05\n",
      "Step: NaN | Loss: 1.3088e-06 | Loss_d: 4.5785e-05 Loss_e: 1.9788e-05 | Loss_b: 1.2840e-05\n",
      "Step: NaN | Loss: 1.3093e-06 | Loss_d: 4.5668e-05 Loss_e: 1.9840e-05 | Loss_b: 1.2935e-05\n",
      "Step: NaN | Loss: 1.3084e-06 | Loss_d: 4.5734e-05 Loss_e: 1.9797e-05 | Loss_b: 1.2860e-05\n",
      "Step: NaN | Loss: 1.3077e-06 | Loss_d: 4.5756e-05 Loss_e: 1.9803e-05 | Loss_b: 1.2790e-05\n",
      "Step: NaN | Loss: 1.3085e-06 | Loss_d: 4.5896e-05 Loss_e: 1.9885e-05 | Loss_b: 1.2617e-05\n",
      "Step: NaN | Loss: 1.3073e-06 | Loss_d: 4.5797e-05 Loss_e: 1.9821e-05 | Loss_b: 1.2708e-05\n",
      "Step: NaN | Loss: 1.3070e-06 | Loss_d: 4.5790e-05 Loss_e: 1.9795e-05 | Loss_b: 1.2723e-05\n",
      "Step: NaN | Loss: 1.3079e-06 | Loss_d: 4.5775e-05 Loss_e: 1.9713e-05 | Loss_b: 1.2876e-05\n",
      "Step: NaN | Loss: 1.3069e-06 | Loss_d: 4.5786e-05 Loss_e: 1.9773e-05 | Loss_b: 1.2744e-05\n",
      "Step: NaN | Loss: 1.3065e-06 | Loss_d: 4.5788e-05 Loss_e: 1.9747e-05 | Loss_b: 1.2742e-05\n",
      "Step: NaN | Loss: 1.3060e-06 | Loss_d: 4.5807e-05 Loss_e: 1.9661e-05 | Loss_b: 1.2782e-05\n",
      "Step: NaN | Loss: 1.3060e-06 | Loss_d: 4.5800e-05 Loss_e: 1.9683e-05 | Loss_b: 1.2763e-05\n",
      "Step: NaN | Loss: 1.3051e-06 | Loss_d: 4.5695e-05 Loss_e: 1.9717e-05 | Loss_b: 1.2782e-05\n",
      "Step: NaN | Loss: 1.3046e-06 | Loss_d: 4.5360e-05 Loss_e: 1.9896e-05 | Loss_b: 1.2910e-05\n",
      "Step: NaN | Loss: 1.3043e-06 | Loss_d: 4.5478e-05 Loss_e: 1.9817e-05 | Loss_b: 1.2850e-05\n",
      "Step: NaN | Loss: 1.3030e-06 | Loss_d: 4.5509e-05 Loss_e: 1.9820e-05 | Loss_b: 1.2742e-05\n",
      "Step: NaN | Loss: 1.3111e-06 | Loss_d: 4.5712e-05 Loss_e: 2.0063e-05 | Loss_b: 1.2779e-05\n",
      "Step: NaN | Loss: 1.3029e-06 | Loss_d: 4.5525e-05 Loss_e: 1.9829e-05 | Loss_b: 1.2708e-05\n",
      "Step: NaN | Loss: 1.3020e-06 | Loss_d: 4.5555e-05 Loss_e: 1.9789e-05 | Loss_b: 1.2662e-05\n",
      "Step: NaN | Loss: 1.3010e-06 | Loss_d: 4.5709e-05 Loss_e: 1.9687e-05 | Loss_b: 1.2551e-05\n",
      "Step: NaN | Loss: 1.3008e-06 | Loss_d: 4.5659e-05 Loss_e: 1.9707e-05 | Loss_b: 1.2571e-05\n",
      "Step: NaN | Loss: 1.3020e-06 | Loss_d: 4.5593e-05 Loss_e: 1.9574e-05 | Loss_b: 1.2842e-05\n",
      "Step: NaN | Loss: 1.3002e-06 | Loss_d: 4.5623e-05 Loss_e: 1.9644e-05 | Loss_b: 1.2631e-05\n",
      "Step: NaN | Loss: 1.2996e-06 | Loss_d: 4.5691e-05 Loss_e: 1.9590e-05 | Loss_b: 1.2582e-05\n",
      "Step: NaN | Loss: 1.3005e-06 | Loss_d: 4.6028e-05 Loss_e: 1.9427e-05 | Loss_b: 1.2465e-05\n",
      "Step: NaN | Loss: 1.2993e-06 | Loss_d: 4.5785e-05 Loss_e: 1.9530e-05 | Loss_b: 1.2532e-05\n",
      "Step: NaN | Loss: 1.2973e-06 | Loss_d: 4.5590e-05 Loss_e: 1.9581e-05 | Loss_b: 1.2554e-05\n",
      "Step: NaN | Loss: 1.3008e-06 | Loss_d: 4.4922e-05 Loss_e: 1.9911e-05 | Loss_b: 1.3102e-05\n",
      "Step: NaN | Loss: 1.2964e-06 | Loss_d: 4.5363e-05 Loss_e: 1.9663e-05 | Loss_b: 1.2646e-05\n",
      "Step: NaN | Loss: 1.2939e-06 | Loss_d: 4.5148e-05 Loss_e: 1.9735e-05 | Loss_b: 1.2639e-05\n",
      "Step: NaN | Loss: 1.3002e-06 | Loss_d: 4.4475e-05 Loss_e: 2.0134e-05 | Loss_b: 1.3290e-05\n",
      "Step: NaN | Loss: 1.2930e-06 | Loss_d: 4.4949e-05 Loss_e: 1.9819e-05 | Loss_b: 1.2700e-05\n",
      "Step: NaN | Loss: 1.2927e-06 | Loss_d: 4.4920e-05 Loss_e: 1.9825e-05 | Loss_b: 1.2708e-05\n",
      "Step: NaN | Loss: 1.2922e-06 | Loss_d: 4.4810e-05 Loss_e: 1.9861e-05 | Loss_b: 1.2747e-05\n",
      "Step: NaN | Loss: 1.3010e-06 | Loss_d: 4.4409e-05 Loss_e: 2.0351e-05 | Loss_b: 1.3187e-05\n",
      "Step: NaN | Loss: 1.2921e-06 | Loss_d: 4.4786e-05 Loss_e: 1.9872e-05 | Loss_b: 1.2760e-05\n",
      "Step: NaN | Loss: 1.2910e-06 | Loss_d: 4.4753e-05 Loss_e: 1.9854e-05 | Loss_b: 1.2742e-05\n",
      "Step: NaN | Loss: 1.2890e-06 | Loss_d: 4.4681e-05 Loss_e: 1.9837e-05 | Loss_b: 1.2713e-05\n",
      "Step: NaN | Loss: 1.2890e-06 | Loss_d: 4.4682e-05 Loss_e: 1.9836e-05 | Loss_b: 1.2712e-05\n",
      "Step: NaN | Loss: 1.2914e-06 | Loss_d: 4.4058e-05 Loss_e: 1.9992e-05 | Loss_b: 1.3322e-05\n",
      "Step: NaN | Loss: 1.2884e-06 | Loss_d: 4.4481e-05 Loss_e: 1.9878e-05 | Loss_b: 1.2837e-05\n",
      "Step: NaN | Loss: 1.2879e-06 | Loss_d: 4.4390e-05 Loss_e: 1.9928e-05 | Loss_b: 1.2849e-05\n",
      "Step: NaN | Loss: 1.2919e-06 | Loss_d: 4.4100e-05 Loss_e: 2.0193e-05 | Loss_b: 1.3109e-05\n",
      "Step: NaN | Loss: 1.2879e-06 | Loss_d: 4.4361e-05 Loss_e: 1.9946e-05 | Loss_b: 1.2857e-05\n",
      "Step: NaN | Loss: 1.2876e-06 | Loss_d: 4.4340e-05 Loss_e: 1.9955e-05 | Loss_b: 1.2848e-05\n",
      "Step: NaN | Loss: 1.2879e-06 | Loss_d: 4.4272e-05 Loss_e: 2.0009e-05 | Loss_b: 1.2880e-05\n",
      "Step: NaN | Loss: 1.2873e-06 | Loss_d: 4.4311e-05 Loss_e: 1.9972e-05 | Loss_b: 1.2847e-05\n",
      "Step: NaN | Loss: 1.2865e-06 | Loss_d: 4.4224e-05 Loss_e: 2.0032e-05 | Loss_b: 1.2823e-05\n",
      "Step: NaN | Loss: 1.2873e-06 | Loss_d: 4.3942e-05 Loss_e: 2.0360e-05 | Loss_b: 1.2827e-05\n",
      "Step: NaN | Loss: 1.2859e-06 | Loss_d: 4.4112e-05 Loss_e: 2.0133e-05 | Loss_b: 1.2800e-05\n",
      "Step: NaN | Loss: 1.2844e-06 | Loss_d: 4.4016e-05 Loss_e: 2.0174e-05 | Loss_b: 1.2766e-05\n",
      "Step: NaN | Loss: 1.2867e-06 | Loss_d: 4.3707e-05 Loss_e: 2.0469e-05 | Loss_b: 1.2914e-05\n",
      "Step: NaN | Loss: 1.2837e-06 | Loss_d: 4.3901e-05 Loss_e: 2.0248e-05 | Loss_b: 1.2765e-05\n",
      "Step: NaN | Loss: 1.2825e-06 | Loss_d: 4.4003e-05 Loss_e: 2.0282e-05 | Loss_b: 1.2557e-05\n",
      "Step: NaN | Loss: 1.2992e-06 | Loss_d: 4.4666e-05 Loss_e: 2.0821e-05 | Loss_b: 1.2355e-05\n",
      "Step: NaN | Loss: 1.2825e-06 | Loss_d: 4.4011e-05 Loss_e: 2.0286e-05 | Loss_b: 1.2544e-05\n",
      "Step: NaN | Loss: 1.2811e-06 | Loss_d: 4.3963e-05 Loss_e: 2.0240e-05 | Loss_b: 1.2554e-05\n",
      "Step: NaN | Loss: 1.2914e-06 | Loss_d: 4.3971e-05 Loss_e: 2.0330e-05 | Loss_b: 1.3071e-05\n",
      "Step: NaN | Loss: 1.2810e-06 | Loss_d: 4.3950e-05 Loss_e: 2.0229e-05 | Loss_b: 1.2570e-05\n",
      "Step: NaN | Loss: 1.2803e-06 | Loss_d: 4.3998e-05 Loss_e: 2.0129e-05 | Loss_b: 1.2582e-05\n",
      "Step: NaN | Loss: 1.2831e-06 | Loss_d: 4.4239e-05 Loss_e: 1.9831e-05 | Loss_b: 1.2805e-05\n",
      "Step: NaN | Loss: 1.2802e-06 | Loss_d: 4.4035e-05 Loss_e: 2.0064e-05 | Loss_b: 1.2602e-05\n",
      "Step: NaN | Loss: 1.2810e-06 | Loss_d: 4.4124e-05 Loss_e: 1.9936e-05 | Loss_b: 1.2691e-05\n",
      "Step: NaN | Loss: 1.2798e-06 | Loss_d: 4.4063e-05 Loss_e: 2.0013e-05 | Loss_b: 1.2599e-05\n",
      "Step: NaN | Loss: 1.2796e-06 | Loss_d: 4.4067e-05 Loss_e: 2.0008e-05 | Loss_b: 1.2590e-05\n",
      "Step: NaN | Loss: 1.2800e-06 | Loss_d: 4.4105e-05 Loss_e: 2.0012e-05 | Loss_b: 1.2576e-05\n",
      "Step: NaN | Loss: 1.2795e-06 | Loss_d: 4.4073e-05 Loss_e: 2.0006e-05 | Loss_b: 1.2583e-05\n",
      "Step: NaN | Loss: 1.2792e-06 | Loss_d: 4.4026e-05 Loss_e: 2.0022e-05 | Loss_b: 1.2596e-05\n",
      "Step: NaN | Loss: 1.2783e-06 | Loss_d: 4.3845e-05 Loss_e: 2.0091e-05 | Loss_b: 1.2652e-05\n",
      "Step: NaN | Loss: 1.2794e-06 | Loss_d: 4.3070e-05 Loss_e: 2.0558e-05 | Loss_b: 1.3025e-05\n",
      "Step: NaN | Loss: 1.2775e-06 | Loss_d: 4.3537e-05 Loss_e: 2.0237e-05 | Loss_b: 1.2766e-05\n",
      "Step: NaN | Loss: 1.2769e-06 | Loss_d: 4.3369e-05 Loss_e: 2.0275e-05 | Loss_b: 1.2861e-05\n",
      "Step: NaN | Loss: 1.2769e-06 | Loss_d: 4.3387e-05 Loss_e: 2.0270e-05 | Loss_b: 1.2848e-05\n",
      "Step: NaN | Loss: 1.2763e-06 | Loss_d: 4.3346e-05 Loss_e: 2.0330e-05 | Loss_b: 1.2792e-05\n",
      "Step: NaN | Loss: 1.2763e-06 | Loss_d: 4.3238e-05 Loss_e: 2.0627e-05 | Loss_b: 1.2606e-05\n",
      "Step: NaN | Loss: 1.2758e-06 | Loss_d: 4.3281e-05 Loss_e: 2.0467e-05 | Loss_b: 1.2694e-05\n",
      "Step: NaN | Loss: 1.2744e-06 | Loss_d: 4.3313e-05 Loss_e: 2.0407e-05 | Loss_b: 1.2635e-05\n",
      "Step: NaN | Loss: 1.2733e-06 | Loss_d: 4.3547e-05 Loss_e: 2.0287e-05 | Loss_b: 1.2453e-05\n",
      "Step: NaN | Loss: 1.2728e-06 | Loss_d: 4.3452e-05 Loss_e: 2.0306e-05 | Loss_b: 1.2504e-05\n",
      "Step: NaN | Loss: 1.2716e-06 | Loss_d: 4.3300e-05 Loss_e: 2.0545e-05 | Loss_b: 1.2342e-05\n",
      "Step: NaN | Loss: 1.2710e-06 | Loss_d: 4.3350e-05 Loss_e: 2.0439e-05 | Loss_b: 1.2363e-05\n",
      "Step: NaN | Loss: 1.2698e-06 | Loss_d: 4.3542e-05 Loss_e: 2.0278e-05 | Loss_b: 1.2262e-05\n",
      "Step: NaN | Loss: 1.2854e-06 | Loss_d: 4.4778e-05 Loss_e: 1.9871e-05 | Loss_b: 1.2363e-05\n",
      "Step: NaN | Loss: 1.2698e-06 | Loss_d: 4.3564e-05 Loss_e: 2.0262e-05 | Loss_b: 1.2254e-05\n",
      "Step: NaN | Loss: 1.2694e-06 | Loss_d: 4.3639e-05 Loss_e: 2.0220e-05 | Loss_b: 1.2199e-05\n",
      "Step: NaN | Loss: 1.2699e-06 | Loss_d: 4.3958e-05 Loss_e: 2.0103e-05 | Loss_b: 1.2021e-05\n",
      "Step: NaN | Loss: 1.2692e-06 | Loss_d: 4.3752e-05 Loss_e: 2.0168e-05 | Loss_b: 1.2125e-05\n",
      "Step: NaN | Loss: 1.2682e-06 | Loss_d: 4.3682e-05 Loss_e: 2.0181e-05 | Loss_b: 1.2122e-05\n",
      "Step: NaN | Loss: 1.2688e-06 | Loss_d: 4.3461e-05 Loss_e: 2.0334e-05 | Loss_b: 1.2226e-05\n",
      "Step: NaN | Loss: 1.2676e-06 | Loss_d: 4.3578e-05 Loss_e: 2.0226e-05 | Loss_b: 1.2143e-05\n",
      "Step: NaN | Loss: 1.2665e-06 | Loss_d: 4.3699e-05 Loss_e: 2.0103e-05 | Loss_b: 1.2079e-05\n",
      "Step: NaN | Loss: 1.2700e-06 | Loss_d: 4.4284e-05 Loss_e: 1.9820e-05 | Loss_b: 1.1985e-05\n",
      "Step: NaN | Loss: 1.2662e-06 | Loss_d: 4.3817e-05 Loss_e: 2.0010e-05 | Loss_b: 1.2034e-05\n",
      "Step: NaN | Loss: 1.2660e-06 | Loss_d: 4.3816e-05 Loss_e: 2.0015e-05 | Loss_b: 1.2020e-05\n",
      "Step: NaN | Loss: 1.2668e-06 | Loss_d: 4.3819e-05 Loss_e: 2.0040e-05 | Loss_b: 1.2037e-05\n",
      "Step: NaN | Loss: 1.2660e-06 | Loss_d: 4.3816e-05 Loss_e: 2.0019e-05 | Loss_b: 1.2014e-05\n",
      "Step: NaN | Loss: 1.2658e-06 | Loss_d: 4.3818e-05 Loss_e: 2.0024e-05 | Loss_b: 1.1995e-05\n",
      "Step: NaN | Loss: 1.2657e-06 | Loss_d: 4.3833e-05 Loss_e: 2.0060e-05 | Loss_b: 1.1943e-05\n",
      "Step: NaN | Loss: 1.2656e-06 | Loss_d: 4.3824e-05 Loss_e: 2.0040e-05 | Loss_b: 1.1963e-05\n",
      "Step: NaN | Loss: 1.2652e-06 | Loss_d: 4.3829e-05 Loss_e: 2.0007e-05 | Loss_b: 1.1969e-05\n",
      "Step: NaN | Loss: 1.2681e-06 | Loss_d: 4.3894e-05 Loss_e: 1.9901e-05 | Loss_b: 1.2181e-05\n",
      "Step: NaN | Loss: 1.2652e-06 | Loss_d: 4.3832e-05 Loss_e: 1.9996e-05 | Loss_b: 1.1974e-05\n",
      "Step: NaN | Loss: 1.2649e-06 | Loss_d: 4.3759e-05 Loss_e: 2.0043e-05 | Loss_b: 1.1985e-05\n",
      "Step: NaN | Loss: 1.2647e-06 | Loss_d: 4.3483e-05 Loss_e: 2.0255e-05 | Loss_b: 1.2036e-05\n",
      "Step: NaN | Loss: 1.2646e-06 | Loss_d: 4.3585e-05 Loss_e: 2.0170e-05 | Loss_b: 1.2015e-05\n",
      "Step: NaN | Loss: 1.2634e-06 | Loss_d: 4.3671e-05 Loss_e: 2.0122e-05 | Loss_b: 1.1903e-05\n",
      "Step: NaN | Loss: 1.2647e-06 | Loss_d: 4.4138e-05 Loss_e: 1.9990e-05 | Loss_b: 1.1648e-05\n",
      "Step: NaN | Loss: 1.2627e-06 | Loss_d: 4.3818e-05 Loss_e: 2.0063e-05 | Loss_b: 1.1775e-05\n",
      "Step: NaN | Loss: 1.2611e-06 | Loss_d: 4.3498e-05 Loss_e: 2.0243e-05 | Loss_b: 1.1816e-05\n",
      "Step: NaN | Loss: 1.2610e-06 | Loss_d: 4.3547e-05 Loss_e: 2.0205e-05 | Loss_b: 1.1800e-05\n",
      "Step: NaN | Loss: 1.2602e-06 | Loss_d: 4.3488e-05 Loss_e: 2.0190e-05 | Loss_b: 1.1826e-05\n",
      "Step: NaN | Loss: 1.2592e-06 | Loss_d: 4.3309e-05 Loss_e: 2.0143e-05 | Loss_b: 1.1993e-05\n",
      "Step: NaN | Loss: 1.2591e-06 | Loss_d: 4.3341e-05 Loss_e: 2.0152e-05 | Loss_b: 1.1948e-05\n",
      "Step: NaN | Loss: 1.2576e-06 | Loss_d: 4.3247e-05 Loss_e: 2.0162e-05 | Loss_b: 1.1937e-05\n",
      "Step: NaN | Loss: 1.2575e-06 | Loss_d: 4.3252e-05 Loss_e: 2.0159e-05 | Loss_b: 1.1933e-05\n",
      "Step: NaN | Loss: 1.2567e-06 | Loss_d: 4.3240e-05 Loss_e: 2.0211e-05 | Loss_b: 1.1843e-05\n",
      "Step: NaN | Loss: 1.2606e-06 | Loss_d: 4.3294e-05 Loss_e: 2.0499e-05 | Loss_b: 1.1733e-05\n",
      "Step: NaN | Loss: 1.2565e-06 | Loss_d: 4.3238e-05 Loss_e: 2.0250e-05 | Loss_b: 1.1794e-05\n",
      "Step: NaN | Loss: 1.2563e-06 | Loss_d: 4.3177e-05 Loss_e: 2.0302e-05 | Loss_b: 1.1792e-05\n",
      "Step: NaN | Loss: 1.2565e-06 | Loss_d: 4.2957e-05 Loss_e: 2.0528e-05 | Loss_b: 1.1801e-05\n",
      "Step: NaN | Loss: 1.2562e-06 | Loss_d: 4.3098e-05 Loss_e: 2.0376e-05 | Loss_b: 1.1791e-05\n",
      "Step: NaN | Loss: 1.2560e-06 | Loss_d: 4.3107e-05 Loss_e: 2.0356e-05 | Loss_b: 1.1788e-05\n",
      "Step: NaN | Loss: 1.2554e-06 | Loss_d: 4.3155e-05 Loss_e: 2.0279e-05 | Loss_b: 1.1781e-05\n",
      "Step: NaN | Loss: 1.2612e-06 | Loss_d: 4.3587e-05 Loss_e: 1.9999e-05 | Loss_b: 1.1981e-05\n",
      "Step: NaN | Loss: 1.2553e-06 | Loss_d: 4.3185e-05 Loss_e: 2.0241e-05 | Loss_b: 1.1783e-05\n",
      "Step: NaN | Loss: 1.2538e-06 | Loss_d: 4.3142e-05 Loss_e: 2.0285e-05 | Loss_b: 1.1696e-05\n",
      "Step: NaN | Loss: 1.2700e-06 | Loss_d: 4.3133e-05 Loss_e: 2.0599e-05 | Loss_b: 1.2360e-05\n",
      "Step: NaN | Loss: 1.2538e-06 | Loss_d: 4.3137e-05 Loss_e: 2.0293e-05 | Loss_b: 1.1691e-05\n",
      "Step: NaN | Loss: 1.2515e-06 | Loss_d: 4.3111e-05 Loss_e: 2.0319e-05 | Loss_b: 1.1552e-05\n",
      "Step: NaN | Loss: 1.2577e-06 | Loss_d: 4.3180e-05 Loss_e: 2.0715e-05 | Loss_b: 1.1462e-05\n",
      "Step: NaN | Loss: 1.2507e-06 | Loss_d: 4.3102e-05 Loss_e: 2.0375e-05 | Loss_b: 1.1459e-05\n",
      "Step: NaN | Loss: 1.2502e-06 | Loss_d: 4.3058e-05 Loss_e: 2.0384e-05 | Loss_b: 1.1462e-05\n",
      "Step: NaN | Loss: 1.2514e-06 | Loss_d: 4.2955e-05 Loss_e: 2.0482e-05 | Loss_b: 1.1542e-05\n",
      "Step: NaN | Loss: 1.2500e-06 | Loss_d: 4.3019e-05 Loss_e: 2.0400e-05 | Loss_b: 1.1473e-05\n",
      "Step: NaN | Loss: 1.2492e-06 | Loss_d: 4.2879e-05 Loss_e: 2.0434e-05 | Loss_b: 1.1534e-05\n",
      "Step: NaN | Loss: 1.2491e-06 | Loss_d: 4.2375e-05 Loss_e: 2.0602e-05 | Loss_b: 1.1861e-05\n",
      "Step: NaN | Loss: 1.2486e-06 | Loss_d: 4.2606e-05 Loss_e: 2.0515e-05 | Loss_b: 1.1687e-05\n",
      "Step: NaN | Loss: 1.2468e-06 | Loss_d: 4.2586e-05 Loss_e: 2.0495e-05 | Loss_b: 1.1618e-05\n",
      "Step: NaN | Loss: 1.2466e-06 | Loss_d: 4.2638e-05 Loss_e: 2.0484e-05 | Loss_b: 1.1565e-05\n",
      "Step: NaN | Loss: 1.2453e-06 | Loss_d: 4.2587e-05 Loss_e: 2.0476e-05 | Loss_b: 1.1547e-05\n",
      "Step: NaN | Loss: 1.2429e-06 | Loss_d: 4.2652e-05 Loss_e: 2.0335e-05 | Loss_b: 1.1481e-05\n",
      "Step: NaN | Loss: 1.2419e-06 | Loss_d: 4.3045e-05 Loss_e: 1.9945e-05 | Loss_b: 1.1418e-05\n",
      "Step: NaN | Loss: 1.2407e-06 | Loss_d: 4.2851e-05 Loss_e: 2.0078e-05 | Loss_b: 1.1405e-05\n",
      "Step: NaN | Loss: 1.2383e-06 | Loss_d: 4.2914e-05 Loss_e: 1.9892e-05 | Loss_b: 1.1383e-05\n",
      "Step: NaN | Loss: 1.2705e-06 | Loss_d: 4.3547e-05 Loss_e: 2.0036e-05 | Loss_b: 1.2536e-05\n",
      "Step: NaN | Loss: 1.2382e-06 | Loss_d: 4.2921e-05 Loss_e: 1.9881e-05 | Loss_b: 1.1386e-05\n",
      "Step: NaN | Loss: 1.2377e-06 | Loss_d: 4.2839e-05 Loss_e: 1.9939e-05 | Loss_b: 1.1376e-05\n",
      "Step: NaN | Loss: 1.2426e-06 | Loss_d: 4.2557e-05 Loss_e: 2.0269e-05 | Loss_b: 1.1623e-05\n",
      "Step: NaN | Loss: 1.2376e-06 | Loss_d: 4.2813e-05 Loss_e: 1.9960e-05 | Loss_b: 1.1377e-05\n",
      "Step: NaN | Loss: 1.2375e-06 | Loss_d: 4.2812e-05 Loss_e: 1.9951e-05 | Loss_b: 1.1383e-05\n",
      "Step: NaN | Loss: 1.2376e-06 | Loss_d: 4.2809e-05 Loss_e: 1.9918e-05 | Loss_b: 1.1422e-05\n",
      "Step: NaN | Loss: 1.2375e-06 | Loss_d: 4.2810e-05 Loss_e: 1.9936e-05 | Loss_b: 1.1396e-05\n",
      "Step: NaN | Loss: 1.2373e-06 | Loss_d: 4.2787e-05 Loss_e: 1.9947e-05 | Loss_b: 1.1396e-05\n",
      "Step: NaN | Loss: 1.2366e-06 | Loss_d: 4.2698e-05 Loss_e: 1.9993e-05 | Loss_b: 1.1401e-05\n",
      "Step: NaN | Loss: 1.2405e-06 | Loss_d: 4.2349e-05 Loss_e: 2.0332e-05 | Loss_b: 1.1640e-05\n",
      "Step: NaN | Loss: 1.2365e-06 | Loss_d: 4.2629e-05 Loss_e: 2.0037e-05 | Loss_b: 1.1417e-05\n",
      "Step: NaN | Loss: 1.2346e-06 | Loss_d: 4.2793e-05 Loss_e: 1.9747e-05 | Loss_b: 1.1433e-05\n",
      "Step: NaN | Loss: 1.2463e-06 | Loss_d: 4.3699e-05 Loss_e: 1.9054e-05 | Loss_b: 1.1920e-05\n",
      "Step: NaN | Loss: 1.2344e-06 | Loss_d: 4.2876e-05 Loss_e: 1.9630e-05 | Loss_b: 1.1451e-05\n",
      "Step: NaN | Loss: 1.2350e-06 | Loss_d: 4.2864e-05 Loss_e: 1.9631e-05 | Loss_b: 1.1501e-05\n",
      "Step: NaN | Loss: 1.2335e-06 | Loss_d: 4.2865e-05 Loss_e: 1.9625e-05 | Loss_b: 1.1417e-05\n",
      "Step: NaN | Loss: 1.2327e-06 | Loss_d: 4.2959e-05 Loss_e: 1.9587e-05 | Loss_b: 1.1312e-05\n",
      "Step: NaN | Loss: 1.2432e-06 | Loss_d: 4.3391e-05 Loss_e: 1.9515e-05 | Loss_b: 1.1579e-05\n",
      "Step: NaN | Loss: 1.2327e-06 | Loss_d: 4.2968e-05 Loss_e: 1.9584e-05 | Loss_b: 1.1306e-05\n",
      "Step: NaN | Loss: 1.2325e-06 | Loss_d: 4.2976e-05 Loss_e: 1.9575e-05 | Loss_b: 1.1292e-05\n",
      "Step: NaN | Loss: 1.2316e-06 | Loss_d: 4.3011e-05 Loss_e: 1.9537e-05 | Loss_b: 1.1245e-05\n",
      "Step: NaN | Loss: 1.2307e-06 | Loss_d: 4.3205e-05 Loss_e: 1.9380e-05 | Loss_b: 1.1151e-05\n",
      "Step: NaN | Loss: 1.2304e-06 | Loss_d: 4.3138e-05 Loss_e: 1.9426e-05 | Loss_b: 1.1155e-05\n",
      "Step: NaN | Loss: 1.2292e-06 | Loss_d: 4.3053e-05 Loss_e: 1.9412e-05 | Loss_b: 1.1180e-05\n",
      "Step: NaN | Loss: 1.2318e-06 | Loss_d: 4.2779e-05 Loss_e: 1.9434e-05 | Loss_b: 1.1592e-05\n",
      "Step: NaN | Loss: 1.2287e-06 | Loss_d: 4.2964e-05 Loss_e: 1.9406e-05 | Loss_b: 1.1245e-05\n",
      "Step: NaN | Loss: 1.2284e-06 | Loss_d: 4.2965e-05 Loss_e: 1.9367e-05 | Loss_b: 1.1264e-05\n",
      "Step: NaN | Loss: 1.2289e-06 | Loss_d: 4.3012e-05 Loss_e: 1.9237e-05 | Loss_b: 1.1377e-05\n",
      "Step: NaN | Loss: 1.2282e-06 | Loss_d: 4.2973e-05 Loss_e: 1.9321e-05 | Loss_b: 1.1294e-05\n",
      "Step: NaN | Loss: 1.2273e-06 | Loss_d: 4.3040e-05 Loss_e: 1.9262e-05 | Loss_b: 1.1233e-05\n",
      "Step: NaN | Loss: 1.2270e-06 | Loss_d: 4.3321e-05 Loss_e: 1.9070e-05 | Loss_b: 1.1123e-05\n",
      "Step: NaN | Loss: 1.2265e-06 | Loss_d: 4.3195e-05 Loss_e: 1.9146e-05 | Loss_b: 1.1144e-05\n",
      "Step: NaN | Loss: 1.2273e-06 | Loss_d: 4.3000e-05 Loss_e: 1.9380e-05 | Loss_b: 1.1154e-05\n",
      "Step: NaN | Loss: 1.2257e-06 | Loss_d: 4.3103e-05 Loss_e: 1.9213e-05 | Loss_b: 1.1120e-05\n",
      "Step: NaN | Loss: 1.2249e-06 | Loss_d: 4.2745e-05 Loss_e: 1.9455e-05 | Loss_b: 1.1191e-05\n",
      "Step: NaN | Loss: 1.2247e-06 | Loss_d: 4.2855e-05 Loss_e: 1.9369e-05 | Loss_b: 1.1155e-05\n",
      "Step: NaN | Loss: 1.2244e-06 | Loss_d: 4.2813e-05 Loss_e: 1.9398e-05 | Loss_b: 1.1149e-05\n",
      "Step: NaN | Loss: 1.2245e-06 | Loss_d: 4.2658e-05 Loss_e: 1.9539e-05 | Loss_b: 1.1169e-05\n",
      "Step: NaN | Loss: 1.2242e-06 | Loss_d: 4.2741e-05 Loss_e: 1.9456e-05 | Loss_b: 1.1149e-05\n",
      "Step: NaN | Loss: 1.2230e-06 | Loss_d: 4.2744e-05 Loss_e: 1.9373e-05 | Loss_b: 1.1157e-05\n",
      "Step: NaN | Loss: 1.2253e-06 | Loss_d: 4.2813e-05 Loss_e: 1.9113e-05 | Loss_b: 1.1487e-05\n",
      "Step: NaN | Loss: 1.2225e-06 | Loss_d: 4.2756e-05 Loss_e: 1.9283e-05 | Loss_b: 1.1205e-05\n",
      "Step: NaN | Loss: 1.2194e-06 | Loss_d: 4.2662e-05 Loss_e: 1.9235e-05 | Loss_b: 1.1161e-05\n",
      "Step: NaN | Loss: 1.2245e-06 | Loss_d: 4.2392e-05 Loss_e: 1.9599e-05 | Loss_b: 1.1371e-05\n",
      "Step: NaN | Loss: 1.2178e-06 | Loss_d: 4.2559e-05 Loss_e: 1.9254e-05 | Loss_b: 1.1153e-05\n",
      "Step: NaN | Loss: 1.2168e-06 | Loss_d: 4.2388e-05 Loss_e: 1.9286e-05 | Loss_b: 1.1229e-05\n",
      "Step: NaN | Loss: 1.2166e-06 | Loss_d: 4.2427e-05 Loss_e: 1.9272e-05 | Loss_b: 1.1193e-05\n",
      "Step: NaN | Loss: 1.2162e-06 | Loss_d: 4.2445e-05 Loss_e: 1.9218e-05 | Loss_b: 1.1202e-05\n",
      "Step: NaN | Loss: 1.2166e-06 | Loss_d: 4.2544e-05 Loss_e: 1.9033e-05 | Loss_b: 1.1315e-05\n",
      "Step: NaN | Loss: 1.2159e-06 | Loss_d: 4.2476e-05 Loss_e: 1.9143e-05 | Loss_b: 1.1232e-05\n",
      "Step: NaN | Loss: 1.2150e-06 | Loss_d: 4.2498e-05 Loss_e: 1.9096e-05 | Loss_b: 1.1199e-05\n",
      "Step: NaN | Loss: 1.2167e-06 | Loss_d: 4.2612e-05 Loss_e: 1.8990e-05 | Loss_b: 1.1297e-05\n",
      "Step: NaN | Loss: 1.2145e-06 | Loss_d: 4.2528e-05 Loss_e: 1.9049e-05 | Loss_b: 1.1188e-05\n",
      "Step: NaN | Loss: 1.2130e-06 | Loss_d: 4.2390e-05 Loss_e: 1.9073e-05 | Loss_b: 1.1216e-05\n",
      "Step: NaN | Loss: 1.2212e-06 | Loss_d: 4.1936e-05 Loss_e: 1.9409e-05 | Loss_b: 1.1819e-05\n",
      "Step: NaN | Loss: 1.2128e-06 | Loss_d: 4.2318e-05 Loss_e: 1.9096e-05 | Loss_b: 1.1250e-05\n",
      "Step: NaN | Loss: 1.2111e-06 | Loss_d: 4.2139e-05 Loss_e: 1.9104e-05 | Loss_b: 1.1316e-05\n",
      "Step: NaN | Loss: 1.2130e-06 | Loss_d: 4.1522e-05 Loss_e: 1.9260e-05 | Loss_b: 1.1896e-05\n",
      "Step: NaN | Loss: 1.2101e-06 | Loss_d: 4.1896e-05 Loss_e: 1.9137e-05 | Loss_b: 1.1469e-05\n",
      "Step: NaN | Loss: 1.2087e-06 | Loss_d: 4.1765e-05 Loss_e: 1.9214e-05 | Loss_b: 1.1439e-05\n",
      "Step: NaN | Loss: 1.2090e-06 | Loss_d: 4.1293e-05 Loss_e: 1.9567e-05 | Loss_b: 1.1574e-05\n",
      "Step: NaN | Loss: 1.2077e-06 | Loss_d: 4.1528e-05 Loss_e: 1.9374e-05 | Loss_b: 1.1457e-05\n",
      "Step: NaN | Loss: 1.2069e-06 | Loss_d: 4.1478e-05 Loss_e: 1.9383e-05 | Loss_b: 1.1450e-05\n",
      "Step: NaN | Loss: 1.2060e-06 | Loss_d: 4.1296e-05 Loss_e: 1.9465e-05 | Loss_b: 1.1498e-05\n",
      "Step: NaN | Loss: 1.2059e-06 | Loss_d: 4.1337e-05 Loss_e: 1.9438e-05 | Loss_b: 1.1476e-05\n",
      "Step: NaN | Loss: 1.2047e-06 | Loss_d: 4.1210e-05 Loss_e: 1.9489e-05 | Loss_b: 1.1479e-05\n",
      "Step: NaN | Loss: 1.2032e-06 | Loss_d: 4.0733e-05 Loss_e: 1.9751e-05 | Loss_b: 1.1603e-05\n",
      "Step: NaN | Loss: 1.2030e-06 | Loss_d: 4.0846e-05 Loss_e: 1.9677e-05 | Loss_b: 1.1555e-05\n",
      "Step: NaN | Loss: 1.2013e-06 | Loss_d: 4.0881e-05 Loss_e: 1.9478e-05 | Loss_b: 1.1613e-05\n",
      "Step: NaN | Loss: 1.2165e-06 | Loss_d: 4.1495e-05 Loss_e: 1.9015e-05 | Loss_b: 1.2377e-05\n",
      "Step: NaN | Loss: 1.2012e-06 | Loss_d: 4.0898e-05 Loss_e: 1.9432e-05 | Loss_b: 1.1638e-05\n",
      "Step: NaN | Loss: 1.1997e-06 | Loss_d: 4.1146e-05 Loss_e: 1.9315e-05 | Loss_b: 1.1417e-05\n",
      "Step: NaN | Loss: 1.1994e-06 | Loss_d: 4.1065e-05 Loss_e: 1.9340e-05 | Loss_b: 1.1454e-05\n",
      "Step: NaN | Loss: 1.1983e-06 | Loss_d: 4.1056e-05 Loss_e: 1.9340e-05 | Loss_b: 1.1399e-05\n",
      "Step: NaN | Loss: 1.2003e-06 | Loss_d: 4.1128e-05 Loss_e: 1.9395e-05 | Loss_b: 1.1391e-05\n",
      "Step: NaN | Loss: 1.1979e-06 | Loss_d: 4.1060e-05 Loss_e: 1.9347e-05 | Loss_b: 1.1362e-05\n",
      "Step: NaN | Loss: 1.1972e-06 | Loss_d: 4.1017e-05 Loss_e: 1.9395e-05 | Loss_b: 1.1315e-05\n",
      "Step: NaN | Loss: 1.2019e-06 | Loss_d: 4.0876e-05 Loss_e: 1.9750e-05 | Loss_b: 1.1385e-05\n",
      "Step: NaN | Loss: 1.1971e-06 | Loss_d: 4.1000e-05 Loss_e: 1.9421e-05 | Loss_b: 1.1302e-05\n",
      "Step: NaN | Loss: 1.1966e-06 | Loss_d: 4.1013e-05 Loss_e: 1.9410e-05 | Loss_b: 1.1270e-05\n",
      "Step: NaN | Loss: 1.1985e-06 | Loss_d: 4.1089e-05 Loss_e: 1.9454e-05 | Loss_b: 1.1267e-05\n",
      "Step: NaN | Loss: 1.1965e-06 | Loss_d: 4.1024e-05 Loss_e: 1.9407e-05 | Loss_b: 1.1254e-05\n",
      "Step: NaN | Loss: 1.1965e-06 | Loss_d: 4.1000e-05 Loss_e: 1.9428e-05 | Loss_b: 1.1261e-05\n",
      "Step: NaN | Loss: 1.1960e-06 | Loss_d: 4.1008e-05 Loss_e: 1.9414e-05 | Loss_b: 1.1238e-05\n",
      "Step: NaN | Loss: 1.1955e-06 | Loss_d: 4.0981e-05 Loss_e: 1.9430e-05 | Loss_b: 1.1217e-05\n",
      "Step: NaN | Loss: 1.1941e-06 | Loss_d: 4.0883e-05 Loss_e: 1.9513e-05 | Loss_b: 1.1150e-05\n",
      "Step: NaN | Loss: 1.2084e-06 | Loss_d: 4.0661e-05 Loss_e: 2.0396e-05 | Loss_b: 1.1344e-05\n",
      "Step: NaN | Loss: 1.1939e-06 | Loss_d: 4.0843e-05 Loss_e: 1.9564e-05 | Loss_b: 1.1127e-05\n",
      "Step: NaN | Loss: 1.1924e-06 | Loss_d: 4.0856e-05 Loss_e: 1.9482e-05 | Loss_b: 1.1105e-05\n",
      "Step: NaN | Loss: 1.1937e-06 | Loss_d: 4.0955e-05 Loss_e: 1.9349e-05 | Loss_b: 1.1216e-05\n",
      "Step: NaN | Loss: 1.1915e-06 | Loss_d: 4.0885e-05 Loss_e: 1.9392e-05 | Loss_b: 1.1110e-05\n",
      "Step: NaN | Loss: 1.1907e-06 | Loss_d: 4.0819e-05 Loss_e: 1.9338e-05 | Loss_b: 1.1185e-05\n",
      "Step: NaN | Loss: 1.1926e-06 | Loss_d: 4.0607e-05 Loss_e: 1.9152e-05 | Loss_b: 1.1696e-05\n",
      "Step: NaN | Loss: 1.1905e-06 | Loss_d: 4.0755e-05 Loss_e: 1.9286e-05 | Loss_b: 1.1285e-05\n",
      "Step: NaN | Loss: 1.1898e-06 | Loss_d: 4.0677e-05 Loss_e: 1.9338e-05 | Loss_b: 1.1270e-05\n",
      "Step: NaN | Loss: 1.1906e-06 | Loss_d: 4.0389e-05 Loss_e: 1.9619e-05 | Loss_b: 1.1324e-05\n",
      "Step: NaN | Loss: 1.1895e-06 | Loss_d: 4.0568e-05 Loss_e: 1.9427e-05 | Loss_b: 1.1270e-05\n",
      "Step: NaN | Loss: 1.1887e-06 | Loss_d: 4.0493e-05 Loss_e: 1.9472e-05 | Loss_b: 1.1257e-05\n",
      "Step: NaN | Loss: 1.1888e-06 | Loss_d: 4.0212e-05 Loss_e: 1.9692e-05 | Loss_b: 1.1320e-05\n",
      "Step: NaN | Loss: 1.1882e-06 | Loss_d: 4.0347e-05 Loss_e: 1.9575e-05 | Loss_b: 1.1268e-05\n",
      "Step: NaN | Loss: 1.1867e-06 | Loss_d: 4.0174e-05 Loss_e: 1.9615e-05 | Loss_b: 1.1312e-05\n",
      "Step: NaN | Loss: 1.1860e-06 | Loss_d: 3.9555e-05 Loss_e: 1.9909e-05 | Loss_b: 1.1592e-05\n",
      "Step: NaN | Loss: 1.1852e-06 | Loss_d: 3.9807e-05 Loss_e: 1.9755e-05 | Loss_b: 1.1448e-05\n",
      "Step: NaN | Loss: 1.1832e-06 | Loss_d: 3.9798e-05 Loss_e: 1.9719e-05 | Loss_b: 1.1376e-05\n",
      "Step: NaN | Loss: 1.1873e-06 | Loss_d: 3.9855e-05 Loss_e: 1.9707e-05 | Loss_b: 1.1574e-05\n",
      "Step: NaN | Loss: 1.1825e-06 | Loss_d: 3.9799e-05 Loss_e: 1.9693e-05 | Loss_b: 1.1354e-05\n",
      "Step: NaN | Loss: 1.1811e-06 | Loss_d: 3.9948e-05 Loss_e: 1.9511e-05 | Loss_b: 1.1306e-05\n",
      "Step: NaN | Loss: 1.1862e-06 | Loss_d: 4.0638e-05 Loss_e: 1.8950e-05 | Loss_b: 1.1482e-05\n",
      "Step: NaN | Loss: 1.1808e-06 | Loss_d: 4.0071e-05 Loss_e: 1.9380e-05 | Loss_b: 1.1297e-05\n",
      "Step: NaN | Loss: 1.1799e-06 | Loss_d: 4.0089e-05 Loss_e: 1.9411e-05 | Loss_b: 1.1193e-05\n",
      "Step: NaN | Loss: 1.1815e-06 | Loss_d: 4.0208e-05 Loss_e: 1.9567e-05 | Loss_b: 1.1012e-05\n",
      "Step: NaN | Loss: 1.1795e-06 | Loss_d: 4.0118e-05 Loss_e: 1.9453e-05 | Loss_b: 1.1096e-05\n",
      "Step: NaN | Loss: 1.1777e-06 | Loss_d: 4.0151e-05 Loss_e: 1.9342e-05 | Loss_b: 1.1069e-05\n",
      "Step: NaN | Loss: 1.1836e-06 | Loss_d: 4.0471e-05 Loss_e: 1.9067e-05 | Loss_b: 1.1374e-05\n",
      "Step: NaN | Loss: 1.1772e-06 | Loss_d: 4.0195e-05 Loss_e: 1.9259e-05 | Loss_b: 1.1079e-05\n",
      "Step: NaN | Loss: 1.1761e-06 | Loss_d: 4.0036e-05 Loss_e: 1.9289e-05 | Loss_b: 1.1139e-05\n",
      "Step: NaN | Loss: 1.1886e-06 | Loss_d: 3.9675e-05 Loss_e: 1.9503e-05 | Loss_b: 1.2033e-05\n",
      "Step: NaN | Loss: 1.1761e-06 | Loss_d: 4.0012e-05 Loss_e: 1.9295e-05 | Loss_b: 1.1156e-05\n",
      "Step: NaN | Loss: 1.1755e-06 | Loss_d: 3.9976e-05 Loss_e: 1.9289e-05 | Loss_b: 1.1162e-05\n",
      "Step: NaN | Loss: 1.1744e-06 | Loss_d: 3.9837e-05 Loss_e: 1.9279e-05 | Loss_b: 1.1249e-05\n",
      "Step: NaN | Loss: 1.1744e-06 | Loss_d: 3.9843e-05 Loss_e: 1.9278e-05 | Loss_b: 1.1242e-05\n",
      "Step: NaN | Loss: 1.1731e-06 | Loss_d: 3.9717e-05 Loss_e: 1.9357e-05 | Loss_b: 1.1210e-05\n",
      "Step: NaN | Loss: 1.1779e-06 | Loss_d: 3.9266e-05 Loss_e: 1.9821e-05 | Loss_b: 1.1485e-05\n",
      "Step: NaN | Loss: 1.1727e-06 | Loss_d: 3.9620e-05 Loss_e: 1.9430e-05 | Loss_b: 1.1210e-05\n",
      "Step: NaN | Loss: 1.1717e-06 | Loss_d: 3.9710e-05 Loss_e: 1.9281e-05 | Loss_b: 1.1209e-05\n",
      "Step: NaN | Loss: 1.1766e-06 | Loss_d: 4.0194e-05 Loss_e: 1.8922e-05 | Loss_b: 1.1381e-05\n",
      "Step: NaN | Loss: 1.1715e-06 | Loss_d: 3.9771e-05 Loss_e: 1.9203e-05 | Loss_b: 1.1218e-05\n",
      "Step: NaN | Loss: 1.1716e-06 | Loss_d: 3.9850e-05 Loss_e: 1.9196e-05 | Loss_b: 1.1147e-05\n",
      "Step: NaN | Loss: 1.1707e-06 | Loss_d: 3.9807e-05 Loss_e: 1.9192e-05 | Loss_b: 1.1143e-05\n",
      "Step: NaN | Loss: 1.1698e-06 | Loss_d: 3.9817e-05 Loss_e: 1.9200e-05 | Loss_b: 1.1068e-05\n",
      "Step: NaN | Loss: 1.1699e-06 | Loss_d: 3.9895e-05 Loss_e: 1.9276e-05 | Loss_b: 1.0925e-05\n",
      "Step: NaN | Loss: 1.1690e-06 | Loss_d: 3.9846e-05 Loss_e: 1.9227e-05 | Loss_b: 1.0969e-05\n",
      "Step: NaN | Loss: 1.1684e-06 | Loss_d: 3.9820e-05 Loss_e: 1.9196e-05 | Loss_b: 1.0985e-05\n",
      "Step: NaN | Loss: 1.1689e-06 | Loss_d: 3.9733e-05 Loss_e: 1.9184e-05 | Loss_b: 1.1118e-05\n",
      "Step: NaN | Loss: 1.1680e-06 | Loss_d: 3.9782e-05 Loss_e: 1.9171e-05 | Loss_b: 1.1025e-05\n",
      "Step: NaN | Loss: 1.1676e-06 | Loss_d: 3.9823e-05 Loss_e: 1.9196e-05 | Loss_b: 1.0936e-05\n",
      "Step: NaN | Loss: 1.1674e-06 | Loss_d: 3.9805e-05 Loss_e: 1.9182e-05 | Loss_b: 1.0955e-05\n",
      "Step: NaN | Loss: 1.1669e-06 | Loss_d: 3.9790e-05 Loss_e: 1.9211e-05 | Loss_b: 1.0911e-05\n",
      "Step: NaN | Loss: 1.1662e-06 | Loss_d: 3.9749e-05 Loss_e: 1.9341e-05 | Loss_b: 1.0784e-05\n",
      "Step: NaN | Loss: 1.1662e-06 | Loss_d: 3.9757e-05 Loss_e: 1.9307e-05 | Loss_b: 1.0807e-05\n",
      "Step: NaN | Loss: 1.1650e-06 | Loss_d: 3.9767e-05 Loss_e: 1.9268e-05 | Loss_b: 1.0763e-05\n",
      "Step: NaN | Loss: 1.1621e-06 | Loss_d: 3.9817e-05 Loss_e: 1.9132e-05 | Loss_b: 1.0679e-05\n",
      "Step: NaN | Loss: 1.1934e-06 | Loss_d: 4.0255e-05 Loss_e: 1.8925e-05 | Loss_b: 1.2320e-05\n",
      "Step: NaN | Loss: 1.1618e-06 | Loss_d: 3.9842e-05 Loss_e: 1.9083e-05 | Loss_b: 1.0686e-05\n",
      "Step: NaN | Loss: 1.1578e-06 | Loss_d: 3.9735e-05 Loss_e: 1.9010e-05 | Loss_b: 1.0623e-05\n",
      "Step: NaN | Loss: 1.1624e-06 | Loss_d: 3.9536e-05 Loss_e: 1.9179e-05 | Loss_b: 1.0929e-05\n",
      "Step: NaN | Loss: 1.1556e-06 | Loss_d: 3.9622e-05 Loss_e: 1.8986e-05 | Loss_b: 1.0629e-05\n",
      "Step: NaN | Loss: 1.1546e-06 | Loss_d: 3.9930e-05 Loss_e: 1.8744e-05 | Loss_b: 1.0504e-05\n",
      "Step: NaN | Loss: 1.1546e-06 | Loss_d: 3.9868e-05 Loss_e: 1.8787e-05 | Loss_b: 1.0520e-05\n",
      "Step: NaN | Loss: 1.1545e-06 | Loss_d: 3.9945e-05 Loss_e: 1.8731e-05 | Loss_b: 1.0497e-05\n",
      "Step: NaN | Loss: 1.1542e-06 | Loss_d: 3.9906e-05 Loss_e: 1.8757e-05 | Loss_b: 1.0488e-05\n",
      "Step: NaN | Loss: 1.1539e-06 | Loss_d: 3.9901e-05 Loss_e: 1.8747e-05 | Loss_b: 1.0488e-05\n",
      "Step: NaN | Loss: 1.1531e-06 | Loss_d: 3.9881e-05 Loss_e: 1.8711e-05 | Loss_b: 1.0492e-05\n",
      "Step: NaN | Loss: 1.1523e-06 | Loss_d: 3.9835e-05 Loss_e: 1.8636e-05 | Loss_b: 1.0570e-05\n",
      "Step: NaN | Loss: 1.1519e-06 | Loss_d: 3.9843e-05 Loss_e: 1.8643e-05 | Loss_b: 1.0530e-05\n",
      "Step: NaN | Loss: 1.1513e-06 | Loss_d: 3.9844e-05 Loss_e: 1.8623e-05 | Loss_b: 1.0510e-05\n",
      "Step: NaN | Loss: 1.1503e-06 | Loss_d: 3.9873e-05 Loss_e: 1.8564e-05 | Loss_b: 1.0483e-05\n",
      "Step: NaN | Loss: 1.1503e-06 | Loss_d: 3.9868e-05 Loss_e: 1.8569e-05 | Loss_b: 1.0481e-05\n",
      "Step: NaN | Loss: 1.1490e-06 | Loss_d: 3.9883e-05 Loss_e: 1.8480e-05 | Loss_b: 1.0479e-05\n",
      "Step: NaN | Loss: 1.1482e-06 | Loss_d: 4.0009e-05 Loss_e: 1.8256e-05 | Loss_b: 1.0529e-05\n",
      "Step: NaN | Loss: 1.1477e-06 | Loss_d: 3.9948e-05 Loss_e: 1.8317e-05 | Loss_b: 1.0498e-05\n",
      "Step: NaN | Loss: 1.1476e-06 | Loss_d: 3.9864e-05 Loss_e: 1.8367e-05 | Loss_b: 1.0525e-05\n",
      "Step: NaN | Loss: 1.1473e-06 | Loss_d: 3.9899e-05 Loss_e: 1.8340e-05 | Loss_b: 1.0502e-05\n",
      "Step: NaN | Loss: 1.1468e-06 | Loss_d: 3.9873e-05 Loss_e: 1.8350e-05 | Loss_b: 1.0485e-05\n",
      "Step: NaN | Loss: 1.1461e-06 | Loss_d: 3.9773e-05 Loss_e: 1.8416e-05 | Loss_b: 1.0480e-05\n",
      "Step: NaN | Loss: 1.1460e-06 | Loss_d: 3.9797e-05 Loss_e: 1.8395e-05 | Loss_b: 1.0472e-05\n",
      "Step: NaN | Loss: 1.1420e-06 | Loss_d: 3.9524e-05 Loss_e: 1.8394e-05 | Loss_b: 1.0507e-05\n",
      "Step: NaN | Loss: 1.1383e-06 | Loss_d: 3.8622e-05 Loss_e: 1.8631e-05 | Loss_b: 1.0946e-05\n",
      "Step: NaN | Loss: 1.1373e-06 | Loss_d: 3.8884e-05 Loss_e: 1.8512e-05 | Loss_b: 1.0745e-05\n",
      "Step: NaN | Loss: 1.1817e-06 | Loss_d: 3.9516e-05 Loss_e: 1.8525e-05 | Loss_b: 1.2759e-05\n",
      "Step: NaN | Loss: 1.1369e-06 | Loss_d: 3.8903e-05 Loss_e: 1.8500e-05 | Loss_b: 1.0713e-05\n",
      "Step: NaN | Loss: 1.1361e-06 | Loss_d: 3.8748e-05 Loss_e: 1.8541e-05 | Loss_b: 1.0777e-05\n",
      "Step: NaN | Loss: 1.1388e-06 | Loss_d: 3.8177e-05 Loss_e: 1.8804e-05 | Loss_b: 1.1251e-05\n",
      "Step: NaN | Loss: 1.1358e-06 | Loss_d: 3.8617e-05 Loss_e: 1.8584e-05 | Loss_b: 1.0851e-05\n",
      "Step: NaN | Loss: 1.1353e-06 | Loss_d: 3.8537e-05 Loss_e: 1.8638e-05 | Loss_b: 1.0849e-05\n",
      "Step: NaN | Loss: 1.1352e-06 | Loss_d: 3.8244e-05 Loss_e: 1.8883e-05 | Loss_b: 1.0886e-05\n",
      "Step: NaN | Loss: 1.1349e-06 | Loss_d: 3.8373e-05 Loss_e: 1.8763e-05 | Loss_b: 1.0857e-05\n",
      "Step: NaN | Loss: 1.1337e-06 | Loss_d: 3.8451e-05 Loss_e: 1.8667e-05 | Loss_b: 1.0808e-05\n",
      "Step: NaN | Loss: 1.1449e-06 | Loss_d: 3.8828e-05 Loss_e: 1.8535e-05 | Loss_b: 1.1235e-05\n",
      "Step: NaN | Loss: 1.1337e-06 | Loss_d: 3.8469e-05 Loss_e: 1.8649e-05 | Loss_b: 1.0806e-05\n",
      "Step: NaN | Loss: 1.1331e-06 | Loss_d: 3.8546e-05 Loss_e: 1.8658e-05 | Loss_b: 1.0686e-05\n",
      "Step: NaN | Loss: 1.1331e-06 | Loss_d: 3.8526e-05 Loss_e: 1.8655e-05 | Loss_b: 1.0705e-05\n",
      "Step: NaN | Loss: 1.1327e-06 | Loss_d: 3.8488e-05 Loss_e: 1.8653e-05 | Loss_b: 1.0722e-05\n",
      "Step: NaN | Loss: 1.1334e-06 | Loss_d: 3.8350e-05 Loss_e: 1.8693e-05 | Loss_b: 1.0864e-05\n",
      "Step: NaN | Loss: 1.1325e-06 | Loss_d: 3.8444e-05 Loss_e: 1.8656e-05 | Loss_b: 1.0753e-05\n",
      "Step: NaN | Loss: 1.1314e-06 | Loss_d: 3.8404e-05 Loss_e: 1.8670e-05 | Loss_b: 1.0712e-05\n",
      "Step: NaN | Loss: 1.1309e-06 | Loss_d: 3.8285e-05 Loss_e: 1.8779e-05 | Loss_b: 1.0696e-05\n",
      "Step: NaN | Loss: 1.1303e-06 | Loss_d: 3.8328e-05 Loss_e: 1.8720e-05 | Loss_b: 1.0674e-05\n",
      "Step: NaN | Loss: 1.1286e-06 | Loss_d: 3.8233e-05 Loss_e: 1.8614e-05 | Loss_b: 1.0772e-05\n",
      "Step: NaN | Loss: 1.1320e-06 | Loss_d: 3.7970e-05 Loss_e: 1.8405e-05 | Loss_b: 1.1449e-05\n",
      "Step: NaN | Loss: 1.1279e-06 | Loss_d: 3.8137e-05 Loss_e: 1.8517e-05 | Loss_b: 1.0923e-05\n",
      "Step: NaN | Loss: 1.1260e-06 | Loss_d: 3.8104e-05 Loss_e: 1.8413e-05 | Loss_b: 1.0946e-05\n",
      "Step: NaN | Loss: 1.1342e-06 | Loss_d: 3.8056e-05 Loss_e: 1.8147e-05 | Loss_b: 1.1749e-05\n",
      "Step: NaN | Loss: 1.1256e-06 | Loss_d: 3.8086e-05 Loss_e: 1.8348e-05 | Loss_b: 1.1006e-05\n",
      "Step: NaN | Loss: 1.1239e-06 | Loss_d: 3.7968e-05 Loss_e: 1.8349e-05 | Loss_b: 1.1022e-05\n",
      "Step: NaN | Loss: 1.1277e-06 | Loss_d: 3.7568e-05 Loss_e: 1.8482e-05 | Loss_b: 1.1518e-05\n",
      "Step: NaN | Loss: 1.1233e-06 | Loss_d: 3.7849e-05 Loss_e: 1.8365e-05 | Loss_b: 1.1088e-05\n",
      "Step: NaN | Loss: 1.1228e-06 | Loss_d: 3.7824e-05 Loss_e: 1.8356e-05 | Loss_b: 1.1093e-05\n",
      "Step: NaN | Loss: 1.1231e-06 | Loss_d: 3.7768e-05 Loss_e: 1.8341e-05 | Loss_b: 1.1184e-05\n",
      "Step: NaN | Loss: 1.1225e-06 | Loss_d: 3.7793e-05 Loss_e: 1.8346e-05 | Loss_b: 1.1116e-05\n",
      "Step: NaN | Loss: 1.1222e-06 | Loss_d: 3.7757e-05 Loss_e: 1.8371e-05 | Loss_b: 1.1106e-05\n",
      "Step: NaN | Loss: 1.1220e-06 | Loss_d: 3.7629e-05 Loss_e: 1.8479e-05 | Loss_b: 1.1115e-05\n",
      "Step: NaN | Loss: 1.1218e-06 | Loss_d: 3.7677e-05 Loss_e: 1.8435e-05 | Loss_b: 1.1103e-05\n",
      "Step: NaN | Loss: 1.1213e-06 | Loss_d: 3.7752e-05 Loss_e: 1.8364e-05 | Loss_b: 1.1063e-05\n",
      "Step: NaN | Loss: 1.1216e-06 | Loss_d: 3.8085e-05 Loss_e: 1.8150e-05 | Loss_b: 1.0965e-05\n",
      "Step: NaN | Loss: 1.1209e-06 | Loss_d: 3.7887e-05 Loss_e: 1.8260e-05 | Loss_b: 1.1011e-05\n",
      "Step: NaN | Loss: 1.1232e-06 | Loss_d: 3.7398e-05 Loss_e: 1.8511e-05 | Loss_b: 1.1389e-05\n",
      "Step: NaN | Loss: 1.1204e-06 | Loss_d: 3.7721e-05 Loss_e: 1.8323e-05 | Loss_b: 1.1085e-05\n",
      "Step: NaN | Loss: 1.1201e-06 | Loss_d: 3.7693e-05 Loss_e: 1.8318e-05 | Loss_b: 1.1100e-05\n",
      "Step: NaN | Loss: 1.1194e-06 | Loss_d: 3.7583e-05 Loss_e: 1.8305e-05 | Loss_b: 1.1179e-05\n",
      "Step: NaN | Loss: 1.1302e-06 | Loss_d: 3.7115e-05 Loss_e: 1.8486e-05 | Loss_b: 1.2117e-05\n",
      "Step: NaN | Loss: 1.1193e-06 | Loss_d: 3.7556e-05 Loss_e: 1.8305e-05 | Loss_b: 1.1203e-05\n",
      "Step: NaN | Loss: 1.1183e-06 | Loss_d: 3.7546e-05 Loss_e: 1.8333e-05 | Loss_b: 1.1124e-05\n",
      "Step: NaN | Loss: 1.1174e-06 | Loss_d: 3.7532e-05 Loss_e: 1.8500e-05 | Loss_b: 1.0915e-05\n",
      "Step: NaN | Loss: 1.1171e-06 | Loss_d: 3.7532e-05 Loss_e: 1.8437e-05 | Loss_b: 1.0963e-05\n",
      "Step: NaN | Loss: 1.1167e-06 | Loss_d: 3.7543e-05 Loss_e: 1.8435e-05 | Loss_b: 1.0928e-05\n",
      "Step: NaN | Loss: 1.1160e-06 | Loss_d: 3.7595e-05 Loss_e: 1.8436e-05 | Loss_b: 1.0833e-05\n",
      "Step: NaN | Loss: 1.1160e-06 | Loss_d: 3.7591e-05 Loss_e: 1.8436e-05 | Loss_b: 1.0839e-05\n",
      "Step: NaN | Loss: 1.1153e-06 | Loss_d: 3.7547e-05 Loss_e: 1.8438e-05 | Loss_b: 1.0834e-05\n",
      "Step: NaN | Loss: 1.1147e-06 | Loss_d: 3.7390e-05 Loss_e: 1.8482e-05 | Loss_b: 1.0916e-05\n",
      "Step: NaN | Loss: 1.1144e-06 | Loss_d: 3.7445e-05 Loss_e: 1.8459e-05 | Loss_b: 1.0867e-05\n",
      "Step: NaN | Loss: 1.1127e-06 | Loss_d: 3.7346e-05 Loss_e: 1.8413e-05 | Loss_b: 1.0909e-05\n",
      "Step: NaN | Loss: 1.1127e-06 | Loss_d: 3.7353e-05 Loss_e: 1.8415e-05 | Loss_b: 1.0899e-05\n",
      "Step: NaN | Loss: 1.1122e-06 | Loss_d: 3.7356e-05 Loss_e: 1.8389e-05 | Loss_b: 1.0892e-05\n",
      "Step: NaN | Loss: 1.1137e-06 | Loss_d: 3.7381e-05 Loss_e: 1.8314e-05 | Loss_b: 1.1029e-05\n",
      "Step: NaN | Loss: 1.1121e-06 | Loss_d: 3.7360e-05 Loss_e: 1.8367e-05 | Loss_b: 1.0901e-05\n",
      "Step: NaN | Loss: 1.1118e-06 | Loss_d: 3.7283e-05 Loss_e: 1.8425e-05 | Loss_b: 1.0904e-05\n",
      "Step: NaN | Loss: 1.1148e-06 | Loss_d: 3.7015e-05 Loss_e: 1.8691e-05 | Loss_b: 1.1087e-05\n",
      "Step: NaN | Loss: 1.1118e-06 | Loss_d: 3.7270e-05 Loss_e: 1.8435e-05 | Loss_b: 1.0906e-05\n",
      "Step: NaN | Loss: 1.1117e-06 | Loss_d: 3.7264e-05 Loss_e: 1.8432e-05 | Loss_b: 1.0909e-05\n",
      "Step: NaN | Loss: 1.1117e-06 | Loss_d: 3.7257e-05 Loss_e: 1.8426e-05 | Loss_b: 1.0922e-05\n",
      "Step: NaN | Loss: 1.1116e-06 | Loss_d: 3.7258e-05 Loss_e: 1.8429e-05 | Loss_b: 1.0913e-05\n",
      "Step: NaN | Loss: 1.1111e-06 | Loss_d: 3.7228e-05 Loss_e: 1.8419e-05 | Loss_b: 1.0920e-05\n",
      "Step: NaN | Loss: 1.1099e-06 | Loss_d: 3.7119e-05 Loss_e: 1.8410e-05 | Loss_b: 1.0970e-05\n",
      "Step: NaN | Loss: 1.1266e-06 | Loss_d: 3.6753e-05 Loss_e: 1.9048e-05 | Loss_b: 1.1700e-05\n",
      "Step: NaN | Loss: 1.1099e-06 | Loss_d: 3.7092e-05 Loss_e: 1.8415e-05 | Loss_b: 1.0989e-05\n",
      "Step: NaN | Loss: 1.1084e-06 | Loss_d: 3.6870e-05 Loss_e: 1.8442e-05 | Loss_b: 1.1098e-05\n",
      "Step: NaN | Loss: 1.1084e-06 | Loss_d: 3.6892e-05 Loss_e: 1.8437e-05 | Loss_b: 1.1079e-05\n",
      "Step: NaN | Loss: 1.1078e-06 | Loss_d: 3.6714e-05 Loss_e: 1.8499e-05 | Loss_b: 1.1163e-05\n",
      "Step: NaN | Loss: 1.1115e-06 | Loss_d: 3.6095e-05 Loss_e: 1.8855e-05 | Loss_b: 1.1643e-05\n",
      "Step: NaN | Loss: 1.1078e-06 | Loss_d: 3.6636e-05 Loss_e: 1.8530e-05 | Loss_b: 1.1207e-05\n",
      "Step: NaN | Loss: 1.1076e-06 | Loss_d: 3.6636e-05 Loss_e: 1.8526e-05 | Loss_b: 1.1201e-05\n",
      "Step: NaN | Loss: 1.1072e-06 | Loss_d: 3.6637e-05 Loss_e: 1.8511e-05 | Loss_b: 1.1186e-05\n",
      "Step: NaN | Loss: 1.1064e-06 | Loss_d: 3.6667e-05 Loss_e: 1.8456e-05 | Loss_b: 1.1167e-05\n",
      "Step: NaN | Loss: 1.1063e-06 | Loss_d: 3.6656e-05 Loss_e: 1.8467e-05 | Loss_b: 1.1163e-05\n",
      "Step: NaN | Loss: 1.1049e-06 | Loss_d: 3.6589e-05 Loss_e: 1.8384e-05 | Loss_b: 1.1225e-05\n",
      "Step: NaN | Loss: 1.1055e-06 | Loss_d: 3.6427e-05 Loss_e: 1.8147e-05 | Loss_b: 1.1661e-05\n",
      "Step: NaN | Loss: 1.1039e-06 | Loss_d: 3.6498e-05 Loss_e: 1.8260e-05 | Loss_b: 1.1382e-05\n",
      "Step: NaN | Loss: 1.1034e-06 | Loss_d: 3.6488e-05 Loss_e: 1.8364e-05 | Loss_b: 1.1257e-05\n",
      "Step: NaN | Loss: 1.1033e-06 | Loss_d: 3.6489e-05 Loss_e: 1.8327e-05 | Loss_b: 1.1285e-05\n",
      "Step: NaN | Loss: 1.1027e-06 | Loss_d: 3.6535e-05 Loss_e: 1.8266e-05 | Loss_b: 1.1265e-05\n",
      "Step: NaN | Loss: 1.1023e-06 | Loss_d: 3.6744e-05 Loss_e: 1.8056e-05 | Loss_b: 1.1244e-05\n",
      "Step: NaN | Loss: 1.1021e-06 | Loss_d: 3.6666e-05 Loss_e: 1.8123e-05 | Loss_b: 1.1241e-05\n",
      "Step: NaN | Loss: 1.1017e-06 | Loss_d: 3.6668e-05 Loss_e: 1.8161e-05 | Loss_b: 1.1177e-05\n",
      "Step: NaN | Loss: 1.1015e-06 | Loss_d: 3.6665e-05 Loss_e: 1.8146e-05 | Loss_b: 1.1187e-05\n",
      "Step: NaN | Loss: 1.1012e-06 | Loss_d: 3.6622e-05 Loss_e: 1.8186e-05 | Loss_b: 1.1168e-05\n",
      "Step: NaN | Loss: 1.1057e-06 | Loss_d: 3.6499e-05 Loss_e: 1.8389e-05 | Loss_b: 1.1358e-05\n",
      "Step: NaN | Loss: 1.1012e-06 | Loss_d: 3.6616e-05 Loss_e: 1.8191e-05 | Loss_b: 1.1167e-05\n",
      "Step: NaN | Loss: 1.1011e-06 | Loss_d: 3.6597e-05 Loss_e: 1.8198e-05 | Loss_b: 1.1174e-05\n",
      "Step: NaN | Loss: 1.1008e-06 | Loss_d: 3.6524e-05 Loss_e: 1.8228e-05 | Loss_b: 1.1200e-05\n",
      "Step: NaN | Loss: 1.1025e-06 | Loss_d: 3.6238e-05 Loss_e: 1.8442e-05 | Loss_b: 1.1376e-05\n",
      "Step: NaN | Loss: 1.1007e-06 | Loss_d: 3.6466e-05 Loss_e: 1.8257e-05 | Loss_b: 1.1225e-05\n",
      "Step: NaN | Loss: 1.0998e-06 | Loss_d: 3.6490e-05 Loss_e: 1.8211e-05 | Loss_b: 1.1193e-05\n",
      "Step: NaN | Loss: 1.0987e-06 | Loss_d: 3.6600e-05 Loss_e: 1.8060e-05 | Loss_b: 1.1168e-05\n",
      "Step: NaN | Loss: 1.0986e-06 | Loss_d: 3.6578e-05 Loss_e: 1.8084e-05 | Loss_b: 1.1161e-05\n",
      "Step: NaN | Loss: 1.0975e-06 | Loss_d: 3.6808e-05 Loss_e: 1.7914e-05 | Loss_b: 1.1031e-05\n",
      "Step: NaN | Loss: 1.0972e-06 | Loss_d: 3.6723e-05 Loss_e: 1.7962e-05 | Loss_b: 1.1052e-05\n",
      "Step: NaN | Loss: 1.0967e-06 | Loss_d: 3.6719e-05 Loss_e: 1.7945e-05 | Loss_b: 1.1045e-05\n",
      "Step: NaN | Loss: 1.0960e-06 | Loss_d: 3.6708e-05 Loss_e: 1.7901e-05 | Loss_b: 1.1054e-05\n",
      "Step: NaN | Loss: 1.0960e-06 | Loss_d: 3.6709e-05 Loss_e: 1.7903e-05 | Loss_b: 1.1052e-05\n",
      "Step: NaN | Loss: 1.0947e-06 | Loss_d: 3.6707e-05 Loss_e: 1.7885e-05 | Loss_b: 1.0996e-05\n",
      "Step: NaN | Loss: 1.0947e-06 | Loss_d: 3.6721e-05 Loss_e: 1.7942e-05 | Loss_b: 1.0926e-05\n",
      "Step: NaN | Loss: 1.0937e-06 | Loss_d: 3.6710e-05 Loss_e: 1.7888e-05 | Loss_b: 1.0931e-05\n",
      "Step: NaN | Loss: 1.0932e-06 | Loss_d: 3.6734e-05 Loss_e: 1.7878e-05 | Loss_b: 1.0889e-05\n",
      "Step: NaN | Loss: 1.0925e-06 | Loss_d: 3.6837e-05 Loss_e: 1.7842e-05 | Loss_b: 1.0775e-05\n",
      "Step: NaN | Loss: 1.0925e-06 | Loss_d: 3.6831e-05 Loss_e: 1.7844e-05 | Loss_b: 1.0778e-05\n",
      "Step: NaN | Loss: 1.0918e-06 | Loss_d: 3.6898e-05 Loss_e: 1.7764e-05 | Loss_b: 1.0752e-05\n",
      "Step: NaN | Loss: 1.0921e-06 | Loss_d: 3.7215e-05 Loss_e: 1.7517e-05 | Loss_b: 1.0702e-05\n",
      "Step: NaN | Loss: 1.0913e-06 | Loss_d: 3.7025e-05 Loss_e: 1.7643e-05 | Loss_b: 1.0719e-05\n",
      "Step: NaN | Loss: 1.0912e-06 | Loss_d: 3.7226e-05 Loss_e: 1.7695e-05 | Loss_b: 1.0456e-05\n",
      "Step: NaN | Loss: 1.0907e-06 | Loss_d: 3.7129e-05 Loss_e: 1.7668e-05 | Loss_b: 1.0553e-05\n",
      "Step: NaN | Loss: 1.0903e-06 | Loss_d: 3.7148e-05 Loss_e: 1.7646e-05 | Loss_b: 1.0532e-05\n",
      "Step: NaN | Loss: 1.0891e-06 | Loss_d: 3.7232e-05 Loss_e: 1.7564e-05 | Loss_b: 1.0458e-05\n",
      "Step: NaN | Loss: 1.0948e-06 | Loss_d: 3.7873e-05 Loss_e: 1.7328e-05 | Loss_b: 1.0392e-05\n",
      "Step: NaN | Loss: 1.0887e-06 | Loss_d: 3.7334e-05 Loss_e: 1.7493e-05 | Loss_b: 1.0404e-05\n",
      "Step: NaN | Loss: 1.0878e-06 | Loss_d: 3.7246e-05 Loss_e: 1.7515e-05 | Loss_b: 1.0414e-05\n",
      "Step: NaN | Loss: 1.0929e-06 | Loss_d: 3.6955e-05 Loss_e: 1.7765e-05 | Loss_b: 1.0761e-05\n",
      "Step: NaN | Loss: 1.0877e-06 | Loss_d: 3.7199e-05 Loss_e: 1.7534e-05 | Loss_b: 1.0434e-05\n",
      "Step: NaN | Loss: 1.0874e-06 | Loss_d: 3.7197e-05 Loss_e: 1.7516e-05 | Loss_b: 1.0440e-05\n",
      "Step: NaN | Loss: 1.0871e-06 | Loss_d: 3.7196e-05 Loss_e: 1.7448e-05 | Loss_b: 1.0487e-05\n",
      "Step: NaN | Loss: 1.0871e-06 | Loss_d: 3.7196e-05 Loss_e: 1.7451e-05 | Loss_b: 1.0484e-05\n",
      "Step: NaN | Loss: 1.0865e-06 | Loss_d: 3.7013e-05 Loss_e: 1.7550e-05 | Loss_b: 1.0533e-05\n",
      "Step: NaN | Loss: 1.0908e-06 | Loss_d: 3.6373e-05 Loss_e: 1.8050e-05 | Loss_b: 1.0929e-05\n",
      "Step: NaN | Loss: 1.0865e-06 | Loss_d: 3.6948e-05 Loss_e: 1.7589e-05 | Loss_b: 1.0557e-05\n",
      "Step: NaN | Loss: 1.0856e-06 | Loss_d: 3.6900e-05 Loss_e: 1.7586e-05 | Loss_b: 1.0558e-05\n",
      "Step: NaN | Loss: 1.0850e-06 | Loss_d: 3.6736e-05 Loss_e: 1.7624e-05 | Loss_b: 1.0645e-05\n",
      "Step: NaN | Loss: 1.0847e-06 | Loss_d: 3.6786e-05 Loss_e: 1.7603e-05 | Loss_b: 1.0602e-05\n",
      "Step: NaN | Loss: 1.0826e-06 | Loss_d: 3.6778e-05 Loss_e: 1.7529e-05 | Loss_b: 1.0557e-05\n",
      "Step: NaN | Loss: 1.0830e-06 | Loss_d: 3.6787e-05 Loss_e: 1.7463e-05 | Loss_b: 1.0637e-05\n",
      "Step: NaN | Loss: 1.0810e-06 | Loss_d: 3.6774e-05 Loss_e: 1.7451e-05 | Loss_b: 1.0542e-05\n",
      "Step: NaN | Loss: 1.0806e-06 | Loss_d: 3.6719e-05 Loss_e: 1.7474e-05 | Loss_b: 1.0549e-05\n",
      "Step: NaN | Loss: 1.0801e-06 | Loss_d: 3.6734e-05 Loss_e: 1.7457e-05 | Loss_b: 1.0520e-05\n",
      "Step: NaN | Loss: 1.0794e-06 | Loss_d: 3.6717e-05 Loss_e: 1.7441e-05 | Loss_b: 1.0513e-05\n",
      "Step: NaN | Loss: 1.0797e-06 | Loss_d: 3.6696e-05 Loss_e: 1.7468e-05 | Loss_b: 1.0525e-05\n",
      "Step: NaN | Loss: 1.0789e-06 | Loss_d: 3.6698e-05 Loss_e: 1.7435e-05 | Loss_b: 1.0509e-05\n",
      "Step: NaN | Loss: 1.0828e-06 | Loss_d: 3.6899e-05 Loss_e: 1.7596e-05 | Loss_b: 1.0381e-05\n",
      "Step: NaN | Loss: 1.0786e-06 | Loss_d: 3.6731e-05 Loss_e: 1.7464e-05 | Loss_b: 1.0428e-05\n",
      "Step: NaN | Loss: 1.0781e-06 | Loss_d: 3.6724e-05 Loss_e: 1.7457e-05 | Loss_b: 1.0414e-05\n",
      "Step: NaN | Loss: 1.0770e-06 | Loss_d: 3.6704e-05 Loss_e: 1.7437e-05 | Loss_b: 1.0388e-05\n",
      "Step: NaN | Loss: 1.0908e-06 | Loss_d: 3.6849e-05 Loss_e: 1.7524e-05 | Loss_b: 1.0983e-05\n",
      "Step: NaN | Loss: 1.0770e-06 | Loss_d: 3.6701e-05 Loss_e: 1.7433e-05 | Loss_b: 1.0392e-05\n",
      "Step: NaN | Loss: 1.0759e-06 | Loss_d: 3.6716e-05 Loss_e: 1.7420e-05 | Loss_b: 1.0327e-05\n",
      "Step: NaN | Loss: 1.0762e-06 | Loss_d: 3.6828e-05 Loss_e: 1.7404e-05 | Loss_b: 1.0248e-05\n",
      "Step: NaN | Loss: 1.0752e-06 | Loss_d: 3.6756e-05 Loss_e: 1.7406e-05 | Loss_b: 1.0255e-05\n",
      "Step: NaN | Loss: 1.0746e-06 | Loss_d: 3.6761e-05 Loss_e: 1.7384e-05 | Loss_b: 1.0236e-05\n",
      "Step: NaN | Loss: 1.0740e-06 | Loss_d: 3.6794e-05 Loss_e: 1.7320e-05 | Loss_b: 1.0235e-05\n",
      "Step: NaN | Loss: 1.0739e-06 | Loss_d: 3.6781e-05 Loss_e: 1.7337e-05 | Loss_b: 1.0222e-05\n",
      "Step: NaN | Loss: 1.0729e-06 | Loss_d: 3.6543e-05 Loss_e: 1.7470e-05 | Loss_b: 1.0270e-05\n",
      "Step: NaN | Loss: 1.0803e-06 | Loss_d: 3.5879e-05 Loss_e: 1.8189e-05 | Loss_b: 1.0656e-05\n",
      "Step: NaN | Loss: 1.0728e-06 | Loss_d: 3.6462e-05 Loss_e: 1.7524e-05 | Loss_b: 1.0291e-05\n",
      "Step: NaN | Loss: 1.0708e-06 | Loss_d: 3.6344e-05 Loss_e: 1.7577e-05 | Loss_b: 1.0237e-05\n",
      "Step: NaN | Loss: 1.0810e-06 | Loss_d: 3.6115e-05 Loss_e: 1.7973e-05 | Loss_b: 1.0679e-05\n",
      "Step: NaN | Loss: 1.0705e-06 | Loss_d: 3.6286e-05 Loss_e: 1.7617e-05 | Loss_b: 1.0234e-05\n",
      "Step: NaN | Loss: 1.0687e-06 | Loss_d: 3.6346e-05 Loss_e: 1.7568e-05 | Loss_b: 1.0117e-05\n",
      "Step: NaN | Loss: 1.0683e-06 | Loss_d: 3.6322e-05 Loss_e: 1.7576e-05 | Loss_b: 1.0112e-05\n",
      "Step: NaN | Loss: 1.0671e-06 | Loss_d: 3.6269e-05 Loss_e: 1.7538e-05 | Loss_b: 1.0129e-05\n",
      "Step: NaN | Loss: 1.0684e-06 | Loss_d: 3.6104e-05 Loss_e: 1.7518e-05 | Loss_b: 1.0393e-05\n",
      "Step: NaN | Loss: 1.0665e-06 | Loss_d: 3.6200e-05 Loss_e: 1.7506e-05 | Loss_b: 1.0190e-05\n",
      "Step: NaN | Loss: 1.0646e-06 | Loss_d: 3.6186e-05 Loss_e: 1.7371e-05 | Loss_b: 1.0229e-05\n",
      "Step: NaN | Loss: 1.0892e-06 | Loss_d: 3.6467e-05 Loss_e: 1.7509e-05 | Loss_b: 1.1280e-05\n",
      "Step: NaN | Loss: 1.0646e-06 | Loss_d: 3.6187e-05 Loss_e: 1.7364e-05 | Loss_b: 1.0235e-05\n",
      "Step: NaN | Loss: 1.0639e-06 | Loss_d: 3.6268e-05 Loss_e: 1.7344e-05 | Loss_b: 1.0131e-05\n",
      "Step: NaN | Loss: 1.0638e-06 | Loss_d: 3.6250e-05 Loss_e: 1.7344e-05 | Loss_b: 1.0146e-05\n",
      "Step: NaN | Loss: 1.0636e-06 | Loss_d: 3.6260e-05 Loss_e: 1.7345e-05 | Loss_b: 1.0120e-05\n",
      "Step: NaN | Loss: 1.0640e-06 | Loss_d: 3.6312e-05 Loss_e: 1.7364e-05 | Loss_b: 1.0073e-05\n",
      "Step: NaN | Loss: 1.0635e-06 | Loss_d: 3.6274e-05 Loss_e: 1.7348e-05 | Loss_b: 1.0094e-05\n",
      "Step: NaN | Loss: 1.0631e-06 | Loss_d: 3.6283e-05 Loss_e: 1.7342e-05 | Loss_b: 1.0072e-05\n",
      "Step: NaN | Loss: 1.0620e-06 | Loss_d: 3.6319e-05 Loss_e: 1.7322e-05 | Loss_b: 9.9909e-06\n",
      "Step: NaN | Loss: 1.0606e-06 | Loss_d: 3.6526e-05 Loss_e: 1.7303e-05 | Loss_b: 9.7128e-06\n",
      "Step: NaN | Loss: 1.0603e-06 | Loss_d: 3.6463e-05 Loss_e: 1.7294e-05 | Loss_b: 9.7698e-06\n",
      "Step: NaN | Loss: 1.0806e-06 | Loss_d: 3.5029e-05 Loss_e: 1.7847e-05 | Loss_b: 1.1869e-05\n",
      "Step: NaN | Loss: 1.0596e-06 | Loss_d: 3.6218e-05 Loss_e: 1.7345e-05 | Loss_b: 9.9230e-06\n",
      "Step: NaN | Loss: 1.0596e-06 | Loss_d: 3.5993e-05 Loss_e: 1.7460e-05 | Loss_b: 1.0029e-05\n",
      "Step: NaN | Loss: 1.0592e-06 | Loss_d: 3.6099e-05 Loss_e: 1.7400e-05 | Loss_b: 9.9605e-06\n",
      "Step: NaN | Loss: 1.0590e-06 | Loss_d: 3.6055e-05 Loss_e: 1.7452e-05 | Loss_b: 9.9401e-06\n",
      "Step: NaN | Loss: 1.0602e-06 | Loss_d: 3.5936e-05 Loss_e: 1.7692e-05 | Loss_b: 9.8920e-06\n",
      "Step: NaN | Loss: 1.0589e-06 | Loss_d: 3.6034e-05 Loss_e: 1.7481e-05 | Loss_b: 9.9302e-06\n",
      "Step: NaN | Loss: 1.0586e-06 | Loss_d: 3.6007e-05 Loss_e: 1.7496e-05 | Loss_b: 9.9238e-06\n",
      "Step: NaN | Loss: 1.0577e-06 | Loss_d: 3.5901e-05 Loss_e: 1.7563e-05 | Loss_b: 9.9060e-06\n",
      "Step: NaN | Loss: 1.0610e-06 | Loss_d: 3.5445e-05 Loss_e: 1.8110e-05 | Loss_b: 1.0013e-05\n",
      "Step: NaN | Loss: 1.0573e-06 | Loss_d: 3.5776e-05 Loss_e: 1.7667e-05 | Loss_b: 9.9044e-06\n",
      "Step: NaN | Loss: 1.0651e-06 | Loss_d: 3.6001e-05 Loss_e: 1.7504e-05 | Loss_b: 1.0312e-05\n",
      "Step: NaN | Loss: 1.0568e-06 | Loss_d: 3.5794e-05 Loss_e: 1.7620e-05 | Loss_b: 9.9038e-06\n",
      "Step: NaN | Loss: 1.0560e-06 | Loss_d: 3.5803e-05 Loss_e: 1.7559e-05 | Loss_b: 9.9097e-06\n",
      "Step: NaN | Loss: 1.0639e-06 | Loss_d: 3.5923e-05 Loss_e: 1.7419e-05 | Loss_b: 1.0398e-05\n",
      "Step: NaN | Loss: 1.0560e-06 | Loss_d: 3.5806e-05 Loss_e: 1.7547e-05 | Loss_b: 9.9165e-06\n",
      "Step: NaN | Loss: 1.0557e-06 | Loss_d: 3.5849e-05 Loss_e: 1.7521e-05 | Loss_b: 9.8843e-06\n",
      "Step: NaN | Loss: 1.0564e-06 | Loss_d: 3.6047e-05 Loss_e: 1.7429e-05 | Loss_b: 9.8199e-06\n",
      "Step: NaN | Loss: 1.0557e-06 | Loss_d: 3.5895e-05 Loss_e: 1.7496e-05 | Loss_b: 9.8590e-06\n",
      "Step: NaN | Loss: 1.0553e-06 | Loss_d: 3.5859e-05 Loss_e: 1.7518e-05 | Loss_b: 9.8534e-06\n",
      "Step: NaN | Loss: 1.0545e-06 | Loss_d: 3.5722e-05 Loss_e: 1.7613e-05 | Loss_b: 9.8461e-06\n",
      "Step: NaN | Loss: 1.0613e-06 | Loss_d: 3.5174e-05 Loss_e: 1.8248e-05 | Loss_b: 1.0164e-05\n",
      "Step: NaN | Loss: 1.0544e-06 | Loss_d: 3.5641e-05 Loss_e: 1.7678e-05 | Loss_b: 9.8533e-06\n",
      "Step: NaN | Loss: 1.0537e-06 | Loss_d: 3.5665e-05 Loss_e: 1.7647e-05 | Loss_b: 9.8166e-06\n",
      "Step: NaN | Loss: 1.0617e-06 | Loss_d: 3.5915e-05 Loss_e: 1.7759e-05 | Loss_b: 9.9372e-06\n",
      "Step: NaN | Loss: 1.0536e-06 | Loss_d: 3.5670e-05 Loss_e: 1.7645e-05 | Loss_b: 9.8115e-06\n",
      "Step: NaN | Loss: 1.0531e-06 | Loss_d: 3.5553e-05 Loss_e: 1.7693e-05 | Loss_b: 9.8517e-06\n",
      "Step: NaN | Loss: 1.0531e-06 | Loss_d: 3.5581e-05 Loss_e: 1.7680e-05 | Loss_b: 9.8326e-06\n",
      "Step: NaN | Loss: 1.0529e-06 | Loss_d: 3.5592e-05 Loss_e: 1.7663e-05 | Loss_b: 9.8282e-06\n",
      "Step: NaN | Loss: 1.0528e-06 | Loss_d: 3.5641e-05 Loss_e: 1.7608e-05 | Loss_b: 9.8268e-06\n",
      "Step: NaN | Loss: 1.0527e-06 | Loss_d: 3.5620e-05 Loss_e: 1.7627e-05 | Loss_b: 9.8237e-06\n",
      "Step: NaN | Loss: 1.0523e-06 | Loss_d: 3.5560e-05 Loss_e: 1.7640e-05 | Loss_b: 9.8483e-06\n",
      "Step: NaN | Loss: 1.0520e-06 | Loss_d: 3.5336e-05 Loss_e: 1.7709e-05 | Loss_b: 9.9841e-06\n",
      "Step: NaN | Loss: 1.0519e-06 | Loss_d: 3.5400e-05 Loss_e: 1.7686e-05 | Loss_b: 9.9384e-06\n",
      "Step: NaN | Loss: 1.0552e-06 | Loss_d: 3.5278e-05 Loss_e: 1.7845e-05 | Loss_b: 1.0100e-05\n",
      "Step: NaN | Loss: 1.0517e-06 | Loss_d: 3.5370e-05 Loss_e: 1.7707e-05 | Loss_b: 9.9339e-06\n",
      "Step: NaN | Loss: 1.0515e-06 | Loss_d: 3.5389e-05 Loss_e: 1.7689e-05 | Loss_b: 9.9204e-06\n",
      "Step: NaN | Loss: 1.0521e-06 | Loss_d: 3.5477e-05 Loss_e: 1.7649e-05 | Loss_b: 9.9122e-06\n",
      "Step: NaN | Loss: 1.0514e-06 | Loss_d: 3.5406e-05 Loss_e: 1.7676e-05 | Loss_b: 9.9134e-06\n",
      "Step: NaN | Loss: 1.0513e-06 | Loss_d: 3.5412e-05 Loss_e: 1.7672e-05 | Loss_b: 9.9036e-06\n",
      "Step: NaN | Loss: 1.0510e-06 | Loss_d: 3.5437e-05 Loss_e: 1.7655e-05 | Loss_b: 9.8772e-06\n",
      "Step: NaN | Loss: 1.0544e-06 | Loss_d: 3.5592e-05 Loss_e: 1.7603e-05 | Loss_b: 9.9771e-06\n",
      "Step: NaN | Loss: 1.0510e-06 | Loss_d: 3.5448e-05 Loss_e: 1.7648e-05 | Loss_b: 9.8711e-06\n",
      "Step: NaN | Loss: 1.0504e-06 | Loss_d: 3.5389e-05 Loss_e: 1.7656e-05 | Loss_b: 9.8871e-06\n",
      "Step: NaN | Loss: 1.0492e-06 | Loss_d: 3.5181e-05 Loss_e: 1.7704e-05 | Loss_b: 9.9805e-06\n",
      "Step: NaN | Loss: 1.0749e-06 | Loss_d: 3.4896e-05 Loss_e: 1.8306e-05 | Loss_b: 1.1198e-05\n",
      "Step: NaN | Loss: 1.0493e-06 | Loss_d: 3.5174e-05 Loss_e: 1.7706e-05 | Loss_b: 9.9852e-06\n",
      "Step: NaN | Loss: 1.0484e-06 | Loss_d: 3.5276e-05 Loss_e: 1.7624e-05 | Loss_b: 9.9119e-06\n",
      "Step: NaN | Loss: 1.0521e-06 | Loss_d: 3.5844e-05 Loss_e: 1.7354e-05 | Loss_b: 9.8383e-06\n",
      "Step: NaN | Loss: 1.0482e-06 | Loss_d: 3.5359e-05 Loss_e: 1.7568e-05 | Loss_b: 9.8717e-06\n",
      "Step: NaN | Loss: 1.0468e-06 | Loss_d: 3.5259e-05 Loss_e: 1.7592e-05 | Loss_b: 9.8655e-06\n",
      "Step: NaN | Loss: 1.0480e-06 | Loss_d: 3.4915e-05 Loss_e: 1.7757e-05 | Loss_b: 1.0116e-05\n",
      "Step: NaN | Loss: 1.0460e-06 | Loss_d: 3.5114e-05 Loss_e: 1.7643e-05 | Loss_b: 9.9118e-06\n",
      "Step: NaN | Loss: 1.0443e-06 | Loss_d: 3.5059e-05 Loss_e: 1.7611e-05 | Loss_b: 9.8959e-06\n",
      "Step: NaN | Loss: 1.0396e-06 | Loss_d: 3.4877e-05 Loss_e: 1.7514e-05 | Loss_b: 9.8965e-06\n",
      "Step: NaN | Loss: 1.0733e-06 | Loss_d: 3.4800e-05 Loss_e: 1.7835e-05 | Loss_b: 1.1673e-05\n",
      "Step: NaN | Loss: 1.0385e-06 | Loss_d: 3.4781e-05 Loss_e: 1.7477e-05 | Loss_b: 9.9625e-06\n",
      "Step: NaN | Loss: 1.0365e-06 | Loss_d: 3.4541e-05 Loss_e: 1.7337e-05 | Loss_b: 1.0222e-05\n",
      "Step: NaN | Loss: 1.0363e-06 | Loss_d: 3.4593e-05 Loss_e: 1.7362e-05 | Loss_b: 1.0132e-05\n",
      "Step: NaN | Loss: 1.0346e-06 | Loss_d: 3.4482e-05 Loss_e: 1.7346e-05 | Loss_b: 1.0158e-05\n",
      "Step: NaN | Loss: 1.0316e-06 | Loss_d: 3.4074e-05 Loss_e: 1.7329e-05 | Loss_b: 1.0403e-05\n",
      "Step: NaN | Loss: 1.0316e-06 | Loss_d: 3.4078e-05 Loss_e: 1.7329e-05 | Loss_b: 1.0398e-05\n",
      "Step: NaN | Loss: 1.0289e-06 | Loss_d: 3.3959e-05 Loss_e: 1.7366e-05 | Loss_b: 1.0318e-05\n",
      "Step: NaN | Loss: 1.0288e-06 | Loss_d: 3.3970e-05 Loss_e: 1.7360e-05 | Loss_b: 1.0311e-05\n",
      "Step: NaN | Loss: 1.0271e-06 | Loss_d: 3.3755e-05 Loss_e: 1.7445e-05 | Loss_b: 1.0337e-05\n",
      "Step: NaN | Loss: 1.0273e-06 | Loss_d: 3.3016e-05 Loss_e: 1.7871e-05 | Loss_b: 1.0665e-05\n",
      "Step: NaN | Loss: 1.0258e-06 | Loss_d: 3.3378e-05 Loss_e: 1.7631e-05 | Loss_b: 1.0449e-05\n",
      "Step: NaN | Loss: 1.0233e-06 | Loss_d: 3.3284e-05 Loss_e: 1.7677e-05 | Loss_b: 1.0349e-05\n",
      "Step: NaN | Loss: 1.0260e-06 | Loss_d: 3.3057e-05 Loss_e: 1.8225e-05 | Loss_b: 1.0187e-05\n",
      "Step: NaN | Loss: 1.0219e-06 | Loss_d: 3.3174e-05 Loss_e: 1.7808e-05 | Loss_b: 1.0243e-05\n",
      "Step: NaN | Loss: 1.0249e-06 | Loss_d: 3.3324e-05 Loss_e: 1.7635e-05 | Loss_b: 1.0447e-05\n",
      "Step: NaN | Loss: 1.0216e-06 | Loss_d: 3.3205e-05 Loss_e: 1.7759e-05 | Loss_b: 1.0244e-05\n",
      "Step: NaN | Loss: 1.0211e-06 | Loss_d: 3.3319e-05 Loss_e: 1.7701e-05 | Loss_b: 1.0158e-05\n",
      "Step: NaN | Loss: 1.0214e-06 | Loss_d: 3.3798e-05 Loss_e: 1.7501e-05 | Loss_b: 9.8978e-06\n",
      "Step: NaN | Loss: 1.0208e-06 | Loss_d: 3.3514e-05 Loss_e: 1.7611e-05 | Loss_b: 1.0034e-05\n",
      "Step: NaN | Loss: 1.0198e-06 | Loss_d: 3.3479e-05 Loss_e: 1.7610e-05 | Loss_b: 1.0011e-05\n",
      "Step: NaN | Loss: 1.0188e-06 | Loss_d: 3.3392e-05 Loss_e: 1.7653e-05 | Loss_b: 9.9931e-06\n",
      "Step: NaN | Loss: 1.0186e-06 | Loss_d: 3.3407e-05 Loss_e: 1.7635e-05 | Loss_b: 9.9878e-06\n",
      "Step: NaN | Loss: 1.0161e-06 | Loss_d: 3.3257e-05 Loss_e: 1.7678e-05 | Loss_b: 9.9415e-06\n",
      "Step: NaN | Loss: 1.0170e-06 | Loss_d: 3.2753e-05 Loss_e: 1.8070e-05 | Loss_b: 1.0111e-05\n",
      "Step: NaN | Loss: 1.0143e-06 | Loss_d: 3.3009e-05 Loss_e: 1.7812e-05 | Loss_b: 9.9506e-06\n",
      "Step: NaN | Loss: 1.0124e-06 | Loss_d: 3.3093e-05 Loss_e: 1.7726e-05 | Loss_b: 9.8369e-06\n",
      "Step: NaN | Loss: 1.0381e-06 | Loss_d: 3.3630e-05 Loss_e: 1.7662e-05 | Loss_b: 1.0907e-05\n",
      "Step: NaN | Loss: 1.0124e-06 | Loss_d: 3.3101e-05 Loss_e: 1.7720e-05 | Loss_b: 9.8341e-06\n",
      "Step: NaN | Loss: 1.0115e-06 | Loss_d: 3.3105e-05 Loss_e: 1.7683e-05 | Loss_b: 9.8139e-06\n",
      "Step: NaN | Loss: 1.0108e-06 | Loss_d: 3.3189e-05 Loss_e: 1.7580e-05 | Loss_b: 9.7924e-06\n",
      "Step: NaN | Loss: 1.0105e-06 | Loss_d: 3.3146e-05 Loss_e: 1.7609e-05 | Loss_b: 9.7887e-06\n",
      "Step: NaN | Loss: 1.0098e-06 | Loss_d: 3.3477e-05 Loss_e: 1.7422e-05 | Loss_b: 9.6030e-06\n",
      "Step: NaN | Loss: 1.0094e-06 | Loss_d: 3.3352e-05 Loss_e: 1.7486e-05 | Loss_b: 9.6406e-06\n",
      "Step: NaN | Loss: 1.0077e-06 | Loss_d: 3.3317e-05 Loss_e: 1.7442e-05 | Loss_b: 9.6162e-06\n",
      "Step: NaN | Loss: 1.0123e-06 | Loss_d: 3.3335e-05 Loss_e: 1.7365e-05 | Loss_b: 9.9495e-06\n",
      "Step: NaN | Loss: 1.0071e-06 | Loss_d: 3.3297e-05 Loss_e: 1.7408e-05 | Loss_b: 9.6357e-06\n",
      "Step: NaN | Loss: 1.0063e-06 | Loss_d: 3.3213e-05 Loss_e: 1.7419e-05 | Loss_b: 9.6586e-06\n",
      "Step: NaN | Loss: 1.0056e-06 | Loss_d: 3.2907e-05 Loss_e: 1.7496e-05 | Loss_b: 9.8440e-06\n",
      "Step: NaN | Loss: 1.0053e-06 | Loss_d: 3.3001e-05 Loss_e: 1.7464e-05 | Loss_b: 9.7675e-06\n",
      "Step: NaN | Loss: 1.0031e-06 | Loss_d: 3.2880e-05 Loss_e: 1.7528e-05 | Loss_b: 9.6905e-06\n",
      "Step: NaN | Loss: 1.0204e-06 | Loss_d: 3.2600e-05 Loss_e: 1.8307e-05 | Loss_b: 1.0227e-05\n",
      "Step: NaN | Loss: 1.0029e-06 | Loss_d: 3.2841e-05 Loss_e: 1.7565e-05 | Loss_b: 9.6808e-06\n",
      "Step: NaN | Loss: 1.0008e-06 | Loss_d: 3.2833e-05 Loss_e: 1.7584e-05 | Loss_b: 9.5483e-06\n",
      "Step: NaN | Loss: 1.0038e-06 | Loss_d: 3.3009e-05 Loss_e: 1.7845e-05 | Loss_b: 9.2866e-06\n",
      "Step: NaN | Loss: 9.9985e-07 | Loss_d: 3.2854e-05 Loss_e: 1.7638e-05 | Loss_b: 9.4132e-06\n",
      "Step: NaN | Loss: 9.9884e-07 | Loss_d: 3.2700e-05 Loss_e: 1.7774e-05 | Loss_b: 9.3708e-06\n",
      "Step: NaN | Loss: 1.0060e-06 | Loss_d: 3.2201e-05 Loss_e: 1.8411e-05 | Loss_b: 9.6634e-06\n",
      "Step: NaN | Loss: 9.9873e-07 | Loss_d: 3.2640e-05 Loss_e: 1.7833e-05 | Loss_b: 9.3657e-06\n",
      "Step: NaN | Loss: 9.9851e-07 | Loss_d: 3.2604e-05 Loss_e: 1.7860e-05 | Loss_b: 9.3611e-06\n",
      "Step: NaN | Loss: 9.9940e-07 | Loss_d: 3.2480e-05 Loss_e: 1.7996e-05 | Loss_b: 9.4023e-06\n",
      "Step: NaN | Loss: 9.9845e-07 | Loss_d: 3.2578e-05 Loss_e: 1.7883e-05 | Loss_b: 9.3608e-06\n",
      "Step: NaN | Loss: 9.9816e-07 | Loss_d: 3.2587e-05 Loss_e: 1.7866e-05 | Loss_b: 9.3507e-06\n",
      "Step: NaN | Loss: 9.9783e-07 | Loss_d: 3.2637e-05 Loss_e: 1.7808e-05 | Loss_b: 9.3396e-06\n",
      "Step: NaN | Loss: 9.9779e-07 | Loss_d: 3.2622e-05 Loss_e: 1.7822e-05 | Loss_b: 9.3378e-06\n",
      "Step: NaN | Loss: 9.9687e-07 | Loss_d: 3.2685e-05 Loss_e: 1.7784e-05 | Loss_b: 9.2576e-06\n",
      "Step: NaN | Loss: 9.9739e-07 | Loss_d: 3.2969e-05 Loss_e: 1.7664e-05 | Loss_b: 9.1242e-06\n",
      "Step: NaN | Loss: 9.9626e-07 | Loss_d: 3.2799e-05 Loss_e: 1.7727e-05 | Loss_b: 9.1645e-06\n",
      "Step: NaN | Loss: 9.9568e-07 | Loss_d: 3.2791e-05 Loss_e: 1.7725e-05 | Loss_b: 9.1394e-06\n",
      "Step: NaN | Loss: 9.9535e-07 | Loss_d: 3.2786e-05 Loss_e: 1.7748e-05 | Loss_b: 9.1016e-06\n",
      "Step: NaN | Loss: 9.9511e-07 | Loss_d: 3.2783e-05 Loss_e: 1.7733e-05 | Loss_b: 9.1053e-06\n",
      "Step: NaN | Loss: 9.9447e-07 | Loss_d: 3.2701e-05 Loss_e: 1.7760e-05 | Loss_b: 9.1218e-06\n",
      "Step: NaN | Loss: 9.9393e-07 | Loss_d: 3.2390e-05 Loss_e: 1.7882e-05 | Loss_b: 9.2777e-06\n",
      "Step: NaN | Loss: 9.9376e-07 | Loss_d: 3.2491e-05 Loss_e: 1.7839e-05 | Loss_b: 9.2099e-06\n",
      "Step: NaN | Loss: 9.9311e-07 | Loss_d: 3.2408e-05 Loss_e: 1.7897e-05 | Loss_b: 9.1961e-06\n",
      "Step: NaN | Loss: 9.9284e-07 | Loss_d: 3.2121e-05 Loss_e: 1.8181e-05 | Loss_b: 9.1833e-06\n",
      "Step: NaN | Loss: 9.9246e-07 | Loss_d: 3.2243e-05 Loss_e: 1.8041e-05 | Loss_b: 9.1781e-06\n",
      "Step: NaN | Loss: 9.9088e-07 | Loss_d: 3.2159e-05 Loss_e: 1.8043e-05 | Loss_b: 9.1664e-06\n",
      "Step: NaN | Loss: 9.9054e-07 | Loss_d: 3.1923e-05 Loss_e: 1.8134e-05 | Loss_b: 9.2895e-06\n",
      "Step: NaN | Loss: 9.8951e-07 | Loss_d: 3.2012e-05 Loss_e: 1.8075e-05 | Loss_b: 9.1989e-06\n",
      "Step: NaN | Loss: 9.8880e-07 | Loss_d: 3.1912e-05 Loss_e: 1.8131e-05 | Loss_b: 9.2000e-06\n",
      "Step: NaN | Loss: 9.8840e-07 | Loss_d: 3.1945e-05 Loss_e: 1.8107e-05 | Loss_b: 9.1673e-06\n",
      "Step: NaN | Loss: 9.8769e-07 | Loss_d: 3.1951e-05 Loss_e: 1.8049e-05 | Loss_b: 9.1766e-06\n",
      "Step: NaN | Loss: 9.8759e-07 | Loss_d: 3.1993e-05 Loss_e: 1.7839e-05 | Loss_b: 9.3386e-06\n",
      "Step: NaN | Loss: 9.8708e-07 | Loss_d: 3.1969e-05 Loss_e: 1.7936e-05 | Loss_b: 9.2350e-06\n",
      "Step: NaN | Loss: 9.8601e-07 | Loss_d: 3.1865e-05 Loss_e: 1.7988e-05 | Loss_b: 9.2236e-06\n",
      "Step: NaN | Loss: 9.9571e-07 | Loss_d: 3.1554e-05 Loss_e: 1.8482e-05 | Loss_b: 9.6206e-06\n",
      "Step: NaN | Loss: 9.8596e-07 | Loss_d: 3.1838e-05 Loss_e: 1.8007e-05 | Loss_b: 9.2280e-06\n",
      "Step: NaN | Loss: 9.8405e-07 | Loss_d: 3.1789e-05 Loss_e: 1.7934e-05 | Loss_b: 9.2352e-06\n",
      "Step: NaN | Loss: 9.9646e-07 | Loss_d: 3.2009e-05 Loss_e: 1.7965e-05 | Loss_b: 9.7284e-06\n",
      "Step: NaN | Loss: 9.8385e-07 | Loss_d: 3.1781e-05 Loss_e: 1.7912e-05 | Loss_b: 9.2538e-06\n",
      "Step: NaN | Loss: 9.8637e-07 | Loss_d: 3.2013e-05 Loss_e: 1.7970e-05 | Loss_b: 9.1149e-06\n",
      "Step: NaN | Loss: 9.8364e-07 | Loss_d: 3.1827e-05 Loss_e: 1.7920e-05 | Loss_b: 9.1872e-06\n",
      "Step: NaN | Loss: 9.8350e-07 | Loss_d: 3.1815e-05 Loss_e: 1.7925e-05 | Loss_b: 9.1854e-06\n",
      "Step: NaN | Loss: 9.8302e-07 | Loss_d: 3.1767e-05 Loss_e: 1.7947e-05 | Loss_b: 9.1823e-06\n",
      "Step: NaN | Loss: 9.8245e-07 | Loss_d: 3.1569e-05 Loss_e: 1.8081e-05 | Loss_b: 9.2121e-06\n",
      "Step: NaN | Loss: 9.8231e-07 | Loss_d: 3.1624e-05 Loss_e: 1.8036e-05 | Loss_b: 9.1948e-06\n",
      "Step: NaN | Loss: 9.7982e-07 | Loss_d: 3.1541e-05 Loss_e: 1.7907e-05 | Loss_b: 9.2568e-06\n",
      "Step: NaN | Loss: 9.8062e-07 | Loss_d: 3.1262e-05 Loss_e: 1.7739e-05 | Loss_b: 9.7519e-06\n",
      "Step: NaN | Loss: 9.7807e-07 | Loss_d: 3.1405e-05 Loss_e: 1.7762e-05 | Loss_b: 9.4333e-06\n",
      "Step: NaN | Loss: 9.8592e-07 | Loss_d: 3.1365e-05 Loss_e: 1.7765e-05 | Loss_b: 9.9406e-06\n",
      "Step: NaN | Loss: 9.7710e-07 | Loss_d: 3.1377e-05 Loss_e: 1.7750e-05 | Loss_b: 9.4153e-06\n",
      "Step: NaN | Loss: 9.7690e-07 | Loss_d: 3.1413e-05 Loss_e: 1.7763e-05 | Loss_b: 9.3544e-06\n",
      "Step: NaN | Loss: 9.7686e-07 | Loss_d: 3.1403e-05 Loss_e: 1.7759e-05 | Loss_b: 9.3661e-06\n",
      "Step: NaN | Loss: 9.7680e-07 | Loss_d: 3.1403e-05 Loss_e: 1.7752e-05 | Loss_b: 9.3687e-06\n",
      "Step: NaN | Loss: 9.7664e-07 | Loss_d: 3.1406e-05 Loss_e: 1.7726e-05 | Loss_b: 9.3827e-06\n",
      "Step: NaN | Loss: 9.7716e-07 | Loss_d: 3.1426e-05 Loss_e: 1.7612e-05 | Loss_b: 9.5078e-06\n",
      "Step: NaN | Loss: 9.7655e-07 | Loss_d: 3.1409e-05 Loss_e: 1.7693e-05 | Loss_b: 9.4071e-06\n",
      "Step: NaN | Loss: 9.7612e-07 | Loss_d: 3.1397e-05 Loss_e: 1.7678e-05 | Loss_b: 9.4088e-06\n",
      "Step: NaN | Loss: 9.7504e-07 | Loss_d: 3.1353e-05 Loss_e: 1.7643e-05 | Loss_b: 9.4235e-06\n",
      "Step: NaN | Loss: 9.8640e-07 | Loss_d: 3.1275e-05 Loss_e: 1.8014e-05 | Loss_b: 9.8098e-06\n",
      "Step: NaN | Loss: 9.7493e-07 | Loss_d: 3.1336e-05 Loss_e: 1.7638e-05 | Loss_b: 9.4380e-06\n",
      "Step: NaN | Loss: 9.7487e-07 | Loss_d: 3.1393e-05 Loss_e: 1.7512e-05 | Loss_b: 9.5037e-06\n",
      "Step: NaN | Loss: 9.7456e-07 | Loss_d: 3.1362e-05 Loss_e: 1.7568e-05 | Loss_b: 9.4594e-06\n",
      "Step: NaN | Loss: 9.7370e-07 | Loss_d: 3.1383e-05 Loss_e: 1.7551e-05 | Loss_b: 9.4036e-06\n",
      "Step: NaN | Loss: 9.7444e-07 | Loss_d: 3.1552e-05 Loss_e: 1.7536e-05 | Loss_b: 9.2952e-06\n",
      "Step: NaN | Loss: 9.7319e-07 | Loss_d: 3.1434e-05 Loss_e: 1.7536e-05 | Loss_b: 9.3389e-06\n",
      "Step: NaN | Loss: 9.7220e-07 | Loss_d: 3.1391e-05 Loss_e: 1.7519e-05 | Loss_b: 9.3387e-06\n",
      "Step: NaN | Loss: 9.7244e-07 | Loss_d: 3.1292e-05 Loss_e: 1.7531e-05 | Loss_b: 9.4409e-06\n",
      "Step: NaN | Loss: 9.7148e-07 | Loss_d: 3.1330e-05 Loss_e: 1.7509e-05 | Loss_b: 9.3656e-06\n",
      "Step: NaN | Loss: 9.7043e-07 | Loss_d: 3.1250e-05 Loss_e: 1.7505e-05 | Loss_b: 9.3880e-06\n",
      "Step: NaN | Loss: 9.6971e-07 | Loss_d: 3.1027e-05 Loss_e: 1.7509e-05 | Loss_b: 9.5630e-06\n",
      "Step: NaN | Loss: 9.6934e-07 | Loss_d: 3.1091e-05 Loss_e: 1.7503e-05 | Loss_b: 9.4835e-06\n",
      "Step: NaN | Loss: 9.6855e-07 | Loss_d: 3.1271e-05 Loss_e: 1.7417e-05 | Loss_b: 9.3411e-06\n",
      "Step: NaN | Loss: 9.6833e-07 | Loss_d: 3.1212e-05 Loss_e: 1.7441e-05 | Loss_b: 9.3639e-06\n",
      "Step: NaN | Loss: 9.6722e-07 | Loss_d: 3.1204e-05 Loss_e: 1.7381e-05 | Loss_b: 9.3648e-06\n",
      "Step: NaN | Loss: 9.6731e-07 | Loss_d: 3.1187e-05 Loss_e: 1.7215e-05 | Loss_b: 9.5538e-06\n",
      "Step: NaN | Loss: 9.6634e-07 | Loss_d: 3.1193e-05 Loss_e: 1.7286e-05 | Loss_b: 9.4185e-06\n",
      "Step: NaN | Loss: 9.6517e-07 | Loss_d: 3.1148e-05 Loss_e: 1.7275e-05 | Loss_b: 9.4045e-06\n",
      "Step: NaN | Loss: 9.6395e-07 | Loss_d: 3.0988e-05 Loss_e: 1.7306e-05 | Loss_b: 9.4602e-06\n",
      "Step: NaN | Loss: 9.6374e-07 | Loss_d: 3.1030e-05 Loss_e: 1.7285e-05 | Loss_b: 9.4268e-06\n",
      "Step: NaN | Loss: 9.6205e-07 | Loss_d: 3.1067e-05 Loss_e: 1.7255e-05 | Loss_b: 9.3186e-06\n",
      "Step: NaN | Loss: 9.7012e-07 | Loss_d: 3.1332e-05 Loss_e: 1.7369e-05 | Loss_b: 9.4231e-06\n",
      "Step: NaN | Loss: 9.6175e-07 | Loss_d: 3.1096e-05 Loss_e: 1.7249e-05 | Loss_b: 9.2777e-06\n",
      "Step: NaN | Loss: 9.6040e-07 | Loss_d: 3.1072e-05 Loss_e: 1.7285e-05 | Loss_b: 9.1845e-06\n",
      "Step: NaN | Loss: 9.6485e-07 | Loss_d: 3.1094e-05 Loss_e: 1.7579e-05 | Loss_b: 9.1351e-06\n",
      "Step: NaN | Loss: 9.6000e-07 | Loss_d: 3.1061e-05 Loss_e: 1.7328e-05 | Loss_b: 9.1294e-06\n",
      "Step: NaN | Loss: 9.5804e-07 | Loss_d: 3.0827e-05 Loss_e: 1.7314e-05 | Loss_b: 9.2595e-06\n",
      "Step: NaN | Loss: 9.7888e-07 | Loss_d: 3.0040e-05 Loss_e: 1.7660e-05 | Loss_b: 1.0949e-05\n",
      "Step: NaN | Loss: 9.5797e-07 | Loss_d: 3.0785e-05 Loss_e: 1.7316e-05 | Loss_b: 9.2958e-06\n",
      "Step: NaN | Loss: 9.5666e-07 | Loss_d: 3.0597e-05 Loss_e: 1.7344e-05 | Loss_b: 9.3769e-06\n",
      "Step: NaN | Loss: 9.5658e-07 | Loss_d: 3.0628e-05 Loss_e: 1.7335e-05 | Loss_b: 9.3489e-06\n",
      "Step: NaN | Loss: 9.5628e-07 | Loss_d: 3.0604e-05 Loss_e: 1.7327e-05 | Loss_b: 9.3638e-06\n",
      "Step: NaN | Loss: 9.5549e-07 | Loss_d: 3.0508e-05 Loss_e: 1.7296e-05 | Loss_b: 9.4434e-06\n",
      "Step: NaN | Loss: 9.6125e-07 | Loss_d: 3.0097e-05 Loss_e: 1.7208e-05 | Loss_b: 1.0288e-05\n",
      "Step: NaN | Loss: 9.5531e-07 | Loss_d: 3.0441e-05 Loss_e: 1.7276e-05 | Loss_b: 9.5197e-06\n",
      "Step: NaN | Loss: 9.5376e-07 | Loss_d: 3.0364e-05 Loss_e: 1.7279e-05 | Loss_b: 9.5011e-06\n",
      "Step: NaN | Loss: 9.4984e-07 | Loss_d: 3.0090e-05 Loss_e: 1.7358e-05 | Loss_b: 9.4616e-06\n",
      "Step: NaN | Loss: 9.8545e-07 | Loss_d: 2.9532e-05 Loss_e: 1.9411e-05 | Loss_b: 1.0099e-05\n",
      "Step: NaN | Loss: 9.4925e-07 | Loss_d: 2.9959e-05 Loss_e: 1.7451e-05 | Loss_b: 9.4643e-06\n",
      "Step: NaN | Loss: 9.4559e-07 | Loss_d: 2.9468e-05 Loss_e: 1.7607e-05 | Loss_b: 9.5791e-06\n",
      "Step: NaN | Loss: 9.9496e-07 | Loss_d: 2.8658e-05 Loss_e: 1.9101e-05 | Loss_b: 1.1853e-05\n",
      "Step: NaN | Loss: 9.4546e-07 | Loss_d: 2.9404e-05 Loss_e: 1.7637e-05 | Loss_b: 9.6053e-06\n",
      "Step: NaN | Loss: 9.4254e-07 | Loss_d: 2.9160e-05 Loss_e: 1.7648e-05 | Loss_b: 9.6644e-06\n",
      "Step: NaN | Loss: 9.6268e-07 | Loss_d: 2.8520e-05 Loss_e: 1.8334e-05 | Loss_b: 1.0823e-05\n",
      "Step: NaN | Loss: 9.4226e-07 | Loss_d: 2.9067e-05 Loss_e: 1.7672e-05 | Loss_b: 9.7166e-06\n",
      "Step: NaN | Loss: 9.4124e-07 | Loss_d: 2.9005e-05 Loss_e: 1.7670e-05 | Loss_b: 9.7191e-06\n",
      "Step: NaN | Loss: 9.3823e-07 | Loss_d: 2.8779e-05 Loss_e: 1.7686e-05 | Loss_b: 9.7488e-06\n",
      "Step: NaN | Loss: 9.4905e-07 | Loss_d: 2.8120e-05 Loss_e: 1.8329e-05 | Loss_b: 1.0413e-05\n",
      "Step: NaN | Loss: 9.3692e-07 | Loss_d: 2.8540e-05 Loss_e: 1.7759e-05 | Loss_b: 9.8356e-06\n",
      "Step: NaN | Loss: 9.3668e-07 | Loss_d: 2.8638e-05 Loss_e: 1.7889e-05 | Loss_b: 9.5935e-06\n",
      "Step: NaN | Loss: 9.3544e-07 | Loss_d: 2.8586e-05 Loss_e: 1.7820e-05 | Loss_b: 9.6410e-06\n",
      "Step: NaN | Loss: 9.3367e-07 | Loss_d: 2.8625e-05 Loss_e: 1.7752e-05 | Loss_b: 9.5631e-06\n",
      "Step: NaN | Loss: 9.5729e-07 | Loss_d: 2.9115e-05 Loss_e: 1.8053e-05 | Loss_b: 1.0188e-05\n",
      "Step: NaN | Loss: 9.3365e-07 | Loss_d: 2.8630e-05 Loss_e: 1.7749e-05 | Loss_b: 9.5602e-06\n",
      "Step: NaN | Loss: 9.3318e-07 | Loss_d: 2.8574e-05 Loss_e: 1.7779e-05 | Loss_b: 9.5578e-06\n",
      "Step: NaN | Loss: 9.3399e-07 | Loss_d: 2.8360e-05 Loss_e: 1.7923e-05 | Loss_b: 9.6763e-06\n",
      "Step: NaN | Loss: 9.3299e-07 | Loss_d: 2.8506e-05 Loss_e: 1.7820e-05 | Loss_b: 9.5735e-06\n",
      "Step: NaN | Loss: 9.3273e-07 | Loss_d: 2.8502e-05 Loss_e: 1.7823e-05 | Loss_b: 9.5589e-06\n",
      "Step: NaN | Loss: 9.3269e-07 | Loss_d: 2.8488e-05 Loss_e: 1.7849e-05 | Loss_b: 9.5436e-06\n",
      "Step: NaN | Loss: 9.3251e-07 | Loss_d: 2.8494e-05 Loss_e: 1.7834e-05 | Loss_b: 9.5425e-06\n",
      "Step: NaN | Loss: 9.3234e-07 | Loss_d: 2.8433e-05 Loss_e: 1.7858e-05 | Loss_b: 9.5696e-06\n",
      "Step: NaN | Loss: 9.3253e-07 | Loss_d: 2.8206e-05 Loss_e: 1.7958e-05 | Loss_b: 9.7071e-06\n",
      "Step: NaN | Loss: 9.3224e-07 | Loss_d: 2.8347e-05 Loss_e: 1.7893e-05 | Loss_b: 9.6146e-06\n",
      "Step: NaN | Loss: 9.3203e-07 | Loss_d: 2.8384e-05 Loss_e: 1.7850e-05 | Loss_b: 9.6072e-06\n",
      "Step: NaN | Loss: 9.3187e-07 | Loss_d: 2.8544e-05 Loss_e: 1.7691e-05 | Loss_b: 9.5980e-06\n",
      "Step: NaN | Loss: 9.3180e-07 | Loss_d: 2.8485e-05 Loss_e: 1.7746e-05 | Loss_b: 9.5970e-06\n",
      "Step: NaN | Loss: 9.3093e-07 | Loss_d: 2.8469e-05 Loss_e: 1.7712e-05 | Loss_b: 9.5955e-06\n",
      "Step: NaN | Loss: 9.2995e-07 | Loss_d: 2.8455e-05 Loss_e: 1.7620e-05 | Loss_b: 9.6423e-06\n",
      "Step: NaN | Loss: 9.2983e-07 | Loss_d: 2.8451e-05 Loss_e: 1.7636e-05 | Loss_b: 9.6227e-06\n",
      "Step: NaN | Loss: 9.2830e-07 | Loss_d: 2.8434e-05 Loss_e: 1.7637e-05 | Loss_b: 9.5474e-06\n",
      "Step: NaN | Loss: 9.3398e-07 | Loss_d: 2.8477e-05 Loss_e: 1.8010e-05 | Loss_b: 9.4718e-06\n",
      "Step: NaN | Loss: 9.2794e-07 | Loss_d: 2.8429e-05 Loss_e: 1.7664e-05 | Loss_b: 9.5045e-06\n",
      "Step: NaN | Loss: 9.2597e-07 | Loss_d: 2.8304e-05 Loss_e: 1.7635e-05 | Loss_b: 9.5402e-06\n",
      "Step: NaN | Loss: 9.2381e-07 | Loss_d: 2.7989e-05 Loss_e: 1.7627e-05 | Loss_b: 9.7332e-06\n",
      "Step: NaN | Loss: 9.2350e-07 | Loss_d: 2.8044e-05 Loss_e: 1.7612e-05 | Loss_b: 9.6745e-06\n",
      "Step: NaN | Loss: 9.2832e-07 | Loss_d: 2.7583e-05 Loss_e: 1.7688e-05 | Loss_b: 1.0349e-05\n",
      "Step: NaN | Loss: 9.2277e-07 | Loss_d: 2.7902e-05 Loss_e: 1.7604e-05 | Loss_b: 9.7819e-06\n",
      "Step: NaN | Loss: 9.2176e-07 | Loss_d: 2.7956e-05 Loss_e: 1.7518e-05 | Loss_b: 9.7525e-06\n",
      "Step: NaN | Loss: 9.2289e-07 | Loss_d: 2.8211e-05 Loss_e: 1.7242e-05 | Loss_b: 9.8412e-06\n",
      "Step: NaN | Loss: 9.2121e-07 | Loss_d: 2.8042e-05 Loss_e: 1.7405e-05 | Loss_b: 9.7470e-06\n",
      "Step: NaN | Loss: 9.2040e-07 | Loss_d: 2.8015e-05 Loss_e: 1.7423e-05 | Loss_b: 9.7075e-06\n",
      "Step: NaN | Loss: 9.2081e-07 | Loss_d: 2.7963e-05 Loss_e: 1.7542e-05 | Loss_b: 9.6650e-06\n",
      "Step: NaN | Loss: 9.1984e-07 | Loss_d: 2.7982e-05 Loss_e: 1.7464e-05 | Loss_b: 9.6655e-06\n",
      "Step: NaN | Loss: 9.1940e-07 | Loss_d: 2.7881e-05 Loss_e: 1.7306e-05 | Loss_b: 9.8978e-06\n",
      "Step: NaN | Loss: 9.1854e-07 | Loss_d: 2.7912e-05 Loss_e: 1.7367e-05 | Loss_b: 9.7544e-06\n",
      "Step: NaN | Loss: 9.1914e-07 | Loss_d: 2.8239e-05 Loss_e: 1.7090e-05 | Loss_b: 9.7404e-06\n",
      "Step: NaN | Loss: 9.1797e-07 | Loss_d: 2.8045e-05 Loss_e: 1.7240e-05 | Loss_b: 9.7147e-06\n",
      "Step: NaN | Loss: 9.1771e-07 | Loss_d: 2.8098e-05 Loss_e: 1.7181e-05 | Loss_b: 9.7043e-06\n",
      "Step: NaN | Loss: 9.1882e-07 | Loss_d: 2.8329e-05 Loss_e: 1.6969e-05 | Loss_b: 9.7514e-06\n",
      "Step: NaN | Loss: 9.1766e-07 | Loss_d: 2.8137e-05 Loss_e: 1.7142e-05 | Loss_b: 9.7022e-06\n",
      "Step: NaN | Loss: 9.1745e-07 | Loss_d: 2.8119e-05 Loss_e: 1.7141e-05 | Loss_b: 9.7084e-06\n",
      "Step: NaN | Loss: 9.1683e-07 | Loss_d: 2.8047e-05 Loss_e: 1.7142e-05 | Loss_b: 9.7413e-06\n",
      "Step: NaN | Loss: 9.1943e-07 | Loss_d: 2.7726e-05 Loss_e: 1.7246e-05 | Loss_b: 1.0115e-05\n",
      "Step: NaN | Loss: 9.1659e-07 | Loss_d: 2.7970e-05 Loss_e: 1.7152e-05 | Loss_b: 9.7954e-06\n",
      "Step: NaN | Loss: 9.1481e-07 | Loss_d: 2.8018e-05 Loss_e: 1.7094e-05 | Loss_b: 9.6979e-06\n",
      "Step: NaN | Loss: 9.1778e-07 | Loss_d: 2.8293e-05 Loss_e: 1.7036e-05 | Loss_b: 9.6594e-06\n",
      "Step: NaN | Loss: 9.1403e-07 | Loss_d: 2.8091e-05 Loss_e: 1.7046e-05 | Loss_b: 9.6266e-06\n",
      "Step: NaN | Loss: 9.1268e-07 | Loss_d: 2.7958e-05 Loss_e: 1.7079e-05 | Loss_b: 9.6454e-06\n",
      "Step: NaN | Loss: 9.1331e-07 | Loss_d: 2.7523e-05 Loss_e: 1.7277e-05 | Loss_b: 9.9203e-06\n",
      "Step: NaN | Loss: 9.1174e-07 | Loss_d: 2.7749e-05 Loss_e: 1.7153e-05 | Loss_b: 9.7248e-06\n",
      "Step: NaN | Loss: 9.1082e-07 | Loss_d: 2.7676e-05 Loss_e: 1.7190e-05 | Loss_b: 9.7050e-06\n",
      "Step: NaN | Loss: 9.1404e-07 | Loss_d: 2.7459e-05 Loss_e: 1.7440e-05 | Loss_b: 9.8651e-06\n",
      "Step: NaN | Loss: 9.1054e-07 | Loss_d: 2.7620e-05 Loss_e: 1.7229e-05 | Loss_b: 9.7051e-06\n",
      "Step: NaN | Loss: 9.0997e-07 | Loss_d: 2.7581e-05 Loss_e: 1.7239e-05 | Loss_b: 9.6999e-06\n",
      "Step: NaN | Loss: 9.0835e-07 | Loss_d: 2.7446e-05 Loss_e: 1.7286e-05 | Loss_b: 9.6915e-06\n",
      "Step: NaN | Loss: 9.1674e-07 | Loss_d: 2.7212e-05 Loss_e: 1.7736e-05 | Loss_b: 9.9772e-06\n",
      "Step: NaN | Loss: 9.0782e-07 | Loss_d: 2.7342e-05 Loss_e: 1.7345e-05 | Loss_b: 9.7039e-06\n",
      "Step: NaN | Loss: 9.4236e-07 | Loss_d: 2.7207e-05 Loss_e: 1.7499e-05 | Loss_b: 1.1755e-05\n",
      "Step: NaN | Loss: 9.0751e-07 | Loss_d: 2.7281e-05 Loss_e: 1.7327e-05 | Loss_b: 9.7659e-06\n",
      "Step: NaN | Loss: 9.0706e-07 | Loss_d: 2.7232e-05 Loss_e: 1.7333e-05 | Loss_b: 9.7809e-06\n",
      "Step: NaN | Loss: 9.0845e-07 | Loss_d: 2.7072e-05 Loss_e: 1.7382e-05 | Loss_b: 9.9761e-06\n",
      "Step: NaN | Loss: 9.0692e-07 | Loss_d: 2.7190e-05 Loss_e: 1.7341e-05 | Loss_b: 9.8062e-06\n",
      "Step: NaN | Loss: 9.0660e-07 | Loss_d: 2.7202e-05 Loss_e: 1.7326e-05 | Loss_b: 9.7902e-06\n",
      "Step: NaN | Loss: 9.0605e-07 | Loss_d: 2.7254e-05 Loss_e: 1.7284e-05 | Loss_b: 9.7471e-06\n",
      "Step: NaN | Loss: 9.0605e-07 | Loss_d: 2.7254e-05 Loss_e: 1.7284e-05 | Loss_b: 9.7471e-06\n",
      "Step: NaN | Loss: 9.0469e-07 | Loss_d: 2.7113e-05 Loss_e: 1.7379e-05 | Loss_b: 9.7119e-06\n",
      "Step: NaN | Loss: 9.1327e-07 | Loss_d: 2.6594e-05 Loss_e: 1.8027e-05 | Loss_b: 1.0097e-05\n",
      "Step: NaN | Loss: 9.0452e-07 | Loss_d: 2.7048e-05 Loss_e: 1.7433e-05 | Loss_b: 9.7130e-06\n",
      "Step: NaN | Loss: 9.0512e-07 | Loss_d: 2.6892e-05 Loss_e: 1.7489e-05 | Loss_b: 9.8495e-06\n",
      "Step: NaN | Loss: 9.0421e-07 | Loss_d: 2.6986e-05 Loss_e: 1.7451e-05 | Loss_b: 9.7382e-06\n",
      "Step: NaN | Loss: 9.0396e-07 | Loss_d: 2.7006e-05 Loss_e: 1.7430e-05 | Loss_b: 9.7237e-06\n",
      "Step: NaN | Loss: 9.0396e-07 | Loss_d: 2.7093e-05 Loss_e: 1.7362e-05 | Loss_b: 9.7056e-06\n",
      "Step: NaN | Loss: 9.0377e-07 | Loss_d: 2.7048e-05 Loss_e: 1.7393e-05 | Loss_b: 9.7072e-06\n",
      "Step: NaN | Loss: 9.0337e-07 | Loss_d: 2.7010e-05 Loss_e: 1.7400e-05 | Loss_b: 9.7153e-06\n",
      "Step: NaN | Loss: 9.0345e-07 | Loss_d: 2.6874e-05 Loss_e: 1.7447e-05 | Loss_b: 9.8090e-06\n",
      "Step: NaN | Loss: 9.0308e-07 | Loss_d: 2.6942e-05 Loss_e: 1.7418e-05 | Loss_b: 9.7478e-06\n",
      "Step: NaN | Loss: 9.0339e-07 | Loss_d: 2.7213e-05 Loss_e: 1.7215e-05 | Loss_b: 9.6974e-06\n",
      "Step: NaN | Loss: 9.0284e-07 | Loss_d: 2.7045e-05 Loss_e: 1.7331e-05 | Loss_b: 9.7166e-06\n",
      "Step: NaN | Loss: 9.0259e-07 | Loss_d: 2.7072e-05 Loss_e: 1.7307e-05 | Loss_b: 9.6993e-06\n",
      "Step: NaN | Loss: 9.0188e-07 | Loss_d: 2.7184e-05 Loss_e: 1.7217e-05 | Loss_b: 9.6350e-06\n",
      "Step: NaN | Loss: 9.0571e-07 | Loss_d: 2.7859e-05 Loss_e: 1.6967e-05 | Loss_b: 9.4393e-06\n",
      "Step: NaN | Loss: 9.0166e-07 | Loss_d: 2.7296e-05 Loss_e: 1.7144e-05 | Loss_b: 9.5823e-06\n",
      "Step: NaN | Loss: 9.0087e-07 | Loss_d: 2.7332e-05 Loss_e: 1.7101e-05 | Loss_b: 9.5420e-06\n",
      "Step: NaN | Loss: 9.0830e-07 | Loss_d: 2.7533e-05 Loss_e: 1.7132e-05 | Loss_b: 9.7552e-06\n",
      "Step: NaN | Loss: 9.0084e-07 | Loss_d: 2.7341e-05 Loss_e: 1.7094e-05 | Loss_b: 9.5382e-06\n",
      "Step: NaN | Loss: 8.9941e-07 | Loss_d: 2.7269e-05 Loss_e: 1.7126e-05 | Loss_b: 9.4925e-06\n",
      "Step: NaN | Loss: 9.0369e-07 | Loss_d: 2.7137e-05 Loss_e: 1.7479e-05 | Loss_b: 9.5282e-06\n",
      "Step: NaN | Loss: 8.9898e-07 | Loss_d: 2.7215e-05 Loss_e: 1.7177e-05 | Loss_b: 9.4694e-06\n",
      "Step: NaN | Loss: 8.9791e-07 | Loss_d: 2.7259e-05 Loss_e: 1.7126e-05 | Loss_b: 9.4127e-06\n",
      "Step: NaN | Loss: 8.9955e-07 | Loss_d: 2.7537e-05 Loss_e: 1.6998e-05 | Loss_b: 9.3605e-06\n",
      "Step: NaN | Loss: 8.9738e-07 | Loss_d: 2.7332e-05 Loss_e: 1.7071e-05 | Loss_b: 9.3631e-06\n",
      "Step: NaN | Loss: 8.9688e-07 | Loss_d: 2.7392e-05 Loss_e: 1.6979e-05 | Loss_b: 9.3647e-06\n",
      "Step: NaN | Loss: 9.0275e-07 | Loss_d: 2.7673e-05 Loss_e: 1.6677e-05 | Loss_b: 9.7379e-06\n",
      "Step: NaN | Loss: 8.9687e-07 | Loss_d: 2.7401e-05 Loss_e: 1.6966e-05 | Loss_b: 9.3681e-06\n",
      "Step: NaN | Loss: 8.9648e-07 | Loss_d: 2.7392e-05 Loss_e: 1.6947e-05 | Loss_b: 9.3732e-06\n",
      "Step: NaN | Loss: 8.9637e-07 | Loss_d: 2.7365e-05 Loss_e: 1.6887e-05 | Loss_b: 9.4539e-06\n",
      "Step: NaN | Loss: 8.9613e-07 | Loss_d: 2.7375e-05 Loss_e: 1.6910e-05 | Loss_b: 9.4061e-06\n",
      "Step: NaN | Loss: 8.9564e-07 | Loss_d: 2.7348e-05 Loss_e: 1.6909e-05 | Loss_b: 9.4048e-06\n",
      "Step: NaN | Loss: 8.9424e-07 | Loss_d: 2.7250e-05 Loss_e: 1.6922e-05 | Loss_b: 9.4056e-06\n",
      "Step: NaN | Loss: 9.0369e-07 | Loss_d: 2.7026e-05 Loss_e: 1.7415e-05 | Loss_b: 9.7022e-06\n",
      "Step: NaN | Loss: 8.9391e-07 | Loss_d: 2.7187e-05 Loss_e: 1.6951e-05 | Loss_b: 9.4205e-06\n",
      "Step: NaN | Loss: 9.3118e-07 | Loss_d: 2.6422e-05 Loss_e: 1.8031e-05 | Loss_b: 1.1338e-05\n",
      "Step: NaN | Loss: 8.9333e-07 | Loss_d: 2.7077e-05 Loss_e: 1.7019e-05 | Loss_b: 9.4270e-06\n",
      "Step: NaN | Loss: 8.9246e-07 | Loss_d: 2.7098e-05 Loss_e: 1.6998e-05 | Loss_b: 9.3746e-06\n",
      "Step: NaN | Loss: 8.9458e-07 | Loss_d: 2.7287e-05 Loss_e: 1.6977e-05 | Loss_b: 9.3340e-06\n",
      "Step: NaN | Loss: 8.9213e-07 | Loss_d: 2.7132e-05 Loss_e: 1.6983e-05 | Loss_b: 9.3363e-06\n",
      "Step: NaN | Loss: 8.9182e-07 | Loss_d: 2.7099e-05 Loss_e: 1.6988e-05 | Loss_b: 9.3464e-06\n",
      "Step: NaN | Loss: 8.9146e-07 | Loss_d: 2.6970e-05 Loss_e: 1.7027e-05 | Loss_b: 9.4145e-06\n",
      "Step: NaN | Loss: 8.9143e-07 | Loss_d: 2.6997e-05 Loss_e: 1.7016e-05 | Loss_b: 9.3966e-06\n",
      "Step: NaN | Loss: 8.9074e-07 | Loss_d: 2.6930e-05 Loss_e: 1.6997e-05 | Loss_b: 9.4410e-06\n",
      "Step: NaN | Loss: 8.9396e-07 | Loss_d: 2.6756e-05 Loss_e: 1.6956e-05 | Loss_b: 9.8482e-06\n",
      "Step: NaN | Loss: 8.9063e-07 | Loss_d: 2.6892e-05 Loss_e: 1.6986e-05 | Loss_b: 9.4832e-06\n",
      "Step: NaN | Loss: 8.8945e-07 | Loss_d: 2.6872e-05 Loss_e: 1.6968e-05 | Loss_b: 9.4508e-06\n",
      "Step: NaN | Loss: 8.8632e-07 | Loss_d: 2.6810e-05 Loss_e: 1.6912e-05 | Loss_b: 9.3812e-06\n",
      "Step: NaN | Loss: 9.0729e-07 | Loss_d: 2.6933e-05 Loss_e: 1.7000e-05 | Loss_b: 1.0427e-05\n",
      "Step: NaN | Loss: 8.8556e-07 | Loss_d: 2.6781e-05 Loss_e: 1.6885e-05 | Loss_b: 9.3916e-06\n",
      "Step: NaN | Loss: 8.8271e-07 | Loss_d: 2.6900e-05 Loss_e: 1.6803e-05 | Loss_b: 9.1827e-06\n",
      "Step: NaN | Loss: 8.8855e-07 | Loss_d: 2.7595e-05 Loss_e: 1.6684e-05 | Loss_b: 8.9575e-06\n",
      "Step: NaN | Loss: 8.8157e-07 | Loss_d: 2.7065e-05 Loss_e: 1.6736e-05 | Loss_b: 9.0183e-06\n",
      "Step: NaN | Loss: 8.8114e-07 | Loss_d: 2.7038e-05 Loss_e: 1.6728e-05 | Loss_b: 9.0268e-06\n",
      "Step: NaN | Loss: 8.8047e-07 | Loss_d: 2.6942e-05 Loss_e: 1.6725e-05 | Loss_b: 9.0858e-06\n",
      "Step: NaN | Loss: 8.8046e-07 | Loss_d: 2.6953e-05 Loss_e: 1.6723e-05 | Loss_b: 9.0765e-06\n",
      "Step: NaN | Loss: 8.7984e-07 | Loss_d: 2.7018e-05 Loss_e: 1.6675e-05 | Loss_b: 9.0227e-06\n",
      "Step: NaN | Loss: 8.7980e-07 | Loss_d: 2.7003e-05 Loss_e: 1.6682e-05 | Loss_b: 9.0275e-06\n",
      "Step: NaN | Loss: 8.7909e-07 | Loss_d: 2.6882e-05 Loss_e: 1.6757e-05 | Loss_b: 9.0302e-06\n",
      "Step: NaN | Loss: 8.7902e-07 | Loss_d: 2.6419e-05 Loss_e: 1.7131e-05 | Loss_b: 9.1158e-06\n",
      "Step: NaN | Loss: 8.7844e-07 | Loss_d: 2.6648e-05 Loss_e: 1.6929e-05 | Loss_b: 9.0550e-06\n",
      "Step: NaN | Loss: 8.7843e-07 | Loss_d: 2.6507e-05 Loss_e: 1.7025e-05 | Loss_b: 9.0983e-06\n",
      "Step: NaN | Loss: 8.7787e-07 | Loss_d: 2.6576e-05 Loss_e: 1.6974e-05 | Loss_b: 9.0471e-06\n",
      "Step: NaN | Loss: 8.7768e-07 | Loss_d: 2.6561e-05 Loss_e: 1.6975e-05 | Loss_b: 9.0494e-06\n",
      "Step: NaN | Loss: 8.7714e-07 | Loss_d: 2.6503e-05 Loss_e: 1.6979e-05 | Loss_b: 9.0704e-06\n",
      "Step: NaN | Loss: 8.8090e-07 | Loss_d: 2.6244e-05 Loss_e: 1.7071e-05 | Loss_b: 9.4633e-06\n",
      "Step: NaN | Loss: 8.7699e-07 | Loss_d: 2.6461e-05 Loss_e: 1.6986e-05 | Loss_b: 9.0980e-06\n",
      "Step: NaN | Loss: 8.7635e-07 | Loss_d: 2.6515e-05 Loss_e: 1.6927e-05 | Loss_b: 9.0644e-06\n",
      "Step: NaN | Loss: 8.7574e-07 | Loss_d: 2.6761e-05 Loss_e: 1.6742e-05 | Loss_b: 8.9666e-06\n",
      "Step: NaN | Loss: 8.7559e-07 | Loss_d: 2.6681e-05 Loss_e: 1.6790e-05 | Loss_b: 8.9900e-06\n",
      "Step: NaN | Loss: 8.7489e-07 | Loss_d: 2.6495e-05 Loss_e: 1.6865e-05 | Loss_b: 9.0579e-06\n",
      "Step: NaN | Loss: 8.7468e-07 | Loss_d: 2.6549e-05 Loss_e: 1.6834e-05 | Loss_b: 9.0223e-06\n",
      "Step: NaN | Loss: 8.7388e-07 | Loss_d: 2.6483e-05 Loss_e: 1.6844e-05 | Loss_b: 9.0309e-06\n",
      "Step: NaN | Loss: 8.7223e-07 | Loss_d: 2.6231e-05 Loss_e: 1.6909e-05 | Loss_b: 9.1184e-06\n",
      "Step: NaN | Loss: 9.0207e-07 | Loss_d: 2.5282e-05 Loss_e: 1.7898e-05 | Loss_b: 1.0867e-05\n",
      "Step: NaN | Loss: 8.7220e-07 | Loss_d: 2.6199e-05 Loss_e: 1.6922e-05 | Loss_b: 9.1370e-06\n",
      "Step: NaN | Loss: 8.7047e-07 | Loss_d: 2.6134e-05 Loss_e: 1.6948e-05 | Loss_b: 9.0720e-06\n",
      "Step: NaN | Loss: 8.9115e-07 | Loss_d: 2.6087e-05 Loss_e: 1.8071e-05 | Loss_b: 9.2338e-06\n",
      "Step: NaN | Loss: 8.7044e-07 | Loss_d: 2.6127e-05 Loss_e: 1.6958e-05 | Loss_b: 9.0665e-06\n",
      "Step: NaN | Loss: 8.7009e-07 | Loss_d: 2.6034e-05 Loss_e: 1.7013e-05 | Loss_b: 9.0841e-06\n",
      "Step: NaN | Loss: 8.6916e-07 | Loss_d: 2.6064e-05 Loss_e: 1.6979e-05 | Loss_b: 9.0320e-06\n",
      "Step: NaN | Loss: 8.6843e-07 | Loss_d: 2.5982e-05 Loss_e: 1.7001e-05 | Loss_b: 9.0482e-06\n",
      "Step: NaN | Loss: 8.6734e-07 | Loss_d: 2.5673e-05 Loss_e: 1.7112e-05 | Loss_b: 9.1807e-06\n",
      "Step: NaN | Loss: 8.6732e-07 | Loss_d: 2.5710e-05 Loss_e: 1.7097e-05 | Loss_b: 9.1583e-06\n",
      "Step: NaN | Loss: 8.6606e-07 | Loss_d: 2.5795e-05 Loss_e: 1.6950e-05 | Loss_b: 9.1443e-06\n",
      "Step: NaN | Loss: 8.7883e-07 | Loss_d: 2.6289e-05 Loss_e: 1.6534e-05 | Loss_b: 9.8307e-06\n",
      "Step: NaN | Loss: 8.6603e-07 | Loss_d: 2.5815e-05 Loss_e: 1.6921e-05 | Loss_b: 9.1510e-06\n",
      "Step: NaN | Loss: 8.6537e-07 | Loss_d: 2.5820e-05 Loss_e: 1.6889e-05 | Loss_b: 9.1394e-06\n",
      "Step: NaN | Loss: 8.6464e-07 | Loss_d: 2.5851e-05 Loss_e: 1.6796e-05 | Loss_b: 9.1574e-06\n",
      "Step: NaN | Loss: 8.6455e-07 | Loss_d: 2.5842e-05 Loss_e: 1.6813e-05 | Loss_b: 9.1442e-06\n",
      "Step: NaN | Loss: 8.6355e-07 | Loss_d: 2.5793e-05 Loss_e: 1.6842e-05 | Loss_b: 9.1043e-06\n",
      "Step: NaN | Loss: 8.6258e-07 | Loss_d: 2.5627e-05 Loss_e: 1.7018e-05 | Loss_b: 9.0359e-06\n",
      "Step: NaN | Loss: 8.6234e-07 | Loss_d: 2.5672e-05 Loss_e: 1.6954e-05 | Loss_b: 9.0405e-06\n",
      "Step: NaN | Loss: 8.6211e-07 | Loss_d: 2.5658e-05 Loss_e: 1.6951e-05 | Loss_b: 9.0433e-06\n",
      "Step: NaN | Loss: 8.6209e-07 | Loss_d: 2.5660e-05 Loss_e: 1.6951e-05 | Loss_b: 9.0408e-06\n",
      "Step: NaN | Loss: 8.6155e-07 | Loss_d: 2.5628e-05 Loss_e: 1.6955e-05 | Loss_b: 9.0369e-06\n",
      "Step: NaN | Loss: 8.6048e-07 | Loss_d: 2.5506e-05 Loss_e: 1.6987e-05 | Loss_b: 9.0626e-06\n",
      "Step: NaN | Loss: 8.8053e-07 | Loss_d: 2.5036e-05 Loss_e: 1.7559e-05 | Loss_b: 1.0161e-05\n",
      "Step: NaN | Loss: 8.6048e-07 | Loss_d: 2.5492e-05 Loss_e: 1.6992e-05 | Loss_b: 9.0708e-06\n",
      "Step: NaN | Loss: 8.5961e-07 | Loss_d: 2.5453e-05 Loss_e: 1.7030e-05 | Loss_b: 9.0199e-06\n",
      "Step: NaN | Loss: 8.6298e-07 | Loss_d: 2.5365e-05 Loss_e: 1.7266e-05 | Loss_b: 9.0738e-06\n",
      "Step: NaN | Loss: 8.5942e-07 | Loss_d: 2.5427e-05 Loss_e: 1.7065e-05 | Loss_b: 8.9997e-06\n",
      "Step: NaN | Loss: 8.5928e-07 | Loss_d: 2.5446e-05 Loss_e: 1.7041e-05 | Loss_b: 8.9962e-06\n",
      "Step: NaN | Loss: 8.5892e-07 | Loss_d: 2.5526e-05 Loss_e: 1.6949e-05 | Loss_b: 8.9874e-06\n",
      "Step: NaN | Loss: 8.6172e-07 | Loss_d: 2.5987e-05 Loss_e: 1.6571e-05 | Loss_b: 9.0706e-06\n",
      "Step: NaN | Loss: 8.5887e-07 | Loss_d: 2.5581e-05 Loss_e: 1.6890e-05 | Loss_b: 8.9875e-06\n",
      "Step: NaN | Loss: 8.6242e-07 | Loss_d: 2.5250e-05 Loss_e: 1.7111e-05 | Loss_b: 9.3101e-06\n",
      "Step: NaN | Loss: 8.5848e-07 | Loss_d: 2.5478e-05 Loss_e: 1.6935e-05 | Loss_b: 9.0220e-06\n",
      "Step: NaN | Loss: 8.5770e-07 | Loss_d: 2.5426e-05 Loss_e: 1.6964e-05 | Loss_b: 8.9992e-06\n",
      "Step: NaN | Loss: 8.5773e-07 | Loss_d: 2.5248e-05 Loss_e: 1.7160e-05 | Loss_b: 8.9825e-06\n",
      "Step: NaN | Loss: 8.5709e-07 | Loss_d: 2.5332e-05 Loss_e: 1.7044e-05 | Loss_b: 8.9757e-06\n",
      "Step: NaN | Loss: 8.5607e-07 | Loss_d: 2.5320e-05 Loss_e: 1.7013e-05 | Loss_b: 8.9570e-06\n",
      "Step: NaN | Loss: 8.6147e-07 | Loss_d: 2.5323e-05 Loss_e: 1.6991e-05 | Loss_b: 9.3009e-06\n",
      "Step: NaN | Loss: 8.5592e-07 | Loss_d: 2.5316e-05 Loss_e: 1.7000e-05 | Loss_b: 8.9656e-06\n",
      "Step: NaN | Loss: 8.5498e-07 | Loss_d: 2.5389e-05 Loss_e: 1.6939e-05 | Loss_b: 8.8978e-06\n",
      "Step: NaN | Loss: 8.5756e-07 | Loss_d: 2.5716e-05 Loss_e: 1.6765e-05 | Loss_b: 8.8983e-06\n",
      "Step: NaN | Loss: 8.5467e-07 | Loss_d: 2.5464e-05 Loss_e: 1.6885e-05 | Loss_b: 8.8574e-06\n",
      "Step: NaN | Loss: 8.5376e-07 | Loss_d: 2.5399e-05 Loss_e: 1.6891e-05 | Loss_b: 8.8617e-06\n",
      "Step: NaN | Loss: 8.5274e-07 | Loss_d: 2.5167e-05 Loss_e: 1.6959e-05 | Loss_b: 8.9648e-06\n",
      "Step: NaN | Loss: 8.5260e-07 | Loss_d: 2.5223e-05 Loss_e: 1.6935e-05 | Loss_b: 8.9250e-06\n",
      "Step: NaN | Loss: 8.5113e-07 | Loss_d: 2.5235e-05 Loss_e: 1.6899e-05 | Loss_b: 8.8616e-06\n",
      "Step: NaN | Loss: 8.6380e-07 | Loss_d: 2.5352e-05 Loss_e: 1.7143e-05 | Loss_b: 9.2591e-06\n",
      "Step: NaN | Loss: 8.5103e-07 | Loss_d: 2.5240e-05 Loss_e: 1.6895e-05 | Loss_b: 8.8538e-06\n",
      "Step: NaN | Loss: 8.5081e-07 | Loss_d: 2.5234e-05 Loss_e: 1.6898e-05 | Loss_b: 8.8439e-06\n",
      "Step: NaN | Loss: 8.5006e-07 | Loss_d: 2.5211e-05 Loss_e: 1.6912e-05 | Loss_b: 8.8073e-06\n",
      "Step: NaN | Loss: 8.4937e-07 | Loss_d: 2.5127e-05 Loss_e: 1.7036e-05 | Loss_b: 8.7260e-06\n",
      "Step: NaN | Loss: 8.4905e-07 | Loss_d: 2.5152e-05 Loss_e: 1.6981e-05 | Loss_b: 8.7371e-06\n",
      "Step: NaN | Loss: 8.4828e-07 | Loss_d: 2.5067e-05 Loss_e: 1.7000e-05 | Loss_b: 8.7570e-06\n",
      "Step: NaN | Loss: 8.5363e-07 | Loss_d: 2.4964e-05 Loss_e: 1.7122e-05 | Loss_b: 9.0581e-06\n",
      "Step: NaN | Loss: 8.4822e-07 | Loss_d: 2.5040e-05 Loss_e: 1.7009e-05 | Loss_b: 8.7717e-06\n",
      "Step: NaN | Loss: 8.4763e-07 | Loss_d: 2.5044e-05 Loss_e: 1.6985e-05 | Loss_b: 8.7558e-06\n",
      "Step: NaN | Loss: 8.4783e-07 | Loss_d: 2.5073e-05 Loss_e: 1.6935e-05 | Loss_b: 8.7893e-06\n",
      "Step: NaN | Loss: 8.4721e-07 | Loss_d: 2.5055e-05 Loss_e: 1.6954e-05 | Loss_b: 8.7513e-06\n",
      "Step: NaN | Loss: 8.4645e-07 | Loss_d: 2.5045e-05 Loss_e: 1.6943e-05 | Loss_b: 8.7262e-06\n",
      "Step: NaN | Loss: 8.4748e-07 | Loss_d: 2.5044e-05 Loss_e: 1.7032e-05 | Loss_b: 8.6991e-06\n",
      "Step: NaN | Loss: 8.4604e-07 | Loss_d: 2.5037e-05 Loss_e: 1.6951e-05 | Loss_b: 8.7021e-06\n",
      "Step: NaN | Loss: 8.4612e-07 | Loss_d: 2.5049e-05 Loss_e: 1.6924e-05 | Loss_b: 8.7216e-06\n",
      "Step: NaN | Loss: 8.4541e-07 | Loss_d: 2.5040e-05 Loss_e: 1.6932e-05 | Loss_b: 8.6806e-06\n",
      "Step: NaN | Loss: 8.4501e-07 | Loss_d: 2.4991e-05 Loss_e: 1.6963e-05 | Loss_b: 8.6747e-06\n",
      "Step: NaN | Loss: 8.4385e-07 | Loss_d: 2.4799e-05 Loss_e: 1.7099e-05 | Loss_b: 8.6608e-06\n",
      "Step: NaN | Loss: 8.4923e-07 | Loss_d: 2.4001e-05 Loss_e: 1.8023e-05 | Loss_b: 8.8576e-06\n",
      "Step: NaN | Loss: 8.4335e-07 | Loss_d: 2.4616e-05 Loss_e: 1.7252e-05 | Loss_b: 8.6604e-06\n",
      "Step: NaN | Loss: 8.4119e-07 | Loss_d: 2.4500e-05 Loss_e: 1.7243e-05 | Loss_b: 8.6560e-06\n",
      "Step: NaN | Loss: 8.5610e-07 | Loss_d: 2.4380e-05 Loss_e: 1.7732e-05 | Loss_b: 9.1812e-06\n",
      "Step: NaN | Loss: 8.4100e-07 | Loss_d: 2.4462e-05 Loss_e: 1.7255e-05 | Loss_b: 8.6710e-06\n",
      "Step: NaN | Loss: 8.3931e-07 | Loss_d: 2.4427e-05 Loss_e: 1.7220e-05 | Loss_b: 8.6397e-06\n",
      "Step: NaN | Loss: 8.4582e-07 | Loss_d: 2.4394e-05 Loss_e: 1.7392e-05 | Loss_b: 8.8914e-06\n",
      "Step: NaN | Loss: 8.3893e-07 | Loss_d: 2.4407e-05 Loss_e: 1.7215e-05 | Loss_b: 8.6420e-06\n",
      "Step: NaN | Loss: 8.3812e-07 | Loss_d: 2.4410e-05 Loss_e: 1.7198e-05 | Loss_b: 8.6079e-06\n",
      "Step: NaN | Loss: 8.4476e-07 | Loss_d: 2.4527e-05 Loss_e: 1.7205e-05 | Loss_b: 8.8810e-06\n",
      "Step: NaN | Loss: 8.3808e-07 | Loss_d: 2.4413e-05 Loss_e: 1.7194e-05 | Loss_b: 8.6059e-06\n",
      "Step: NaN | Loss: 8.3729e-07 | Loss_d: 2.4495e-05 Loss_e: 1.7113e-05 | Loss_b: 8.5581e-06\n",
      "Step: NaN | Loss: 8.3863e-07 | Loss_d: 2.4900e-05 Loss_e: 1.6835e-05 | Loss_b: 8.5109e-06\n",
      "Step: NaN | Loss: 8.3694e-07 | Loss_d: 2.4609e-05 Loss_e: 1.7018e-05 | Loss_b: 8.5187e-06\n",
      "Step: NaN | Loss: 8.3615e-07 | Loss_d: 2.4507e-05 Loss_e: 1.7070e-05 | Loss_b: 8.5203e-06\n",
      "Step: NaN | Loss: 8.3882e-07 | Loss_d: 2.4139e-05 Loss_e: 1.7313e-05 | Loss_b: 8.8046e-06\n",
      "Step: NaN | Loss: 8.3590e-07 | Loss_d: 2.4423e-05 Loss_e: 1.7117e-05 | Loss_b: 8.5424e-06\n",
      "Step: NaN | Loss: 8.3469e-07 | Loss_d: 2.4352e-05 Loss_e: 1.7136e-05 | Loss_b: 8.5222e-06\n",
      "Step: NaN | Loss: 8.4051e-07 | Loss_d: 2.4117e-05 Loss_e: 1.7321e-05 | Loss_b: 8.9205e-06\n",
      "Step: NaN | Loss: 8.3446e-07 | Loss_d: 2.4309e-05 Loss_e: 1.7154e-05 | Loss_b: 8.5338e-06\n",
      "Step: NaN | Loss: 8.3381e-07 | Loss_d: 2.4384e-05 Loss_e: 1.7057e-05 | Loss_b: 8.5164e-06\n",
      "Step: NaN | Loss: 8.3542e-07 | Loss_d: 2.4731e-05 Loss_e: 1.6790e-05 | Loss_b: 8.5330e-06\n",
      "Step: NaN | Loss: 8.3359e-07 | Loss_d: 2.4467e-05 Loss_e: 1.6969e-05 | Loss_b: 8.5075e-06\n",
      "Step: NaN | Loss: 8.3274e-07 | Loss_d: 2.4394e-05 Loss_e: 1.6953e-05 | Loss_b: 8.5455e-06\n",
      "Step: NaN | Loss: 8.4038e-07 | Loss_d: 2.4226e-05 Loss_e: 1.6989e-05 | Loss_b: 9.1348e-06\n",
      "Step: NaN | Loss: 8.3269e-07 | Loss_d: 2.4376e-05 Loss_e: 1.6951e-05 | Loss_b: 8.5626e-06\n",
      "Step: NaN | Loss: 8.3156e-07 | Loss_d: 2.4328e-05 Loss_e: 1.6949e-05 | Loss_b: 8.5456e-06\n",
      "Step: NaN | Loss: 8.3508e-07 | Loss_d: 2.4194e-05 Loss_e: 1.7104e-05 | Loss_b: 8.7352e-06\n",
      "Step: NaN | Loss: 8.3120e-07 | Loss_d: 2.4289e-05 Loss_e: 1.6961e-05 | Loss_b: 8.5513e-06\n",
      "Step: NaN | Loss: 8.3071e-07 | Loss_d: 2.4330e-05 Loss_e: 1.6904e-05 | Loss_b: 8.5365e-06\n",
      "Step: NaN | Loss: 8.3452e-07 | Loss_d: 2.4510e-05 Loss_e: 1.6765e-05 | Loss_b: 8.7252e-06\n",
      "Step: NaN | Loss: 8.3070e-07 | Loss_d: 2.4345e-05 Loss_e: 1.6887e-05 | Loss_b: 8.5386e-06\n",
      "Step: NaN | Loss: 8.3032e-07 | Loss_d: 2.4347e-05 Loss_e: 1.6873e-05 | Loss_b: 8.5280e-06\n",
      "Step: NaN | Loss: 8.2906e-07 | Loss_d: 2.4356e-05 Loss_e: 1.6821e-05 | Loss_b: 8.4956e-06\n",
      "Step: NaN | Loss: 8.2659e-07 | Loss_d: 2.4413e-05 Loss_e: 1.6700e-05 | Loss_b: 8.4108e-06\n",
      "Step: NaN | Loss: 8.2653e-07 | Loss_d: 2.4405e-05 Loss_e: 1.6703e-05 | Loss_b: 8.4128e-06\n",
      "Step: NaN | Loss: 8.2714e-07 | Loss_d: 2.4235e-05 Loss_e: 1.6887e-05 | Loss_b: 8.4361e-06\n",
      "Step: NaN | Loss: 8.2600e-07 | Loss_d: 2.4323e-05 Loss_e: 1.6761e-05 | Loss_b: 8.4057e-06\n",
      "Step: NaN | Loss: 8.2631e-07 | Loss_d: 2.4329e-05 Loss_e: 1.6707e-05 | Loss_b: 8.4715e-06\n",
      "Step: NaN | Loss: 8.2559e-07 | Loss_d: 2.4317e-05 Loss_e: 1.6728e-05 | Loss_b: 8.4189e-06\n",
      "Step: NaN | Loss: 8.2551e-07 | Loss_d: 2.4323e-05 Loss_e: 1.6717e-05 | Loss_b: 8.4196e-06\n",
      "Step: NaN | Loss: 8.2544e-07 | Loss_d: 2.4350e-05 Loss_e: 1.6673e-05 | Loss_b: 8.4318e-06\n",
      "Step: NaN | Loss: 8.2540e-07 | Loss_d: 2.4340e-05 Loss_e: 1.6689e-05 | Loss_b: 8.4246e-06\n",
      "Step: NaN | Loss: 8.2517e-07 | Loss_d: 2.4345e-05 Loss_e: 1.6676e-05 | Loss_b: 8.4184e-06\n",
      "Step: NaN | Loss: 8.2460e-07 | Loss_d: 2.4370e-05 Loss_e: 1.6627e-05 | Loss_b: 8.4091e-06\n",
      "Step: NaN | Loss: 8.3038e-07 | Loss_d: 2.4583e-05 Loss_e: 1.6430e-05 | Loss_b: 8.7381e-06\n",
      "Step: NaN | Loss: 8.2456e-07 | Loss_d: 2.4384e-05 Loss_e: 1.6604e-05 | Loss_b: 8.4149e-06\n",
      "Step: NaN | Loss: 8.2425e-07 | Loss_d: 2.4483e-05 Loss_e: 1.6537e-05 | Loss_b: 8.3653e-06\n",
      "Step: NaN | Loss: 8.2412e-07 | Loss_d: 2.4444e-05 Loss_e: 1.6559e-05 | Loss_b: 8.3727e-06\n",
      "Step: NaN | Loss: 8.2390e-07 | Loss_d: 2.4428e-05 Loss_e: 1.6576e-05 | Loss_b: 8.3596e-06\n",
      "Step: NaN | Loss: 8.2359e-07 | Loss_d: 2.4364e-05 Loss_e: 1.6655e-05 | Loss_b: 8.3255e-06\n",
      "Step: NaN | Loss: 8.2359e-07 | Loss_d: 2.4371e-05 Loss_e: 1.6645e-05 | Loss_b: 8.3284e-06\n",
      "Step: NaN | Loss: 8.2319e-07 | Loss_d: 2.4330e-05 Loss_e: 1.6671e-05 | Loss_b: 8.3199e-06\n",
      "Step: NaN | Loss: 8.2288e-07 | Loss_d: 2.4175e-05 Loss_e: 1.6798e-05 | Loss_b: 8.3293e-06\n",
      "Step: NaN | Loss: 8.2274e-07 | Loss_d: 2.4228e-05 Loss_e: 1.6748e-05 | Loss_b: 8.3175e-06\n",
      "Step: NaN | Loss: 8.2223e-07 | Loss_d: 2.4151e-05 Loss_e: 1.6781e-05 | Loss_b: 8.3313e-06\n",
      "Step: NaN | Loss: 8.2149e-07 | Loss_d: 2.3857e-05 Loss_e: 1.6933e-05 | Loss_b: 8.4295e-06\n",
      "Step: NaN | Loss: 8.2146e-07 | Loss_d: 2.3897e-05 Loss_e: 1.6909e-05 | Loss_b: 8.4110e-06\n",
      "Step: NaN | Loss: 8.2003e-07 | Loss_d: 2.3848e-05 Loss_e: 1.6879e-05 | Loss_b: 8.4047e-06\n",
      "Step: NaN | Loss: 8.2647e-07 | Loss_d: 2.3764e-05 Loss_e: 1.6941e-05 | Loss_b: 8.8116e-06\n",
      "Step: NaN | Loss: 8.1976e-07 | Loss_d: 2.3821e-05 Loss_e: 1.6869e-05 | Loss_b: 8.4252e-06\n",
      "Step: NaN | Loss: 8.1822e-07 | Loss_d: 2.3746e-05 Loss_e: 1.6860e-05 | Loss_b: 8.4164e-06\n",
      "Step: NaN | Loss: 8.3260e-07 | Loss_d: 2.3564e-05 Loss_e: 1.7421e-05 | Loss_b: 8.8990e-06\n",
      "Step: NaN | Loss: 8.1816e-07 | Loss_d: 2.3730e-05 Loss_e: 1.6867e-05 | Loss_b: 8.4226e-06\n",
      "Step: NaN | Loss: 8.1707e-07 | Loss_d: 2.3662e-05 Loss_e: 1.6897e-05 | Loss_b: 8.3959e-06\n",
      "Step: NaN | Loss: 8.2527e-07 | Loss_d: 2.3577e-05 Loss_e: 1.7215e-05 | Loss_b: 8.6537e-06\n",
      "Step: NaN | Loss: 8.1699e-07 | Loss_d: 2.3642e-05 Loss_e: 1.6912e-05 | Loss_b: 8.3954e-06\n",
      "Step: NaN | Loss: 8.1671e-07 | Loss_d: 2.3569e-05 Loss_e: 1.6961e-05 | Loss_b: 8.4022e-06\n",
      "Step: NaN | Loss: 8.1642e-07 | Loss_d: 2.3297e-05 Loss_e: 1.7181e-05 | Loss_b: 8.4377e-06\n",
      "Step: NaN | Loss: 8.1637e-07 | Loss_d: 2.3373e-05 Loss_e: 1.7114e-05 | Loss_b: 8.4262e-06\n",
      "Step: NaN | Loss: 8.1537e-07 | Loss_d: 2.3383e-05 Loss_e: 1.7068e-05 | Loss_b: 8.4018e-06\n",
      "Step: NaN | Loss: 8.1769e-07 | Loss_d: 2.3454e-05 Loss_e: 1.7004e-05 | Loss_b: 8.5336e-06\n",
      "Step: NaN | Loss: 8.1503e-07 | Loss_d: 2.3397e-05 Loss_e: 1.7032e-05 | Loss_b: 8.4034e-06\n",
      "Step: NaN | Loss: 8.1429e-07 | Loss_d: 2.3400e-05 Loss_e: 1.6998e-05 | Loss_b: 8.3896e-06\n",
      "Step: NaN | Loss: 8.1427e-07 | Loss_d: 2.3423e-05 Loss_e: 1.6907e-05 | Loss_b: 8.4571e-06\n",
      "Step: NaN | Loss: 8.1369e-07 | Loss_d: 2.3410e-05 Loss_e: 1.6943e-05 | Loss_b: 8.3992e-06\n",
      "Step: NaN | Loss: 8.1319e-07 | Loss_d: 2.3433e-05 Loss_e: 1.6889e-05 | Loss_b: 8.4004e-06\n",
      "Step: NaN | Loss: 8.1318e-07 | Loss_d: 2.3577e-05 Loss_e: 1.6692e-05 | Loss_b: 8.4524e-06\n",
      "Step: NaN | Loss: 8.1279e-07 | Loss_d: 2.3495e-05 Loss_e: 1.6785e-05 | Loss_b: 8.4173e-06\n",
      "Step: NaN | Loss: 8.1180e-07 | Loss_d: 2.3494e-05 Loss_e: 1.6763e-05 | Loss_b: 8.3813e-06\n",
      "Step: NaN | Loss: 8.1451e-07 | Loss_d: 2.3577e-05 Loss_e: 1.6726e-05 | Loss_b: 8.4979e-06\n",
      "Step: NaN | Loss: 8.1148e-07 | Loss_d: 2.3502e-05 Loss_e: 1.6747e-05 | Loss_b: 8.3708e-06\n",
      "Step: NaN | Loss: 8.1131e-07 | Loss_d: 2.3601e-05 Loss_e: 1.6730e-05 | Loss_b: 8.2776e-06\n",
      "Step: NaN | Loss: 8.1080e-07 | Loss_d: 2.3552e-05 Loss_e: 1.6734e-05 | Loss_b: 8.2928e-06\n",
      "Step: NaN | Loss: 8.1048e-07 | Loss_d: 2.3493e-05 Loss_e: 1.6762e-05 | Loss_b: 8.3035e-06\n",
      "Step: NaN | Loss: 8.1154e-07 | Loss_d: 2.3277e-05 Loss_e: 1.6920e-05 | Loss_b: 8.4258e-06\n",
      "Step: NaN | Loss: 8.1037e-07 | Loss_d: 2.3443e-05 Loss_e: 1.6792e-05 | Loss_b: 8.3185e-06\n",
      "Step: NaN | Loss: 8.0985e-07 | Loss_d: 2.3450e-05 Loss_e: 1.6770e-05 | Loss_b: 8.3024e-06\n",
      "Step: NaN | Loss: 8.1101e-07 | Loss_d: 2.3502e-05 Loss_e: 1.6726e-05 | Loss_b: 8.3633e-06\n",
      "Step: NaN | Loss: 8.0965e-07 | Loss_d: 2.3460e-05 Loss_e: 1.6750e-05 | Loss_b: 8.2991e-06\n",
      "Step: NaN | Loss: 8.0908e-07 | Loss_d: 2.3461e-05 Loss_e: 1.6745e-05 | Loss_b: 8.2689e-06\n",
      "Step: NaN | Loss: 8.0911e-07 | Loss_d: 2.3511e-05 Loss_e: 1.6747e-05 | Loss_b: 8.2189e-06\n",
      "Step: NaN | Loss: 8.0862e-07 | Loss_d: 2.3477e-05 Loss_e: 1.6742e-05 | Loss_b: 8.2293e-06\n",
      "Step: NaN | Loss: 8.0790e-07 | Loss_d: 2.3461e-05 Loss_e: 1.6746e-05 | Loss_b: 8.1977e-06\n",
      "Step: NaN | Loss: 8.0651e-07 | Loss_d: 2.3418e-05 Loss_e: 1.6770e-05 | Loss_b: 8.1333e-06\n",
      "Step: NaN | Loss: 8.3579e-07 | Loss_d: 2.3733e-05 Loss_e: 1.7078e-05 | Loss_b: 9.2648e-06\n",
      "Step: NaN | Loss: 8.0649e-07 | Loss_d: 2.3416e-05 Loss_e: 1.6772e-05 | Loss_b: 8.1315e-06\n",
      "Step: NaN | Loss: 8.0627e-07 | Loss_d: 2.3415e-05 Loss_e: 1.6786e-05 | Loss_b: 8.1057e-06\n",
      "Step: NaN | Loss: 8.0578e-07 | Loss_d: 2.3410e-05 Loss_e: 1.6761e-05 | Loss_b: 8.1068e-06\n",
      "Step: NaN | Loss: 8.0507e-07 | Loss_d: 2.3447e-05 Loss_e: 1.6716e-05 | Loss_b: 8.0717e-06\n",
      "Step: NaN | Loss: 8.0508e-07 | Loss_d: 2.3608e-05 Loss_e: 1.6571e-05 | Loss_b: 8.0560e-06\n",
      "Step: NaN | Loss: 8.0453e-07 | Loss_d: 2.3526e-05 Loss_e: 1.6637e-05 | Loss_b: 8.0403e-06\n",
      "Step: NaN | Loss: 8.0383e-07 | Loss_d: 2.3538e-05 Loss_e: 1.6620e-05 | Loss_b: 8.0033e-06\n",
      "Step: NaN | Loss: 8.0354e-07 | Loss_d: 2.3612e-05 Loss_e: 1.6612e-05 | Loss_b: 7.9198e-06\n",
      "Step: NaN | Loss: 8.0316e-07 | Loss_d: 2.3575e-05 Loss_e: 1.6603e-05 | Loss_b: 7.9422e-06\n",
      "Step: NaN | Loss: 8.0275e-07 | Loss_d: 2.3576e-05 Loss_e: 1.6593e-05 | Loss_b: 7.9279e-06\n",
      "Step: NaN | Loss: 8.0287e-07 | Loss_d: 2.3586e-05 Loss_e: 1.6560e-05 | Loss_b: 7.9567e-06\n",
      "Step: NaN | Loss: 8.0244e-07 | Loss_d: 2.3579e-05 Loss_e: 1.6576e-05 | Loss_b: 7.9233e-06\n",
      "Step: NaN | Loss: 8.0195e-07 | Loss_d: 2.3524e-05 Loss_e: 1.6634e-05 | Loss_b: 7.8901e-06\n",
      "Step: NaN | Loss: 8.0806e-07 | Loss_d: 2.3415e-05 Loss_e: 1.6980e-05 | Loss_b: 8.0200e-06\n",
      "Step: NaN | Loss: 8.0194e-07 | Loss_d: 2.3519e-05 Loss_e: 1.6641e-05 | Loss_b: 7.8883e-06\n",
      "Step: NaN | Loss: 8.0177e-07 | Loss_d: 2.3496e-05 Loss_e: 1.6659e-05 | Loss_b: 7.8826e-06\n",
      "Step: NaN | Loss: 8.0186e-07 | Loss_d: 2.3412e-05 Loss_e: 1.6743e-05 | Loss_b: 7.8878e-06\n",
      "Step: NaN | Loss: 8.0167e-07 | Loss_d: 2.3459e-05 Loss_e: 1.6692e-05 | Loss_b: 7.8805e-06\n",
      "Step: NaN | Loss: 8.0127e-07 | Loss_d: 2.3468e-05 Loss_e: 1.6667e-05 | Loss_b: 7.8723e-06\n",
      "Step: NaN | Loss: 8.0070e-07 | Loss_d: 2.3520e-05 Loss_e: 1.6583e-05 | Loss_b: 7.8700e-06\n",
      "Step: NaN | Loss: 8.0069e-07 | Loss_d: 2.3510e-05 Loss_e: 1.6596e-05 | Loss_b: 7.8670e-06\n",
      "Step: NaN | Loss: 7.9956e-07 | Loss_d: 2.3538e-05 Loss_e: 1.6523e-05 | Loss_b: 7.8438e-06\n",
      "Step: NaN | Loss: 7.9781e-07 | Loss_d: 2.3698e-05 Loss_e: 1.6307e-05 | Loss_b: 7.7946e-06\n",
      "Step: NaN | Loss: 7.9779e-07 | Loss_d: 2.3678e-05 Loss_e: 1.6325e-05 | Loss_b: 7.7964e-06\n",
      "Step: NaN | Loss: 7.9730e-07 | Loss_d: 2.3743e-05 Loss_e: 1.6276e-05 | Loss_b: 7.7511e-06\n",
      "Step: NaN | Loss: 7.9729e-07 | Loss_d: 2.3737e-05 Loss_e: 1.6280e-05 | Loss_b: 7.7528e-06\n",
      "Step: NaN | Loss: 7.9692e-07 | Loss_d: 2.3743e-05 Loss_e: 1.6259e-05 | Loss_b: 7.7447e-06\n",
      "Step: NaN | Loss: 7.9875e-07 | Loss_d: 2.3802e-05 Loss_e: 1.6217e-05 | Loss_b: 7.8381e-06\n",
      "Step: NaN | Loss: 7.9684e-07 | Loss_d: 2.3749e-05 Loss_e: 1.6248e-05 | Loss_b: 7.7456e-06\n",
      "Step: NaN | Loss: 7.9651e-07 | Loss_d: 2.3745e-05 Loss_e: 1.6244e-05 | Loss_b: 7.7335e-06\n",
      "Step: NaN | Loss: 7.9560e-07 | Loss_d: 2.3741e-05 Loss_e: 1.6234e-05 | Loss_b: 7.6932e-06\n",
      "Step: NaN | Loss: 8.0347e-07 | Loss_d: 2.4023e-05 Loss_e: 1.6306e-05 | Loss_b: 7.8100e-06\n",
      "Step: NaN | Loss: 7.9547e-07 | Loss_d: 2.3748e-05 Loss_e: 1.6232e-05 | Loss_b: 7.6798e-06\n",
      "Step: NaN | Loss: 7.9392e-07 | Loss_d: 2.3640e-05 Loss_e: 1.6219e-05 | Loss_b: 7.7076e-06\n",
      "Step: NaN | Loss: 7.9506e-07 | Loss_d: 2.3275e-05 Loss_e: 1.6246e-05 | Loss_b: 8.1139e-06\n",
      "Step: NaN | Loss: 7.9295e-07 | Loss_d: 2.3480e-05 Loss_e: 1.6215e-05 | Loss_b: 7.8135e-06\n",
      "Step: NaN | Loss: 7.9455e-07 | Loss_d: 2.3632e-05 Loss_e: 1.6137e-05 | Loss_b: 7.8356e-06\n",
      "Step: NaN | Loss: 7.9271e-07 | Loss_d: 2.3516e-05 Loss_e: 1.6181e-05 | Loss_b: 7.7978e-06\n",
      "Step: NaN | Loss: 7.9247e-07 | Loss_d: 2.3500e-05 Loss_e: 1.6185e-05 | Loss_b: 7.7952e-06\n",
      "Step: NaN | Loss: 7.9164e-07 | Loss_d: 2.3437e-05 Loss_e: 1.6203e-05 | Loss_b: 7.7897e-06\n",
      "Step: NaN | Loss: 7.9048e-07 | Loss_d: 2.3164e-05 Loss_e: 1.6339e-05 | Loss_b: 7.8583e-06\n",
      "Step: NaN | Loss: 7.9031e-07 | Loss_d: 2.3227e-05 Loss_e: 1.6297e-05 | Loss_b: 7.8261e-06\n",
      "Step: NaN | Loss: 7.8844e-07 | Loss_d: 2.3105e-05 Loss_e: 1.6334e-05 | Loss_b: 7.8005e-06\n",
      "Step: NaN | Loss: 7.9110e-07 | Loss_d: 2.2707e-05 Loss_e: 1.6758e-05 | Loss_b: 7.9341e-06\n",
      "Step: NaN | Loss: 7.8752e-07 | Loss_d: 2.2955e-05 Loss_e: 1.6426e-05 | Loss_b: 7.8026e-06\n",
      "Step: NaN | Loss: 7.8726e-07 | Loss_d: 2.2955e-05 Loss_e: 1.6423e-05 | Loss_b: 7.7899e-06\n",
      "Step: NaN | Loss: 7.8700e-07 | Loss_d: 2.2961e-05 Loss_e: 1.6423e-05 | Loss_b: 7.7680e-06\n",
      "Step: NaN | Loss: 7.8695e-07 | Loss_d: 2.2958e-05 Loss_e: 1.6421e-05 | Loss_b: 7.7702e-06\n",
      "Step: NaN | Loss: 7.8629e-07 | Loss_d: 2.2924e-05 Loss_e: 1.6401e-05 | Loss_b: 7.7852e-06\n",
      "Step: NaN | Loss: 7.8775e-07 | Loss_d: 2.2812e-05 Loss_e: 1.6448e-05 | Loss_b: 7.9375e-06\n",
      "Step: NaN | Loss: 7.8606e-07 | Loss_d: 2.2890e-05 Loss_e: 1.6393e-05 | Loss_b: 7.8140e-06\n",
      "Step: NaN | Loss: 7.8493e-07 | Loss_d: 2.2786e-05 Loss_e: 1.6415e-05 | Loss_b: 7.8281e-06\n",
      "Step: NaN | Loss: 7.8627e-07 | Loss_d: 2.2486e-05 Loss_e: 1.6612e-05 | Loss_b: 8.0105e-06\n",
      "Step: NaN | Loss: 7.8431e-07 | Loss_d: 2.2660e-05 Loss_e: 1.6464e-05 | Loss_b: 7.8675e-06\n",
      "Step: NaN | Loss: 7.8595e-07 | Loss_d: 2.2677e-05 Loss_e: 1.6465e-05 | Loss_b: 7.9469e-06\n",
      "Step: NaN | Loss: 7.8367e-07 | Loss_d: 2.2645e-05 Loss_e: 1.6454e-05 | Loss_b: 7.8532e-06\n",
      "Step: NaN | Loss: 7.8298e-07 | Loss_d: 2.2678e-05 Loss_e: 1.6431e-05 | Loss_b: 7.8034e-06\n",
      "Step: NaN | Loss: 7.8492e-07 | Loss_d: 2.2863e-05 Loss_e: 1.6368e-05 | Loss_b: 7.7967e-06\n",
      "Step: NaN | Loss: 7.8277e-07 | Loss_d: 2.2714e-05 Loss_e: 1.6411e-05 | Loss_b: 7.7740e-06\n",
      "Step: NaN | Loss: 7.8157e-07 | Loss_d: 2.2681e-05 Loss_e: 1.6399e-05 | Loss_b: 7.7475e-06\n",
      "Step: NaN | Loss: 7.7917e-07 | Loss_d: 2.2566e-05 Loss_e: 1.6385e-05 | Loss_b: 7.7321e-06\n",
      "Step: NaN | Loss: 8.2371e-07 | Loss_d: 2.2416e-05 Loss_e: 1.7151e-05 | Loss_b: 9.7846e-06\n",
      "Step: NaN | Loss: 7.7914e-07 | Loss_d: 2.2552e-05 Loss_e: 1.6388e-05 | Loss_b: 7.7414e-06\n",
      "Step: NaN | Loss: 7.8099e-07 | Loss_d: 2.2845e-05 Loss_e: 1.6271e-05 | Loss_b: 7.6764e-06\n",
      "Step: NaN | Loss: 7.7851e-07 | Loss_d: 2.2636e-05 Loss_e: 1.6336e-05 | Loss_b: 7.6714e-06\n",
      "Step: NaN | Loss: 7.7798e-07 | Loss_d: 2.2701e-05 Loss_e: 1.6274e-05 | Loss_b: 7.6364e-06\n",
      "Step: NaN | Loss: 7.8019e-07 | Loss_d: 2.3022e-05 Loss_e: 1.6090e-05 | Loss_b: 7.6325e-06\n",
      "Step: NaN | Loss: 7.7787e-07 | Loss_d: 2.2751e-05 Loss_e: 1.6234e-05 | Loss_b: 7.6200e-06\n",
      "Step: NaN | Loss: 7.7831e-07 | Loss_d: 2.2766e-05 Loss_e: 1.6159e-05 | Loss_b: 7.7068e-06\n",
      "Step: NaN | Loss: 7.7737e-07 | Loss_d: 2.2754e-05 Loss_e: 1.6189e-05 | Loss_b: 7.6325e-06\n",
      "Step: NaN | Loss: 7.7704e-07 | Loss_d: 2.2747e-05 Loss_e: 1.6187e-05 | Loss_b: 7.6227e-06\n",
      "Step: NaN | Loss: 7.7789e-07 | Loss_d: 2.2738e-05 Loss_e: 1.6231e-05 | Loss_b: 7.6378e-06\n",
      "Step: NaN | Loss: 7.7691e-07 | Loss_d: 2.2741e-05 Loss_e: 1.6189e-05 | Loss_b: 7.6172e-06\n",
      "Step: NaN | Loss: 7.7643e-07 | Loss_d: 2.2709e-05 Loss_e: 1.6192e-05 | Loss_b: 7.6180e-06\n",
      "Step: NaN | Loss: 7.7547e-07 | Loss_d: 2.2606e-05 Loss_e: 1.6218e-05 | Loss_b: 7.6382e-06\n",
      "Step: NaN | Loss: 7.9488e-07 | Loss_d: 2.2676e-05 Loss_e: 1.6708e-05 | Loss_b: 8.2399e-06\n",
      "Step: NaN | Loss: 7.7546e-07 | Loss_d: 2.2598e-05 Loss_e: 1.6221e-05 | Loss_b: 7.6421e-06\n",
      "Step: NaN | Loss: 7.7479e-07 | Loss_d: 2.2448e-05 Loss_e: 1.6273e-05 | Loss_b: 7.7007e-06\n",
      "Step: NaN | Loss: 7.7463e-07 | Loss_d: 2.2489e-05 Loss_e: 1.6252e-05 | Loss_b: 7.6700e-06\n",
      "Step: NaN | Loss: 7.7398e-07 | Loss_d: 2.2511e-05 Loss_e: 1.6259e-05 | Loss_b: 7.6031e-06\n",
      "Step: NaN | Loss: 7.7423e-07 | Loss_d: 2.2631e-05 Loss_e: 1.6317e-05 | Loss_b: 7.4391e-06\n",
      "Step: NaN | Loss: 7.7352e-07 | Loss_d: 2.2557e-05 Loss_e: 1.6279e-05 | Loss_b: 7.5097e-06\n",
      "Step: NaN | Loss: 7.7307e-07 | Loss_d: 2.2528e-05 Loss_e: 1.6287e-05 | Loss_b: 7.5023e-06\n",
      "Step: NaN | Loss: 7.7171e-07 | Loss_d: 2.2421e-05 Loss_e: 1.6328e-05 | Loss_b: 7.4881e-06\n",
      "Step: NaN | Loss: 7.7806e-07 | Loss_d: 2.2071e-05 Loss_e: 1.6671e-05 | Loss_b: 7.8751e-06\n",
      "Step: NaN | Loss: 7.7115e-07 | Loss_d: 2.2324e-05 Loss_e: 1.6378e-05 | Loss_b: 7.5009e-06\n",
      "Step: NaN | Loss: 7.7159e-07 | Loss_d: 2.2202e-05 Loss_e: 1.6403e-05 | Loss_b: 7.6243e-06\n",
      "Step: NaN | Loss: 7.7066e-07 | Loss_d: 2.2262e-05 Loss_e: 1.6379e-05 | Loss_b: 7.5323e-06\n",
      "Step: NaN | Loss: 7.7023e-07 | Loss_d: 2.2254e-05 Loss_e: 1.6362e-05 | Loss_b: 7.5314e-06\n",
      "Step: NaN | Loss: 7.7295e-07 | Loss_d: 2.2247e-05 Loss_e: 1.6320e-05 | Loss_b: 7.7436e-06\n",
      "Step: NaN | Loss: 7.7019e-07 | Loss_d: 2.2252e-05 Loss_e: 1.6355e-05 | Loss_b: 7.5389e-06\n",
      "Step: NaN | Loss: 7.6993e-07 | Loss_d: 2.2245e-05 Loss_e: 1.6361e-05 | Loss_b: 7.5244e-06\n",
      "Step: NaN | Loss: 7.6919e-07 | Loss_d: 2.2222e-05 Loss_e: 1.6389e-05 | Loss_b: 7.4744e-06\n",
      "Step: NaN | Loss: 7.7198e-07 | Loss_d: 2.2203e-05 Loss_e: 1.6613e-05 | Loss_b: 7.4374e-06\n",
      "Step: NaN | Loss: 7.6890e-07 | Loss_d: 2.2203e-05 Loss_e: 1.6431e-05 | Loss_b: 7.4343e-06\n",
      "Step: NaN | Loss: 7.6843e-07 | Loss_d: 2.2116e-05 Loss_e: 1.6409e-05 | Loss_b: 7.5156e-06\n",
      "Step: NaN | Loss: 7.6823e-07 | Loss_d: 2.2144e-05 Loss_e: 1.6413e-05 | Loss_b: 7.4705e-06\n",
      "Step: NaN | Loss: 7.6796e-07 | Loss_d: 2.2209e-05 Loss_e: 1.6350e-05 | Loss_b: 7.4525e-06\n",
      "Step: NaN | Loss: 7.6975e-07 | Loss_d: 2.2516e-05 Loss_e: 1.6160e-05 | Loss_b: 7.4427e-06\n",
      "Step: NaN | Loss: 7.6795e-07 | Loss_d: 2.2237e-05 Loss_e: 1.6326e-05 | Loss_b: 7.4478e-06\n",
      "Step: NaN | Loss: 7.6814e-07 | Loss_d: 2.2151e-05 Loss_e: 1.6368e-05 | Loss_b: 7.5043e-06\n",
      "Step: NaN | Loss: 7.6786e-07 | Loss_d: 2.2205e-05 Loss_e: 1.6340e-05 | Loss_b: 7.4612e-06\n",
      "Step: NaN | Loss: 7.6773e-07 | Loss_d: 2.2197e-05 Loss_e: 1.6342e-05 | Loss_b: 7.4598e-06\n",
      "Step: NaN | Loss: 7.6756e-07 | Loss_d: 2.2167e-05 Loss_e: 1.6352e-05 | Loss_b: 7.4687e-06\n",
      "Step: NaN | Loss: 7.6754e-07 | Loss_d: 2.2171e-05 Loss_e: 1.6350e-05 | Loss_b: 7.4652e-06\n",
      "Step: NaN | Loss: 7.6727e-07 | Loss_d: 2.2187e-05 Loss_e: 1.6325e-05 | Loss_b: 7.4584e-06\n",
      "Step: NaN | Loss: 7.6713e-07 | Loss_d: 2.2270e-05 Loss_e: 1.6236e-05 | Loss_b: 7.4556e-06\n",
      "Step: NaN | Loss: 7.6700e-07 | Loss_d: 2.2233e-05 Loss_e: 1.6270e-05 | Loss_b: 7.4516e-06\n",
      "Step: NaN | Loss: 7.6686e-07 | Loss_d: 2.2228e-05 Loss_e: 1.6261e-05 | Loss_b: 7.4569e-06\n",
      "Step: NaN | Loss: 7.6658e-07 | Loss_d: 2.2228e-05 Loss_e: 1.6260e-05 | Loss_b: 7.4410e-06\n",
      "Step: NaN | Loss: 7.6628e-07 | Loss_d: 2.2190e-05 Loss_e: 1.6266e-05 | Loss_b: 7.4558e-06\n",
      "Step: NaN | Loss: 7.6641e-07 | Loss_d: 2.2049e-05 Loss_e: 1.6301e-05 | Loss_b: 7.5690e-06\n",
      "Step: NaN | Loss: 7.6609e-07 | Loss_d: 2.2126e-05 Loss_e: 1.6278e-05 | Loss_b: 7.4958e-06\n",
      "Step: NaN | Loss: 7.6578e-07 | Loss_d: 2.2120e-05 Loss_e: 1.6278e-05 | Loss_b: 7.4836e-06\n",
      "Step: NaN | Loss: 7.6539e-07 | Loss_d: 2.2104e-05 Loss_e: 1.6293e-05 | Loss_b: 7.4600e-06\n",
      "Step: NaN | Loss: 7.6536e-07 | Loss_d: 2.2106e-05 Loss_e: 1.6288e-05 | Loss_b: 7.4613e-06\n",
      "Step: NaN | Loss: 7.6497e-07 | Loss_d: 2.2054e-05 Loss_e: 1.6288e-05 | Loss_b: 7.4903e-06\n",
      "Step: NaN | Loss: 7.6731e-07 | Loss_d: 2.1911e-05 Loss_e: 1.6335e-05 | Loss_b: 7.7263e-06\n",
      "Step: NaN | Loss: 7.6494e-07 | Loss_d: 2.2031e-05 Loss_e: 1.6290e-05 | Loss_b: 7.5097e-06\n",
      "Step: NaN | Loss: 7.6484e-07 | Loss_d: 2.2027e-05 Loss_e: 1.6279e-05 | Loss_b: 7.5190e-06\n",
      "Step: NaN | Loss: 7.6480e-07 | Loss_d: 2.2027e-05 Loss_e: 1.6282e-05 | Loss_b: 7.5134e-06\n",
      "Step: NaN | Loss: 7.6469e-07 | Loss_d: 2.2018e-05 Loss_e: 1.6287e-05 | Loss_b: 7.5102e-06\n",
      "Step: NaN | Loss: 7.6439e-07 | Loss_d: 2.1984e-05 Loss_e: 1.6311e-05 | Loss_b: 7.5031e-06\n",
      "Step: NaN | Loss: 7.6654e-07 | Loss_d: 2.1843e-05 Loss_e: 1.6489e-05 | Loss_b: 7.5947e-06\n",
      "Step: NaN | Loss: 7.6434e-07 | Loss_d: 2.1961e-05 Loss_e: 1.6330e-05 | Loss_b: 7.5036e-06\n",
      "Step: NaN | Loss: 7.6400e-07 | Loss_d: 2.1963e-05 Loss_e: 1.6322e-05 | Loss_b: 7.4892e-06\n",
      "Step: NaN | Loss: 7.6319e-07 | Loss_d: 2.1977e-05 Loss_e: 1.6305e-05 | Loss_b: 7.4442e-06\n",
      "Step: NaN | Loss: 7.7218e-07 | Loss_d: 2.2184e-05 Loss_e: 1.6537e-05 | Loss_b: 7.5442e-06\n",
      "Step: NaN | Loss: 7.6310e-07 | Loss_d: 2.1986e-05 Loss_e: 1.6304e-05 | Loss_b: 7.4310e-06\n",
      "Step: NaN | Loss: 7.6263e-07 | Loss_d: 2.1868e-05 Loss_e: 1.6347e-05 | Loss_b: 7.4780e-06\n",
      "Step: NaN | Loss: 7.6693e-07 | Loss_d: 2.1453e-05 Loss_e: 1.6581e-05 | Loss_b: 7.9161e-06\n",
      "Step: NaN | Loss: 7.6259e-07 | Loss_d: 2.1837e-05 Loss_e: 1.6360e-05 | Loss_b: 7.4939e-06\n",
      "Step: NaN | Loss: 7.6229e-07 | Loss_d: 2.1820e-05 Loss_e: 1.6376e-05 | Loss_b: 7.4766e-06\n",
      "Step: NaN | Loss: 7.6687e-07 | Loss_d: 2.1769e-05 Loss_e: 1.6498e-05 | Loss_b: 7.6790e-06\n",
      "Step: NaN | Loss: 7.6229e-07 | Loss_d: 2.1819e-05 Loss_e: 1.6376e-05 | Loss_b: 7.4765e-06\n",
      "Step: NaN | Loss: 7.6200e-07 | Loss_d: 2.1784e-05 Loss_e: 1.6396e-05 | Loss_b: 7.4747e-06\n",
      "Step: NaN | Loss: 7.6195e-07 | Loss_d: 2.1660e-05 Loss_e: 1.6485e-05 | Loss_b: 7.5066e-06\n",
      "Step: NaN | Loss: 7.6176e-07 | Loss_d: 2.1715e-05 Loss_e: 1.6441e-05 | Loss_b: 7.4843e-06\n",
      "Step: NaN | Loss: 7.6142e-07 | Loss_d: 2.1704e-05 Loss_e: 1.6449e-05 | Loss_b: 7.4677e-06\n",
      "Step: NaN | Loss: 7.6079e-07 | Loss_d: 2.1663e-05 Loss_e: 1.6495e-05 | Loss_b: 7.4242e-06\n",
      "Step: NaN | Loss: 7.7435e-07 | Loss_d: 2.1558e-05 Loss_e: 1.7087e-05 | Loss_b: 7.7496e-06\n",
      "Step: NaN | Loss: 7.6079e-07 | Loss_d: 2.1660e-05 Loss_e: 1.6499e-05 | Loss_b: 7.4222e-06\n",
      "Step: NaN | Loss: 7.5924e-07 | Loss_d: 2.1601e-05 Loss_e: 1.6463e-05 | Loss_b: 7.4250e-06\n",
      "Step: NaN | Loss: 7.5752e-07 | Loss_d: 2.1423e-05 Loss_e: 1.6462e-05 | Loss_b: 7.5005e-06\n",
      "Step: NaN | Loss: 7.5731e-07 | Loss_d: 2.1460e-05 Loss_e: 1.6440e-05 | Loss_b: 7.4729e-06\n",
      "Step: NaN | Loss: 7.6087e-07 | Loss_d: 2.1338e-05 Loss_e: 1.6601e-05 | Loss_b: 7.6483e-06\n",
      "Step: NaN | Loss: 7.5659e-07 | Loss_d: 2.1404e-05 Loss_e: 1.6466e-05 | Loss_b: 7.4601e-06\n",
      "Step: NaN | Loss: 7.5639e-07 | Loss_d: 2.1369e-05 Loss_e: 1.6487e-05 | Loss_b: 7.4625e-06\n",
      "Step: NaN | Loss: 7.5697e-07 | Loss_d: 2.1260e-05 Loss_e: 1.6589e-05 | Loss_b: 7.5048e-06\n",
      "Step: NaN | Loss: 7.5635e-07 | Loss_d: 2.1340e-05 Loss_e: 1.6507e-05 | Loss_b: 7.4690e-06\n",
      "Step: NaN | Loss: 7.5605e-07 | Loss_d: 2.1333e-05 Loss_e: 1.6510e-05 | Loss_b: 7.4559e-06\n",
      "Step: NaN | Loss: 7.5510e-07 | Loss_d: 2.1307e-05 Loss_e: 1.6524e-05 | Loss_b: 7.4104e-06\n",
      "Step: NaN | Loss: 7.5664e-07 | Loss_d: 2.1221e-05 Loss_e: 1.6726e-05 | Loss_b: 7.3866e-06\n",
      "Step: NaN | Loss: 7.5447e-07 | Loss_d: 2.1268e-05 Loss_e: 1.6571e-05 | Loss_b: 7.3644e-06\n",
      "Step: NaN | Loss: 7.5324e-07 | Loss_d: 2.1104e-05 Loss_e: 1.6626e-05 | Loss_b: 7.4002e-06\n",
      "Step: NaN | Loss: 7.5998e-07 | Loss_d: 2.0676e-05 Loss_e: 1.7021e-05 | Loss_b: 7.8366e-06\n",
      "Step: NaN | Loss: 7.5308e-07 | Loss_d: 2.1024e-05 Loss_e: 1.6663e-05 | Loss_b: 7.4325e-06\n",
      "Step: NaN | Loss: 7.5127e-07 | Loss_d: 2.0929e-05 Loss_e: 1.6716e-05 | Loss_b: 7.3664e-06\n",
      "Step: NaN | Loss: 7.6386e-07 | Loss_d: 2.0794e-05 Loss_e: 1.7145e-05 | Loss_b: 7.8268e-06\n",
      "Step: NaN | Loss: 7.5111e-07 | Loss_d: 2.0897e-05 Loss_e: 1.6744e-05 | Loss_b: 7.3607e-06\n",
      "Step: NaN | Loss: 7.5009e-07 | Loss_d: 2.0927e-05 Loss_e: 1.6729e-05 | Loss_b: 7.2846e-06\n",
      "Step: NaN | Loss: 7.5224e-07 | Loss_d: 2.1107e-05 Loss_e: 1.6784e-05 | Loss_b: 7.1792e-06\n",
      "Step: NaN | Loss: 7.4968e-07 | Loss_d: 2.0969e-05 Loss_e: 1.6726e-05 | Loss_b: 7.2219e-06\n",
      "Step: NaN | Loss: 7.4895e-07 | Loss_d: 2.0909e-05 Loss_e: 1.6771e-05 | Loss_b: 7.1920e-06\n",
      "Step: NaN | Loss: 7.5071e-07 | Loss_d: 2.0737e-05 Loss_e: 1.6996e-05 | Loss_b: 7.2454e-06\n",
      "Step: NaN | Loss: 7.4865e-07 | Loss_d: 2.0854e-05 Loss_e: 1.6824e-05 | Loss_b: 7.1777e-06\n",
      "Step: NaN | Loss: 7.4918e-07 | Loss_d: 2.0842e-05 Loss_e: 1.6807e-05 | Loss_b: 7.2371e-06\n",
      "Step: NaN | Loss: 7.4822e-07 | Loss_d: 2.0844e-05 Loss_e: 1.6808e-05 | Loss_b: 7.1764e-06\n",
      "Step: NaN | Loss: 7.4786e-07 | Loss_d: 2.0855e-05 Loss_e: 1.6793e-05 | Loss_b: 7.1595e-06\n",
      "Step: NaN | Loss: 7.4879e-07 | Loss_d: 2.0917e-05 Loss_e: 1.6757e-05 | Loss_b: 7.1895e-06\n",
      "Step: NaN | Loss: 7.4775e-07 | Loss_d: 2.0868e-05 Loss_e: 1.6780e-05 | Loss_b: 7.1530e-06\n",
      "Step: NaN | Loss: 7.4758e-07 | Loss_d: 2.0832e-05 Loss_e: 1.6805e-05 | Loss_b: 7.1541e-06\n",
      "Step: NaN | Loss: 7.4745e-07 | Loss_d: 2.0701e-05 Loss_e: 1.6911e-05 | Loss_b: 7.1711e-06\n",
      "Step: NaN | Loss: 7.4738e-07 | Loss_d: 2.0747e-05 Loss_e: 1.6870e-05 | Loss_b: 7.1618e-06\n",
      "Step: NaN | Loss: 7.4661e-07 | Loss_d: 2.0676e-05 Loss_e: 1.6893e-05 | Loss_b: 7.1637e-06\n",
      "Step: NaN | Loss: 7.4726e-07 | Loss_d: 2.0449e-05 Loss_e: 1.7029e-05 | Loss_b: 7.2932e-06\n",
      "Step: NaN | Loss: 7.4616e-07 | Loss_d: 2.0576e-05 Loss_e: 1.6938e-05 | Loss_b: 7.1913e-06\n",
      "Step: NaN | Loss: 7.4480e-07 | Loss_d: 2.0489e-05 Loss_e: 1.6912e-05 | Loss_b: 7.2233e-06\n",
      "Step: NaN | Loss: 7.4414e-07 | Loss_d: 2.0202e-05 Loss_e: 1.6902e-05 | Loss_b: 7.4800e-06\n",
      "Step: NaN | Loss: 7.4349e-07 | Loss_d: 2.0309e-05 Loss_e: 1.6887e-05 | Loss_b: 7.3496e-06\n",
      "Step: NaN | Loss: 7.4662e-07 | Loss_d: 2.0344e-05 Loss_e: 1.6786e-05 | Loss_b: 7.6033e-06\n",
      "Step: NaN | Loss: 7.4228e-07 | Loss_d: 2.0309e-05 Loss_e: 1.6812e-05 | Loss_b: 7.3523e-06\n",
      "Step: NaN | Loss: 7.4197e-07 | Loss_d: 2.0322e-05 Loss_e: 1.6792e-05 | Loss_b: 7.3403e-06\n",
      "Step: NaN | Loss: 7.4219e-07 | Loss_d: 2.0398e-05 Loss_e: 1.6724e-05 | Loss_b: 7.3462e-06\n",
      "Step: NaN | Loss: 7.4176e-07 | Loss_d: 2.0347e-05 Loss_e: 1.6763e-05 | Loss_b: 7.3316e-06\n",
      "Step: NaN | Loss: 7.4133e-07 | Loss_d: 2.0326e-05 Loss_e: 1.6767e-05 | Loss_b: 7.3234e-06\n",
      "Step: NaN | Loss: 7.4064e-07 | Loss_d: 2.0248e-05 Loss_e: 1.6791e-05 | Loss_b: 7.3360e-06\n",
      "Step: NaN | Loss: 7.4062e-07 | Loss_d: 2.0252e-05 Loss_e: 1.6789e-05 | Loss_b: 7.3325e-06\n",
      "Step: NaN | Loss: 7.4095e-07 | Loss_d: 2.0182e-05 Loss_e: 1.6811e-05 | Loss_b: 7.3997e-06\n",
      "Step: NaN | Loss: 7.4042e-07 | Loss_d: 2.0223e-05 Loss_e: 1.6796e-05 | Loss_b: 7.3429e-06\n",
      "Step: NaN | Loss: 7.4011e-07 | Loss_d: 2.0173e-05 Loss_e: 1.6832e-05 | Loss_b: 7.3386e-06\n",
      "Step: NaN | Loss: 7.3964e-07 | Loss_d: 1.9985e-05 Loss_e: 1.6992e-05 | Loss_b: 7.3379e-06\n",
      "Step: NaN | Loss: 7.3964e-07 | Loss_d: 2.0005e-05 Loss_e: 1.6973e-05 | Loss_b: 7.3373e-06\n",
      "Step: NaN | Loss: 7.3813e-07 | Loss_d: 1.9951e-05 Loss_e: 1.6915e-05 | Loss_b: 7.3585e-06\n",
      "Step: NaN | Loss: 7.4887e-07 | Loss_d: 1.9979e-05 Loss_e: 1.6937e-05 | Loss_b: 7.9527e-06\n",
      "Step: NaN | Loss: 7.3803e-07 | Loss_d: 1.9936e-05 Loss_e: 1.6900e-05 | Loss_b: 7.3824e-06\n",
      "Step: NaN | Loss: 7.3805e-07 | Loss_d: 1.9797e-05 Loss_e: 1.6958e-05 | Loss_b: 7.4646e-06\n",
      "Step: NaN | Loss: 7.3739e-07 | Loss_d: 1.9862e-05 Loss_e: 1.6916e-05 | Loss_b: 7.4018e-06\n",
      "Step: NaN | Loss: 7.3684e-07 | Loss_d: 1.9825e-05 Loss_e: 1.6909e-05 | Loss_b: 7.4134e-06\n",
      "Step: NaN | Loss: 7.3683e-07 | Loss_d: 1.9827e-05 Loss_e: 1.6909e-05 | Loss_b: 7.4105e-06\n",
      "Step: NaN | Loss: 7.3666e-07 | Loss_d: 1.9831e-05 Loss_e: 1.6903e-05 | Loss_b: 7.4022e-06\n",
      "Step: NaN | Loss: 7.3612e-07 | Loss_d: 1.9848e-05 Loss_e: 1.6879e-05 | Loss_b: 7.3765e-06\n",
      "Step: NaN | Loss: 7.3649e-07 | Loss_d: 1.9967e-05 Loss_e: 1.6785e-05 | Loss_b: 7.3744e-06\n",
      "Step: NaN | Loss: 7.3562e-07 | Loss_d: 1.9892e-05 Loss_e: 1.6834e-05 | Loss_b: 7.3482e-06\n",
      "Step: NaN | Loss: 7.3473e-07 | Loss_d: 1.9761e-05 Loss_e: 1.6909e-05 | Loss_b: 7.3508e-06\n",
      "Step: NaN | Loss: 7.3509e-07 | Loss_d: 1.9310e-05 Loss_e: 1.7265e-05 | Loss_b: 7.4672e-06\n",
      "Step: NaN | Loss: 7.3412e-07 | Loss_d: 1.9546e-05 Loss_e: 1.7056e-05 | Loss_b: 7.3822e-06\n",
      "Step: NaN | Loss: 7.3363e-07 | Loss_d: 1.9536e-05 Loss_e: 1.7060e-05 | Loss_b: 7.3596e-06\n",
      "Step: NaN | Loss: 7.3720e-07 | Loss_d: 1.9628e-05 Loss_e: 1.7148e-05 | Loss_b: 7.3931e-06\n",
      "Step: NaN | Loss: 7.3360e-07 | Loss_d: 1.9535e-05 Loss_e: 1.7063e-05 | Loss_b: 7.3550e-06\n",
      "Step: NaN | Loss: 7.3344e-07 | Loss_d: 1.9493e-05 Loss_e: 1.7091e-05 | Loss_b: 7.3595e-06\n",
      "Step: NaN | Loss: 7.3342e-07 | Loss_d: 1.9497e-05 Loss_e: 1.7088e-05 | Loss_b: 7.3573e-06\n",
      "Step: NaN | Loss: 7.3323e-07 | Loss_d: 1.9496e-05 Loss_e: 1.7091e-05 | Loss_b: 7.3435e-06\n",
      "Step: NaN | Loss: 7.3296e-07 | Loss_d: 1.9497e-05 Loss_e: 1.7109e-05 | Loss_b: 7.3093e-06\n",
      "Step: NaN | Loss: 7.3295e-07 | Loss_d: 1.9497e-05 Loss_e: 1.7105e-05 | Loss_b: 7.3119e-06\n",
      "Step: NaN | Loss: 7.3278e-07 | Loss_d: 1.9470e-05 Loss_e: 1.7141e-05 | Loss_b: 7.2937e-06\n",
      "Step: NaN | Loss: 7.3379e-07 | Loss_d: 1.9378e-05 Loss_e: 1.7306e-05 | Loss_b: 7.2804e-06\n",
      "Step: NaN | Loss: 7.3276e-07 | Loss_d: 1.9457e-05 Loss_e: 1.7159e-05 | Loss_b: 7.2870e-06\n",
      "Step: NaN | Loss: 7.3263e-07 | Loss_d: 1.9463e-05 Loss_e: 1.7148e-05 | Loss_b: 7.2832e-06\n",
      "Step: NaN | Loss: 7.3256e-07 | Loss_d: 1.9492e-05 Loss_e: 1.7111e-05 | Loss_b: 7.2878e-06\n",
      "Step: NaN | Loss: 7.3249e-07 | Loss_d: 1.9479e-05 Loss_e: 1.7126e-05 | Loss_b: 7.2816e-06\n",
      "Step: NaN | Loss: 7.3216e-07 | Loss_d: 1.9480e-05 Loss_e: 1.7104e-05 | Loss_b: 7.2826e-06\n",
      "Step: NaN | Loss: 7.3313e-07 | Loss_d: 1.9503e-05 Loss_e: 1.7045e-05 | Loss_b: 7.3768e-06\n",
      "Step: NaN | Loss: 7.3206e-07 | Loss_d: 1.9483e-05 Loss_e: 1.7086e-05 | Loss_b: 7.2918e-06\n",
      "Step: NaN | Loss: 7.3190e-07 | Loss_d: 1.9447e-05 Loss_e: 1.7100e-05 | Loss_b: 7.3043e-06\n",
      "Step: NaN | Loss: 7.3183e-07 | Loss_d: 1.9309e-05 Loss_e: 1.7166e-05 | Loss_b: 7.3714e-06\n",
      "Step: NaN | Loss: 7.3176e-07 | Loss_d: 1.9363e-05 Loss_e: 1.7138e-05 | Loss_b: 7.3420e-06\n",
      "Step: NaN | Loss: 7.3155e-07 | Loss_d: 1.9361e-05 Loss_e: 1.7116e-05 | Loss_b: 7.3524e-06\n",
      "Step: NaN | Loss: 7.3459e-07 | Loss_d: 1.9393e-05 Loss_e: 1.7108e-05 | Loss_b: 7.5111e-06\n",
      "Step: NaN | Loss: 7.3156e-07 | Loss_d: 1.9362e-05 Loss_e: 1.7116e-05 | Loss_b: 7.3534e-06\n",
      "Step: NaN | Loss: 7.3146e-07 | Loss_d: 1.9392e-05 Loss_e: 1.7086e-05 | Loss_b: 7.3477e-06\n",
      "Step: NaN | Loss: 7.3184e-07 | Loss_d: 1.9523e-05 Loss_e: 1.6973e-05 | Loss_b: 7.3520e-06\n",
      "Step: NaN | Loss: 7.3144e-07 | Loss_d: 1.9414e-05 Loss_e: 1.7065e-05 | Loss_b: 7.3452e-06\n",
      "Step: NaN | Loss: 7.3136e-07 | Loss_d: 1.9406e-05 Loss_e: 1.7057e-05 | Loss_b: 7.3563e-06\n",
      "Step: NaN | Loss: 7.3188e-07 | Loss_d: 1.9380e-05 Loss_e: 1.7029e-05 | Loss_b: 7.4406e-06\n",
      "Step: NaN | Loss: 7.3136e-07 | Loss_d: 1.9402e-05 Loss_e: 1.7053e-05 | Loss_b: 7.3633e-06\n",
      "Step: NaN | Loss: 7.3126e-07 | Loss_d: 1.9404e-05 Loss_e: 1.7047e-05 | Loss_b: 7.3626e-06\n",
      "Step: NaN | Loss: 7.3095e-07 | Loss_d: 1.9410e-05 Loss_e: 1.7021e-05 | Loss_b: 7.3634e-06\n",
      "Step: NaN | Loss: 7.3084e-07 | Loss_d: 1.9462e-05 Loss_e: 1.6918e-05 | Loss_b: 7.4080e-06\n",
      "Step: NaN | Loss: 7.3060e-07 | Loss_d: 1.9434e-05 Loss_e: 1.6960e-05 | Loss_b: 7.3798e-06\n",
      "Step: NaN | Loss: 7.2980e-07 | Loss_d: 1.9349e-05 Loss_e: 1.7017e-05 | Loss_b: 7.3593e-06\n",
      "Step: NaN | Loss: 7.2980e-07 | Loss_d: 1.9069e-05 Loss_e: 1.7313e-05 | Loss_b: 7.3438e-06\n",
      "Step: NaN | Loss: 7.2914e-07 | Loss_d: 1.9203e-05 Loss_e: 1.7144e-05 | Loss_b: 7.3383e-06\n",
      "Step: NaN | Loss: 7.2799e-07 | Loss_d: 1.9137e-05 Loss_e: 1.7217e-05 | Loss_b: 7.2627e-06\n",
      "Step: NaN | Loss: 7.2792e-07 | Loss_d: 1.9145e-05 Loss_e: 1.7196e-05 | Loss_b: 7.2713e-06\n",
      "Step: NaN | Loss: 7.3017e-07 | Loss_d: 1.9335e-05 Loss_e: 1.7111e-05 | Loss_b: 7.3017e-06\n",
      "Step: NaN | Loss: 7.2782e-07 | Loss_d: 1.9176e-05 Loss_e: 1.7176e-05 | Loss_b: 7.2545e-06\n",
      "Step: NaN | Loss: 7.2772e-07 | Loss_d: 1.9183e-05 Loss_e: 1.7167e-05 | Loss_b: 7.2503e-06\n",
      "Step: NaN | Loss: 7.2762e-07 | Loss_d: 1.9214e-05 Loss_e: 1.7139e-05 | Loss_b: 7.2421e-06\n",
      "Step: NaN | Loss: 7.2761e-07 | Loss_d: 1.9205e-05 Loss_e: 1.7145e-05 | Loss_b: 7.2434e-06\n",
      "Step: NaN | Loss: 7.2711e-07 | Loss_d: 1.9187e-05 Loss_e: 1.7149e-05 | Loss_b: 7.2282e-06\n",
      "Step: NaN | Loss: 7.2695e-07 | Loss_d: 1.9139e-05 Loss_e: 1.7188e-05 | Loss_b: 7.2276e-06\n",
      "Step: NaN | Loss: 7.2665e-07 | Loss_d: 1.9155e-05 Loss_e: 1.7166e-05 | Loss_b: 7.2159e-06\n",
      "Step: NaN | Loss: 7.2622e-07 | Loss_d: 1.9109e-05 Loss_e: 1.7202e-05 | Loss_b: 7.1993e-06\n",
      "Step: NaN | Loss: 7.2614e-07 | Loss_d: 1.9121e-05 Loss_e: 1.7191e-05 | Loss_b: 7.1934e-06\n",
      "Step: NaN | Loss: 7.2577e-07 | Loss_d: 1.9165e-05 Loss_e: 1.7131e-05 | Loss_b: 7.1881e-06\n",
      "Step: NaN | Loss: 7.2616e-07 | Loss_d: 1.9368e-05 Loss_e: 1.6921e-05 | Loss_b: 7.2183e-06\n",
      "Step: NaN | Loss: 7.2556e-07 | Loss_d: 1.9236e-05 Loss_e: 1.7045e-05 | Loss_b: 7.1895e-06\n",
      "Step: NaN | Loss: 7.2531e-07 | Loss_d: 1.9151e-05 Loss_e: 1.7121e-05 | Loss_b: 7.1842e-06\n",
      "Step: NaN | Loss: 7.2501e-07 | Loss_d: 1.9183e-05 Loss_e: 1.7085e-05 | Loss_b: 7.1706e-06\n",
      "Step: NaN | Loss: 7.2468e-07 | Loss_d: 1.9159e-05 Loss_e: 1.7103e-05 | Loss_b: 7.1569e-06\n",
      "Step: NaN | Loss: 7.2572e-07 | Loss_d: 1.9087e-05 Loss_e: 1.7210e-05 | Loss_b: 7.1839e-06\n",
      "Step: NaN | Loss: 7.2457e-07 | Loss_d: 1.9139e-05 Loss_e: 1.7122e-05 | Loss_b: 7.1507e-06\n",
      "Step: NaN | Loss: 7.2425e-07 | Loss_d: 1.9111e-05 Loss_e: 1.7119e-05 | Loss_b: 7.1618e-06\n",
      "Step: NaN | Loss: 7.2403e-07 | Loss_d: 1.9022e-05 Loss_e: 1.7114e-05 | Loss_b: 7.2435e-06\n",
      "Step: NaN | Loss: 7.2389e-07 | Loss_d: 1.9052e-05 Loss_e: 1.7115e-05 | Loss_b: 7.2043e-06\n",
      "Step: NaN | Loss: 7.2338e-07 | Loss_d: 1.9053e-05 Loss_e: 1.7083e-05 | Loss_b: 7.2043e-06\n",
      "Step: NaN | Loss: 7.2306e-07 | Loss_d: 1.9074e-05 Loss_e: 1.6997e-05 | Loss_b: 7.2504e-06\n",
      "Step: NaN | Loss: 7.2286e-07 | Loss_d: 1.9063e-05 Loss_e: 1.7022e-05 | Loss_b: 7.2236e-06\n",
      "Step: NaN | Loss: 7.2202e-07 | Loss_d: 1.9008e-05 Loss_e: 1.7053e-05 | Loss_b: 7.1978e-06\n",
      "Step: NaN | Loss: 7.2344e-07 | Loss_d: 1.8855e-05 Loss_e: 1.7249e-05 | Loss_b: 7.2410e-06\n",
      "Step: NaN | Loss: 7.2164e-07 | Loss_d: 1.8948e-05 Loss_e: 1.7103e-05 | Loss_b: 7.1860e-06\n",
      "Step: NaN | Loss: 7.2104e-07 | Loss_d: 1.9041e-05 Loss_e: 1.7027e-05 | Loss_b: 7.1325e-06\n",
      "Step: NaN | Loss: 7.2099e-07 | Loss_d: 1.9020e-05 Loss_e: 1.7041e-05 | Loss_b: 7.1366e-06\n",
      "Step: NaN | Loss: 7.2074e-07 | Loss_d: 1.9071e-05 Loss_e: 1.6984e-05 | Loss_b: 7.1272e-06\n",
      "Step: NaN | Loss: 7.2416e-07 | Loss_d: 1.9299e-05 Loss_e: 1.6807e-05 | Loss_b: 7.2817e-06\n",
      "Step: NaN | Loss: 7.2072e-07 | Loss_d: 1.9076e-05 Loss_e: 1.6979e-05 | Loss_b: 7.1265e-06\n",
      "Step: NaN | Loss: 7.2034e-07 | Loss_d: 1.9070e-05 Loss_e: 1.6969e-05 | Loss_b: 7.1195e-06\n",
      "Step: NaN | Loss: 7.1896e-07 | Loss_d: 1.9049e-05 Loss_e: 1.6931e-05 | Loss_b: 7.0958e-06\n",
      "Step: NaN | Loss: 7.1831e-07 | Loss_d: 1.9003e-05 Loss_e: 1.6828e-05 | Loss_b: 7.2063e-06\n",
      "Step: NaN | Loss: 7.1733e-07 | Loss_d: 1.9011e-05 Loss_e: 1.6855e-05 | Loss_b: 7.1120e-06\n",
      "Step: NaN | Loss: 7.1507e-07 | Loss_d: 1.8928e-05 Loss_e: 1.6842e-05 | Loss_b: 7.0729e-06\n",
      "Step: NaN | Loss: 7.1951e-07 | Loss_d: 1.8757e-05 Loss_e: 1.7017e-05 | Loss_b: 7.3351e-06\n",
      "Step: NaN | Loss: 7.1411e-07 | Loss_d: 1.8852e-05 Loss_e: 1.6855e-05 | Loss_b: 7.0785e-06\n",
      "Step: NaN | Loss: 7.1362e-07 | Loss_d: 1.8891e-05 Loss_e: 1.6804e-05 | Loss_b: 7.0608e-06\n",
      "Step: NaN | Loss: 7.1363e-07 | Loss_d: 1.8891e-05 Loss_e: 1.6804e-05 | Loss_b: 7.0613e-06\n",
      "Step: NaN | Loss: 7.1303e-07 | Loss_d: 1.8892e-05 Loss_e: 1.6791e-05 | Loss_b: 7.0374e-06\n",
      "Step: NaN | Loss: 7.1376e-07 | Loss_d: 1.8916e-05 Loss_e: 1.6809e-05 | Loss_b: 7.0400e-06\n",
      "Step: NaN | Loss: 7.1270e-07 | Loss_d: 1.8897e-05 Loss_e: 1.6785e-05 | Loss_b: 7.0195e-06\n",
      "Step: NaN | Loss: 7.1216e-07 | Loss_d: 1.8937e-05 Loss_e: 1.6688e-05 | Loss_b: 7.0433e-06\n",
      "Step: NaN | Loss: 7.1745e-07 | Loss_d: 1.9149e-05 Loss_e: 1.6467e-05 | Loss_b: 7.3698e-06\n",
      "Step: NaN | Loss: 7.1214e-07 | Loss_d: 1.8947e-05 Loss_e: 1.6668e-05 | Loss_b: 7.0526e-06\n",
      "Step: NaN | Loss: 7.1175e-07 | Loss_d: 1.8950e-05 Loss_e: 1.6670e-05 | Loss_b: 7.0245e-06\n",
      "Step: NaN | Loss: 7.1387e-07 | Loss_d: 1.8987e-05 Loss_e: 1.6710e-05 | Loss_b: 7.0737e-06\n",
      "Step: NaN | Loss: 7.1170e-07 | Loss_d: 1.8953e-05 Loss_e: 1.6672e-05 | Loss_b: 7.0163e-06\n",
      "Step: NaN | Loss: 7.1147e-07 | Loss_d: 1.8962e-05 Loss_e: 1.6664e-05 | Loss_b: 7.0019e-06\n",
      "Step: NaN | Loss: 7.1105e-07 | Loss_d: 1.9002e-05 Loss_e: 1.6635e-05 | Loss_b: 6.9652e-06\n",
      "Step: NaN | Loss: 7.1105e-07 | Loss_d: 1.9000e-05 Loss_e: 1.6636e-05 | Loss_b: 6.9656e-06\n",
      "Step: NaN | Loss: 7.1005e-07 | Loss_d: 1.8969e-05 Loss_e: 1.6628e-05 | Loss_b: 6.9458e-06\n",
      "Step: NaN | Loss: 7.0789e-07 | Loss_d: 1.8862e-05 Loss_e: 1.6609e-05 | Loss_b: 6.9415e-06\n",
      "Step: NaN | Loss: 7.3993e-07 | Loss_d: 1.8828e-05 Loss_e: 1.6832e-05 | Loss_b: 8.6718e-06\n",
      "Step: NaN | Loss: 7.0782e-07 | Loss_d: 1.8841e-05 Loss_e: 1.6608e-05 | Loss_b: 6.9598e-06\n",
      "Step: NaN | Loss: 7.0629e-07 | Loss_d: 1.8936e-05 Loss_e: 1.6621e-05 | Loss_b: 6.7600e-06\n",
      "Step: NaN | Loss: 7.0592e-07 | Loss_d: 1.8887e-05 Loss_e: 1.6615e-05 | Loss_b: 6.7926e-06\n",
      "Step: NaN | Loss: 7.0459e-07 | Loss_d: 1.8877e-05 Loss_e: 1.6576e-05 | Loss_b: 6.7625e-06\n",
      "Step: NaN | Loss: 7.0623e-07 | Loss_d: 1.8891e-05 Loss_e: 1.6594e-05 | Loss_b: 6.8284e-06\n",
      "Step: NaN | Loss: 7.0390e-07 | Loss_d: 1.8871e-05 Loss_e: 1.6551e-05 | Loss_b: 6.7518e-06\n",
      "Step: NaN | Loss: 7.0312e-07 | Loss_d: 1.8845e-05 Loss_e: 1.6543e-05 | Loss_b: 6.7390e-06\n",
      "Step: NaN | Loss: 7.0197e-07 | Loss_d: 1.8766e-05 Loss_e: 1.6546e-05 | Loss_b: 6.7465e-06\n",
      "Step: NaN | Loss: 7.0195e-07 | Loss_d: 1.8774e-05 Loss_e: 1.6542e-05 | Loss_b: 6.7403e-06\n",
      "Step: NaN | Loss: 7.0109e-07 | Loss_d: 1.8586e-05 Loss_e: 1.6642e-05 | Loss_b: 6.7769e-06\n",
      "Step: NaN | Loss: 7.0078e-07 | Loss_d: 1.8642e-05 Loss_e: 1.6599e-05 | Loss_b: 6.7462e-06\n",
      "Step: NaN | Loss: 7.0059e-07 | Loss_d: 1.8620e-05 Loss_e: 1.6615e-05 | Loss_b: 6.7400e-06\n",
      "Step: NaN | Loss: 7.0109e-07 | Loss_d: 1.8549e-05 Loss_e: 1.6690e-05 | Loss_b: 6.7657e-06\n",
      "Step: NaN | Loss: 7.0052e-07 | Loss_d: 1.8600e-05 Loss_e: 1.6633e-05 | Loss_b: 6.7386e-06\n",
      "Step: NaN | Loss: 7.0033e-07 | Loss_d: 1.8608e-05 Loss_e: 1.6627e-05 | Loss_b: 6.7248e-06\n",
      "Step: NaN | Loss: 7.0103e-07 | Loss_d: 1.8643e-05 Loss_e: 1.6613e-05 | Loss_b: 6.7457e-06\n",
      "Step: NaN | Loss: 7.0028e-07 | Loss_d: 1.8615e-05 Loss_e: 1.6623e-05 | Loss_b: 6.7194e-06\n",
      "Step: NaN | Loss: 6.9997e-07 | Loss_d: 1.8633e-05 Loss_e: 1.6596e-05 | Loss_b: 6.7092e-06\n",
      "Step: NaN | Loss: 6.9926e-07 | Loss_d: 1.8718e-05 Loss_e: 1.6498e-05 | Loss_b: 6.6796e-06\n",
      "Step: NaN | Loss: 7.0788e-07 | Loss_d: 1.9441e-05 Loss_e: 1.6194e-05 | Loss_b: 6.7776e-06\n",
      "Step: NaN | Loss: 6.9920e-07 | Loss_d: 1.8755e-05 Loss_e: 1.6465e-05 | Loss_b: 6.6732e-06\n",
      "Step: NaN | Loss: 7.1099e-07 | Loss_d: 1.8734e-05 Loss_e: 1.6869e-05 | Loss_b: 6.9954e-06\n",
      "Step: NaN | Loss: 6.9908e-07 | Loss_d: 1.8745e-05 Loss_e: 1.6471e-05 | Loss_b: 6.6697e-06\n",
      "Step: NaN | Loss: 6.9884e-07 | Loss_d: 1.8723e-05 Loss_e: 1.6469e-05 | Loss_b: 6.6781e-06\n",
      "Step: NaN | Loss: 7.0035e-07 | Loss_d: 1.8661e-05 Loss_e: 1.6495e-05 | Loss_b: 6.8048e-06\n",
      "Step: NaN | Loss: 6.9881e-07 | Loss_d: 1.8713e-05 Loss_e: 1.6469e-05 | Loss_b: 6.6861e-06\n",
      "Step: NaN | Loss: 6.9873e-07 | Loss_d: 1.8710e-05 Loss_e: 1.6467e-05 | Loss_b: 6.6868e-06\n",
      "Step: NaN | Loss: 6.9871e-07 | Loss_d: 1.8702e-05 Loss_e: 1.6465e-05 | Loss_b: 6.6951e-06\n",
      "Step: NaN | Loss: 6.9868e-07 | Loss_d: 1.8705e-05 Loss_e: 1.6464e-05 | Loss_b: 6.6909e-06\n",
      "Step: NaN | Loss: 6.9863e-07 | Loss_d: 1.8695e-05 Loss_e: 1.6447e-05 | Loss_b: 6.7163e-06\n",
      "Step: NaN | Loss: 6.9856e-07 | Loss_d: 1.8699e-05 Loss_e: 1.6454e-05 | Loss_b: 6.7012e-06\n",
      "Step: NaN | Loss: 6.9840e-07 | Loss_d: 1.8690e-05 Loss_e: 1.6448e-05 | Loss_b: 6.7056e-06\n",
      "Step: NaN | Loss: 6.9826e-07 | Loss_d: 1.8660e-05 Loss_e: 1.6432e-05 | Loss_b: 6.7443e-06\n",
      "Step: NaN | Loss: 6.9820e-07 | Loss_d: 1.8669e-05 Loss_e: 1.6435e-05 | Loss_b: 6.7274e-06\n",
      "Step: NaN | Loss: 6.9794e-07 | Loss_d: 1.8664e-05 Loss_e: 1.6441e-05 | Loss_b: 6.7116e-06\n",
      "Step: NaN | Loss: 6.9809e-07 | Loss_d: 1.8657e-05 Loss_e: 1.6467e-05 | Loss_b: 6.7006e-06\n",
      "Step: NaN | Loss: 6.9778e-07 | Loss_d: 1.8659e-05 Loss_e: 1.6451e-05 | Loss_b: 6.6968e-06\n",
      "Step: NaN | Loss: 6.9741e-07 | Loss_d: 1.8622e-05 Loss_e: 1.6464e-05 | Loss_b: 6.6984e-06\n",
      "Step: NaN | Loss: 6.9984e-07 | Loss_d: 1.8553e-05 Loss_e: 1.6572e-05 | Loss_b: 6.8061e-06\n",
      "Step: NaN | Loss: 6.9739e-07 | Loss_d: 1.8609e-05 Loss_e: 1.6472e-05 | Loss_b: 6.7032e-06\n",
      "Step: NaN | Loss: 6.9681e-07 | Loss_d: 1.8588e-05 Loss_e: 1.6468e-05 | Loss_b: 6.6934e-06\n",
      "Step: NaN | Loss: 6.9743e-07 | Loss_d: 1.8532e-05 Loss_e: 1.6528e-05 | Loss_b: 6.7263e-06\n",
      "Step: NaN | Loss: 6.9652e-07 | Loss_d: 1.8562e-05 Loss_e: 1.6476e-05 | Loss_b: 6.6935e-06\n",
      "Step: NaN | Loss: 6.9517e-07 | Loss_d: 1.8499e-05 Loss_e: 1.6497e-05 | Loss_b: 6.6550e-06\n",
      "Step: NaN | Loss: 6.9601e-07 | Loss_d: 1.8304e-05 Loss_e: 1.6727e-05 | Loss_b: 6.6699e-06\n",
      "Step: NaN | Loss: 6.9434e-07 | Loss_d: 1.8405e-05 Loss_e: 1.6565e-05 | Loss_b: 6.6306e-06\n",
      "Step: NaN | Loss: 6.9493e-07 | Loss_d: 1.8456e-05 Loss_e: 1.6535e-05 | Loss_b: 6.6454e-06\n",
      "Step: NaN | Loss: 6.9400e-07 | Loss_d: 1.8421e-05 Loss_e: 1.6551e-05 | Loss_b: 6.6083e-06\n",
      "Step: NaN | Loss: 6.9374e-07 | Loss_d: 1.8428e-05 Loss_e: 1.6528e-05 | Loss_b: 6.6086e-06\n",
      "Step: NaN | Loss: 6.9466e-07 | Loss_d: 1.8466e-05 Loss_e: 1.6461e-05 | Loss_b: 6.6926e-06\n",
      "Step: NaN | Loss: 6.9366e-07 | Loss_d: 1.8436e-05 Loss_e: 1.6510e-05 | Loss_b: 6.6140e-06\n",
      "Step: NaN | Loss: 6.9355e-07 | Loss_d: 1.8443e-05 Loss_e: 1.6503e-05 | Loss_b: 6.6082e-06\n",
      "Step: NaN | Loss: 6.9428e-07 | Loss_d: 1.8481e-05 Loss_e: 1.6486e-05 | Loss_b: 6.6300e-06\n",
      "Step: NaN | Loss: 6.9353e-07 | Loss_d: 1.8447e-05 Loss_e: 1.6499e-05 | Loss_b: 6.6060e-06\n",
      "Step: NaN | Loss: 6.9342e-07 | Loss_d: 1.8443e-05 Loss_e: 1.6498e-05 | Loss_b: 6.6051e-06\n",
      "Step: NaN | Loss: 6.9310e-07 | Loss_d: 1.8429e-05 Loss_e: 1.6493e-05 | Loss_b: 6.6045e-06\n",
      "Step: NaN | Loss: 6.9399e-07 | Loss_d: 1.8383e-05 Loss_e: 1.6513e-05 | Loss_b: 6.6837e-06\n",
      "Step: NaN | Loss: 6.9293e-07 | Loss_d: 1.8412e-05 Loss_e: 1.6491e-05 | Loss_b: 6.6137e-06\n",
      "Step: NaN | Loss: 6.9206e-07 | Loss_d: 1.8437e-05 Loss_e: 1.6406e-05 | Loss_b: 6.6221e-06\n",
      "Step: NaN | Loss: 6.9176e-07 | Loss_d: 1.8577e-05 Loss_e: 1.6163e-05 | Loss_b: 6.7067e-06\n",
      "Step: NaN | Loss: 6.9130e-07 | Loss_d: 1.8509e-05 Loss_e: 1.6248e-05 | Loss_b: 6.6610e-06\n",
      "Step: NaN | Loss: 6.9164e-07 | Loss_d: 1.8548e-05 Loss_e: 1.6201e-05 | Loss_b: 6.6905e-06\n",
      "Step: NaN | Loss: 6.9103e-07 | Loss_d: 1.8521e-05 Loss_e: 1.6225e-05 | Loss_b: 6.6559e-06\n",
      "Step: NaN | Loss: 6.9080e-07 | Loss_d: 1.8520e-05 Loss_e: 1.6221e-05 | Loss_b: 6.6481e-06\n",
      "Step: NaN | Loss: 6.9166e-07 | Loss_d: 1.8521e-05 Loss_e: 1.6254e-05 | Loss_b: 6.6657e-06\n",
      "Step: NaN | Loss: 6.9076e-07 | Loss_d: 1.8519e-05 Loss_e: 1.6221e-05 | Loss_b: 6.6462e-06\n",
      "Step: NaN | Loss: 6.9056e-07 | Loss_d: 1.8505e-05 Loss_e: 1.6217e-05 | Loss_b: 6.6533e-06\n",
      "Step: NaN | Loss: 6.9025e-07 | Loss_d: 1.8453e-05 Loss_e: 1.6203e-05 | Loss_b: 6.6998e-06\n",
      "Step: NaN | Loss: 6.9025e-07 | Loss_d: 1.8456e-05 Loss_e: 1.6203e-05 | Loss_b: 6.6959e-06\n",
      "Step: NaN | Loss: 6.8973e-07 | Loss_d: 1.8438e-05 Loss_e: 1.6193e-05 | Loss_b: 6.6942e-06\n",
      "Step: NaN | Loss: 6.9640e-07 | Loss_d: 1.8483e-05 Loss_e: 1.6261e-05 | Loss_b: 6.9803e-06\n",
      "Step: NaN | Loss: 6.8973e-07 | Loss_d: 1.8436e-05 Loss_e: 1.6193e-05 | Loss_b: 6.6955e-06\n",
      "Step: NaN | Loss: 6.8956e-07 | Loss_d: 1.8418e-05 Loss_e: 1.6209e-05 | Loss_b: 6.6878e-06\n",
      "Step: NaN | Loss: 6.9011e-07 | Loss_d: 1.8352e-05 Loss_e: 1.6283e-05 | Loss_b: 6.7126e-06\n",
      "Step: NaN | Loss: 6.8952e-07 | Loss_d: 1.8402e-05 Loss_e: 1.6224e-05 | Loss_b: 6.6856e-06\n",
      "Step: NaN | Loss: 6.8945e-07 | Loss_d: 1.8401e-05 Loss_e: 1.6219e-05 | Loss_b: 6.6873e-06\n",
      "Step: NaN | Loss: 6.8935e-07 | Loss_d: 1.8396e-05 Loss_e: 1.6203e-05 | Loss_b: 6.7023e-06\n",
      "Step: NaN | Loss: 6.8935e-07 | Loss_d: 1.8397e-05 Loss_e: 1.6205e-05 | Loss_b: 6.7006e-06\n",
      "Step: NaN | Loss: 6.8907e-07 | Loss_d: 1.8379e-05 Loss_e: 1.6209e-05 | Loss_b: 6.6971e-06\n",
      "Step: NaN | Loss: 6.8827e-07 | Loss_d: 1.8311e-05 Loss_e: 1.6233e-05 | Loss_b: 6.6928e-06\n",
      "Step: NaN | Loss: 6.9269e-07 | Loss_d: 1.8055e-05 Loss_e: 1.6476e-05 | Loss_b: 6.9707e-06\n",
      "Step: NaN | Loss: 6.8799e-07 | Loss_d: 1.8255e-05 Loss_e: 1.6261e-05 | Loss_b: 6.7037e-06\n",
      "Step: NaN | Loss: 6.8906e-07 | Loss_d: 1.8126e-05 Loss_e: 1.6272e-05 | Loss_b: 6.8863e-06\n",
      "Step: NaN | Loss: 6.8767e-07 | Loss_d: 1.8211e-05 Loss_e: 1.6261e-05 | Loss_b: 6.7293e-06\n",
      "Step: NaN | Loss: 6.8748e-07 | Loss_d: 1.8205e-05 Loss_e: 1.6256e-05 | Loss_b: 6.7291e-06\n",
      "Step: NaN | Loss: 6.8742e-07 | Loss_d: 1.8187e-05 Loss_e: 1.6247e-05 | Loss_b: 6.7520e-06\n",
      "Step: NaN | Loss: 6.8729e-07 | Loss_d: 1.8194e-05 Loss_e: 1.6248e-05 | Loss_b: 6.7369e-06\n",
      "Step: NaN | Loss: 6.8673e-07 | Loss_d: 1.8135e-05 Loss_e: 1.6292e-05 | Loss_b: 6.7181e-06\n",
      "Step: NaN | Loss: 6.8925e-07 | Loss_d: 1.7956e-05 Loss_e: 1.6519e-05 | Loss_b: 6.8206e-06\n",
      "Step: NaN | Loss: 6.8661e-07 | Loss_d: 1.8099e-05 Loss_e: 1.6324e-05 | Loss_b: 6.7149e-06\n",
      "Step: NaN | Loss: 6.8606e-07 | Loss_d: 1.8122e-05 Loss_e: 1.6272e-05 | Loss_b: 6.7113e-06\n",
      "Step: NaN | Loss: 6.8725e-07 | Loss_d: 1.8278e-05 Loss_e: 1.6125e-05 | Loss_b: 6.7735e-06\n",
      "Step: NaN | Loss: 6.8586e-07 | Loss_d: 1.8156e-05 Loss_e: 1.6220e-05 | Loss_b: 6.7177e-06\n",
      "Step: NaN | Loss: 6.8532e-07 | Loss_d: 1.8161e-05 Loss_e: 1.6190e-05 | Loss_b: 6.7098e-06\n",
      "Step: NaN | Loss: 6.8947e-07 | Loss_d: 1.8238e-05 Loss_e: 1.6113e-05 | Loss_b: 6.9578e-06\n",
      "Step: NaN | Loss: 6.8528e-07 | Loss_d: 1.8164e-05 Loss_e: 1.6180e-05 | Loss_b: 6.7143e-06\n",
      "Step: NaN | Loss: 6.8453e-07 | Loss_d: 1.8149e-05 Loss_e: 1.6181e-05 | Loss_b: 6.6837e-06\n",
      "Step: NaN | Loss: 6.8639e-07 | Loss_d: 1.8112e-05 Loss_e: 1.6316e-05 | Loss_b: 6.6965e-06\n",
      "Step: NaN | Loss: 6.8428e-07 | Loss_d: 1.8136e-05 Loss_e: 1.6196e-05 | Loss_b: 6.6670e-06\n",
      "Step: NaN | Loss: 6.8389e-07 | Loss_d: 1.8108e-05 Loss_e: 1.6186e-05 | Loss_b: 6.6807e-06\n",
      "Step: NaN | Loss: 6.8403e-07 | Loss_d: 1.8010e-05 Loss_e: 1.6173e-05 | Loss_b: 6.8000e-06\n",
      "Step: NaN | Loss: 6.8360e-07 | Loss_d: 1.8061e-05 Loss_e: 1.6175e-05 | Loss_b: 6.7214e-06\n",
      "Step: NaN | Loss: 6.8319e-07 | Loss_d: 1.8050e-05 Loss_e: 1.6169e-05 | Loss_b: 6.7144e-06\n",
      "Step: NaN | Loss: 6.8229e-07 | Loss_d: 1.8026e-05 Loss_e: 1.6154e-05 | Loss_b: 6.6986e-06\n",
      "Step: NaN | Loss: 6.9632e-07 | Loss_d: 1.8419e-05 Loss_e: 1.6367e-05 | Loss_b: 6.9337e-06\n",
      "Step: NaN | Loss: 6.8226e-07 | Loss_d: 1.8026e-05 Loss_e: 1.6153e-05 | Loss_b: 6.6979e-06\n",
      "Step: NaN | Loss: 6.8207e-07 | Loss_d: 1.8032e-05 Loss_e: 1.6101e-05 | Loss_b: 6.7326e-06\n",
      "Step: NaN | Loss: 6.8201e-07 | Loss_d: 1.8029e-05 Loss_e: 1.6118e-05 | Loss_b: 6.7145e-06\n",
      "Step: NaN | Loss: 6.8170e-07 | Loss_d: 1.8016e-05 Loss_e: 1.6132e-05 | Loss_b: 6.6953e-06\n",
      "Step: NaN | Loss: 6.8556e-07 | Loss_d: 1.7981e-05 Loss_e: 1.6262e-05 | Loss_b: 6.8322e-06\n",
      "Step: NaN | Loss: 6.8169e-07 | Loss_d: 1.8015e-05 Loss_e: 1.6134e-05 | Loss_b: 6.6944e-06\n",
      "Step: NaN | Loss: 6.8151e-07 | Loss_d: 1.8022e-05 Loss_e: 1.6123e-05 | Loss_b: 6.6873e-06\n",
      "Step: NaN | Loss: 6.8114e-07 | Loss_d: 1.8056e-05 Loss_e: 1.6084e-05 | Loss_b: 6.6695e-06\n",
      "Step: NaN | Loss: 6.8753e-07 | Loss_d: 1.8317e-05 Loss_e: 1.6035e-05 | Loss_b: 6.8406e-06\n",
      "Step: NaN | Loss: 6.8113e-07 | Loss_d: 1.8062e-05 Loss_e: 1.6079e-05 | Loss_b: 6.6686e-06\n",
      "Step: NaN | Loss: 6.8059e-07 | Loss_d: 1.8071e-05 Loss_e: 1.6078e-05 | Loss_b: 6.6288e-06\n",
      "Step: NaN | Loss: 6.8312e-07 | Loss_d: 1.8179e-05 Loss_e: 1.6177e-05 | Loss_b: 6.5724e-06\n",
      "Step: NaN | Loss: 6.8050e-07 | Loss_d: 1.8080e-05 Loss_e: 1.6083e-05 | Loss_b: 6.6091e-06\n",
      "Step: NaN | Loss: 6.8051e-07 | Loss_d: 1.8032e-05 Loss_e: 1.6110e-05 | Loss_b: 6.6304e-06\n",
      "Step: NaN | Loss: 6.8039e-07 | Loss_d: 1.8055e-05 Loss_e: 1.6095e-05 | Loss_b: 6.6150e-06\n",
      "Step: NaN | Loss: 6.8030e-07 | Loss_d: 1.8060e-05 Loss_e: 1.6087e-05 | Loss_b: 6.6126e-06\n",
      "Step: NaN | Loss: 6.8005e-07 | Loss_d: 1.8081e-05 Loss_e: 1.6054e-05 | Loss_b: 6.6090e-06\n",
      "Step: NaN | Loss: 6.8257e-07 | Loss_d: 1.8235e-05 Loss_e: 1.5928e-05 | Loss_b: 6.7324e-06\n",
      "Step: NaN | Loss: 6.8002e-07 | Loss_d: 1.8093e-05 Loss_e: 1.6039e-05 | Loss_b: 6.6108e-06\n",
      "Step: NaN | Loss: 6.7938e-07 | Loss_d: 1.8094e-05 Loss_e: 1.6019e-05 | Loss_b: 6.5917e-06\n",
      "Step: NaN | Loss: 6.7869e-07 | Loss_d: 1.8117e-05 Loss_e: 1.5973e-05 | Loss_b: 6.5734e-06\n",
      "Step: NaN | Loss: 6.7859e-07 | Loss_d: 1.8108e-05 Loss_e: 1.5979e-05 | Loss_b: 6.5699e-06\n",
      "Step: NaN | Loss: 6.7982e-07 | Loss_d: 1.8235e-05 Loss_e: 1.5917e-05 | Loss_b: 6.5789e-06\n",
      "Step: NaN | Loss: 6.7848e-07 | Loss_d: 1.8133e-05 Loss_e: 1.5961e-05 | Loss_b: 6.5563e-06\n",
      "Step: NaN | Loss: 6.7838e-07 | Loss_d: 1.8117e-05 Loss_e: 1.5970e-05 | Loss_b: 6.5574e-06\n",
      "Step: NaN | Loss: 6.7858e-07 | Loss_d: 1.8055e-05 Loss_e: 1.6022e-05 | Loss_b: 6.5800e-06\n",
      "Step: NaN | Loss: 6.7833e-07 | Loss_d: 1.8098e-05 Loss_e: 1.5983e-05 | Loss_b: 6.5611e-06\n",
      "Step: NaN | Loss: 6.7826e-07 | Loss_d: 1.8062e-05 Loss_e: 1.5975e-05 | Loss_b: 6.6009e-06\n",
      "Step: NaN | Loss: 6.7824e-07 | Loss_d: 1.8075e-05 Loss_e: 1.5977e-05 | Loss_b: 6.5843e-06\n",
      "Step: NaN | Loss: 6.7810e-07 | Loss_d: 1.8071e-05 Loss_e: 1.5974e-05 | Loss_b: 6.5835e-06\n",
      "Step: NaN | Loss: 6.7790e-07 | Loss_d: 1.8060e-05 Loss_e: 1.5964e-05 | Loss_b: 6.5918e-06\n",
      "Step: NaN | Loss: 6.7791e-07 | Loss_d: 1.8061e-05 Loss_e: 1.5964e-05 | Loss_b: 6.5915e-06\n",
      "Step: NaN | Loss: 6.7774e-07 | Loss_d: 1.8061e-05 Loss_e: 1.5964e-05 | Loss_b: 6.5818e-06\n",
      "Step: NaN | Loss: 6.7813e-07 | Loss_d: 1.8086e-05 Loss_e: 1.5969e-05 | Loss_b: 6.5756e-06\n",
      "Step: NaN | Loss: 6.7769e-07 | Loss_d: 1.8063e-05 Loss_e: 1.5965e-05 | Loss_b: 6.5753e-06\n",
      "Step: NaN | Loss: 6.7749e-07 | Loss_d: 1.8056e-05 Loss_e: 1.5960e-05 | Loss_b: 6.5746e-06\n",
      "Step: NaN | Loss: 6.7682e-07 | Loss_d: 1.8030e-05 Loss_e: 1.5947e-05 | Loss_b: 6.5740e-06\n",
      "Step: NaN | Loss: 6.7665e-07 | Loss_d: 1.7923e-05 Loss_e: 1.5961e-05 | Loss_b: 6.6571e-06\n",
      "Step: NaN | Loss: 6.7606e-07 | Loss_d: 1.7968e-05 Loss_e: 1.5938e-05 | Loss_b: 6.5997e-06\n",
      "Step: NaN | Loss: 6.8063e-07 | Loss_d: 1.8095e-05 Loss_e: 1.5901e-05 | Loss_b: 6.7837e-06\n",
      "Step: NaN | Loss: 6.7540e-07 | Loss_d: 1.7988e-05 Loss_e: 1.5905e-05 | Loss_b: 6.5732e-06\n",
      "Step: NaN | Loss: 6.7478e-07 | Loss_d: 1.8001e-05 Loss_e: 1.5897e-05 | Loss_b: 6.5318e-06\n",
      "Step: NaN | Loss: 6.8049e-07 | Loss_d: 1.8196e-05 Loss_e: 1.5980e-05 | Loss_b: 6.5948e-06\n",
      "Step: NaN | Loss: 6.7477e-07 | Loss_d: 1.8006e-05 Loss_e: 1.5897e-05 | Loss_b: 6.5259e-06\n",
      "Step: NaN | Loss: 6.7469e-07 | Loss_d: 1.8003e-05 Loss_e: 1.5892e-05 | Loss_b: 6.5278e-06\n",
      "Step: NaN | Loss: 6.7450e-07 | Loss_d: 1.7995e-05 Loss_e: 1.5876e-05 | Loss_b: 6.5407e-06\n",
      "Step: NaN | Loss: 6.7574e-07 | Loss_d: 1.7976e-05 Loss_e: 1.5823e-05 | Loss_b: 6.6879e-06\n",
      "Step: NaN | Loss: 6.7445e-07 | Loss_d: 1.7989e-05 Loss_e: 1.5864e-05 | Loss_b: 6.5557e-06\n",
      "Step: NaN | Loss: 6.7384e-07 | Loss_d: 1.8029e-05 Loss_e: 1.5818e-05 | Loss_b: 6.5257e-06\n",
      "Step: NaN | Loss: 6.7918e-07 | Loss_d: 1.8283e-05 Loss_e: 1.5761e-05 | Loss_b: 6.6490e-06\n",
      "Step: NaN | Loss: 6.7380e-07 | Loss_d: 1.8042e-05 Loss_e: 1.5807e-05 | Loss_b: 6.5216e-06\n",
      "Step: NaN | Loss: 6.7332e-07 | Loss_d: 1.8041e-05 Loss_e: 1.5801e-05 | Loss_b: 6.4990e-06\n",
      "Step: NaN | Loss: 6.7454e-07 | Loss_d: 1.8055e-05 Loss_e: 1.5828e-05 | Loss_b: 6.5318e-06\n",
      "Step: NaN | Loss: 6.7314e-07 | Loss_d: 1.8042e-05 Loss_e: 1.5801e-05 | Loss_b: 6.4882e-06\n",
      "Step: NaN | Loss: 6.7258e-07 | Loss_d: 1.8018e-05 Loss_e: 1.5787e-05 | Loss_b: 6.4922e-06\n",
      "Step: NaN | Loss: 6.7136e-07 | Loss_d: 1.7934e-05 Loss_e: 1.5765e-05 | Loss_b: 6.5250e-06\n",
      "Step: NaN | Loss: 6.8866e-07 | Loss_d: 1.7807e-05 Loss_e: 1.6433e-05 | Loss_b: 7.0202e-06\n",
      "Step: NaN | Loss: 6.7130e-07 | Loss_d: 1.7914e-05 Loss_e: 1.5768e-05 | Loss_b: 6.5387e-06\n",
      "Step: NaN | Loss: 6.7073e-07 | Loss_d: 1.7979e-05 Loss_e: 1.5634e-05 | Loss_b: 6.5736e-06\n",
      "Step: NaN | Loss: 6.7043e-07 | Loss_d: 1.7952e-05 Loss_e: 1.5675e-05 | Loss_b: 6.5409e-06\n",
      "Step: NaN | Loss: 6.7025e-07 | Loss_d: 1.7954e-05 Loss_e: 1.5667e-05 | Loss_b: 6.5366e-06\n",
      "Step: NaN | Loss: 6.7007e-07 | Loss_d: 1.7967e-05 Loss_e: 1.5638e-05 | Loss_b: 6.5429e-06\n",
      "Step: NaN | Loss: 6.7006e-07 | Loss_d: 1.7962e-05 Loss_e: 1.5646e-05 | Loss_b: 6.5380e-06\n",
      "Step: NaN | Loss: 6.6977e-07 | Loss_d: 1.7957e-05 Loss_e: 1.5638e-05 | Loss_b: 6.5341e-06\n",
      "Step: NaN | Loss: 6.6914e-07 | Loss_d: 1.7945e-05 Loss_e: 1.5607e-05 | Loss_b: 6.5394e-06\n",
      "Step: NaN | Loss: 6.7677e-07 | Loss_d: 1.8019e-05 Loss_e: 1.5525e-05 | Loss_b: 7.0047e-06\n",
      "Step: NaN | Loss: 6.6909e-07 | Loss_d: 1.7942e-05 Loss_e: 1.5596e-05 | Loss_b: 6.5495e-06\n",
      "Step: NaN | Loss: 6.6877e-07 | Loss_d: 1.7997e-05 Loss_e: 1.5540e-05 | Loss_b: 6.5319e-06\n",
      "Step: NaN | Loss: 6.6873e-07 | Loss_d: 1.7983e-05 Loss_e: 1.5552e-05 | Loss_b: 6.5308e-06\n",
      "Step: NaN | Loss: 6.6857e-07 | Loss_d: 1.7977e-05 Loss_e: 1.5547e-05 | Loss_b: 6.5331e-06\n",
      "Step: NaN | Loss: 6.6970e-07 | Loss_d: 1.7980e-05 Loss_e: 1.5549e-05 | Loss_b: 6.5960e-06\n",
      "Step: NaN | Loss: 6.6855e-07 | Loss_d: 1.7975e-05 Loss_e: 1.5546e-05 | Loss_b: 6.5353e-06\n",
      "Step: NaN | Loss: 6.6841e-07 | Loss_d: 1.7950e-05 Loss_e: 1.5545e-05 | Loss_b: 6.5520e-06\n",
      "Step: NaN | Loss: 6.6841e-07 | Loss_d: 1.7954e-05 Loss_e: 1.5545e-05 | Loss_b: 6.5482e-06\n",
      "Step: NaN | Loss: 6.6825e-07 | Loss_d: 1.7950e-05 Loss_e: 1.5530e-05 | Loss_b: 6.5573e-06\n",
      "Step: NaN | Loss: 6.6905e-07 | Loss_d: 1.7952e-05 Loss_e: 1.5497e-05 | Loss_b: 6.6364e-06\n",
      "Step: NaN | Loss: 6.6822e-07 | Loss_d: 1.7949e-05 Loss_e: 1.5522e-05 | Loss_b: 6.5649e-06\n",
      "Step: NaN | Loss: 6.6807e-07 | Loss_d: 1.7954e-05 Loss_e: 1.5518e-05 | Loss_b: 6.5547e-06\n",
      "Step: NaN | Loss: 6.6844e-07 | Loss_d: 1.7980e-05 Loss_e: 1.5519e-05 | Loss_b: 6.5502e-06\n",
      "Step: NaN | Loss: 6.6801e-07 | Loss_d: 1.7960e-05 Loss_e: 1.5515e-05 | Loss_b: 6.5481e-06\n",
      "Step: NaN | Loss: 6.6786e-07 | Loss_d: 1.7977e-05 Loss_e: 1.5502e-05 | Loss_b: 6.5358e-06\n",
      "Step: NaN | Loss: 6.6914e-07 | Loss_d: 1.8068e-05 Loss_e: 1.5463e-05 | Loss_b: 6.5604e-06\n",
      "Step: NaN | Loss: 6.6786e-07 | Loss_d: 1.7982e-05 Loss_e: 1.5499e-05 | Loss_b: 6.5340e-06\n",
      "Step: NaN | Loss: 6.6767e-07 | Loss_d: 1.7978e-05 Loss_e: 1.5492e-05 | Loss_b: 6.5335e-06\n",
      "Step: NaN | Loss: 6.6724e-07 | Loss_d: 1.7968e-05 Loss_e: 1.5469e-05 | Loss_b: 6.5408e-06\n",
      "Step: NaN | Loss: 6.7125e-07 | Loss_d: 1.7967e-05 Loss_e: 1.5492e-05 | Loss_b: 6.7590e-06\n",
      "Step: NaN | Loss: 6.6717e-07 | Loss_d: 1.7963e-05 Loss_e: 1.5460e-05 | Loss_b: 6.5499e-06\n",
      "Step: NaN | Loss: 6.6662e-07 | Loss_d: 1.7929e-05 Loss_e: 1.5460e-05 | Loss_b: 6.5515e-06\n",
      "Step: NaN | Loss: 6.6554e-07 | Loss_d: 1.7806e-05 Loss_e: 1.5477e-05 | Loss_b: 6.5927e-06\n",
      "Step: NaN | Loss: 6.8727e-07 | Loss_d: 1.7522e-05 Loss_e: 1.5962e-05 | Loss_b: 7.6930e-06\n",
      "Step: NaN | Loss: 6.6553e-07 | Loss_d: 1.7795e-05 Loss_e: 1.5480e-05 | Loss_b: 6.6004e-06\n",
      "Step: NaN | Loss: 6.6522e-07 | Loss_d: 1.7820e-05 Loss_e: 1.5452e-05 | Loss_b: 6.5846e-06\n",
      "Step: NaN | Loss: 6.6962e-07 | Loss_d: 1.7963e-05 Loss_e: 1.5416e-05 | Loss_b: 6.7406e-06\n",
      "Step: NaN | Loss: 6.6522e-07 | Loss_d: 1.7821e-05 Loss_e: 1.5451e-05 | Loss_b: 6.5846e-06\n",
      "Step: NaN | Loss: 6.6495e-07 | Loss_d: 1.7795e-05 Loss_e: 1.5454e-05 | Loss_b: 6.5906e-06\n",
      "Step: NaN | Loss: 6.6552e-07 | Loss_d: 1.7702e-05 Loss_e: 1.5487e-05 | Loss_b: 6.6850e-06\n",
      "Step: NaN | Loss: 6.6483e-07 | Loss_d: 1.7767e-05 Loss_e: 1.5460e-05 | Loss_b: 6.6059e-06\n",
      "Step: NaN | Loss: 6.6440e-07 | Loss_d: 1.7759e-05 Loss_e: 1.5460e-05 | Loss_b: 6.5884e-06\n",
      "Step: NaN | Loss: 6.6358e-07 | Loss_d: 1.7741e-05 Loss_e: 1.5478e-05 | Loss_b: 6.5383e-06\n",
      "Step: NaN | Loss: 6.8325e-07 | Loss_d: 1.7977e-05 Loss_e: 1.6085e-05 | Loss_b: 6.8742e-06\n",
      "Step: NaN | Loss: 6.6360e-07 | Loss_d: 1.7741e-05 Loss_e: 1.5479e-05 | Loss_b: 6.5389e-06\n",
      "Step: NaN | Loss: 6.6571e-07 | Loss_d: 1.7859e-05 Loss_e: 1.5504e-05 | Loss_b: 6.5222e-06\n",
      "Step: NaN | Loss: 6.6341e-07 | Loss_d: 1.7760e-05 Loss_e: 1.5478e-05 | Loss_b: 6.5104e-06\n",
      "Step: NaN | Loss: 6.6330e-07 | Loss_d: 1.7755e-05 Loss_e: 1.5480e-05 | Loss_b: 6.5061e-06\n",
      "Step: NaN | Loss: 6.6284e-07 | Loss_d: 1.7738e-05 Loss_e: 1.5490e-05 | Loss_b: 6.4865e-06\n",
      "Step: NaN | Loss: 6.6211e-07 | Loss_d: 1.7672e-05 Loss_e: 1.5562e-05 | Loss_b: 6.4358e-06\n",
      "Step: NaN | Loss: 6.6205e-07 | Loss_d: 1.7683e-05 Loss_e: 1.5542e-05 | Loss_b: 6.4408e-06\n",
      "Step: NaN | Loss: 6.6106e-07 | Loss_d: 1.7612e-05 Loss_e: 1.5529e-05 | Loss_b: 6.4658e-06\n",
      "Step: NaN | Loss: 6.6241e-07 | Loss_d: 1.7345e-05 Loss_e: 1.5553e-05 | Loss_b: 6.7900e-06\n",
      "Step: NaN | Loss: 6.6056e-07 | Loss_d: 1.7517e-05 Loss_e: 1.5524e-05 | Loss_b: 6.5362e-06\n",
      "Step: NaN | Loss: 6.6001e-07 | Loss_d: 1.7504e-05 Loss_e: 1.5515e-05 | Loss_b: 6.5247e-06\n",
      "Step: NaN | Loss: 6.5846e-07 | Loss_d: 1.7463e-05 Loss_e: 1.5490e-05 | Loss_b: 6.4978e-06\n",
      "Step: NaN | Loss: 6.6708e-07 | Loss_d: 1.7569e-05 Loss_e: 1.5584e-05 | Loss_b: 6.8153e-06\n",
      "Step: NaN | Loss: 6.5799e-07 | Loss_d: 1.7444e-05 Loss_e: 1.5480e-05 | Loss_b: 6.4996e-06\n",
      "Step: NaN | Loss: 6.5907e-07 | Loss_d: 1.7728e-05 Loss_e: 1.5420e-05 | Loss_b: 6.3400e-06\n",
      "Step: NaN | Loss: 6.5745e-07 | Loss_d: 1.7531e-05 Loss_e: 1.5446e-05 | Loss_b: 6.4133e-06\n",
      "Step: NaN | Loss: 6.5694e-07 | Loss_d: 1.7515e-05 Loss_e: 1.5438e-05 | Loss_b: 6.4071e-06\n",
      "Step: NaN | Loss: 6.5611e-07 | Loss_d: 1.7460e-05 Loss_e: 1.5420e-05 | Loss_b: 6.4306e-06\n",
      "Step: NaN | Loss: 6.5611e-07 | Loss_d: 1.7464e-05 Loss_e: 1.5421e-05 | Loss_b: 6.4258e-06\n",
      "Step: NaN | Loss: 6.5422e-07 | Loss_d: 1.7428e-05 Loss_e: 1.5385e-05 | Loss_b: 6.3839e-06\n",
      "Step: NaN | Loss: 6.5207e-07 | Loss_d: 1.7390e-05 Loss_e: 1.5350e-05 | Loss_b: 6.3287e-06\n",
      "Step: NaN | Loss: 6.5181e-07 | Loss_d: 1.7383e-05 Loss_e: 1.5343e-05 | Loss_b: 6.3264e-06\n",
      "Step: NaN | Loss: 6.5052e-07 | Loss_d: 1.7355e-05 Loss_e: 1.5297e-05 | Loss_b: 6.3230e-06\n",
      "Step: NaN | Loss: 6.5052e-07 | Loss_d: 1.7356e-05 Loss_e: 1.5298e-05 | Loss_b: 6.3219e-06\n",
      "Step: NaN | Loss: 6.5031e-07 | Loss_d: 1.7337e-05 Loss_e: 1.5312e-05 | Loss_b: 6.3146e-06\n",
      "Step: NaN | Loss: 6.5161e-07 | Loss_d: 1.7285e-05 Loss_e: 1.5437e-05 | Loss_b: 6.3186e-06\n",
      "Step: NaN | Loss: 6.5028e-07 | Loss_d: 1.7328e-05 Loss_e: 1.5322e-05 | Loss_b: 6.3119e-06\n",
      "Step: NaN | Loss: 6.4993e-07 | Loss_d: 1.7350e-05 Loss_e: 1.5301e-05 | Loss_b: 6.2890e-06\n",
      "Step: NaN | Loss: 6.4984e-07 | Loss_d: 1.7447e-05 Loss_e: 1.5248e-05 | Loss_b: 6.2401e-06\n",
      "Step: NaN | Loss: 6.4963e-07 | Loss_d: 1.7401e-05 Loss_e: 1.5267e-05 | Loss_b: 6.2547e-06\n",
      "Step: NaN | Loss: 6.4950e-07 | Loss_d: 1.7397e-05 Loss_e: 1.5266e-05 | Loss_b: 6.2509e-06\n",
      "Step: NaN | Loss: 6.4935e-07 | Loss_d: 1.7397e-05 Loss_e: 1.5263e-05 | Loss_b: 6.2456e-06\n",
      "Step: NaN | Loss: 6.4922e-07 | Loss_d: 1.7380e-05 Loss_e: 1.5267e-05 | Loss_b: 6.2502e-06\n",
      "Step: NaN | Loss: 6.4933e-07 | Loss_d: 1.7321e-05 Loss_e: 1.5290e-05 | Loss_b: 6.2932e-06\n",
      "Step: NaN | Loss: 6.4916e-07 | Loss_d: 1.7355e-05 Loss_e: 1.5274e-05 | Loss_b: 6.2641e-06\n",
      "Step: NaN | Loss: 6.4884e-07 | Loss_d: 1.7348e-05 Loss_e: 1.5263e-05 | Loss_b: 6.2627e-06\n",
      "Step: NaN | Loss: 6.4811e-07 | Loss_d: 1.7323e-05 Loss_e: 1.5226e-05 | Loss_b: 6.2813e-06\n",
      "Step: NaN | Loss: 6.5796e-07 | Loss_d: 1.7265e-05 Loss_e: 1.5231e-05 | Loss_b: 6.9253e-06\n",
      "Step: NaN | Loss: 6.4809e-07 | Loss_d: 1.7317e-05 Loss_e: 1.5218e-05 | Loss_b: 6.2946e-06\n",
      "Step: NaN | Loss: 6.4749e-07 | Loss_d: 1.7358e-05 Loss_e: 1.5191e-05 | Loss_b: 6.2455e-06\n",
      "Step: NaN | Loss: 6.5110e-07 | Loss_d: 1.7555e-05 Loss_e: 1.5138e-05 | Loss_b: 6.3175e-06\n",
      "Step: NaN | Loss: 6.4741e-07 | Loss_d: 1.7380e-05 Loss_e: 1.5179e-05 | Loss_b: 6.2303e-06\n",
      "Step: NaN | Loss: 6.4696e-07 | Loss_d: 1.7386e-05 Loss_e: 1.5151e-05 | Loss_b: 6.2254e-06\n",
      "Step: NaN | Loss: 6.4577e-07 | Loss_d: 1.7418e-05 Loss_e: 1.5049e-05 | Loss_b: 6.2239e-06\n",
      "Step: NaN | Loss: 6.5376e-07 | Loss_d: 1.7736e-05 Loss_e: 1.4810e-05 | Loss_b: 6.6237e-06\n",
      "Step: NaN | Loss: 6.4548e-07 | Loss_d: 1.7450e-05 Loss_e: 1.4982e-05 | Loss_b: 6.2415e-06\n",
      "Step: NaN | Loss: 6.4697e-07 | Loss_d: 1.7523e-05 Loss_e: 1.4910e-05 | Loss_b: 6.3295e-06\n",
      "Step: NaN | Loss: 6.4511e-07 | Loss_d: 1.7467e-05 Loss_e: 1.4946e-05 | Loss_b: 6.2394e-06\n",
      "Step: NaN | Loss: 6.4490e-07 | Loss_d: 1.7464e-05 Loss_e: 1.4936e-05 | Loss_b: 6.2380e-06\n",
      "Step: NaN | Loss: 6.4447e-07 | Loss_d: 1.7465e-05 Loss_e: 1.4907e-05 | Loss_b: 6.2410e-06\n",
      "Step: NaN | Loss: 6.5234e-07 | Loss_d: 1.7676e-05 Loss_e: 1.4970e-05 | Loss_b: 6.4384e-06\n",
      "Step: NaN | Loss: 6.4446e-07 | Loss_d: 1.7466e-05 Loss_e: 1.4904e-05 | Loss_b: 6.2417e-06\n",
      "Step: NaN | Loss: 6.4327e-07 | Loss_d: 1.7447e-05 Loss_e: 1.4880e-05 | Loss_b: 6.2144e-06\n",
      "Step: NaN | Loss: 6.4566e-07 | Loss_d: 1.7487e-05 Loss_e: 1.4886e-05 | Loss_b: 6.3116e-06\n",
      "Step: NaN | Loss: 6.4276e-07 | Loss_d: 1.7439e-05 Loss_e: 1.4864e-05 | Loss_b: 6.2068e-06\n",
      "Step: NaN | Loss: 6.4217e-07 | Loss_d: 1.7359e-05 Loss_e: 1.4856e-05 | Loss_b: 6.2605e-06\n",
      "Step: NaN | Loss: 6.4188e-07 | Loss_d: 1.7384e-05 Loss_e: 1.4854e-05 | Loss_b: 6.2195e-06\n",
      "Step: NaN | Loss: 6.4161e-07 | Loss_d: 1.7375e-05 Loss_e: 1.4852e-05 | Loss_b: 6.2147e-06\n",
      "Step: NaN | Loss: 6.4212e-07 | Loss_d: 1.7354e-05 Loss_e: 1.4865e-05 | Loss_b: 6.2524e-06\n",
      "Step: NaN | Loss: 6.4150e-07 | Loss_d: 1.7367e-05 Loss_e: 1.4852e-05 | Loss_b: 6.2161e-06\n",
      "Step: NaN | Loss: 6.4127e-07 | Loss_d: 1.7360e-05 Loss_e: 1.4849e-05 | Loss_b: 6.2119e-06\n",
      "Step: NaN | Loss: 6.4063e-07 | Loss_d: 1.7336e-05 Loss_e: 1.4845e-05 | Loss_b: 6.2010e-06\n",
      "Step: NaN | Loss: 6.4401e-07 | Loss_d: 1.7346e-05 Loss_e: 1.4980e-05 | Loss_b: 6.2600e-06\n",
      "Step: NaN | Loss: 6.4041e-07 | Loss_d: 1.7322e-05 Loss_e: 1.4851e-05 | Loss_b: 6.1971e-06\n",
      "Step: NaN | Loss: 6.4021e-07 | Loss_d: 1.7321e-05 Loss_e: 1.4841e-05 | Loss_b: 6.1956e-06\n",
      "Step: NaN | Loss: 6.4018e-07 | Loss_d: 1.7321e-05 Loss_e: 1.4843e-05 | Loss_b: 6.1924e-06\n",
      "Step: NaN | Loss: 6.4007e-07 | Loss_d: 1.7314e-05 Loss_e: 1.4840e-05 | Loss_b: 6.1953e-06\n",
      "Step: NaN | Loss: 6.4026e-07 | Loss_d: 1.7293e-05 Loss_e: 1.4840e-05 | Loss_b: 6.2273e-06\n",
      "Step: NaN | Loss: 6.4004e-07 | Loss_d: 1.7307e-05 Loss_e: 1.4838e-05 | Loss_b: 6.2022e-06\n",
      "Step: NaN | Loss: 6.3979e-07 | Loss_d: 1.7298e-05 Loss_e: 1.4838e-05 | Loss_b: 6.1968e-06\n",
      "Step: NaN | Loss: 6.3919e-07 | Loss_d: 1.7268e-05 Loss_e: 1.4841e-05 | Loss_b: 6.1878e-06\n",
      "Step: NaN | Loss: 6.4539e-07 | Loss_d: 1.7215e-05 Loss_e: 1.4987e-05 | Loss_b: 6.4655e-06\n",
      "Step: NaN | Loss: 6.3913e-07 | Loss_d: 1.7256e-05 Loss_e: 1.4845e-05 | Loss_b: 6.1918e-06\n",
      "Step: NaN | Loss: 6.3784e-07 | Loss_d: 1.7186e-05 Loss_e: 1.4827e-05 | Loss_b: 6.2031e-06\n",
      "Step: NaN | Loss: 6.4323e-07 | Loss_d: 1.6992e-05 Loss_e: 1.4988e-05 | Loss_b: 6.5581e-06\n",
      "Step: NaN | Loss: 6.3757e-07 | Loss_d: 1.7140e-05 Loss_e: 1.4828e-05 | Loss_b: 6.2312e-06\n",
      "Step: NaN | Loss: 6.3688e-07 | Loss_d: 1.7139e-05 Loss_e: 1.4819e-05 | Loss_b: 6.1998e-06\n",
      "Step: NaN | Loss: 6.3957e-07 | Loss_d: 1.7206e-05 Loss_e: 1.4886e-05 | Loss_b: 6.2280e-06\n",
      "Step: NaN | Loss: 6.3673e-07 | Loss_d: 1.7143e-05 Loss_e: 1.4819e-05 | Loss_b: 6.1870e-06\n",
      "Step: NaN | Loss: 6.3628e-07 | Loss_d: 1.7145e-05 Loss_e: 1.4807e-05 | Loss_b: 6.1699e-06\n",
      "Step: NaN | Loss: 6.3551e-07 | Loss_d: 1.7163e-05 Loss_e: 1.4783e-05 | Loss_b: 6.1303e-06\n",
      "Step: NaN | Loss: 6.3551e-07 | Loss_d: 1.7163e-05 Loss_e: 1.4783e-05 | Loss_b: 6.1303e-06\n",
      "Step: NaN | Loss: 6.3406e-07 | Loss_d: 1.7090e-05 Loss_e: 1.4804e-05 | Loss_b: 6.0948e-06\n",
      "Step: NaN | Loss: 6.4588e-07 | Loss_d: 1.6978e-05 Loss_e: 1.5306e-05 | Loss_b: 6.4137e-06\n",
      "Step: NaN | Loss: 6.3396e-07 | Loss_d: 1.7070e-05 Loss_e: 1.4820e-05 | Loss_b: 6.0931e-06\n",
      "Step: NaN | Loss: 6.3353e-07 | Loss_d: 1.7034e-05 Loss_e: 1.4812e-05 | Loss_b: 6.1119e-06\n",
      "Step: NaN | Loss: 6.3567e-07 | Loss_d: 1.6976e-05 Loss_e: 1.4822e-05 | Loss_b: 6.2873e-06\n",
      "Step: NaN | Loss: 6.3347e-07 | Loss_d: 1.7015e-05 Loss_e: 1.4810e-05 | Loss_b: 6.1289e-06\n",
      "Step: NaN | Loss: 6.3318e-07 | Loss_d: 1.7012e-05 Loss_e: 1.4787e-05 | Loss_b: 6.1374e-06\n",
      "Step: NaN | Loss: 6.3609e-07 | Loss_d: 1.7032e-05 Loss_e: 1.4727e-05 | Loss_b: 6.3517e-06\n",
      "Step: NaN | Loss: 6.3318e-07 | Loss_d: 1.7012e-05 Loss_e: 1.4783e-05 | Loss_b: 6.1416e-06\n",
      "Step: NaN | Loss: 6.3288e-07 | Loss_d: 1.7010e-05 Loss_e: 1.4770e-05 | Loss_b: 6.1390e-06\n",
      "Step: NaN | Loss: 6.3329e-07 | Loss_d: 1.7016e-05 Loss_e: 1.4760e-05 | Loss_b: 6.1679e-06\n",
      "Step: NaN | Loss: 6.3274e-07 | Loss_d: 1.7009e-05 Loss_e: 1.4759e-05 | Loss_b: 6.1422e-06\n",
      "Step: NaN | Loss: 6.3237e-07 | Loss_d: 1.7003e-05 Loss_e: 1.4748e-05 | Loss_b: 6.1371e-06\n",
      "Step: NaN | Loss: 6.3117e-07 | Loss_d: 1.6985e-05 Loss_e: 1.4708e-05 | Loss_b: 6.1228e-06\n",
      "Step: NaN | Loss: 6.3101e-07 | Loss_d: 1.7000e-05 Loss_e: 1.4606e-05 | Loss_b: 6.2007e-06\n",
      "Step: NaN | Loss: 6.2989e-07 | Loss_d: 1.6970e-05 Loss_e: 1.4636e-05 | Loss_b: 6.1335e-06\n",
      "Step: NaN | Loss: 6.2945e-07 | Loss_d: 1.6931e-05 Loss_e: 1.4666e-05 | Loss_b: 6.1156e-06\n",
      "Step: NaN | Loss: 6.2932e-07 | Loss_d: 1.6943e-05 Loss_e: 1.4654e-05 | Loss_b: 6.1086e-06\n",
      "Step: NaN | Loss: 6.2911e-07 | Loss_d: 1.6938e-05 Loss_e: 1.4644e-05 | Loss_b: 6.1105e-06\n",
      "Step: NaN | Loss: 6.2934e-07 | Loss_d: 1.6925e-05 Loss_e: 1.4624e-05 | Loss_b: 6.1573e-06\n",
      "Step: NaN | Loss: 6.2899e-07 | Loss_d: 1.6932e-05 Loss_e: 1.4633e-05 | Loss_b: 6.1201e-06\n",
      "Step: NaN | Loss: 6.2845e-07 | Loss_d: 1.6901e-05 Loss_e: 1.4632e-05 | Loss_b: 6.1199e-06\n",
      "Step: NaN | Loss: 6.2672e-07 | Loss_d: 1.6783e-05 Loss_e: 1.4636e-05 | Loss_b: 6.1301e-06\n",
      "Step: NaN | Loss: 6.2874e-07 | Loss_d: 1.6370e-05 Loss_e: 1.4859e-05 | Loss_b: 6.4419e-06\n",
      "Step: NaN | Loss: 6.2542e-07 | Loss_d: 1.6588e-05 Loss_e: 1.4682e-05 | Loss_b: 6.2019e-06\n",
      "Step: NaN | Loss: 6.2378e-07 | Loss_d: 1.6492e-05 Loss_e: 1.4695e-05 | Loss_b: 6.1862e-06\n",
      "Step: NaN | Loss: 6.2378e-07 | Loss_d: 1.6494e-05 Loss_e: 1.4694e-05 | Loss_b: 6.1855e-06\n",
      "Step: NaN | Loss: 6.2318e-07 | Loss_d: 1.6471e-05 Loss_e: 1.4685e-05 | Loss_b: 6.1814e-06\n",
      "Step: NaN | Loss: 6.2505e-07 | Loss_d: 1.6394e-05 Loss_e: 1.4691e-05 | Loss_b: 6.3640e-06\n",
      "Step: NaN | Loss: 6.2300e-07 | Loss_d: 1.6451e-05 Loss_e: 1.4681e-05 | Loss_b: 6.1947e-06\n",
      "Step: NaN | Loss: 6.2226e-07 | Loss_d: 1.6422e-05 Loss_e: 1.4673e-05 | Loss_b: 6.1874e-06\n",
      "Step: NaN | Loss: 6.2266e-07 | Loss_d: 1.6326e-05 Loss_e: 1.4711e-05 | Loss_b: 6.2692e-06\n",
      "Step: NaN | Loss: 6.2177e-07 | Loss_d: 1.6377e-05 Loss_e: 1.4676e-05 | Loss_b: 6.1998e-06\n",
      "Step: NaN | Loss: 6.2107e-07 | Loss_d: 1.6324e-05 Loss_e: 1.4688e-05 | Loss_b: 6.1988e-06\n",
      "Step: NaN | Loss: 6.2471e-07 | Loss_d: 1.6166e-05 Loss_e: 1.4784e-05 | Loss_b: 6.4798e-06\n",
      "Step: NaN | Loss: 6.2094e-07 | Loss_d: 1.6296e-05 Loss_e: 1.4697e-05 | Loss_b: 6.2103e-06\n",
      "Step: NaN | Loss: 6.2017e-07 | Loss_d: 1.6292e-05 Loss_e: 1.4660e-05 | Loss_b: 6.2045e-06\n",
      "Step: NaN | Loss: 6.2189e-07 | Loss_d: 1.6342e-05 Loss_e: 1.4595e-05 | Loss_b: 6.3235e-06\n",
      "Step: NaN | Loss: 6.1986e-07 | Loss_d: 1.6295e-05 Loss_e: 1.4629e-05 | Loss_b: 6.2146e-06\n",
      "Step: NaN | Loss: 6.1997e-07 | Loss_d: 1.6269e-05 Loss_e: 1.4618e-05 | Loss_b: 6.2571e-06\n",
      "Step: NaN | Loss: 6.1935e-07 | Loss_d: 1.6277e-05 Loss_e: 1.4616e-05 | Loss_b: 6.2149e-06\n",
      "Step: NaN | Loss: 6.1902e-07 | Loss_d: 1.6281e-05 Loss_e: 1.4609e-05 | Loss_b: 6.1981e-06\n",
      "Step: NaN | Loss: 6.2037e-07 | Loss_d: 1.6323e-05 Loss_e: 1.4670e-05 | Loss_b: 6.1756e-06\n",
      "Step: NaN | Loss: 6.1895e-07 | Loss_d: 1.6286e-05 Loss_e: 1.4609e-05 | Loss_b: 6.1883e-06\n",
      "Step: NaN | Loss: 6.1854e-07 | Loss_d: 1.6279e-05 Loss_e: 1.4612e-05 | Loss_b: 6.1683e-06\n",
      "Step: NaN | Loss: 6.1799e-07 | Loss_d: 1.6282e-05 Loss_e: 1.4630e-05 | Loss_b: 6.1149e-06\n",
      "Step: NaN | Loss: 6.1797e-07 | Loss_d: 1.6278e-05 Loss_e: 1.4626e-05 | Loss_b: 6.1214e-06\n",
      "Step: NaN | Loss: 6.1793e-07 | Loss_d: 1.6345e-05 Loss_e: 1.4602e-05 | Loss_b: 6.0757e-06\n",
      "Step: NaN | Loss: 6.1769e-07 | Loss_d: 1.6311e-05 Loss_e: 1.4612e-05 | Loss_b: 6.0855e-06\n",
      "Step: NaN | Loss: 6.1757e-07 | Loss_d: 1.6321e-05 Loss_e: 1.4603e-05 | Loss_b: 6.0780e-06\n",
      "Step: NaN | Loss: 6.1734e-07 | Loss_d: 1.6365e-05 Loss_e: 1.4568e-05 | Loss_b: 6.0545e-06\n",
      "Step: NaN | Loss: 6.1735e-07 | Loss_d: 1.6364e-05 Loss_e: 1.4569e-05 | Loss_b: 6.0552e-06\n",
      "Step: NaN | Loss: 6.1676e-07 | Loss_d: 1.6335e-05 Loss_e: 1.4578e-05 | Loss_b: 6.0393e-06\n",
      "Step: NaN | Loss: 6.1894e-07 | Loss_d: 1.6250e-05 Loss_e: 1.4684e-05 | Loss_b: 6.1497e-06\n",
      "Step: NaN | Loss: 6.1663e-07 | Loss_d: 1.6315e-05 Loss_e: 1.4590e-05 | Loss_b: 6.0396e-06\n",
      "Step: NaN | Loss: 6.1611e-07 | Loss_d: 1.6309e-05 Loss_e: 1.4565e-05 | Loss_b: 6.0393e-06\n",
      "Step: NaN | Loss: 6.1453e-07 | Loss_d: 1.6295e-05 Loss_e: 1.4473e-05 | Loss_b: 6.0510e-06\n",
      "Step: NaN | Loss: 6.1926e-07 | Loss_d: 1.6430e-05 Loss_e: 1.4220e-05 | Loss_b: 6.4531e-06\n",
      "Step: NaN | Loss: 6.1372e-07 | Loss_d: 1.6297e-05 Loss_e: 1.4369e-05 | Loss_b: 6.1044e-06\n",
      "Step: NaN | Loss: 6.1318e-07 | Loss_d: 1.6253e-05 Loss_e: 1.4337e-05 | Loss_b: 6.1479e-06\n",
      "Step: NaN | Loss: 6.1305e-07 | Loss_d: 1.6265e-05 Loss_e: 1.4344e-05 | Loss_b: 6.1222e-06\n",
      "Step: NaN | Loss: 6.1256e-07 | Loss_d: 1.6265e-05 Loss_e: 1.4326e-05 | Loss_b: 6.1109e-06\n",
      "Step: NaN | Loss: 6.1411e-07 | Loss_d: 1.6291e-05 Loss_e: 1.4316e-05 | Loss_b: 6.1866e-06\n",
      "Step: NaN | Loss: 6.1242e-07 | Loss_d: 1.6267e-05 Loss_e: 1.4314e-05 | Loss_b: 6.1111e-06\n",
      "Step: NaN | Loss: 6.1209e-07 | Loss_d: 1.6280e-05 Loss_e: 1.4298e-05 | Loss_b: 6.0950e-06\n",
      "Step: NaN | Loss: 6.1160e-07 | Loss_d: 1.6337e-05 Loss_e: 1.4249e-05 | Loss_b: 6.0575e-06\n",
      "Step: NaN | Loss: 6.1158e-07 | Loss_d: 1.6333e-05 Loss_e: 1.4251e-05 | Loss_b: 6.0583e-06\n",
      "Step: NaN | Loss: 6.1066e-07 | Loss_d: 1.6301e-05 Loss_e: 1.4249e-05 | Loss_b: 6.0368e-06\n",
      "Step: NaN | Loss: 6.1447e-07 | Loss_d: 1.6262e-05 Loss_e: 1.4326e-05 | Loss_b: 6.2283e-06\n",
      "Step: NaN | Loss: 6.1047e-07 | Loss_d: 1.6284e-05 Loss_e: 1.4253e-05 | Loss_b: 6.0385e-06\n",
      "Step: NaN | Loss: 6.0937e-07 | Loss_d: 1.6246e-05 Loss_e: 1.4233e-05 | Loss_b: 6.0306e-06\n",
      "Step: NaN | Loss: 6.0828e-07 | Loss_d: 1.6132e-05 Loss_e: 1.4185e-05 | Loss_b: 6.1272e-06\n",
      "Step: NaN | Loss: 6.0806e-07 | Loss_d: 1.6160e-05 Loss_e: 1.4194e-05 | Loss_b: 6.0780e-06\n",
      "Step: NaN | Loss: 6.0625e-07 | Loss_d: 1.5939e-05 Loss_e: 1.4232e-05 | Loss_b: 6.1523e-06\n",
      "Step: NaN | Loss: 6.3307e-07 | Loss_d: 1.5666e-05 Loss_e: 1.4776e-05 | Loss_b: 7.4885e-06\n",
      "Step: NaN | Loss: 6.0624e-07 | Loss_d: 1.5929e-05 Loss_e: 1.4235e-05 | Loss_b: 6.1585e-06\n",
      "Step: NaN | Loss: 6.0580e-07 | Loss_d: 1.5918e-05 Loss_e: 1.4219e-05 | Loss_b: 6.1592e-06\n",
      "Step: NaN | Loss: 6.0721e-07 | Loss_d: 1.5907e-05 Loss_e: 1.4188e-05 | Loss_b: 6.2846e-06\n",
      "Step: NaN | Loss: 6.0569e-07 | Loss_d: 1.5911e-05 Loss_e: 1.4208e-05 | Loss_b: 6.1710e-06\n",
      "Step: NaN | Loss: 6.0550e-07 | Loss_d: 1.5907e-05 Loss_e: 1.4204e-05 | Loss_b: 6.1667e-06\n",
      "Step: NaN | Loss: 6.0506e-07 | Loss_d: 1.5893e-05 Loss_e: 1.4191e-05 | Loss_b: 6.1677e-06\n",
      "Step: NaN | Loss: 6.0860e-07 | Loss_d: 1.5851e-05 Loss_e: 1.4161e-05 | Loss_b: 6.4520e-06\n",
      "Step: NaN | Loss: 6.0496e-07 | Loss_d: 1.5884e-05 Loss_e: 1.4183e-05 | Loss_b: 6.1781e-06\n",
      "Step: NaN | Loss: 6.0409e-07 | Loss_d: 1.5853e-05 Loss_e: 1.4176e-05 | Loss_b: 6.1644e-06\n",
      "Step: NaN | Loss: 6.0265e-07 | Loss_d: 1.5742e-05 Loss_e: 1.4179e-05 | Loss_b: 6.1860e-06\n",
      "Step: NaN | Loss: 6.0263e-07 | Loss_d: 1.5747e-05 Loss_e: 1.4178e-05 | Loss_b: 6.1822e-06\n",
      "Step: NaN | Loss: 6.1037e-07 | Loss_d: 1.5505e-05 Loss_e: 1.4386e-05 | Loss_b: 6.6792e-06\n",
      "Step: NaN | Loss: 6.0204e-07 | Loss_d: 1.5679e-05 Loss_e: 1.4198e-05 | Loss_b: 6.1938e-06\n",
      "Step: NaN | Loss: 6.0132e-07 | Loss_d: 1.5650e-05 Loss_e: 1.4201e-05 | Loss_b: 6.1761e-06\n",
      "Step: NaN | Loss: 6.0207e-07 | Loss_d: 1.5593e-05 Loss_e: 1.4258e-05 | Loss_b: 6.2211e-06\n",
      "Step: NaN | Loss: 6.0093e-07 | Loss_d: 1.5618e-05 Loss_e: 1.4214e-05 | Loss_b: 6.1715e-06\n",
      "Step: NaN | Loss: 6.0047e-07 | Loss_d: 1.5630e-05 Loss_e: 1.4217e-05 | Loss_b: 6.1299e-06\n",
      "Step: NaN | Loss: 6.0096e-07 | Loss_d: 1.5712e-05 Loss_e: 1.4255e-05 | Loss_b: 6.0395e-06\n",
      "Step: NaN | Loss: 6.0023e-07 | Loss_d: 1.5653e-05 Loss_e: 1.4227e-05 | Loss_b: 6.0830e-06\n",
      "Step: NaN | Loss: 5.9999e-07 | Loss_d: 1.5659e-05 Loss_e: 1.4225e-05 | Loss_b: 6.0640e-06\n",
      "Step: NaN | Loss: 5.9948e-07 | Loss_d: 1.5683e-05 Loss_e: 1.4228e-05 | Loss_b: 6.0056e-06\n",
      "Step: NaN | Loss: 6.0794e-07 | Loss_d: 1.5854e-05 Loss_e: 1.4447e-05 | Loss_b: 6.1238e-06\n",
      "Step: NaN | Loss: 5.9947e-07 | Loss_d: 1.5688e-05 Loss_e: 1.4230e-05 | Loss_b: 5.9980e-06\n",
      "Step: NaN | Loss: 5.9892e-07 | Loss_d: 1.5677e-05 Loss_e: 1.4224e-05 | Loss_b: 5.9833e-06\n",
      "Step: NaN | Loss: 6.0444e-07 | Loss_d: 1.5707e-05 Loss_e: 1.4304e-05 | Loss_b: 6.2038e-06\n",
      "Step: NaN | Loss: 5.9890e-07 | Loss_d: 1.5675e-05 Loss_e: 1.4224e-05 | Loss_b: 5.9841e-06\n",
      "Step: NaN | Loss: 5.9819e-07 | Loss_d: 1.5602e-05 Loss_e: 1.4215e-05 | Loss_b: 6.0233e-06\n",
      "Step: NaN | Loss: 5.9817e-07 | Loss_d: 1.5608e-05 Loss_e: 1.4215e-05 | Loss_b: 6.0161e-06\n",
      "Step: NaN | Loss: 5.9768e-07 | Loss_d: 1.5626e-05 Loss_e: 1.4189e-05 | Loss_b: 5.9942e-06\n",
      "Step: NaN | Loss: 5.9774e-07 | Loss_d: 1.5731e-05 Loss_e: 1.4114e-05 | Loss_b: 5.9681e-06\n",
      "Step: NaN | Loss: 5.9731e-07 | Loss_d: 1.5671e-05 Loss_e: 1.4147e-05 | Loss_b: 5.9694e-06\n",
      "Step: NaN | Loss: 5.9661e-07 | Loss_d: 1.5654e-05 Loss_e: 1.4132e-05 | Loss_b: 5.9587e-06\n",
      "Step: NaN | Loss: 5.9744e-07 | Loss_d: 1.5617e-05 Loss_e: 1.4104e-05 | Loss_b: 6.0737e-06\n",
      "Step: NaN | Loss: 5.9621e-07 | Loss_d: 1.5635e-05 Loss_e: 1.4117e-05 | Loss_b: 5.9696e-06\n",
      "Step: NaN | Loss: 5.9561e-07 | Loss_d: 1.5612e-05 Loss_e: 1.4108e-05 | Loss_b: 5.9650e-06\n",
      "Step: NaN | Loss: 5.9372e-07 | Loss_d: 1.5528e-05 Loss_e: 1.4085e-05 | Loss_b: 5.9594e-06\n",
      "Step: NaN | Loss: 5.9719e-07 | Loss_d: 1.5248e-05 Loss_e: 1.4264e-05 | Loss_b: 6.2680e-06\n",
      "Step: NaN | Loss: 5.9249e-07 | Loss_d: 1.5406e-05 Loss_e: 1.4091e-05 | Loss_b: 6.0012e-06\n",
      "Step: NaN | Loss: 5.9123e-07 | Loss_d: 1.5330e-05 Loss_e: 1.4120e-05 | Loss_b: 5.9742e-06\n",
      "Step: NaN | Loss: 5.9104e-07 | Loss_d: 1.5341e-05 Loss_e: 1.4105e-05 | Loss_b: 5.9659e-06\n",
      "Step: NaN | Loss: 5.9071e-07 | Loss_d: 1.5329e-05 Loss_e: 1.4103e-05 | Loss_b: 5.9604e-06\n",
      "Step: NaN | Loss: 5.9063e-07 | Loss_d: 1.5331e-05 Loss_e: 1.4102e-05 | Loss_b: 5.9537e-06\n",
      "Step: NaN | Loss: 5.9050e-07 | Loss_d: 1.5343e-05 Loss_e: 1.4083e-05 | Loss_b: 5.9533e-06\n",
      "Step: NaN | Loss: 5.9069e-07 | Loss_d: 1.5398e-05 Loss_e: 1.4016e-05 | Loss_b: 5.9773e-06\n",
      "Step: NaN | Loss: 5.9045e-07 | Loss_d: 1.5360e-05 Loss_e: 1.4059e-05 | Loss_b: 5.9577e-06\n",
      "Step: NaN | Loss: 5.9012e-07 | Loss_d: 1.5360e-05 Loss_e: 1.4050e-05 | Loss_b: 5.9472e-06\n",
      "Step: NaN | Loss: 5.8926e-07 | Loss_d: 1.5365e-05 Loss_e: 1.4019e-05 | Loss_b: 5.9210e-06\n",
      "Step: NaN | Loss: 5.9592e-07 | Loss_d: 1.5457e-05 Loss_e: 1.4059e-05 | Loss_b: 6.1878e-06\n",
      "Step: NaN | Loss: 5.8909e-07 | Loss_d: 1.5371e-05 Loss_e: 1.4005e-05 | Loss_b: 5.9186e-06\n",
      "Step: NaN | Loss: 5.8841e-07 | Loss_d: 1.5436e-05 Loss_e: 1.3962e-05 | Loss_b: 5.8555e-06\n",
      "Step: NaN | Loss: 5.9403e-07 | Loss_d: 1.5836e-05 Loss_e: 1.3938e-05 | Loss_b: 5.8171e-06\n",
      "Step: NaN | Loss: 5.8838e-07 | Loss_d: 1.5458e-05 Loss_e: 1.3952e-05 | Loss_b: 5.8419e-06\n",
      "Step: NaN | Loss: 5.8784e-07 | Loss_d: 1.5443e-05 Loss_e: 1.3944e-05 | Loss_b: 5.8329e-06\n",
      "Step: NaN | Loss: 5.9595e-07 | Loss_d: 1.5461e-05 Loss_e: 1.4025e-05 | Loss_b: 6.2202e-06\n",
      "Step: NaN | Loss: 5.8784e-07 | Loss_d: 1.5443e-05 Loss_e: 1.3944e-05 | Loss_b: 5.8335e-06\n",
      " Total iterations: 4908\n"
     ]
    }
   ],
   "source": [
    "# set the training iteration\n",
    "epoch2 = 5000\n",
    "# re-sample the data and collocation points\n",
    "data_l = dataf_l(key_lbfgs[1])\n",
    "\n",
    "# training with L-bfgs\n",
    "trained_params2, loss2 = lbfgs_optimizer(NN_loss, trained_params, data_l, epoch2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a8718d6-be29-4dbb-bd9a-34ccded8bd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f885f09e-ebd1-4703-be06-1876d596a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets make a prediction\n",
    "from equations.gradients import *\n",
    "f_u = lambda x: pred_u(trained_params2, x)\n",
    "f_gu = lambda x: vectgrad(f_u, x)[0][:, 0:10]\n",
    "f_eqn = lambda x: gov_eqn(f_u, x, info)\n",
    "\n",
    "#x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45809a1e-c355-46d0-a982-b4b537ebdfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = df_norm[['x','z']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24f5156b-e106-4787-a7af-6d9fac1518d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_rho_pmu = f_u(x_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8caa5410-68a1-4a5e-a6df-53349e6b96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the partition number\n",
    "nsp = 4\n",
    "# separate input into different partition to avoid GPU memory limit\n",
    "x_psp = jnp.array_split(x_pred, nsp)\n",
    "idxsp = jnp.arange(nsp).tolist()\n",
    "# calculate the derivative of network output at the velocity-data positions\n",
    "du_list = tree_map(lambda x: f_gu(x_psp[x]), idxsp)\n",
    "# calculate the associated equation residue of the trained network\n",
    "eqnterm_list = tree_map(lambda x: f_eqn(x_psp[x]), idxsp)\n",
    "eqn_list = tree_map(lambda x: eqnterm_list[x][0], idxsp)\n",
    "term_list = tree_map(lambda x: eqnterm_list[x][1], idxsp)\n",
    "# combine the sub-group list into a long array\n",
    "duw_rho_pmu = jnp.vstack(du_list)\n",
    "eqn = jnp.vstack(eqn_list)\n",
    "term = jnp.vstack(term_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae477c1b-f3d4-467d-9e36-7eea16a82d8c",
   "metadata": {},
   "source": [
    "!!! Loss function needs to output terms! Important for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42a60e43-e439-46e3-b9a1-f04d2d38b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for i,key in enumerate(['u','w','rho','p','mu']):\n",
    "    results[f'{key}_g'] = df_filtered[key].values\n",
    "    results[f'{key}_p'] = uw_rho_pmu[:,i:i+1]*info[f'{key}_range'] + info[f'{key}_mean']\n",
    "results['x'] = df_filtered['x'].values\n",
    "results['z'] = df_filtered['z'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580f94e-8e68-48a4-9549-165ae026cdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
